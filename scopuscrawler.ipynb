{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kartik-kumarr/ScopusCrawler/blob/main/scopuscrawler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15nCjUV5uhE6"
      },
      "source": [
        "## Scopus crawler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Oz_2lDotxICj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# from google.colab import userdata\n",
        "\n",
        "# apiKey = userdata.get('apiKey')\n",
        "# insttoken = userdata.get('insttoken')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbDinDpJxSuB",
        "outputId": "67b0418d-a83a-41b6-fc2b-f74f44c99002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 25 entries from start=0 | Unique total so far: 25\n",
            "Fetched 25 entries from start=25 | Unique total so far: 50\n",
            "Fetched 25 entries from start=50 | Unique total so far: 75\n",
            "Fetched 25 entries from start=75 | Unique total so far: 100\n",
            "Fetched 25 entries from start=100 | Unique total so far: 125\n",
            "Fetched 25 entries from start=125 | Unique total so far: 150\n",
            "Fetched 25 entries from start=150 | Unique total so far: 175\n",
            "Fetched 25 entries from start=175 | Unique total so far: 200\n",
            "Fetched 25 entries from start=200 | Unique total so far: 225\n",
            "Fetched 25 entries from start=225 | Unique total so far: 250\n",
            "Fetched 25 entries from start=250 | Unique total so far: 275\n",
            "Fetched 25 entries from start=275 | Unique total so far: 300\n",
            "Fetched 25 entries from start=300 | Unique total so far: 325\n",
            "Fetched 25 entries from start=325 | Unique total so far: 350\n",
            "Fetched 25 entries from start=350 | Unique total so far: 375\n",
            "Fetched 25 entries from start=375 | Unique total so far: 400\n",
            "Fetched 25 entries from start=400 | Unique total so far: 425\n",
            "Fetched 25 entries from start=425 | Unique total so far: 450\n",
            "Fetched 25 entries from start=450 | Unique total so far: 475\n",
            "Fetched 25 entries from start=475 | Unique total so far: 500\n",
            "Fetched 25 entries from start=500 | Unique total so far: 525\n",
            "Fetched 25 entries from start=525 | Unique total so far: 550\n",
            "Fetched 25 entries from start=550 | Unique total so far: 575\n",
            "Fetched 25 entries from start=575 | Unique total so far: 600\n",
            "Fetched 25 entries from start=600 | Unique total so far: 625\n",
            "Fetched 25 entries from start=625 | Unique total so far: 650\n",
            "Fetched 25 entries from start=650 | Unique total so far: 675\n",
            "Fetched 25 entries from start=675 | Unique total so far: 700\n",
            "Fetched 25 entries from start=700 | Unique total so far: 725\n",
            "Fetched 25 entries from start=725 | Unique total so far: 750\n",
            "Fetched 25 entries from start=750 | Unique total so far: 775\n",
            "Fetched 25 entries from start=775 | Unique total so far: 800\n",
            "Fetched 25 entries from start=800 | Unique total so far: 825\n",
            "Fetched 25 entries from start=825 | Unique total so far: 850\n",
            "Fetched 25 entries from start=850 | Unique total so far: 875\n",
            "Fetched 25 entries from start=875 | Unique total so far: 900\n",
            "Fetched 25 entries from start=900 | Unique total so far: 925\n",
            "Fetched 7 entries from start=925 | Unique total so far: 932\n",
            "Fetched 0 entries from start=950 | Unique total so far: 932\n",
            "Total unique entries fetched: 932\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "url = 'https://api.elsevier.com/content/search/scopus'\n",
        "\n",
        "headers = {\n",
        "    'X-ELS-APIKey': apiKey,\n",
        "    'X-ELS-Insttoken': insttoken\n",
        "}\n",
        "\n",
        "query = (\n",
        "    '(\"awkward posture\" OR \"awkward pose\" OR \"awkward posture detection\" OR '\n",
        "    '\"awkward pose classification\" OR \"posture analysis\" OR \"postural assessment\") '\n",
        "    'AND (\"computer vision\" OR \"vision-based system\" OR \"pose estimation\" OR '\n",
        "    '\"human pose estimation\" OR \"deep learning\" OR \"machine learning\" OR '\n",
        "    '\"convolutional neural network\" OR \"transformer model\") '\n",
        "    'AND (\"ergonomics\" OR \"occupational health\" OR \"workplace safety\" OR '\n",
        "    '\"musculoskeletal disorder\" OR \"work-related musculoskeletal disorder\") '\n",
        "    'AND NOT (\"animal model\" OR \"veterinary\" OR \"non-human\" OR \"robotic pose\")'\n",
        ")\n",
        "\n",
        "\n",
        "all_results = []\n",
        "unique_ids = set()\n",
        "count = 25\n",
        "total_results = 4000\n",
        "\n",
        "for start in range(0, total_results, count):\n",
        "    prevUn = len(all_results)\n",
        "    params = {\n",
        "        'query': query,\n",
        "        'count': count,\n",
        "        'start': start,\n",
        "        'view': 'COMPLETE'\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, headers=headers, params=params)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error at start={start}: {response.status_code}\")\n",
        "        break\n",
        "\n",
        "    data = response.json()\n",
        "    entries = data.get('search-results', {}).get('entry', [])\n",
        "\n",
        "    for entry in entries:\n",
        "        eid = entry.get('eid')\n",
        "        if eid and eid not in unique_ids:\n",
        "            unique_ids.add(eid)\n",
        "            all_results.append(entry)\n",
        "\n",
        "    currUn = len(all_results)\n",
        "    print(f\"Fetched {len(entries)} entries from start={start} | Unique total so far: {len(all_results)}\")\n",
        "    if prevUn==currUn:\n",
        "      break\n",
        "\n",
        "    time.sleep(1)\n",
        "\n",
        "print(f\"Total unique entries fetched: {len(all_results)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sdhdn5qPS-bw",
        "outputId": "289fb2a6-5a91-4bd7-be54-5a09c7029f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Posture analysis during tooth extraction\n",
            "Authors: Fukushima T.\n",
            "Abstract: Introduction: Tooth extraction is one of the clinical internship requirements in Japan. Human posture during tooth extraction is important since poor posture can cause failure of the safe operation and musculoskeletal injuries. Only a few studies aimed to evaluate the posture, but most of them used manual or complex measurement methods which can lead to some inconvenient problems such as subjective biases, quantitativeness, and device availability. Thanks to the recent advancement of computer vision and technology, pose estimation has been widely used for kinematic analysis. However, none of the research has been used for posture analysis during tooth extraction. Aim: Therefore, this research aims to analyze posture kinematics during tooth extraction using pose estimation and find key kinematic variables for tooth extraction. Method: All participants were grouped into three; dental students, young dentists, and experienced dentists. They were asked to perform tooth extraction on a tooth extraction simulator while being video recorded. Pose estimation was used to extract joint locations on recorded videos. Joint angles of interest were calculated based on the extracted joint locations. Results: Right shoulder angles were significantly lower in the experienced dentists’ group than in other groups, Discussion: Which has been pointed out by other research as a crucial point. Conclusion: Although sample size is a main concern in this study, the result shows that pose estimation can be useful in posture analysis during tooth extraction.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Reliability of sitting posture between physical therapist video-based evaluation and SMART IMU system using rapid upper limb assessment (RULA)\n",
            "Authors: Tanthuwapathom R.\n",
            "Abstract: This study investigates the ergonomic assessment of sitting postures and the potential for work-related musculoskeletal disorders (WMSDs) in office environments by comparing traditional physical therapist evaluations with Inertial Measurement Unit (IMU) technology by determining the reliability and accuracy of sitting posture assessment using the rapid upper limb assessment (RULA) method. In this experiment, neck and body angle data is collected from twenty participants while sitting and working. The study aims to capture and compare the neck and trunk posture score based RULA protocol system to evaluate ergonomic risks. The findings revealed a strong correlation between the video-based evaluations by the physical therapist and the data obtained from the SMART IMU system, demonstrating the feasibility of using these combined approaches for ergonomic assessments. The results highlight the effectiveness of integrating traditional ergonomic assessment tools with modern IMU technology in comprehensively analyzing the ergonomic risks associated with prolonged sitting.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Estimating hip impact velocity and acceleration from video-captured falls using a pose estimation algorithm\n",
            "Authors: Michaels R.\n",
            "Abstract: Analyzing video footage of falls in older adults has emerged as an alternative to traditional lab studies. However, this approach is limited by the labor-intensive process of manually labeling body parts. To address this limitation, we aimed to validate the use of the AI-based pose estimation algorithm (OpenPose) in assessing the hip impact velocity and acceleration of video-captured falls. We analyzed 110 videos of 13 older adults (64.0 ± 5.9 years old) falling sideways in an experimental setting. By applying OpenPose to each video, we generated a time series of hip positions in the video, which were then analyzed using custom MATLAB code to calculate hip impact velocity and acceleration. These calculations were compared against ground truth measurements obtained from motion capture systems (VICON for hip impact velocity) and inertial measurement units (MC10 for hip impact acceleration). We examined the agreement between the ground truth and OpenPose measurements in terms of mean of absolute error (MAE), mean of absolute percentage error (MAPE), and bias (mean of error). Results showed that OpenPose had a good accuracy in estimating hip impact velocity with minimal bias (MAE: 0.17 ± 0.13 m/s, MAPE: 7.28 ± 5.21%; percent bias: − 1.27%). However, its estimation of hip impact acceleration (i.e., peak vertical hip acceleration at impact) showed poor accuracy (MAPE: 26.3 ± 19.4%), showing substantial underestimation in instances of high acceleration impacts (> 3.0 g). Further ANOVA analysis revealed OpenPose’s ability to discern significant differences in hip impact velocity and acceleration based on the movement response utilized during the fall (e.g., stick-like fall, tuck-and-roll, knee block). This is the first study to validate the use of a pose estimation algorithm for identifying the hip impact kinematics in video-captured falls among older adults. Future validation studies involving diverse camera settings, fall contexts, and biomechanical parameters are warranted to extend this support for using pose estimation algorithms in this field.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Scaffolding worker IMU time-series dataset for deep learning-based construction site behavior recognition\n",
            "Authors: Park M.\n",
            "Abstract: The construction industry is one of the most dangerous industries worldwide, and scaffold-related accidents are a significant concern. Despite the widespread use of scaffolds, the safety regulations pertaining to scaffolding remain among the most frequently violated, leading to a high frequency of accidents. Advancements in deep learning offer promising avenues for automating safety monitoring. However, the field is hindered by the lack of accessible datasets for training models in worker-behavior recognition. This study introduces the scaffolding worker inertial measurement unit (IMU) time-series (SWIT) dataset, which is designed to enrich the development of deep learning models for the automated recognition of construction worker behaviors. The SWIT dataset addresses the limitations of existing datasets by incorporating a wide range of hazardous behaviors, regulatory violations, and emergency situations specific to scaffolding. The dataset was developed through a rigorous process involving the analysis of sensor positions from previous studies, studies on abnormal behavior recognition, and scaffolding-safety regulations. It comprises ten categories of behaviors, including hazardous actions, near-miss incidents, and activities that may lead to musculoskeletal disorders. By providing a comprehensive collection of annotated time-series data from IMU sensors, this dataset aims to facilitate the development of robust deep learning models for automated worker-behavior recognition.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Assessment of active back-support exoskeleton on carpentry framing tasks: Muscle activity, range of motion, discomfort, and exertion\n",
            "Authors: Okunola A.\n",
            "Abstract: Despite efforts to reduce work-related musculoskeletal disorders in the construction industry, the challenge persists, particularly among construction trades like carpenters. This study assesses the effectiveness of an active back-support exoskeleton for reducing these disorders during carpentry framing tasks. The assessment encompasses various metrics, including muscle activity, range of motion, perceived discomfort, and perceived exertion. Sixteen participants were engaged in a simulated carpentry framing task, during which data was collected from both subjective evaluations using Borg CR-10 and CR-20 scales and objective measurements employing Electromyography and Inertial Measurement Units. The results are presented through a combination of descriptive and inferential statistics tests. The findings indicate a significant reduction in muscle activity when utilizing the active back-support exoskeleton, with reductions ranging from 16% to 54% across various subtasks. Notably, the right rectus femoris and the left erector spinae experienced more statistically significant reductions in muscle activity in most of the carpentry framing tasks. Dynamic time-warping similarity scores were used to validate the muscle activity results, which show consistency. The use of the exoskeleton also led to a decrease in the range of motion during assembly and nailing subtasks. While the perceived discomfort and exertion did not show statistical significance, there was a reduction in these metrics during exoskeleton-use. This study contributes to the expanding knowledge base on the suitability of exoskeletons in the construction industry. Importantly, it provides a valuable benchmark for evaluating the effectiveness of similar active exoskeletons within the construction sector.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: DanceFormer: Hybrid transformer model for real-time dance pose estimation and feedback\n",
            "Authors: Zhao H.\n",
            "Abstract: Dance pose estimation holds significant value in teaching, training, and performance within the dance domain. However, challenges such as multi-target tracking in complex dynamic scenes, real-time demands, and computational resource constraints have posed difficulties for traditional methods. This paper introduces DanceFormer, a Transformer-based model for dance pose estimation that integrates the Vision Transformer (ViT), Time Series Transformer (TST), and an edge computing layer to achieve deep fusion of multimodal features, enhancing accuracy and real-time feedback capabilities. Experiments on the AIST and DanceTrack datasets show DanceFormer achieves pose estimation accuracy (MPJPE) of 18.4 mm and 20.1 mm, and multi-object tracking accuracy (MOTA) of 92.3% and 89.5%, outperforming other models. The edge computing design reduces average latency to 35.2ms, providing robust real-time processing suitable for low-resource edge devices. DanceFormer offers an efficient, precise, and real-time solution for complex dance scenarios, with broad application potential in dance education and real-time motion analysis. Future work will focus on optimizing the edge computing module and enhancing model generalization through data augmentation and dataset diversification.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Voxel-Based 3D reconstruction and action recognition method for construction workers\n",
            "Authors: Zhang J.\n",
            "Abstract: Workers are critical yet unpredictable elements on construction sites, with their actions significantly impacting safety and productivity. Recognizing these actions is essential for improving efficiency, safety, and quality. Benefiting from the advantages of the voxel format in terms of universal representation, privacy protection and memory saving, a voxel-based method for action recognition was proposed. By transforming the image into a structured voxel, a lightweight 3D CNN, CVARnet (Construction worker Voxel Action Recognition network) was established. To verify the effectiveness of voxel and CVARnet, a dataset named Construction Action Voxel Classification (CAVC) was developed. The image was primarily sourced from the construction site and represented five types of typical actions. The proposed CVARnet achieved 86% ACC in a classification task, demonstrating efficient recognition capabilities for workers’ actions. This study presented a novel perspective with a voxel format, providing innovative insight for the action recognition task.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Validation of markerless vision-based motion capture for ergonomics risk assessment\n",
            "Authors: Bonakdar A.\n",
            "Abstract: Work-related musculoskeletal disorders impact millions annually, often due to awkward postures and heavy lifting. Vision-based markerless optical motion capture (ML-OMC) systems have gained attention as a possible solution for identifying ergonomic risks in workplace settings. However, their reliability remains unknown compared to marker-based optical motion capture (MB-OMC) and inertial measurement units (IMUs). This study reports on a comparative analysis of an ML-OMC against MB-OMC and IMUs and its suitability for joint reaction force estimation. Eight participants performed lifting, a task considered physically demanding among manual handling activities, while their joint angles were recorded using the three measurement systems, and joint reaction forces were determined using joint angle data and ground reaction forces through biomechanical modeling. Furthermore, postural ergonomic assessment scores were computed for the lifting initiation posture of the activity using data from the three systems and biomechanics experts’ inputs. The back angle obtained by ML-OMC exhibited a strong correlation (0.95) with both MB-OMC and IMUs, along with small RMSE values of 6.5° and 9.9° compared to the readouts from MB-OMC and IMUs, respectively. The L5-S1 joint reaction forces obtained by ML-OMC showed a high correlation (0.91 with MB-OMC and 0.85 with IMUs), and small RMSE and normalized RMSE values. Additionally, postural ergonomic assessment scores obtained from ML-OMC aligned with MB-OMC for 87 % of participants, showing significant consistency compared to the notable variation seen with expert-derived scores. These findings underscore the potential of ML-OMC as a dependable in-field ergonomic risk assessment tool for preventing work-related musculoskeletal disorders.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Evaluation of camera configurations of OpenPose-based 3D motion capture system for construction tasks\n",
            "Authors: Yang D.\n",
            "Abstract: This study investigated the optimal camera configurations for a markerless motion capture system utilizing the OpenPose algorithm to assess construction-related activities. By examining various configurations ranging from three to eight camera, tracking accuracy was evaluated for both stationary and dynamic tasks. Results indicated that increasing the number of cameras improved tracking precision, with configurations of seven cameras covering 270 degrees achieving a mean Euclidean distance below 40 mm, which satisfies the acceptable level for ergonomic motion analysis. Furthermore, the findings demonstrated that even configurations with fewer cameras, such as three cameras covering 90 degrees, were effective for tracking specific joints like the ankles, suggesting practical applications in targeted monitoring. This research offers valuable insights into how different camera configurations influence tracking accuracy in construction environments, contributing to improved ergonomic assessments and worker safety.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic Risk Mitigation through Workforce Planning for Construction Projects\n",
            "Authors: Tao Y.\n",
            "Abstract: Construction workers are facing significant ergonomic risks, which negatively affect their health, safety, and productivity, and therefore it is essential to develop effective and applicable risk control measures. In addition to instrument-based risk control methods, which have received the most attention, another easy-to-implement strategy is to consider ergonomic risks in workforce planning to balance physical stress and rest allowance. This study was aimed at mitigating ergonomic risks through workforce planning for construction projects. First, the ergonomic risk can be measured by considering task-specific and personalized features together with processing time. On this basis, a multiobjective mixed-integer programming model with ergonomic considerations was developed. Specifically, ergonomic constraints limit the cumulative ergonomic risk for each worker, and the objective is to minimize overall ergonomic risks across all workers. Small-scale basic examples were used to compare the different strategies for how to take ergonomic risks into account. Then a real-world case was conducted to demonstrate the effectiveness and practicability of the proposed method. Compared with the default plan proposed by the onsite superintendents, a 5% decrease in total ergonomic risks and a 41% decrease in max individual cumulative risk was achieved. The method is easy to adopt compared with instrument-based intervention systems, and is flexible to be adjusted according to real-life situations, contributing to sustainable workforce development in the construction sector.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Effectiveness of gamified intelligent tutoring in physical education through the lens of self-determination theory\n",
            "Authors: Hsia L.H.\n",
            "Abstract: Scholars have recommended the application of an intelligent tutoring and instant feedback system (ITIFS) to enhance students' motor skills performance by automatically evaluating their learning performance and providing personalized guidance and feedback. However, solely providing personalized evaluation and feedback may not necessarily attract students' active and sustained engagement in practice. In particular, it is difficult to arouse students' enthusiasm to participate in sports that require repetitive practice to improve their physical abilities and which involve less interaction with the environment and their opponents. To address this issue, grounded in self-determination theory (SDT), the present study integrated a gamification mechanism that aligned with students' psychological needs into an ITIFS. The gamification features included avatars, achievements (personal ratings and rankings), badges, levels, and social networks (group ratings and rankings). It aimed to attract students to engage continuously in practice, and to address the issue of students lacking motivation to engage in repeated practice. To investigate the effectiveness of the proposed method, a quasi-experimental research design was adopted, and the collected data were analyzed with analysis of covariance (ANCOVA), independent samples t tests and qualitative coding. Four classes of university students participated in the experiment. Two classes (N = 80) were the experimental group adopting the SDT-based gamified ITIFS (G-ITIFS), and the other two classes (N = 76) were the control group adopting the conventional ITIFS (C-ITIFS). The findings indicated that the experimental group showed significantly better yoga skills performance and learning engagement compared to the control group. Feedback from students also revealed that the gamification mechanism provided more excitement and had positive impacts, satisfying students’ psychological needs and reinforcing the learning benefits. The findings of the present study revealed that, from the perspective of SDT, incorporating gamification elements into the development of ITIFS could be a promising approach for physical education. Therefore, it is strongly encouraged that educators promote such a gamified intelligent tutoring mode in physical education curriculums as it is crucial to the development of students' physical and mental health, as well as to their enthusiasm to participate in sports.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic workplace design based on real-time integration between virtual and augmented realities\n",
            "Authors: Chu C.H.\n",
            "Abstract: Virtual Reality (VR) and Augmented Reality (AR) technologies have been separately applied to enhance a wide range of design and manufacturing operations across various industries. Most VR applications are primarily focused on product prototyping and personnel training, whereas AR is commonly used to facilitate manual operations in manufacturing such as assembly and maintenance tasks. This study proposes a novel concept of real-time integration between VR and AR scenes to leverage their individual advantages. A prototyping system is implemented based on this concept to enhance workplace ergonomics in the overhead assembly of car bodies. An operator undergoes the assembly training at a virtual workstation within VR, while an ergonomics expert evaluates the operator's actions from a third-person viewpoint using AR. The expert can iteratively adjust the workstation setup, supported by automatic human posture recognition and biomechanical analysis, to reduce the risk of musculoskeletal injuries during the process. An exemplary case demonstrates the practical value of real-time collaborative applications between VR and AR in the context of human-centric smart manufacturing. A usability study is conducted to verify the prototyping system using both subjective and objective measures. Integrating various reality technologies serves as an effective approach to improving human well-being in the manufacturing environment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Occlusion-aware and jitter-rejection 3D video real-time pose estimation for construction workers\n",
            "Authors: Song B.\n",
            "Abstract: Video pose estimation is widely employed to monitor the activities of workers at construction sites. However, previous studies have often overlooked the challenges posed by complex occlusions and motion jitters, resulting in inaccurate or unrealistic postures that impact subsequent analysis. This paper presents a three-dimensional (3D) worker pose estimation pipeline to mitigate occlusions and jitters using on-site videos. Initially, YOLOv8 is adopted to rapidly extract two-dimensional (2D) skeletons from videos. Subsequently, a view-temporal fusion module is introduced comprising a heuristic multi-view fusion module and a motion smoothing module, designed to address occlusions and jitters, respectively. Finally, MotionBERT is employed to convert 2D skeletons into 3D skeletons. The proposed method achieves a mean per joint position error of 25.64 on the Human3.6 M dataset with 25 % fewer computations, running at 60 FPS. On-site experiments indicate that it was valuable for reconstructing 3D workers' postures from videos, facilitating safety monitoring at construction sites.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Vision-based postural balance assessment of sit-to-stand transitions performed by younger and older adults\n",
            "Authors: Lee C.H.\n",
            "Abstract: Background: The use of inertial measurement units (IMUs) in assessing fall risk is often limited by subject discomfort and challenges in data interpretation. Additionally, there is a scarcity of research on attitude estimation features. To address these issues, we explored novel features and representation methods in the context of sit-to-stand transitions. This study recorded sit-to-stand transition test data from three groups: community-dwelling elderly, elderly in day care centers (DCC), and college students, captured using mobile phone cameras. Method: We employed pose estimation technology to extract key point kinematic features from the video data and used 10-fold cross-validation to train a random forest classifier, mitigating the impact of individual differences. We trained classifiers with the top 5, 10, and 15 features, calculating the average area under the receiver operating characteristic curve (AUC) for each model to compare feature importance. Results: Our results indicated that elbow key point features, such as (KP08) mean Y, (KP08)RMS Y, (KP09) mean Y, and (KP09) RMS Y, are crucial for distinguishing between subject groups. Statistical tests further validated the significance of these features. The application of human pose estimation and key point signals shows promise for clinical postural balance screening. The identified features can be utilized to develop non-invasive tools for assessing postural instability risk, contributing to fall prevention efforts. Conclusion: This study lays the groundwork for integrating additional measurement modalities into sit-to-stand transition analysis to enhance clinical strategies.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Low-cost phone-based LiDAR scanning technology provides sub-centimeter accuracy when measuring the main dimensions of motor-manual tree felling cuts\n",
            "Authors: Borz S.A.\n",
            "Abstract: Motor-manual tree felling in one of the most important technical alternatives in timber harvesting. Commonly, it requires a sequence of cuts and may cause higher volume losses compared to mechanized tree felling. The wood lost depends also on the tree size, but accurate quantifications and their dependencies are difficult to establish since there is a limited ability to manually measure key dimensions and assimilate the tree bottom to parametric geometric features. Short-range LiDAR technology integrated in affordable mobile platforms has already been proved to produce reliable estimates on objects located in a limited space, and point cloud processing algorithms have been developed to compare two instances of the same object, potentially enabling the quantification of tree-level wood loss. However, volume loss estimates based on LiDAR scanning of tree bottoms are very sensitive to the accuracy of scans, while low-cost platforms may lack the capability to produce point clouds of an acceptable density at a reasonable distance. This study was setup to check to what extent proximal scanning by low-cost LiDAR platforms can provide accurate data to support the extraction and computation of volume loss by motor-manual tree felling. Eleven Norway spruce logs having a length of one meter and mid-diameters between 22 and 43 cm were used to make 63 notches by a chainsaw. The main dimensions of each notch were then measured manually to the nearest millimeter by a tape and used as reference data. These were the hinge width, depth of the bottom cut, depth of the top (inclined) cut and the notch height. Close-range (up to 50 cm) scans were taken on each notch by an iPhone 13 Pro Max platform using the freely available software 3D Scanner App. The resulted point clouds were imported to Cloud Compare software, where the same measurements were taken digitally and used as data for comparison. By the commonly used error metrics such as the bias (−0.73–0.10), mean absolute error (0.51–0.78) and root mean squared error (0.68–0.92), the differences between the two were in the sub-centimeter domain. Taken individually, all the measurements agreed well in a ± 2 cm range, with an obvious dominance in much lower ranges and no evident trends in variance related to the measurement size. These results are promising for the forest operations science and practice because they provide evidence on the fact that by low-cost close-range LiDAR scanning and point cloud processing one can get accurate estimations notch volume losses. In turn, this will provide the basis for leveraging the losses by considering the operational conditions, the used procedures and experience of the workers while supporting the attempts of quantifying and relating the losses to the mentioned factors.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Predicting postural risk level with computer vision and machine learning on multiple sources of images\n",
            "Authors: Doong S.H.\n",
            "Abstract: Postural risk level assesses the degree of potential harms to a human body due to bad postures often encountered in workplaces. If accurate 3-dimensional coordinates of body joints can be found from images, then postural risk level can be calculated analytically. Unfortunately, even with today's very successful deep learning technologies, human pose estimation algorithms still cannot give accurately enough coordinates for the task. Machine learning (ML) may be needed to improve risk estimation from outputs of pose estimators. In this study, we apply ML to train a risk level predictor based on joint angles calculated from outputs of pose estimators. We validate our work with publicly available image datasets. Two state-of-the-art pose estimators with pre-trained models were used as is. Multiple sources of images were combined in different ways to tackle covariate shift and concept drift issues in ML. It is found that a weakly supervised algorithm increased balanced accuracy and F1 score substantially from the baseline approach on two public image datasets. F1 score is the harmonic mean of precision and recall. A two-stage multi-source domain adaptation algorithm also improved these measures, though the improvement was not as impressive as the weak supervision approach. The baseline approach calculated risk levels analytically with outputs of pose estimators. The balanced accuracy is 0.676/0.735/0.745 for baseline/two-stage/weak-supervision with one pose estimator, and 0.749/0.745/0.761 with another one. The F1 score is 0.692/0.726/0.736 for baseline/two-stage/weak-supervision with one pose estimator, and 0.745/0.732/0.748 with another estimator. Applications to private images with the proposed procedure are explained.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: IoT-based 3D pose estimation and motion optimization for athletes: Application of C3D and OpenPose\n",
            "Authors: Ren F.\n",
            "Abstract: This study proposes the IoT-Enhanced Pose Optimization Network (IE-PONet) for high-precision 3D pose estimation and motion optimization of track and field athletes. IE-PONet integrates C3D for spatiotemporal feature extraction, OpenPose for real-time keypoint detection, and Bayesian optimization for hyperparameter tuning. Experimental results on NTURGB+D and FineGYM datasets demonstrate superior performance, with APp50 scores of 90.5 and 91.0, and mAP scores of 74.3 and 74.0, respectively. Ablation studies confirm the essential roles of each module in enhancing model accuracy. IE-PONet provides a robust tool for athletic performance analysis and optimization, offering precise technical insights for training and injury prevention. Future work will focus on further model optimization, multimodal data integration, and developing real-time feedback mechanisms to enhance practical applications.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Postural Classification by Image Embedding and Transfer Learning: An Example of Using the OWAS Method in Motor-Manual Work to Automate the Process and Save Resources\n",
            "Authors: Forkuo G.O.\n",
            "Abstract: Forest operations often expose workers to physical risks, including posture-related disorders such as low back pain. The Ovako Working Posture Assessment System (OWAS) is widely used to assess postures in forest operations, but it requires expertise and significant resources. In this study, the use of image embedding and transfer learning was explored to automate OWAS classification. Over 5000 images from motor–manual cross-cutting operations were analyzed using two models: Google’s Inception V3 and SqueezeNet, both of which were integrated with neural networks via the Orange Visual Programming platform. The image vectors were fed into a locally run neural network (a multilayer perceptron with backpropagation) that was optimized for architecture and hyperparameters. The models were trained and tested using 20-fold cross-validation on the Posture and Action datasets, achieving accuracies of 84% and 89%, respectively, with Inception V3 outperforming SqueezeNet on both datasets. Predictions on unseen images yielded lower accuracies (50%–60%), highlighting the challenge of domain differences. These results demonstrate the potential of embedding-based transfer learning to automate postural classification with high accuracy, thereby reducing the need for expertise and resources. However, further research is needed to improve performance on unseen data and to explore alternative classifiers and embedding methods for better representation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automatic Detect Incorrect Lifting Posture with the Pose Estimation Model\n",
            "Authors: Hsu G.S.J.\n",
            "Abstract: Background: Occupational low back pain (LBP) is a pervasive health issue that significantly impacts productivity and contributes to work-related musculoskeletal disorders (WMSDs). Inadequate lifting postures are a primary, modifiable risk factor associated with LBP, making early detection of unsafe practices crucial to mitigating occupational injuries. Our study aims to address these limitations by developing a markerless, smartphone-based camera system integrated with a deep learning model capable of accurately classifying lifting postures. Material and Method: We recruited 50 healthy adults who participated in lifting tasks using correct and incorrect postures to build a robust dataset. Participants lifted boxes of varying sizes and weights while their movements were recorded from multiple angles and heights to ensure comprehensive data capture. We used the OpenPose algorithm to detect and extract key body points to calculate relevant biomechanical features. These extracted features served as inputs to a bidirectional long short-term memory (LSTM) model, which classified lifting postures into correct and incorrect categories. Results: Our model demonstrated high classification accuracy across all datasets, with accuracy rates of 96.9% for Tr, 95.6% for the testing set, and 94.4% for training. We observed that environmental factors, such as camera angle and height, slightly influenced the model’s accuracy, particularly in scenarios where the subject’s posture partially occluded key body points. Nonetheless, these variations were minor, confirming the robustness of our system across different conditions. Conclusions: This study demonstrates the feasibility and effectiveness of a smartphone camera and AI-based system for lifting posture classification. The system’s high accuracy, low setup cost, and ease of deployment make it a promising tool for enhancing workplace ergonomics. This approach highlights the potential of artificial intelligence to improve occupational safety and underscores the relevance of affordable, scalable solutions in the pursuit of healthier workplaces.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: AI-based mobile application for personalized monitoring of healthy sitting posture\n",
            "Authors: Coskun H.\n",
            "Abstract: In modern workplaces, many individuals spend extended periods sitting, often in positions not recommended by health professionals, which can lead to skeletal, back, muscle, and heart issues. This study developed a mobile application that monitors sitting postures based on health guidelines. Using a smart seat cover embedded with electro- textile sensors from previous research, sitting experiments were conducted to assess posture. Participants were first instructed in healthy posture, then asked to sit as they preferred, including the healthy posture, for 5 minutes. The recorded data were categorized manually by reviewing experiment videos, creating a dataset of healthy and unhealthy postures. This dataset was classified using ANN, gradient boosting (GB), AdaBoost, and random forest algorithms, with a 70/30 train- test split and 5-fold cross- validation. ANN, GB, AdaBoost, and random forest achieved accuracy rates of 99.8%, 100%, 99.2%, and 99.3%, respectively. Based on the GB model, a Java- based Android mobile app was developed for real- time monitoring and posture notifications.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Postural Differences in Speaking Versus Non-Speaking Children with Autism Spectrum Disorder\n",
            "Authors: Będziechowska-Czyżewska M.\n",
            "Abstract: Background/Objectives: Autism spectrum disorder (ASD) is a heterogeneous condition with diverse symptoms influenced by factors like gender, severity and the involvement of family and therapists. While many risk factors that contribute to ASD development are known, the exact etiology remains unclear. The relationship between speech ability and postural/gait patterns in ASD has not been extensively studied. This study aimed to verify if the ability to speak can affect body posture and gait patterns. Methods: The study involved 28 boys aged 6–17. The postural assessment used the Adams test, Bunnell scoliometer, goniometer, and inclinometer to measure trunk rotation, joint range of motion, and spinal curvature. Trunk muscle strength was assessed via a flexion test measuring position maintenance time. This study compare body posture parameters in speaking and non-speaking children with Autism Spectrum Disorders. Moreover the parameters were compared to the general norms. Results: The study observed a tendency for speaking children to deviate more from normative body posture. They presented shoulder protraction more often, increased lumbar lordosis angle, and anterior pelvic tilt. Additionally, non-speaking children were more prone to toe-walking, which, according to other studies, is present in approximately 8–9% of all children with autism spectrum disorders. Both groups presented a decreased angle of dorsal flexion in the ankle joint. Conclusions: This study suggests that speaking children with ASD exhibit greater anterior-posterior postural deviations (increased lumbar lordosis, shoulder protraction, anterior pelvic tilt) than non-speaking children. ASD did not affect scoliosis or trunk rotation. Non-speaking children showed a higher incidence of toe-walking. However, the small sample size limits the generalizability of these findings.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Analysis of Kinect-Based Human Motion Capture Accuracy Using Skeletal Cosine Similarity Metrics\n",
            "Authors: Jia W.\n",
            "Abstract: Kinect, with its intrinsic and accessible human motion capture capabilities, found widespread application in real-world scenarios such as rehabilitation therapy and robot control. Consequently, a thorough analysis of its previously under-examined motion capture accuracy is of paramount importance to mitigate the risks potentially arising from recognition errors in practical applications. This study employs a high-precision, marker-based motion capture system to generate ground truth human pose data, enabling an evaluation of Azure Kinect’s performance across a spectrum of tasks, which include both static postures and dynamic movement behaviors. Specifically, the cosine similarity for skeletal representation is employed to assess pose estimation accuracy from an application-centric perspective. Experimental results reveal that factors such as the subject’s distance and orientation relative to the Kinect, as well as self-occlusion, exert a significant influence on the fidelity of Azure Kinect’s human posture recognition. Optimal testing recommendations are derived based on the observed trends. Furthermore, a linear fitting analysis between the ground truth data and Azure Kinect’s output suggests the potential for performance optimization under specific conditions. This research provides valuable insights for the informed deployment of Kinect in applications demanding high-precision motion recognition.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Drowsiness Detection of Construction Workers: Accident Prevention Leveraging Yolov8 Deep Learning and Computer Vision Techniques\n",
            "Authors: Onososen A.O.\n",
            "Abstract: Construction projects’ unsatisfactory performance has been linked to factors influencing individuals’ well-being and mental alertness on projects. Drowsiness is a significant indicator of sleep deprivation and fatigue, so being able to identify the cognitive and physical preparedness of workers on site to engage in construction tasks is important. As a consequence of the strenuous nature of the work involved in construction, long work hours, and environmental conditions, drowsiness is commonplace and has received less attention despite being a leading cause of accidents occurring on-site. Detecting drowsiness is essential for determining the safety and well-being of site workers. This study presents a vision-based approach using an improved version of the You Only Look Once (YOLOv8) algorithm for real-time drowsiness exposure among construction workers. The proposed method leverages computer vision techniques to analyze facial and eye features, enabling the early detection of signs of drowsiness, effectively preventing accidents, and enhancing on-site safety. The model showed significant precision and efficiency in detecting drowsiness from the given dataset, accomplishing a drowsiness class with a mean average precision (mAP) of 92%. However, it also exhibited difficulties handling imbalanced classes, particularly the underrepresented ‘Awake with PPE’ class, which was detected with high precision but comparatively lower recall and mAP. This highlighted the necessity of balanced datasets for optimal deep learning performance. The YOLOv8 model’s average mAP of 78% in drowsiness detection compared favorably with other studies employing different methodologies. The system improves productivity and reduces costs by preventing accidents and enhancing worker safety. However, limitations, such as sensitivity to lighting conditions and occlusions, must be addressed in future iterations.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Exploring Trends and Clusters in Human Posture Recognition Research: An Analysis Using CiteSpace\n",
            "Authors: Yan L.\n",
            "Abstract: This study delves into interdisciplinary research directions in human posture recognition, covering vision-based and non-vision-based methods. Visually analyzing 3066 core research papers published from 2011 to 2024 with CiteSpace software reveals knowledge structures, research topics, key documents, trends, and institutional contributions. In-depth citation analysis identified 1200 articles and five significant research clusters. Findings show that in recent years, deep learning and sensor-based methods have dominated, significantly improving recognition accuracy, like the deep learning-based posture recognition method achieving 99.7% verification set accuracy with a 20-ms delay in a controlled environment. Logarithmic growth analysis of annual publications, supported by logistic model fitting, indicates the field’s maturation since 2011, with a shift from early simple applications of traditional and deep learning algorithms to integrating interdisciplinary approaches for problem-solving as the field matures and a predicted decline in future breakthroughs. By integrating indicators like citation bursts, degree centrality, and sigma, the research identifies interdisciplinary trends and key innovation directions, showing a transition from traditional to deep learning and multi-sensor data fusion methods. The integration of biomechanics principles with engineering technologies highlights new research paths. Overall, this study offers a systematic overview to identify gaps, trends, and innovation directions, facilitating future research and providing a roadmap for innovation in human posture recognition.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Lower Limb Exoskeletons, Application-Centric Classifications: A Review\n",
            "Authors: Karthik V.\n",
            "Abstract: Exoskeletons are a relatively new field of technology used as assistive devices. Since the first development of the exoskeleton in the late 19th century, this field has seen significant advancements, as it has potential in numerous applications. Although this field is rapidly growing, it remains unable to be fully implemented in various applications. It is due to the limitations in the existing technology used to develop the exoskeleton, the lack of standardization, and the rapid growth in the exoskeleton field. To address the existing challenge, this review paper attempts to develop a classification model of lower limb exoskeletons (LLEs), which researchers and engineers can use to understand the relation between various application scenarios and different design aspects while developing an LLE. The classification model has been divided into two levels: application and design aspects of an exoskeleton. In this paper, 53 LLEs have been analyzed and classified into a flexible model, allowing future exoskeletons also to be added. It has also been discussed why each exoskeleton is classified into various categories.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Proposing an Affordable Real-Time Camera-Based Safety and Quality Management Framework for Construction Industries in Developing Countries\n",
            "Authors: Abdullah Z.O.\n",
            "Abstract: The construction industry in developing countries faces persistent challenges, including limited funding, poor infrastructure, insufficient use of technology, and weak quality management practices. These issues reduce productivity, compromise safety, and lower efficiency, often resulting in project delays, cost overruns, and substandard structures. This study introduces a safety and quality management framework that uses affordable camera technology and a structured web-based platform to address these challenges. The proposed system is designed to identify, document, and resolve potential issues systematically, fostering safer and more efficient construction environments. This research addresses the gap between the potential of technological advancements and their limited adoption in resource-constrained settings. Financial barriers often limit the availability of expertise on-site and restrict access to sophisticated tools, while inadequate quality control exacerbates risks, wastes resources, and undermines project outcomes. By introducing an affordable, easy-to-deploy solution, this study aims to bridge that gap and improve industry practices. Initial case studies have demonstrated promising results, including achieving acceptable quality and safety levels through the help of expertise from abroad. This paper details the design, implementation, and scalability of the proposed system while highlighting its adaptability to diverse construction contexts in developing nations. Additionally, it emphasizes the broader benefits of integrating technology into the construction industry, such as promoting economic growth and supporting sustainable development. Adopting this high-impact, cost-effective solution has the potential to significantly enhance technical capabilities, improve efficiency, and elevate social conditions through safer and more sustainable construction practices. This framework represents a transformative opportunity for the construction industry in developing countries, contributing to long-term progress and prosperity.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Overview and Prospects of DNA Sequence Visualization\n",
            "Authors: Wu Y.\n",
            "Abstract: Due to advances in big data technology, deep learning, and knowledge engineering, biological sequence visualization has been extensively explored. In the post-genome era, biological sequence visualization enables the visual representation of both structured and unstructured biological sequence data. However, a universal visualization method for all types of sequences has not been reported. Biological sequence data are rapidly expanding exponentially and the acquisition, extraction, fusion, and inference of knowledge from biological sequences are critical supporting technologies for visualization research. These areas are important and require in-depth exploration. This paper elaborates on a comprehensive overview of visualization methods for DNA sequences from four different perspectives—two-dimensional, three-dimensional, four-dimensional, and dynamic visualization approaches—and discusses the strengths and limitations of each method in detail. Furthermore, this paper proposes two potential future research directions for biological sequence visualization in response to the challenges of inefficient graphical feature extraction and knowledge association network generation in existing methods. The first direction is the construction of knowledge graphs for biological sequence big data, and the second direction is the cross-modal visualization of biological sequences using machine learning methods. This review is anticipated to provide valuable insights and contributions to computational biology, bioinformatics, genomic computing, genetic breeding, evolutionary analysis, and other related disciplines in the fields of biology, medicine, chemistry, statistics, and computing. It has an important reference value in biological sequence recommendation systems and knowledge question answering systems.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Framework Using Multicriteria Analysis for Evaluating the Risk of Musculoskeletal Disorders\n",
            "Authors: Senvaitis K.\n",
            "Abstract: This study includes musculoskeletal disorder (MSD) risk evaluation based on the IMU sensor data gathered from patient-lifting movement performed by healthcare specialists. This is a continuation of previous research focusing on a novel multicriteria statistical model integrating experimental and large-scale statistical datasets. The proposed model estimates MSD probabilities over 5, 10, and 15 years for the neck (0.537 ± 0.156), shoulder (0.449 ± 0.084), and elbows (0.277 ± 0.221). The model enables individual risk profiling, influenced by dynamic parameters that can reduce the long-term risk by up to 70.49%. The model is in its early development stages, i.e., it is the proof of concept that offers a new approach to assessing MSD risk at work using motion tracking data in combination with statistics. Further studies with larger sample sizes and validated criterion weights are needed to refine and validate this approach.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Children’s Perceived Ease of Use of a Projected Augmented Reality Game Designed for Balance and Coordination Training\n",
            "Authors: Liu Y.\n",
            "Abstract: Developing balance and coordination skills is essential for children, especially those aged 4–8, but limited Health and Physical Education (HPE) programs in schools hinder effective training. Game-based learning and Augmented Reality (AR) technologies offer promising ways to enhance these skills by providing immersive HPE experiences. An AR exercise-game prototype was developed to train children’s balance and coordination, with 19 children aged 4 to 9 testing the prototype. Post-activity surveys revealed high engagement and interactivity ratings. The difficultly of the current prototype was found to be appropriately challenging for 4- to 6-year-olds. Feedback emphasized a preference for interactive, challenging elements, suggesting improvements in difficulty customization, visuals, and technical stability. Competitive play between multiple children testing the prototype encouraged repeated attempts, but also highlighted the need for improved tracking solutions and lab setup. Overall, the innovative design shows educational potential but requires further large-scale testing on a refined version to assess its effectiveness in balance and coordination training.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Integrating intelligent algorithms in music education to analyze and improve posture and motion in instrumental training\n",
            "Authors: Yang P.\n",
            "Abstract: This paper presents an innovative Artificial Intelligence (AI)—based system for real-time posture analysis and correction in instrumental music training. The system integrates OpenPose-based Convolutional Neural Networks (CNN) for skeletal tracking, Dynamic Time Warping for motion pattern analysis, and K-Nearest Neighbors (K-NN) for posture classification. Through a 16-week experimental study involving 18 music students, the system demonstrated significant improvements in learning outcomes compared to traditional methods. Key findings include (a) 33.3% faster technique acquisition in AI-assisted learning compared to traditional methods; (b) 18.6% higher posture improvement rates by week 16; (c) 40.2% better self-correction capabilities; and (d) 95.1% retention rate of correct posture after 6 months. The system processes video input at 120 fps with a total latency of 30 ms, achieving 94.3% accuracy in posture detection and 91.2% in motion pattern matching. The research establishes a comprehensive framework for integrating AI technology in music education, providing continuous, objective feedback during practice sessions. This approach addresses the critical gap between supervised instruction and individual practice, potentially reducing the risk of performance-related injuries through early detection of posture deviations.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: PREDICTING MENTAL WORKLOAD OF USING EXOSKELETONS FOR CONSTRUCTION WORK: A DEEP LEARNING APPROACH\n",
            "Authors: Afolabi A.\n",
            "Abstract: SUMMARY: Exoskeletons are gaining attention as a potential solution for addressing back injury in the construction industry. However, using active back-support exoskeletons in construction can trigger unintended consequences which could increase the mental workload of workers. Prolonged increase in mental workload could impact workers’ wellbeing and productivity. Predicting mental workload during exoskeleton use could inform strategies to mitigate the triggers. This study investigates two machine-learning frameworks for predicting mental workload using an active back-support exoskeleton for construction work. Laboratory experiments were conducted wherein electroencephalography (EEG) data was collected from participants wearing an active back-support exoskeleton to perform flooring tasks. The EEG data underwent preprocessing, including band filtering, notch filtering, and independent component analysis, to remove artifacts and ensure data quality. A regression-based Long Short-Term Memory (LSTM) network and a hybrid model of convolutional neural network and LSTM were trained to forecast future time steps of the processed EEG data. The performance of the networks was evaluated using root mean square error and r-squared. An average root mean square error of 0.162 and r-squared of 0.939 indicate that the LSTM network has a better predictive power across all the EEG channels. Results of the comparison between the actual and predicted mental workload also show that about 75% of the variance in the actual mental workload is captured in the predicted mental workload. This study enhances understanding of the unintended consequences of using exoskeletons in construction work. The results highlight the effectiveness of various convolutional neural network methods in identifying key EEG data features, offering guidance for algorithm selection in future applications. Additionally, the study identifies the most suitable brain channels for assessing mental workload during exoskeleton use, aiding the development of EEG devices that optimize cost-effectiveness, explanatory power, and minimal channels. This study provides valuable insights for stakeholders to understand the impact of mental workload while using exoskeletons and discovering opportunities for mitigation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Novel Telerehabilitation System for Physical Exercise Monitoring in Elderly Healthcare\n",
            "Authors: Abrar Ashraf M.\n",
            "Abstract: The increasing demand for remote healthcare solutions has driven the need for effective telerehabilitation systems to support elderly individuals recovering from chronic conditions or post-operative impairments. Existing rehabilitation methods face limitations such as restricted access to specialized care, overburdened healthcare providers, and the need for consistent, real-time monitoring. To address these challenges, we propose a novel telerehabilitation system that processes depth video frames using a multi-stage methodology. The pipeline begins with noise and floor removal, followed by 3D connected component labeling (CCL) to identify the human subject and extract the human silhouette. Next, skeleton joint points are estimated, and features are extracted from both the joints and silhouette. These multimodal features are fused and input into a deep learning model for classification and correctness assessment. Advanced feature extraction techniques, including Synchrosqueezing Transform (SST) and Hilbert-Huang Transform (HHT), are employed to capture dynamic time-frequency characteristics of human actions. The proposed system classifies nine distinct exercises and assesses the correctness of movements. Experimental evaluation on the IRDS dataset demonstrates a classification accuracy of 91% for exercise recognition and 82% for movement correctness assessment. These results highlight the system's potential to deliver scalable, cost-effective, real-time rehabilitation, reducing the need for in-person clinical visits and supporting healthcare services for elderly populations.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Combining Postural Sway Parameters and Machine Learning to Assess Biomechanical Risk Associated with Load-Lifting Activities\n",
            "Authors: Prisco G.\n",
            "Abstract: Background/Objectives: Long-term work-related musculoskeletal disorders are predominantly influenced by factors such as the duration, intensity, and repetitive nature of load lifting. Although traditional ergonomic assessment tools can be effective, they are often challenging and complex to apply due to the absence of a streamlined, standardized framework. Recently, integrating wearable sensors with artificial intelligence has emerged as a promising approach to effectively monitor and mitigate biomechanical risks. This study aimed to evaluate the potential of machine learning models, trained on postural sway metrics derived from an inertial measurement unit (IMU) placed at the lumbar region, to classify risk levels associated with load lifting based on the Revised NIOSH Lifting Equation. Methods: To compute postural sway parameters, the IMU captured acceleration data in both anteroposterior and mediolateral directions, aligning closely with the body’s center of mass. Eight participants undertook two scenarios, each involving twenty consecutive lifting tasks. Eight machine learning classifiers were tested utilizing two validation strategies, with the Gradient Boost Tree algorithm achieving the highest accuracy and an Area under the ROC Curve of 91.2% and 94.5%, respectively. Additionally, feature importance analysis was conducted to identify the most influential sway parameters and directions. Results: The results indicate that the combination of sway metrics and the Gradient Boost model offers a feasible approach for predicting biomechanical risks in load lifting. Conclusions: Further studies with a broader participant pool and varied lifting conditions could enhance the applicability of this method in occupational ergonomics.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Student Engagement Recognition: Comprehensive Analysis Through EEG and Verification by Image Traits Using Deep Learning Techniques\n",
            "Authors: Sukumaran A.\n",
            "Abstract: With the advancement in educational technologies and strategies, hybrid and online teaching methods are gaining significant popularity. Student engagement is an important factor that influences the quality of any teaching and learning process. Tracking student attention can be achieved from facial and body posture analysis. Neurophysiological signals also play a substantial role in measuring students' academic states in the learning environment. EEG signals are more sensitive to cognitive states, providing constructive perceptions of students' emotional and cognitive understandings. In this paper, we propose an engagement recognition system that detects student engagement using EEG signals by integrating levels of valence and arousal with the Russel 2D circumplex model using deep learning algorithm. The public DEAP dataset was used for training the model to predict valence and arousal values. Our system achieved an accuracy of 84.75% for detecting valence and arousal values in the four quadrants (HVHA, HVLA, LVHA, LVLA) for the DEAP dataset. For the engagement classification into four categories, 'highly engaged', 'confused', 'boredom', and 'sleepy', our system attained an accuracy of 84%. The experimental results of the proposed system were verified by analyzing the image traits of the students using the engagement indicator algorithm. Both systems were further validated through a quiz conducted at the end of the session.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Validity of Wearable Inertial Sensors for Gait Analysis: A Systematic Review\n",
            "Authors: Prisco G.\n",
            "Abstract: Background/Objectives: Gait analysis, traditionally performed with lab-based optical motion capture systems, offers high accuracy but is costly and impractical for real-world use. Wearable technologies, especially inertial measurement units (IMUs), enable portable and accessible assessments outside the lab, though challenges with sensor placement, signal selection, and algorithm design can affect accuracy. This systematic review aims to bridge the benchmarking gap between IMU-based and traditional systems, validating the use of wearable inertial systems for gait analysis. Methods: This review examined English studies between 2012 and 2023, retrieved from the Scopus database, comparing wearable sensors to optical motion capture systems, focusing on IMU body placement, gait parameters, and validation metrics. Exclusion criteria for the search included conference papers, reviews, unavailable papers, studies without wearable inertial sensors for gait analysis, and those not involving agreement studies or optical motion capture systems. Results: From an initial pool of 479 articles, 32 were selected for full-text screening. Among them, the lower body resulted in the most common site for single IMU placement (in 22 studies), while the most frequently used multi-sensor configuration involved IMU positioning on the lower back, shanks, feet, and thighs (10 studies). Regarding gait parameters, 11 studies out of the 32 included studies focused on spatial-temporal parameters, 12 on joint kinematics, 2 on gait events, and the remainder on a combination of parameters. In terms of validation metrics, 24 studies employed correlation coefficients as the primary measure, while 7 studies used a combination of error metrics, correlation coefficients, and Bland–Altman analysis. Validation metrics revealed that IMUs exhibited good to moderate agreement with optical motion capture systems for kinematic measures. In contrast, spatiotemporal parameters demonstrated greater variability, with agreement ranging from moderate to poor. Conclusions: This review highlighted the transformative potential of wearable IMUs in advancing gait analysis beyond the constraints of traditional laboratory-based systems.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: How accurately can we estimate spontaneous body kinematics from video recordings? Effect of movement amplitude on OpenPose accuracy\n",
            "Authors: Koul A.\n",
            "Abstract: Estimating how the human body moves in space and time—body kinematics—has important applications for industry, healthcare, and several research fields. Gold-standard methodologies capturing body kinematics are expensive and impractical for naturalistic recordings as they rely on infrared-reflective wearables and bulky instrumentation. To overcome these limitations, several algorithms have been developed to extract body kinematics from plain video recordings. This comes with a drop in accuracy, which however has not been clearly quantified. To fill this knowledge gap, we analysed a dataset comprising 46 human participants exhibiting spontaneous movements of varying amplitude. Body kinematics were estimated using OpenPose (video-based) and Vicon (infrared-based) motion capture systems simultaneously. OpenPose accuracy was assessed using Vicon estimates as ground truth. We report that OpenPose accuracy is overall moderate and varies substantially across participants and body parts. This is explained by variability in movement amplitude. OpenPose estimates are weak for low-amplitude movements. Conversely, large-amplitude movements (i.e., > ~ 10 cm) yield highly accurate estimates. The relationship between accuracy and movement amplitude is not linear (but mostly exponential or power) and relatively robust to camera–body distance. Together, these results dissect the limits of video-based motion capture and provide useful guidelines for future studies.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Infrared thermal energy image and virtual reality application in muscle posture adjustment training based on computer simulation\n",
            "Authors: Sun Z.\n",
            "Abstract: With the continuous progress of science and technology, the traditional training methods in the field of muscle posture adjustment training can not fully meet the needs of athletes and coaches. In order to improve training efficiency and accuracy, this study aims to explore how to combine computer simulation technology and virtual reality technology with infrared thermal image to develop a system that can help athletes and coaches to train more intuitively and accurately. A computer simulation platform was constructed to simulate different motion scenarios and muscle activities. A set of infrared thermal energy image acquisition system is developed, which can capture the changes of thermal energy generated by muscles in the process of movement in real time, and convert these data into visual images. These images are then combined with virtual reality technology to create an interactive training environment. In this environment, athletes can see thermal images of their muscle activity in real time and adjust their movement posture based on the image feedback. The experimental results show that by using a training system based on computer simulation of infrared thermal energy images combined with virtual reality technology, athletes can more intuitively understand their own muscle activity during exercise. Infrared thermal images clearly show the heat distribution and changes of different muscle groups during exercise, helping athletes to identify which muscle groups are overstressed or understressed during exercise. The system not only improves the visualization of sports training, but also helps athletes adjust muscle posture more effectively through real-time feedback.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: DESNet: Real-time human pose estimation for sports applications combining IoT and deep learning\n",
            "Authors: Huang R.\n",
            "Abstract: With the rapid development of IoT technology, real-time human pose estimation has become increasingly important in sports training feedback systems. However, current methods often fall short in balancing high accuracy with low computational resource requirements, especially in resource-constrained environments. Deep learning has shown significant potential in enhancing computer vision tasks, including human pose estimation. In this study, we propose DESNet, an improved EfficientHRNet model that integrates IoT technology. DESNet combines Dynamic Multi-Scale Context (DMC) modules and Squeeze-and-Excitation (SE) modules, and utilizes IoT for real-time data collection, transmission, and processing. Experimental results show that DESNet achieves an average precision (AP) of 74.8% on the COCO dataset and a PCKh (Percentage of Correct Keypoints with head-normalized) of 90.9% on the MPII dataset, outperforming existing lightweight models. The integration of deep learning and IoT technology not only improves the accuracy and efficiency of human pose estimation but also significantly enhances the timeliness and robustness of feedback in sports training applications. Our findings demonstrate that DESNet is a powerful tool for real-time human pose analysis, offering promising solutions for intelligent sports training and rehabilitation systems.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Dynamic Modelling of the Spine for the Estimation of Vertebral Joint Torques using Gordon’s Method\n",
            "Authors: Isa M.S.M.\n",
            "Abstract: World Health Organization (WHO) recognised musculoskeletal disorder (MSD) as the main contributor to disability worldwide, with low back pain as the major disorder globally. The occupational disorder normally occurs during lifting. The weight of the load and manual handling tasks during lifting has an impact on the spine and joint torque. The purpose of this study is to propose a dynamic model of the spine that can estimate the vertebral joint torques. This study is a bimodal approach that consists of the experimental and theoretical parts. Ten healthy UniMAP students (10 males) participated in this study. The subjects were required to lift a 3kg weight plate for kinematics and EMG data collection. Retro-reflective markers were attached to the subject body, and then, the data was collected and stored in QTM software. Kinematic data was processed using C-Motion Visual3D. Eight Trigno Wireless Sensors were attached on the back muscles (left and right erector spinae, latissimus dorsi, external oblique and internal oblique). The EMG data were stored in EMG Acquisition software and subsequently, were processed using EMG Analysis software. Gordon’s method was used to develop a mathematical model of the spine. The model comprises of five kinematic chains which connected three lumbar, two thoracic and one cervical. The model calculated the value of joint torque on flexion/extension movement using Matlab and Microsoft Excel. When calculated on L5, the model gives an estimation within 0 – 30 kgm2s-2. The model was further used to estimate value of L3, L1, MAI and T2. The estimate average value of joint torque at L3 is within 5 – 25 kgm2s-2, MAI is within 0 – 6 kgm2s-2 and T2 is within 0 – 1 kgm2s-2. The average RMS values show the highest muscle activity on the right internal oblique muscle (1519 µV), followed by the right external oblique (1166 µV) and left external oblique (418 µV). The results obtained gives an insight on the value of joint torque that have been applied by the spine and the most activated back muscles during lifting.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: AI in evaluating ambulation of stroke patients: severity classification with video and functional ambulation category scale\n",
            "Authors: Kim J.H.\n",
            "Abstract: Background: The evaluation of gait function and severity classification of stroke patients are important to determine the rehabilitation goal and the level of exercise. Physicians often qualitatively evaluate patients’ walking ability through visual gait analysis using naked eye, video images, or standardized assessment tools. Gait evaluation through observation relies on the doctor’s empirical judgment, potentially introducing subjective opinions. Therefore, conducting research to establish a basis for more objective judgment is crucial. Objective: To verify a deep learning model that classifies gait image data of stroke patients according to Functional Ambulation Category (FAC) scale. Methods: Gait vision data from 203 stroke patients and 182 healthy individuals recruited from six medical institutions were collected to train a deep learning model for classifying gait severity in stroke patients. The recorded videos were processed using OpenPose. The dataset was randomly split into 80% for training and 20% for testing. Results: The deep learning model attained a training accuracy of 0.981 and test accuracy of 0.903. Area Under the Curve(AUC) values of 0.93, 0.95, and 0.96 for discriminating among the mild, moderate, and severe stroke groups, respectively. Conclusion: This confirms the potential of utilizing human posture estimation based on vision data not only to develop gait parameter models but also to develop models to classify severity according to the FAC criteria used by physicians. To develop an AI-based severity classification model, a large amount and variety of data is necessary and data collected in non-standardized real environments, not in laboratories, can also be used meaningfully.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Optimising computer vision-based ergonomic assessments: sensitivity to camera position and monocular 3D pose model\n",
            "Authors: Murugan A.S.\n",
            "Abstract: Numerous computer vision algorithms have been developed to automate posture analysis and enhance the efficiency and accuracy of ergonomic evaluations. However, the most effective algorithm for conducting ergonomic assessments remains uncertain. Therefore, the aim of this study was to identify the optimal camera position and monocular 3D pose model that would facilitate precise and efficient ergonomic evaluations. We evaluated and compared four currently available computer vision algorithms: Mediapipe BlazePose, VideoPose3D, 3D-pose-baseline, and PSTMO to determine the most suitable model for conducting ergonomic assessments. Based on the findings, the side camera position yielded the lowest Mean Absolute Error (MAE) across static, dynamic, and combined tasks. This positioning proved to be the most reliable for ergonomic assessments. Additionally, VP3D_FB demonstrated superior performance among evaluated models. Practitioner Summary: This study aimed to determine the most effective computer vision algorithm and camera position for precise and efficient ergonomic evaluations. Evaluating four algorithms, we found that the side camera position with VideoPose3D yielded the lowest Mean Absolute Error (MAE), ensuring precise and efficient evaluations.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic risk analysis for drone pilots\n",
            "Authors: Elizalde R.R.\n",
            "Abstract: This study aims to analyse the ergonomic risks faced by drone pilots, focusing on postural chal-lenges during flight operations. The research investigates how these postures may contribute to musculoskeletal disorders and proposes corrective measures to mitigate these risks. The study utilized the Rapid Upper Limb Assessment (RULA) methodology to evaluate the postures adopted by drone pilots during real flight operations. Observations were conducted across multiple work cycles involving two drone pilots operating in different environments. Angular measurements of various body segments were captured and analysed to determine ergonomic risk levels. The analysis identified five key postures that posed varying levels of ergonomic risk. Three postures were found to require possible adjustments, while two required task redesign due to significant musculoskeletal strain. Key risk factors included prolonged wrist extension, neck flexion, and static load caused by the control console's design and the pilot’s need to maintain visual contact with the drone. The study concludes that ergonomic risks for drone pilots are significant and require proactive interventions. Recommendations include adopting improved console designs, incor-porating harness support systems, modifying operational protocols to improve body positioning, and utilizing alternative equipment like larger display screens to reduce neck strain. The findings offer actionable insights for drone operators, ergonomics specialists, and employers to implement ergonomic improvements in drone piloting tasks. These changes aim to reduce musculoskeletal disorders, improve working conditions, and enhance overall safety in drone operations.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Integrating Attention Mechanisms in YOLOv8 for Improved Fall Detection Performance\n",
            "Authors: Zaghden N.\n",
            "Abstract: The increasing elderly population has heightened the need for accurate and reliable fall detection systems, as falls can lead to severe health complications. Existing systems often suffer from high false positive and false negative rates due to insufficient training data and suboptimal detection techniques. This study introduces an advanced fall detection model integrating YOLOv8, Faster R-CNN, and Generative Adversarial Networks (GANs) to enhance accuracy and robustness. A modified YOLOv8 architecture serves as the core, utilizing spatial attention mechanisms to improve critical image regions’ detection. Faster R-CNN is employed for fine-grained human posture analysis, while GANs generate synthetic fall scenarios to expand and diversify the training dataset. Experimental evaluations on the DiverseFALL10500 and CAUCAFall datasets demonstrate that the proposed model significantly outperforms state-ofthe-art methods. The model achieves a mean Average Precision (mAP) of 0.9507 on DiverseFALL10500 and 0.996 on CAUCAFall, surpassing conventional YOLO and R-CNN-based models. Precision and recall metrics also indicate superior detection performance, with a recall of 0.929 on DiverseFALL10500 and 0.9993 on CAUCAFall, ensuring minimal false negatives. Real-time deployment tests on the Xilinx Kria™ K26 System-on-Module confirm an average inference time of 43ms per frame, making it suitable for real-time monitoring applications. These results establish the proposed R-CNN_GAN_YOLOv8 model as a benchmark in fall detection, offering a reliable and efficient solution for healthcare applications. By integrating attention mechanisms and GAN-based data augmentation, this approach significantly enhances detection accuracy while reducing false alarms, improving safety for elderly individuals and high-risk environments.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Application of Computer Vision Technology in Optimizing the Running Posture of College Athletes\n",
            "Authors: Zhang J.\n",
            "Abstract: Computer vision techniques such as 3D human pose estimation can help college athletes obtain more accurate running motion data, such as step count, stride length, and posture. This provides data support for athletes to optimize their running posture and scientifically develop fitness plans. This study delves into the algorithm for 3D human posture estimation of collegiate athletes in running scenarios and suggests ways to improve its performance by utilizing temporal information and human body topology. This research presents a solution to the issue of occlusion-induced incorrect 3D posture estimation: a grouped spatiotemporal attention network for human body modeling based on a grouped human skeletal structure. With the use of a self-attention mechanism, a spatial encoder may improve the model’s grasp of spatial joint information and increase the possibility of predicting unusual poses by extracting local inter-joint linkages within the area and global inter-regional correlations. A temporal encoder is designed to capture the temporal relationships of the input frame sequence, obtaining a posture representation with temporal characteristics and alleviating occlusion issues.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Review on design of real-time posture monitoring system for the cervical region\n",
            "Authors: Sharma V.\n",
            "Abstract: In cervical health, the Posture Monitoring System (PMS) employs sensors to capture and transmit posture data to the cloud via Wi-Fi. This systematic review examines wearable PMS devices for cervical posture, analysing their attributes, findings, and limitations. Using systematic literature analysis, related studies were collected from diverse databases concentrating on wearable cervical posture devices. The review analysed the outcomes of each neck posture and each monitor type on the CVA ratio based on PMS. However, limitations, such as small sample sizes, limited functions, and privacy concerns were noted across the devices. The findings underscore the importance of considering user comfort and data accuracy in designing and implementing wearable posture monitors. Future studies should also explore the integration of advanced technologies and user-centred design principles to develop more accurate and user-friendly devices.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Yoga Posture Analysis and Feedback System Using Mediapipe\n",
            "Authors: Snigdha D.\n",
            "Abstract: This project integrates Mediapipe with Python to implement a yoga posture analysis system for evaluating and providing efficacious feedback on human poses. The system establishes ideal joint landmarks using reference images, which are compared with uploaded analysis images over multiple simulated epochs. Angles of key joints, such as the elbow, shoulder, hip and knee are calculated and annotated onto the analyzed images for visual feedback. Deviations of analyzed images are identified and corrective suggestions are provided. Comprehensive graphs of accuracy and loss for each epoch are displayed to visualize the trends in accuracy and pose improvement. Accuracy reflects how well the model predicts the correct output, while loss indicates areas for improvement. In addition, for easy reference, all epoch data are tabulated to summarize overall performance, and a final model accuracy percentage is computed. The project also gives visual presentations of accuracy and loss over each epoch. The system serves as an effective tool for posture correction, making it suitable for fitness applications, physiotherapy, and ergonomic evaluations, with its detailed visual and numerical feedback.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Using AI-Powered video feedback to improve ergonomics: An analog experiment\n",
            "Authors: Espericueta Luna W.A.\n",
            "Abstract: Musculoskeletal disorders (MSDs) are injuries that can result from or are worsened by performing work-related tasks. Approximately 1.7 billion people suffer from MSDs globally. Thus, strategies are needed to improve postural behaviors. The purpose of this study was to evaluate the effectiveness of video feedback using an AI-powered application to improve participants’ low-risk neck positioning while completing an analog work task. Ten undergraduate students completed the analog work task in a simulated office environment. The researchers provided video feedback in a multiple baseline design across participants and the results showed that low-risk neck positioning increased when video feedback was provided. Additionally, the researchers conducted two validation tests comparing the ergonomic measurements produced by the AI-powered app to measurements produced by a gold-standard sensor-based ergonomic measurement system. The results of the validation tests provide preliminary support for the accuracy and reliability of the AI-powered app’s ergonomic measurements.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Work-related musculoskeletal disorders (WRMSDs) through the lens of previous studies: social sustainability-inhibiting features\n",
            "Authors: Zakariyyah K.I.\n",
            "Abstract: Purpose: This study aims to identify the theoretical linkage between work-related musculoskeletal disorders (WRMSDs) and social sustainability to increase awareness of WRMSDs’ social sustainability-inhibiting features and preventive strategies. Design/methodology/approach: This qualitative research adopts a systematic literature review (SLR) approach. Adhering to Preferred Reporting Items for Systematic Reviews and Meta-analyses (PRISMA) guidelines, 303 documents from the Scopus database (2003–2024) were analysed using bibliometric technique and content analysis. Findings: The study identified key bibliometric metrics such as top journals, most recent authors and publications. The trend shows that documents and citations initially progressed, then stagnated but later rose, and recently, documents have risen independently of citations. Only six journals contribute the most (43 of 85% overall citations; 23 of 73% overall publications), and 13 authors are the most influential. The content analysis revealed that 80% of the recent studies centred on risk assessment (RA) with only 5% on health assessment impact (HAI). Research limitations/implications: The findings are limited to the review period. Social implications: WRMSD is injurious to well-being, impairs performance, and impacts society through reduced productivity, medication use and time off work. Therefore, proactive strategies must be implemented to minimise its occurrence and severity. Originality/value: This study’s novelty lies in text mining WRMSD literature by raising awareness of its social inhibiting features so that occupational ill health is minimised, project health and workers’ well-being are enhanced, and the industry’s social sustainability is raised.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Postural analysis and ergonomic intervention of unorganized workers in indian construction sectors\n",
            "Authors: Kumar G.P.\n",
            "Abstract: BACKGROUND: In India's fast-growing economy, the construction sector offers significant developments with huge employment opportunities but poses risks due to poor working environments and uncomfortable postures. Traditional methods, such as manual material handling, can lead to health hazards and musculoskeletal disorders such as overexertion, low back pain, etc. OBJECTIVE: The purpose of this study was to analyze the working postures of unorganized employees engaged in residential buildings using Ergofellow software and to recommend changes in their unsafe working postures. METHODS: Participants' working positions were video recorded and the postures were analyzed using Rapid Upper Limb Assessment (RULA), Rapid Entire Body Assessment (REBA) and Ovako Working Posture Analysis (OWAS). Paired sample t-tests were used to analyze significant differences between the RULA and REBA scores after the ergonomic interventions were implemented. RESULTS: From the analysis of RULA, REBA and OWAS, the working postures showed a high risk of potential injury and required an immediate change in employees' working postures. The RULA and REBA scores were subsequently lower after the ergonomic interventions, which were based on ergonomic and safety principles. The paired sample t-tests with p-values of less than 0.05 demonstrated decreased risks after ergonomic interventions. CONCLUSION: Working postures of the construction workers exposed to musculoskeletal disorders were examined and the ergonomic interventions were implemented. According to the recommendations, working positions were changed, and employee well-being was enhanced by reduced operational risks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Short Review: Photogrammetric Analysis of Posture in Postpartum Women\n",
            "Authors: Patil S.\n",
            "Abstract: Dr. Janda put forth an interesting concept by dividing the muscles into two groups: Postural and Phasic. Postural or tonic muscles are important for maintaining upright posture, have tendency to become tight and hypertonic. Phasic muscles, which include almost all other muscles have tendency to become weak and hypotonic. Muscular imbalances can have certain consequences in the body1. Janda classifies these muscular imbalance patterns into three types including Upper Cross Syndrome, Lower Cross Syndrome, and layered syndrome. Different movement can cause upper cross syndrome, but most cases develop through poor posture. Pregnancy involves postural changes in both upper as well lower body. So due to anatomical changes occurring for such long period of time can lead to development of both upper cross and lower cross which when simultaneously found is termed as Layered Syndrome. Various computer-based application can be used to analyze the postural changes rather than conventional methods to get best outcome for further studies and management.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Fusing YOLOv5s-MediaPipe-HRV to classify engagement in E-learning: From the perspective of external observations and internal factors\n",
            "Authors: Wang J.\n",
            "Abstract: The rapid advancements in computer vision technology present significant potential for the automatic recognition of learner engagement in E-learning. We conducted a two-stage experiment to assess learner engagement based on behavioural (external observations) and physiological (internal factors) cues. Using computer vision technology and wearable sensors, we extracted three feature sets: action, head posture and heart rate variability (HRV). Subsequently, we integrated our constructed YOLOv5s–MediaPipe behaviour detection model with a physiological detection model based on HRV to comprehensively evaluate learners’ behavioural, affective and cognitive engagement. Additionally, we developed a method and criteria for assessing distraction based on behaviour, ultimately creating a comprehensive, efficient, low-cost and easy-to-use system for the automatic recognition of learner engagement. Experimental results showed that our improved YOLOv5s model achieved a mean average precision of 92.2 %, while halving both the number of parameters and model size. Unlike other deep learning-based methods, using MediaPipe–OpenCV for head posture analysis offers advantages in real-time performance, making it lightweight and easy to deploy. Our proposed long short-term memory classifier, based on sensitive HRV metrics and their normalisation, demonstrated satisfactory performance on the test set, with an accuracy = 80 %, precision = 81 %, recall = 80 % and an F1 score = 80 %.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Spatial-Temporal Multi-Feature Network (STMF-Net) for Skeleton-Based Construction Worker Action Recognition\n",
            "Authors: Tian Y.\n",
            "Abstract: Globally, monitoring productivity, occupational health, and safety of construction workers has long been a significant concern. To address this issue, there is an urgent need for efficient methods to continuously monitor construction sites and recognize workers’ actions in a timely manner. Recently, advances in electronic technology and pose estimation algorithms have made it easier to obtain skeleton and joint trajectories of human bodies. Deep learning algorithms have emerged as robust and automated tools for extracting and processing 3D skeleton information on construction sites, proving effective for workforce action assessment. However, most previous studies on action recognition have primarily focused on single-stream data, which limited the network’s ability to capture more comprehensive worker action features. Therefore, this research proposes a Spatial-Temporal Multi-Feature Network (STMF-Net) designed to utilize six 3D skeleton-based features to monitor and capture the movements of construction workers, thereby recognizing their actions. The experimental results demonstrate an accuracy of 79.36%. The significance of this work lies in its potential to enhance management models within the construction industry, ultimately improving workers’ health and work efficiency.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Dynamic Tracking and Real-Time Fall Detection Based on Intelligent Image Analysis with Convolutional Neural Network\n",
            "Authors: Yao C.B.\n",
            "Abstract: As many countries face rapid population aging, the supply of manpower for caregiving falls far short of the increasing demand for care. Therefore, if the care system can continuously recognize and track the care recipient and, at the first sign of a fall, promptly analyze the image to accurately assess the circumstances of the fall, it would be highly critical. This study integrates the mobility of drones in conjunction with the Dlib HOG algorithm and intelligent fall posture analysis, aiming to achieve real-time tracking of care recipients. Additionally, the study improves and enhances the real-time multi-person action analysis feature of OpenPose to enhance its analytical capabilities for various fall scenarios, enabling accurate analysis of the approximate real-time situation when a care recipient falls. In the experimental results, the system’s identification accuracy for four fall directions is higher than that of Google Teachable Machine’s Pose Project training model. Particularly, there is the significant improvement in identifying backward falls, with the identification accuracy increasing from 70.35% to 95%. Furthermore, the identification accuracy for forward and leftward falls also increases by nearly 14%. Therefore, the experimental results demonstrate that the improved identification accuracy for the four fall directions in different scenarios exceeds 95%.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A machine learning approach for the design optimization of a multiple magnetic and inertial sensors wearable system for the spine mobility assessment\n",
            "Authors: Domínguez-Jiménez D.Y.\n",
            "Abstract: Background: Recently, magnetic and inertial measurement units (MIMU) based systems have been applied in the spine mobility assessment; this evaluation is essential in the clinical practice for diagnosis and treatment evaluation. The available systems are limited in the number of sensors, and neither develops a methodology for the correct placement of the sensors, seeking the relevant mobility information of the spine. Methods: This work presents a methodology for analyzing a system consisting of sixteen MIMUs to reduce the amount of information and obtain an optimal configuration that allows distinguishing between different body postures in a movement. Four machine learning algorithms were trained and assessed using data from the range of motion in three movements (Mov.1—Anterior hip flexion; Mov.2—Lateral trunk flexion; Mov.3—Axial trunk rotation) obtained from 12 patients with Ankylosing Spondylitis. Results: The methodology identified the optimal minimal configuration for different movements. The configuration showed good accuracy in discriminating between different body postures. Specifically, it had an accuracy of 0.963 ± 0.021 for detecting when the subject is upright or bending in Mov.1, 0.944 ± 0.038 for identifying when the subject is flexed to the left or right in Mov.2, and 0.852 ± 0.097 for recognizing when the subject is rotated to the right or left in Mov.3. Conclusions: Our results indicate that the methodology developed results in a feasible configuration for practical clinical studies and paves the way for designing specific IMU-based assessment instruments. Trial registration: Study approved by the Local Ethics Committee of the General Hospital of Mexico “Dr. Eduardo Liceaga” (protocol code DI/03/17/471).\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Design of flexible polyimide-based serpentine EMG sensor for AI-enabled fatigue detection in construction\n",
            "Authors: Gautam Y.\n",
            "Abstract: Physical fatigue and musculoskeletal disorders are critical health issues for construction workers, stemming from repetitive motions, heavy lifting, and awkward postures. These factors compromise worker well-being, productivity, and safety while increasing the risk of accidents and long-term health problems. Recent advancements in wearable health monitoring technology offer potential solutions, but current sensors encounter significant challenges in the dynamic construction environment. These include inadequate skin contact, increased contact impedance, and vulnerability to motion artifacts all of which degrade signal quality and reduce the accuracy of fatigue detection. This paper develops a fractal-based, flexible sensor for enhanced adaptability and accurate fatigue estimation. Finite element analysis compared five space-filling designs, with the serpentine curve exhibiting the highest contact area and lowest strain, making it the preferred choice for fabrication. Evaluations demonstrated significant improvements in signal-to-noise ratio (SNR) and motion artifact reduction, with the newly developed sensor achieving a 37 % to 59 % SNR improvement over commercial electrodes across different muscle groups. The developed flexible sensor was integrated with a fatigue-detecting framework based on a vision transformer model which provided an average accuracy of 87 % for fatigue detection. The developed sensor significantly enhances EMG signal quality and reliability, promising improved health monitoring and safety for construction workers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Evaluating functional ability in older adults’ object retrieval behavior from kitchen furniture using OpenPose and REBA\n",
            "Authors: Zhou C.\n",
            "Abstract: The purpose of this study is to evaluate, through analysis, the ability of older persons to retrieve items from kitchen cabinets. To achieve this goal, data were collected from 128 valid questionnaires and supplemented with field research and user interviews. The study revealed that the elderly’s behavior in retrieving items from kitchen spaces is characterized by both high frequency and difficulty. For this experiment, a total of 42 participants, comprising 21 males and 21 females from the self-care elderly population in the Yangtze River Delta region, were recruited. Two different experimental settings were arranged: one with kitchen utensils arranged in a straight line and another with a purpose-made chest of drawers with varying heights. Video recordings using the Logitech C930C were utilized to capture the gestures and behaviors of the elderly while retrieving objects from the kitchen cupboards (cabinets). By employing a combination of the OpenPose model and the Rapid Entire Body Assessment (REBA) method, which involves calculating human posture angles, REBA scores, and determining the risk level of Work-Related Musculoskeletal Disorders (WMSDs), a risk assessment framework for manual operations associated with WMSDs was developed. Using the angle data acquired from the user operation experiment as parameters, a gradient model of the elderly user’s operational capability was established. The findings indicated a significant impact of neck, trunk, and knee movements on the subjects (P < 0.001). The participants were able to distinguish between different levels of exertion, categorizing movements as ‘easy’, ‘moderate,’ or ‘strenuous.’ These results form the basis for a comfort gradient model for leaning over and retrieving items. Given the prevalent conditions of bone and joint degeneration and osteoporosis among the elderly population, it is evident that they face challenges when accessing items in the kitchen. Therefore, investigating the elderly’s execution abilities during the retrieval process becomes crucial. Understanding how different cabinet heights impact the joint angles of the elderly can be instrumental in optimizing cabinet designs for elderly users, thereby reducing their physical exertion in the kitchen and enhancing their comfort levels. This research holds significant value in improving the quality of life for the elderly population at home and fostering the advancement of elderly-friendly design principles.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: LSTM-CNN Architecture for Construction Activity Recognition Using Optimal Positioning of Wearables\n",
            "Authors: Piyush \n",
            "Abstract: Enhancing construction worker performance, safety, and project management through automated activity classification is a promising endeavor. By extracting activity-level information, this technology provides valuable insights for informed decision-making, facilitating project schedule adjustments, efficient resource management, and improved construction site control. Previous studies in this domain focused on basic activities, neglecting optimal sensor placement and no regard for worker comfort. This paper extends beyond existing research, encompassing a broader range of complex construction activities and surpassing current methods. Utilizing unobtrusive wearables like a smartwatch and smartphone, the study determines optimal sensor positions (dominant/nondominant wrist, dominant/nondominant leg pocket). Notably, it introduces a novel deep neural network structure, merging long short-term memory (LSTM) and convolutional layers, offering an innovative solution for automated activity classification tasks in the construction industry. This model extracts activity features automatically reducing the need for manual feature engineering and performs classification with few model parameters indicating efficiency in terms of computational resources and memory requirements making the model more suitable for real-time applications and deployment on resource-constrained devices. By leveraging the strengths of both convolutional layers and LSTM, this approach offers a powerful and efficient solution for activity classification tasks. An experimental study was carried out to recognize four different activities: manual excavation, rebar stirrups, cement plastering, and bar binding. These were performed by four subjects (three males and one female) for 30 s each with different positions of smartwatch and smartphone producing 24,080 data points. Results indicate the optimal positioning of wearables to be smartwatch on dominant hand and smartphone on opposite leg pocket because of a balanced and effective coverage of the relevant movements and contextual information yielding 98.18% accuracy, 98.20% precision, 98.17% recall, and F1 score of 98.17%.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Influence of hip prosthesis position on postoperative gait in symptomatic hip osteoarthritis secondary to hip dysplasia patients after primary total hip arthroplasty: a short-term follow-up study\n",
            "Authors: Wang Y.\n",
            "Abstract: Background: The aim of this study was to analyze the influence of the positioning of the components of total hip arthroplasty (THA) evaluated by the acetabular anteversion (AA) and femoral anteversion (FA) angle on postoperative gait in patients with symptomatic hip osteoarthritis secondary to hip dysplasia undergoing THA. Methods: Between May 2023 and May 2024, patients with symptomatic hip osteoarthritis secondary to hip dysplasia (Crowe Type I and IV) who underwent THA were enrolled in the study. The AA angle and FA angle were measured by computer tomography (CT). Gait data were determined by using the Dynamic Right Gait & Posture analysis system. The relationship between FA, AA and gait data was analyzed by Pearson correlation test, subgroup Pearson correlation test, multiple linear regression. Results: A total of 40 patients (45hips) were included in the study. Compared with preoperative, the patient’s postoperative foot progression angle, foot contact angle, plantarflexion velocity, swing foot speed, gait velocity, cadence, stride length were significantly improved. Preoperative FA is significantly different from postoperative FA (P < 0.05), while the difference between preoperative and postoperative AA is not significant. BMI, Crowe Type, AA were related to change of cadence. The less the postoperative AA of patients, and the more the cadence in the postoperative gait of patients. Conclusion: Our study showed that THA could improve the gait function of patients with symptomatic hip osteoarthritis secondary to hip dysplasia. Adjusting AA lower could obtain a much more postoperative cadence.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Digital ergonomic assessment to enhance the physical resilience of human-centric manufacturing systems in Industry 5.0\n",
            "Authors: Tomelleri F.\n",
            "Abstract: The emergence of Industry 5.0 promotes the creation of human-centric values. To fulfill this objective, Internet of Things (IoT) technologies are increasingly being exploited to digitize the human factor and monitor the ergonomics of manual manufacturing systems. These digital assessments, combined with computational algorithms, contribute to the establishment of socially inclusive workplaces while offering detailed insights to safeguard the health of the aging workforce. In this scenario, this study proposes a digital architecture for evaluating the European Assembly Worksheet (EAWS) in human-centric manufacturing systems. Three distinct enabling technologies are leveraged to acquire heterogeneous data streams. A radio-frequency-based smart glove detects the operator's interactions with the surrounding environment, while a network of marker-less cameras and a four-channel surface Electromyography (sEMG) system capture body joint movements and muscular contractions of the upper limbs, respectively. The acquired data are processed by computational algorithms to define an EAWS-driven set of Key Risk Indicators (KRIs), embedded in an ergonomic decision support system. These risk metrics highlight operator-driven process weaknesses in musculoskeletal, muscular, and material handling dimensions. Finally, the validity of the proposed digital architecture is demonstrated in an industrial-related pilot environment, where an operator assembles a piece of home furniture.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Proactive prevention of work-related musculoskeletal disorders using a motion capture system and time series machine learning\n",
            "Authors: Matos L.M.\n",
            "Abstract: In this paper, we propose a proactive method to prevent Work-related MusculoSkeletal Disorders (WMSDs) in manufacturing industries. The integrated method includes a Motion Capture System (MCS) for data collection, a Time Series Forecasting (TSF) module using Machine Learning (ML) algorithms, a WMSD risk assessment module based on ergonomic standards, and a safety mechanism (e.g., alarm sound). We evaluated the method by analyzing shoulder abduction, rotation, and flexion movements of 12 participants working with textile machines. The computational experiments included a comparison of four ML algorithms and a baseline Naive method using a 12-fold participant cross-validation approach. Overall, the best Ahead-of-Time (AoT) TSF and WMSD risk detection empirical results were obtained by a Support Vector Machine (SVM), which required a reasonable training computational effort and provides an interesting performance for AoT TSF and high risk WMSD detection.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Intelligent ergonomic optimization in bimanual worker-robot interaction: A Reinforcement Learning approach\n",
            "Authors: Amani M.\n",
            "Abstract: Robots have the potential to enhance safety on construction job sites by assuming hazardous tasks. While existing safety research on physical human-robot interaction (pHRI) primarily addresses collision risks, ensuring inherently safe collaborative workflows is equally important. For example, ergonomic optimization in co-manipulation is an important safety consideration in pHRI. While frameworks such as Rapid Entire Body Assessment (REBA) have been an industry standard for these interventions, their lack of a rigorous mathematical structure poses challenges for using them with optimization algorithms. Previous works have tackled this gap by developing approximations or statistical approaches that are error-prone or data-dependent. This paper presents a framework using Reinforcement Learning for precise ergonomic optimization that generalizes to different types of tasks. To ensure practicality and safe experimentations, the training leverages Inverse Kinematics in virtual reality to simulate human movement mechanics. Results of a comparison between the developed framework and ergonomically naive approaches are presented.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: ERG-AI: enhancing occupational ergonomics with uncertainty-aware ML and LLM feedback\n",
            "Authors: Sen S.\n",
            "Abstract: Workers, especially those involved in jobs requiring extended standing or repetitive movements, often face significant health challenges due to Musculoskeletal Disorders (MSDs). To mitigate MSD risks, enhancing workplace ergonomics is vital, which includes forecasting long-term employee postures, educating workers about related occupational health risks, and offering relevant recommendations. However, research gaps remain, such as the lack of a sustainable AI/ML pipeline that combines sensor-based, uncertainty-aware posture prediction with large language models for natural language communication of occupational health risks and recommendations. We introduce ERG-AI, a machine learning pipeline designed to predict extended worker postures using data from multiple wearable sensors. Alongside providing posture prediction and uncertainty estimates, ERG-AI also provides personalized health risk assessments and recommendations by generating prompts based on its performance and prompting Large Language Model (LLM) APIs, like GPT-4, to obtain user-friendly output. We used the Digital Worker Goldicare dataset to assess ERG-AI, which includes data from 114 home care workers who wore five tri-axial accelerometers in various bodily positions for a cumulative 2913 hours. The evaluation focused on the quality of posture prediction under uncertainty, energy consumption and carbon footprint of ERG-AI and the effectiveness of personalized recommendations rendered in easy-to-understand language.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Intelligent systems for sitting posture monitoring and anomaly detection: an overview\n",
            "Authors: Vermander P.\n",
            "Abstract: The number of people who need to use wheelchair for proper mobility is increasing. The integration of technology into these devices enables the simultaneous and objective assessment of posture, while also facilitating the concurrent monitoring of the functional status of wheelchair users. In this way, both the health personnel and the user can be provided with relevant information for the recovery process. This information can be used to carry out an early adaptation of the rehabilitation of patients, thus allowing to prevent further musculoskeletal problems, as well as risk situations such as ulcers or falls. Thus, a higher quality of life is promoted in affected individuals. As a result, this paper presents an orderly and organized analysis of the existing postural diagnosis systems for detecting sitting anomalies in the literature. This analysis can be divided into two parts that compose such postural diagnosis: on the one hand, the monitoring devices necessary for the collection of postural data and, on the other hand, the techniques used for anomaly detection. These anomaly detection techniques will be explained under two different approaches: the traditional generalized approach followed to date by most works, where anomalies are treated as incorrect postures, and a new individualized approach treating anomalies as changes with respect to the normal sitting pattern. In this way, the advantages, limitations and opportunities of the different techniques are analyzed. The main contribution of this overview paper is to synthesize and organize information, identify trends, and provide a comprehensive understanding of sitting posture diagnosis systems, offering researchers an accessible resource for navigating the current state of knowledge of this particular field.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A comprehensive analysis of the machine learning pose estimation models used in human movement and posture analyses: A narrative review\n",
            "Authors: Roggio F.\n",
            "Abstract: The accurate measurement and analysis of human movement are essential in fields ranging from rehabilitation and neuroscience to sports science and ergonomics. Traditional methods, though precise, are often constrained by cost, accessibility, and controlled environments. The advent of machine learning (ML) pose estimation models (PEMs) offers an alternative solution, enabling detailed motion analysis using low-cost imaging systems in various settings. The aim of this review is to evaluate ML PEMs and their impact on human movement sciences, focusing on recent advancements in machine learning and computer vision for accurate, non-invasive motion analysis using low-cost imaging systems. A narrative review was conducted by searching electronic databases, including PubMed and Google Scholar, using key terms such as “machine learning,” \"pose estimation models,\" and “human movement sciences.” Thematic analysis identified key advancements, applications, and challenges in ML PEMs across clinical, sports, and ergonomic contexts. The review highlights the development, capabilities, and applications of models such as OpenPose, PoseNet, AlphaPose, DeepLabCut, HRNet, MediaPipe Pose, BlazePose, EfficientPose, and MoveNet, emphasizing their potential for non-invasive, cost-effective assessments. In clinical settings, these models enable objective gait and posture analysis, aiding in diagnosing musculoskeletal disorders and tracking rehabilitation progress. In sports, ML PEMs enhance performance analysis and injury prevention by providing real-time feedback and detailed biomechanical data. In ergonomics, they offer proactive solutions for workplace injury prevention through real-time posture and movement analysis. While promising, the implementation of ML PEMs faces challenges in accuracy, data quality, and integration into existing practices. Establishing standardized protocols and frameworks is crucial for ensuring reliable, interdisciplinary applications. This review can be useful for coaches, healthcare professionals, and researchers in evaluating and implementing ML PEMs, ultimately advancing the field of human movement sciences.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Biomechanics of Parkinson’s Disease with Systems Based on Expert Knowledge and Machine Learning: A Scoping Review\n",
            "Authors: Sánchez-Fernández L.P.\n",
            "Abstract: Patients with Parkinson’s disease (PD) can present several biomechanical alterations, such as tremors, rigidity, bradykinesia, postural instability, and gait alterations. The Movement Disorder Society–Unified Parkinson’s Disease Rating Scale (MDS-UPDRS) has a good reputation for uniformly evaluating motor and non-motor aspects of PD. However, motor clinical assessment depends on visual observations, which are mostly qualitative, with subtle differences not recognized. Many works have examined evaluations and analyses of these biomechanical alterations. However, there are no reviews on this topic. This paper presents a scoping review of computer models based on expert knowledge and machine learning (ML). The eligibility criteria and sources of evidence are represented by papers in journals indexed in the Journal Citation Report (JCR), and this paper analyzes the data, methods, results, and application opportunities in clinical environments or as support for new research. Finally, we analyze the results’ explainability and the acceptance of such systems as tools to help physicians, both now and in future contributions. Many researchers have addressed PD biomechanics by using explainable artificial intelligence or combining several analysis models to provide explainable and transparent results, considering possible biases and precision and creating trust and security when using the models.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Decision Support System (DSS) for Improving Production Ergonomics in the Construction Sector\n",
            "Authors: Sardinha L.\n",
            "Abstract: Ergonomics is essential to improving workplace safety and efficiency by reducing the risks associated with physical tasks. This study presents a decision support system (DSS) aimed at enhancing production ergonomics in the construction sector through an analysis of high-risk postures. Using the Ovako Work Posture Analysis System (OWAS), the Revised NIOSH Lifting Equation (NIOSH equation) and Rapid Entire Body Assessment (REBA), the DSS identifies ergonomic risks by assessing body postures across common construction tasks. Three specific postures—X, Y and Z—were selected to represent typical construction activities, including lifting, squatting and repetitive tool use. Posture X, involving a forward-leaning stance with arms above the shoulders and a 25 kg load, was identified as critical, yielding the highest OWAS and NIOSH values, thus indicating an immediate need for corrective action to mitigate risks of musculoskeletal injuries. The DSS provides recommendations for workplace adjustments and posture improvements, demonstrating a robust framework that can be adapted to other postures and industries. Future developments may include application to other postures and sectors, as well as the use of artificial intelligence to support ongoing ergonomic assessments, offering a promising solution to enhance Occupational Safety and Health policies.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Multi-Scale and Multi-Stage Human Pose Recognition Method Based on Convolutional Neural Networks for Non-Wearable Ergonomic Evaluation\n",
            "Authors: Zhao W.\n",
            "Abstract: In the context of industrial robot maintenance and assembly, workers often suffer from work-related musculoskeletal disorders (WRMSDs). This paper proposes a multi-scale, multi-stage pose recognition method (MMARM-CNN) based on convolutional neural networks to provide ergonomic intervention. The method leverages computer vision technology to enable non-contact data acquisition, reducing the interference of physiological and psychological factors on assessment results. Built upon the baseline yolov8-pose framework, the method addresses complex maintenance environments, which are prone to occlusion, by introducing the Lightweight Shared Convolutional Detection Head-pose (LSCD-pose) module, Multi-Scale Channel Attention (MSCA) mechanism, and Efficient Multi-Scale Patch Convolution (EMSPC) module, enhancing the model’s feature extraction capabilities. The MMARM-CNN model was validated using the MS COCO 2017 dataset and robot assembly data collected under laboratory conditions. The experimental results show that the MMARM-CNN achieved an accuracy improvement, reaching 0.875 in the mAP@0.5 evaluation. Overall, this method demonstrates significant potential in advancing the automation and intelligence of ergonomic interventions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Establishing the Reliability of the GaitON<sup>®</sup> Motion Analysis System: A Foundational Study for Gait and Posture Analysis in a Healthy Population\n",
            "Authors: Alam M.F.\n",
            "Abstract: Background: Gait and posture analysis plays a crucial role in understanding human movement, with significant applications in rehabilitation, sports science, and clinical settings. The GaitON® system, a 2D motion analysis tool, provides an accessible and cost-effective method for assessing gait and posture. However, its reliability in clinical practice, particularly for intra-rater consistency, remains to be evaluated. This study aims to assess the intra-rater reliability of the GaitON® system in a healthy population, focusing on gait and posture parameters. Methods: A total of 20 healthy participants (10 males and 10 females) aged 18 to 50 years were recruited for the study. Each participant underwent gait and posture assessments using the GaitON® system on two separate occasions, spaced one week apart. Video recordings from anterior and posterior views were used to analyze gait, while images from anterior, posterior, and lateral views were captured to assess posture with markers placed on key anatomical landmarks. The reliability of the measurements was analyzed using intraclass correlation coefficients (ICC), a standard error of measurement (SEM), and the smallest detectable difference (SDD) method. Results: The GaitON® system demonstrated excellent intra-rater reliability across a wide range of gait and posture parameters. ICC values for gait parameters, including hip, knee, and ankle joint angles, ranged from 0.90 to 0.979, indicating strong consistency in repeated measurements. Similarly, ICC values for posture parameters, such as the head alignment, shoulder position, and ASIS alignment, were above 0.90, reflecting excellent reliability. SEM values were low across all parameters, with the smallest SEM recorded for the hip joint angle (0.37°), and SDD values further confirmed the precision of the system. Conclusion: The GaitON® system provides reliable and consistent measurements for both gait and posture analysis in healthy individuals. Its high intra-rater reliability and low measurement error make it a promising tool for clinical and sports applications. Further research is needed to validate its use in clinical populations and compare its performance to more complex 3D motion analysis systems.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Sensor placement determination for a wearable device in dual-arm manipulation tasks\n",
            "Authors: Urukalo D.\n",
            "Abstract: To enhance the quality of life for individuals in various sectors, such as industry, healthcare, and everyday activities, the development of a highly efficient and cost-effective wearable device is essential. This paper presents a feasibility study for a general estimation methodology for human activity assessment using a single sensor placed on the back. The methodology considers the minimal variability in human body movements when carrying different weights. Our approach involves optimizing the sensor's position through a simple pre-processing technique. This technique utilizes virtual sensor position and orientation data derived from a virtual mannequin based on real inertial measurement unit (IMU) measurements obtained during two-arm manipulation tasks in a warehouse setting. The primary contribution is the optimization of a single, non-invasive sensor placement on the back to accurately assess activities involving two-hand manipulation with low variability in movement. We identified 54 different activity classes with an accuracy of 91.77% using a hybrid two-dimensional Convolutional Neural Network (CNN) combined with a Bidirectional Long Short-Term Memory (BiLSTM) network (2D CNN-BiLSTM) model. This model does not require additional sensors that measure other physical quantities, such as electromyography activity. Identifying repetitive tasks involving significant bending, stretching, and twisting, which pose risks of musculoskeletal disorders and back pain, offers a solution for designing wearable devices. The portability and autonomy of these devices are crucial, and current sensor technology meets these needs with low size, cost, and consumption. Wearable medical devices can thus be effectively used for self-monitoring health, preventive medicine, and rehabilitation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Virtual reality in ergonomics by wearable devices: experiences from the automotive sector\n",
            "Authors: Carnazzo C.\n",
            "Abstract: Purpose: Preventive ergonomics is essential to protecting the health and safety of workers as is recognizing human variability. The purpose of this paper is to describe a Unity-based application designed for three-dimensional postural analysis and visualizations using motion capture data. Integration with virtual reality (VR) technologies allows the user to be immersed in the simulated working environment without the need for a physical prototype. The proposed application aims to facilitate the application of ergonomic principles in workplace design and assessment for a proactive, participatory and inclusive approach to worker well-being. Design/methodology/approach: The authors developed an application that leverages motion capturing techniques and VR technologies and aims to support the analysts in the ergonomic assessment of physical prototypes as well as future workplaces. An innovative postural prediction module helps the analyst understanding what postures different users are likely to assume in the interaction with the workplace from a single data record. Findings: The functionalities of the proposed application are illustrated on some case studies, presenting how different information is made available and can support workplace analysts and designers in an industrial context. Originality/value: This paper provides insights into the experience and research carried out by an automotive company in the application of wearable sensors and VR to support a proactive and participatory approach to workplace ergonomics.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: View Selection of Safety Managers Affects Their Ability to Evaluate Safety Level of Workers\n",
            "Authors: Tian X.\n",
            "Abstract: Evaluating the safety level of work behaviors is an important means of safety management through safety managers’ manual visual or video surveillance. This paper aims to grasp the view selection rules of safety managers in correctly observing and analyzing work behavior, which are conducive to safety behavior assessment. Firstly, based on a similarity simulation experiment, the work process of the operators was simulated, and the process was simultaneously monitored from multiple views to obtain surveillance videos. Then, safety managers with different experience levels watched the videos and answered the questionnaire in a questionnaire survey experiment. The authors found the following: (1) Prior experience does not affect the view selection during the observation stage, but it does affect the view selection during the analysis stage. Experienced safety managers perform better in view selection when dealing with complex tasks. (2) The work postures have a significant effect on the view type and their combination order. (3) The view selection of experienced safety managers in the behavior observation and analysis stages is non-constant except for sitting posture operations, while the view selection of amateur managers is always constant. (4) Sitting posture work takes the front view as the main view and the left–right–upper views as auxiliary views; standing posture uses the left and right views as the main views and the front–back–upper views as auxiliary views; and mixed posture takes the left and right views as the main views and the upper–front–back views as auxiliary views. These view selection rules can achieve the highest evaluation performance. These findings can help train or select high-quality safety managers and provide a scientific basis for arranging views during video surveillance.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Monocular 3D Multi-Person Pose Estimation for On-Site Joint Flexion Assessment: A Case of Extreme Knee Flexion Detection\n",
            "Authors: Yan G.\n",
            "Abstract: Work-related musculoskeletal disorders (WMSDs) represent a significant health challenge for workers in construction environments, often arising from prolonged exposure to ergonomic risks associated with manual labor, awkward postures, and repetitive motions. These conditions not only lead to diminished worker productivity but also incur substantial economic costs for employers and healthcare systems alike. Thus, there is an urgent need for effective tools to assess and mitigate these ergonomic risks. This study proposes a novel monocular 3D multi-person pose estimation method designed to enhance ergonomic risk assessments in construction environments. Leveraging advanced computer vision and deep learning techniques, this approach accurately captures and analyzes the spatial dynamics of workers’ postures, with a focus on detecting extreme knee flexion, a critical indicator of work-related musculoskeletal disorders (WMSDs). A pilot study conducted on an actual construction site demonstrated the method’s feasibility and effectiveness, achieving an accurate detection rate for extreme flexion incidents that closely aligned with supervisory observations and worker self-reports. The proposed monocular approach enables universal applicability and enhances ergonomic analysis through 3D pose estimation and group pose recognition for timely interventions. Future efforts will focus on improving robustness and integration with health monitoring to reduce WMSDs and promote worker health.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Safety 4.0: Harnessing computer vision for advanced industrial protection\n",
            "Authors: Yousif I.\n",
            "Abstract: In the pursuit of enhanced productivity, reduced costs, and minimized lead times, manufacturers are transitioning from traditional systems to autonomous systems. This shift, driven by the emergence of smart manufacturing and technological advancements such as robotics, collaborative robots (Cobots), automation, and digitalization, necessitates a parallel evolution in safety protocols—termed Safety 4.0—to mitigate the risks associated with such dynamic environments. The integration of smart technologies within manufacturing significantly transforms traditional workflows and intensifies the need for comprehensive safety training and guidelines. Innovations like smart personal protective equipment (PPE) and wearable sensors are pivotal in this transition, yet they often prove financially burdensome for manufacturers due to high costs and the scale of workforce deployment. Moreover, the effective use of these technologies requires continuous monitoring and data analysis, further straining resources. To address these challenges, this paper proposes the adoption of computer vision technology to enhance safety measures within manufacturing facilities, focusing on human and PPE detection. It details a holistic methodology encompassing data collection, preprocessing, training, and execution. The discussion extends to the implementation framework of this technology, emphasizing its role in enabling autonomous decision-making—a crucial step beyond mere detection. Furthermore, the paper explores the utilization of the accumulated data to develop immersive training modules employing Mixed Reality, thereby reinforcing safety protocols and fostering an environment of continuous learning and adaptation. This approach not only contributes to safeguarding personnel but also aligns with the financial and reputational interests of forward-thinking manufacturers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of a real-time work-related postural risk assessment system of farm workers using a sensor-based artificial intelligence approach\n",
            "Authors: Singh L.P.\n",
            "Abstract: In recent years, the promotion of farm mechanization has been directed toward reducing the human discomfort and fatigue associated with various agricultural work-related activities. During these activities, many factors (like force, awkward posture, vibration, repetition, etc.) play a significant role in causing musculoskeletal disorders. Second, ergonomic risk assessment of physical work is conventionally conducted through observation and direct/indirect physiological measurements. However, these methods are time-consuming and require human subjects to perform the motion to obtain detailed body movement data. In the present study, a semiautomatic rapid entire body assessment (REBA) evaluation tool is developed for real-time assessment of agricultural work-related musculoskeletal disorders risk of farm workers using Kinect V2 sensor-based artificial intelligence approach. It allows the investigator speedy detect of awkward postures leading to critical conditions and to reduce subjective bias. It is useful to analyze online as well as offline posture analysis, it detects the critical areas of the body posture, which may lead to the musculoskeletal disorders of agricultural workers, and suggest aptly to correct the posture. The Kinect V2 REBA assessment score was found with a factual significant match with the reference expert evaluation as reflected by the Landis and Koch scale k = 0.673 (p < 0.001), 95% confidence interval (CI) for the left side, and k = 0.644 (p < 0.001), 95% CI for the right side of the body respectively.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A high-precision multi-human body pose estimation approach for near-electricity work in substations\n",
            "Authors: Ma J.\n",
            "Abstract: Accurate human pose estimation is crucial for precisely locating key points of human body during the near-electricity work in substations. However,traditional detection methods often suffer from low accuracy,missed detections,and misdetections due to occlusion by limb or equipment. To address these challenges,the paper proposes a high-precision multi-human body pose estimation method tailored for near-electricity work in substations. First,a deformable convolutional network(DCN)is embedded into the backbone network,enabling the model to autonomously learn human joint features and enhancing its geometric modeling capabilities. Second,a feature pyramid network is constructed based on the ConvNeXt v2 Block as the neck structure. This strengthens feature interaction learning through cross-scale connections. In the prediction head,the coordinate attention(CA)mechanism is introduced to further capture channel and spatial information of feature maps. Finally,by improving the original loss function,the model’s convergence speed is accelerated. The results show that,compared to the baseline model, the proposed model’s average detection accuracies P0.50,P0.75,and P have increased by 2.7%,7.3%,and 4.2%,respectively. This provides significant technical support for the safety of near-electricity workers in complex substation environments.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A SYSTEM FOR MONITORING THE PROGRESS OF REHABILITATION OF PATIENTS WITH MUSCULOSKELETAL DISORDER\n",
            "Authors: Barkovska O.\n",
            "Abstract: The work is devoted to the development of a system for monitoring the rehabilitation process of patients with musculoskeletal disorders, as well as identifying possible postural distortions in both children and adults based on anthropometric data, which confirms the relevance and practical significance of the work during the period of military operations in Ukraine and a large number of people with musculoskeletal injuries. The paper proposes a model of a system consisting of two subsystems: A subsystem for collecting pododynamic parameters based on a dynamic baropodometric platform and a visual posture monitoring subsystem. The combination of different gait and posture analysis methods in a single system provides high diagnostic and prognostic value. The main purpose of the proposed system is to monitor the progress of patient rehabilitation using hardware and computer-optical diagnostic methods without radiation exposure with the ability to easily transport the created system, the possibility of high-precision diagnostics in real time, as well as the ability to store and analyze changes in the musculoskeletal system over time. For the collection and analysis of pododynamometric parameters, computer data visualization methods, methods of statistical and dynamic data analysis, and data segmentation methods were used. To collect and analyze anthropometric parameters, methods of detecting objects in the image, methods of computer classification, segmentation and image processing, methods of analyzing graphic information were used. In addition, the paper researches the influence of marker characteristics (shape, color model of representation) and lighting conditions during the acquisition of kinematic parameters on the accuracy of marker detection for further determination of the angles of the pelvis and shoulder line. The results obtained by using the hybrid marker detection algorithm show that the representation of any of the used shapes in all the colors under study in the presence of additional lighting gives 100% marker detection accuracy, only in the HSV color model for a simple scene. The RGB model provides 100% accuracy in detecting only yellow markers with additional lighting. In the absence of the possibility of using additional lighting, only round markers in all the studied colors represented in the HSV color model can achieve 100% accuracy. For a complex scene, representing the input images in the RGB color model does not allow achieving 100% accuracy for any of the marker shapes and colors, even with additional lighting. The highest accuracy for a complex scene is also shown by round markers colored in green or orange, regardless of the presence of additional lighting. Further research will focus on expanding the range of system parameters necessary for diagnosing the patient's condition and analyzing the course of treatment using electromyographic indicators.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Sitting Posture Recognition Systems: Comprehensive Literature Review and Analysis\n",
            "Authors: Nadeem M.\n",
            "Abstract: Sitting posture recognition systems have gained significant attention due to their potential applications in various domains, including healthcare, ergonomics, and human-computer interaction. This paper presents a comprehensive literature review and analysis of existing sitting posture recognition systems. Through an extensive examination of relevant research articles and conference papers, we identify and analyze the underlying technologies, methodologies, datasets, performance metrics, and applications associated with these systems. The review encompasses both traditional methods, such as vision-based approaches and sensor-based techniques, as well as emerging technologies such as machine learning and deep learning algorithms. Additionally, we examine the challenges, constraints, and future trends in the field of sitting posture recognition systems. Researchers, practitioners, and policymakers who want to comprehend the most recent developments and latest trends in sitting posture recognition technology will find great value in this study.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Wearable Technology and Its Influence on Motor Development and Biomechanical Analysis\n",
            "Authors: Morouço P.\n",
            "Abstract: The convergence among biomechanics, motor development, and wearable technology redefines our understanding of human movement. These technologies allow for the continuous monitoring of motor development and the state of motor abilities from infancy to old age, enabling early and personalized interventions to promote healthy motor skills. For athletes, they offer valuable insights to optimize technique and prevent injuries, while in old age, they help maintain mobility and prevent falls. Integration with artificial intelligence further extends these capabilities, enabling sophisticated data analysis. Wearable technology is transforming the way we approach motor development and maintenance of motor skills, offering unprecedented possibilities for improving health, performance, and quality of life at every stage of life. The promising future of these technologies paves the way for an era of more personalized and effective healthcare, driven by innovation and interdisciplinary collaboration.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Data-driven ergonomic assessment of construction workers\n",
            "Authors: Li Z.\n",
            "Abstract: Automating ergonomic assessment improves both objectivity and cost-effectiveness. However, existing ergonomic scales remain susceptible to inaccuracy and insensitivity when assessing diversified construction activities. This susceptibility stems from the unreliable ranges, sharp boundaries, and oversimplified binary rules within conventional joint-level assessment rules, coupled with the restricted transformation rules to integer input/output. This paper presents a data-driven ergonomic assessment method grounded in statistical data from Construction Motion Data Library (CML) dataset, comprising: 1) Developing joint-level scoring models to primarily improve accuracy through leveraging Heuristics Gaussian Cloud Transformation (H-GCT), and 2) Designing fuzzy inference mechanism to enhance sensitivity through retaining risk information during transformation across levels. Subsequently, a three-step validation confirms accurate risk identification, sensitive risk feedback, and positive correlation with previous methods, contributing to occupational health and safety management. Future research could enhance the method by expanding the pose dataset, recruiting more participants, and refining the 3D pose estimation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Monitoring and evaluating the status and behaviour of construction workers using wearable sensing technologies\n",
            "Authors: Wang M.\n",
            "Abstract: Wearable sensing technologies (WSTs) are valuable in monitoring status and behaviour of construction workers, providing insights into their response under varying conditions and potentially improving their performance. Despite their importance, a comprehensive review of WSTs for evaluating construction worker behaviour and status is lacking. This paper conducted a quantitative and qualitative review of relevant studies. A bibliometric analysis revealed the selected 200 publications between 2011 and 2023 focusing on musculoskeletal disorders, worker activity, worker status, construction safety and occupational risks. Accordingly, a knowledge framework was proposed for evaluating workers' status and behaviour, compassing data collection, artifact removal, analysis, worker evaluation, and applications. Following a qualitative review, six future research directions were identified: sensor selection and placement, experiment validity, end-to-end data analysis, data fusion, human-technology interaction, and modelling worker status. This review provides the current research state and future trends, aiding the practical implementations of wearable technologies on construction sites.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Recognizing sitting activities of excavator operators using multi-sensor data fusion with machine learning and deep learning algorithms\n",
            "Authors: Li J.\n",
            "Abstract: Recognizing excavator operators' sitting activities is crucial for improving their health, safety, and productivity. Moreover, it provides essential information for comprehending operators' behavior patterns and their interaction with construction equipment. However, limited research has been conducted on recognizing excavator operators' sitting activities. This paper presents a method for recognizing excavator operators' sitting activities by leveraging multi-sensor data and employing machine learning and deep learning algorithms. A multi-sensor system integrating interface pressure sensor arrays and inertial measurement units was developed to capture excavator operators' sitting activity information at a real construction site. Results suggest that the gated recurrent unit achieved outstanding performance, with 98.50% accuracy for static sitting postures and 94.25% accuracy for compound sitting actions. Moreover, several multi-sensor combination schemes were proposed to strike a balance between practicability and recognition accuracy. These findings demonstrate the feasibility and potential of the proposed approach for recognizing operators' sitting activities on construction sites.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Identifying unsafe behaviors of construction workers through an unsupervised multi-anomaly GAN approach\n",
            "Authors: Ding C.\n",
            "Abstract: Unsafe behaviors of construction workers often lead to construction accidents, while traditional safety monitoring methods have low efficiency and timeliness. Although deep learning has been widely applied in detecting construction site unsafe behaviors, most studies still focus on supervised learning for detecting personal protective equipment use, with less emphasis on worker behaviors. This study developed an unsupervised learning model, Multi-Anomaly GAN, based on GAN with five pseudo anomaly synthesizers to detect unsafe behaviors of construction workers. First, the WeTeam22 dataset was built with tower crane edge scenarios to compensate for the lack of construction worker behavior datasets. After training on WeTeam22, Multi-Anomaly GAN achieved better results in AUC, EER, and F1 score compared to baseline methods. The model effectively identified unsafe behaviors during testing. The study proves the effectiveness of Multi-Anomaly GAN in detecting unsafe construction site behaviors, providing a novel and valid detection scheme for this problem.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Use of a wearable electromyography armband to detect lift-lower tasks and classify hand loads\n",
            "Authors: Taori S.\n",
            "Abstract: We used an armband with embedded surface electromyography (sEMG) electrodes, together with machine-learning (ML) models, to automatically detect lifting-lowering activities and classify hand loads. Nine healthy participants (4 male and 5 female) completed simulated lifting-lowering tasks in various conditions and with two different hand loads (2.3 and 6.8 kg). We compared three sEMG signal feature sets (i.e., time, frequency, and a combination of both domains) and three ML classifiers (i.e., Random Forest, Support Vector Machine, and Logistic Regression). Both Random Forest and Support Vector Machine models, using either time-domain or time- and frequency-domain features, yielded the best performance in detecting lifts, with respective accuracies of 79.2% (start) and 86.7% (end). Similarly, both ML models yielded the highest accuracy (80.9%) in classifying the two hand loads, regardless of the sEMG features used, emphasizing the potential of sEMG armbands for assessing exposure and risks in occupational lifting tasks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Public transportation in Kenya (A phenomenological study of transport issues)\n",
            "Authors: Muguro J.K.\n",
            "Abstract: 2D Materials: Chemistry and Applications offers a concise exploration of the revolutionary 2D materials synthesis, their properties, and diverse applications. It presents information about graphene and other 2D materials like germanene and stanene, emphasizing their synthesis, functionalization, and technological use. The book chapters in part 1 cover the foundational aspects of graphene's structure and production techniques, highlighting their potential in areas like energy storage, drug delivery, and nanoelectronics. The book also explains the versatile applications of graphene-based nanocomposites, highlighting their multifunctional capabilities. Chapters also demonstrate the impact of functionalization on applications like biomedical imaging, microbial control, and environmental sustainability. The challenges and solutions concerning the toxicity of graphene-related materials are also highlighted. This book is a foundational resource for researchers, academics, and industry professionals in materials science, nanotechnology, chemistry, and environmental engineering on 2D materials.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Standardizing Continuous Physical Activity Monitoring in Patients with Cervical Spondylosis\n",
            "Authors: Maldaner N.\n",
            "Abstract: Study Design/Setting. Prospective cohort study. Objective. To use a commercial wearable device to measure real-life, continuous physical activity in patients with CS and to establish age-adjusted and sex-adjusted standardized scores. Summary of Background Data. Patients with cervical spondylosis (CS) often present with pain or neurologic deficits that result in functional limitations and inactivity. However, little is known regarding the influence of CS on the patient's real-life physical activity. Methods. This study included 100 English-speaking adult patients with cervical degenerative diseases undergoing elective spine surgery at Stanford University who owned iPhones. Patients undergoing surgery for spine infections, trauma, tumors, or lumbar degenerative disease were excluded. Activity two weeks before surgery was expressed as raw daily step counts. Standardized z-scores were calculated based on age-specific and sex-specific values of a control population. Responses to patient-reported outcome measures (PROMs) surveys assessed convergent validity. Functional impairment was categorized based on predetermined z-score cut-off values. Results. Thirty CS with a mean (±SD) age of 56.0 (±13.4) y wore an Apple Watch for ≥8 hours/day in 87.1% of the days. The mean watch wear time was 15.7 (±4.2) hours/day, and the mean daily step count was 6400 (±3792). There was no significant difference in activity between 13 patients (43%) with myelopathy and 17 (57%) without myelopathy. Test-retest reliability between wearable step count measurements was excellent (ICC β=0.95). Physical activity showed a moderate positive correlation with 36-Item Short Form Survey Physical Component Summary, EuroQol-5-dimension visual analog scale, and Patient-Reported Outcomes Measurement Information System Physical Function Subscale. Activity performance was classified into categories of \"no impairment\"[step count=9640 (±2,412)], \"mild impairment\"[6054(±816)], \"moderate impairment\"[3,481 (±752)], and \"severe impairment\"[1,619 (±240)]. Conclusion. CS patients' physical activity is significantly lower than the general population or the frequently stated goals of 7000 to 10,000 steps/day. Standardized, continuous wearable physical activity monitoring in CS is a reliable, valid, and normalized outcome tool that may help characterize functional impairment before and after spinal interventions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Research on fast network of human pose estimation in underground coal mine based on HigherHRNet\n",
            "Authors: Yanjun Z.\n",
            "Abstract: Fast estimation of human pose in underground coal mine is an important prerequisite for intelligent safety detection of underground operation. Aiming at the problems of dusty and foggy,insufficient illumination and color blending in underground coal mine,this study conducts an in - depth study on the lightweight design and key point assignment of the HigherHRNet model and proposes a new Optimising HigherHRNet(OH-HRNet) fast network model in order to improve the accuracy of the key point assignment for human pose estimation as well as the network operation speed. The OH-HRNet model proposes a memory convolution module based on attention mechanism and a key point assignment algorithm with reinforced skeletal constraints,and the loss function of the algorithm is improved. Experiments on the coal mine underground scenario dataset and COCO public dataset show that,OH-HRNet is 1. 06 times faster than LitePose in terms of GPU speed,with a 7. 4% increase in mAP and a 14. 0% increase in mAR,which can achieve more effective intelligent safety detection.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Measuring the Effect of an Ergonomic Lecture on the Rapid Upper Limb Assessment Scores of Dental Assistant Students Using Inertial Sensor-Based Motion Capture—A Randomized Controlled Study\n",
            "Authors: Simon S.\n",
            "Abstract: Individuals working in the field of dentistry have a high prevalence of musculoskeletal disorders (MSDs) owing to monotonous and one-sided physical exertion. Inertial measurement units (IMU) are increasingly shifting into focus for assessing postural risk at work. Therefore, the present study aimed to evaluate the effects of an ergonomic lecture and training intervention on postural risk and MSDs in dental assistant students using inertial sensor-based motion capture (MoCap). Eighteen female dental assistant students (age: 19.44 ± 6.83 years; height: 164.59 ± 5.32 cm; weight: 64.88 ± 16.52 kg; BMI: 19.70 ± 4.89 kg/m2), randomly divided into intervention (n = 9) and control (n = 9) groups, participated in the present study. The participants completed the Nordic Questionnaire on MSD prevalence, after which a 90 s MoCap with Xsens IMU was performed. A lecture on ergonomics was provided, followed by a five-week intervention for the intervention group. Follow-up assessments were performed, and 5- and 18-week follow-up MSD questionnaires were administered. Mixed analysis of variance (MANOVA) showed a significant difference in the Rapid Upper Limb Assessment (RULA) and part-scores of the upper arm and wrist. Despite a reduction in MSDs, no significant differences in the time of measurement and groups were detected after the five-week training intervention and the 18-week follow-up questionnaire. A targeted ergonomics lecture was effective for dental assistant students, and technologies such as IMU improved workplace ergonomics in dentists. Further studies with a longer measurement periods, follow-up, and larger sample sizes are recommended.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Multi-Task Intelligent Monitoring of Construction Safety Based on Computer Vision\n",
            "Authors: Liu L.\n",
            "Abstract: Effective safety management is vital for ensuring construction safety. Traditional safety inspections in construction heavily rely on manual labor, which is both time-consuming and labor-intensive. Extensive research has been conducted integrating computer-vision technologies to facilitate intelligent surveillance and improve safety measures. However, existing research predominantly focuses on singular tasks, while construction environments necessitate comprehensive analysis. This study introduces a multi-task computer vision technology approach for the enhanced monitoring of construction safety. The process begins with the collection and processing of multi-source video surveillance data. Subsequently, YOLOv8, a deep learning-based computer vision model, is adapted to meet specific task requirements by modifying the head component of the framework. This adaptation enables efficient detection and segmentation of construction elements, as well as the estimation of person and machine poses. Moreover, a tracking algorithm integrates these capabilities to continuously monitor detected elements, thereby facilitating the proactive identification of unsafe practices on construction sites. This paper also presents a novel Integrated Excavator Pose (IEP) dataset designed to address the common challenges associated with different single datasets, thereby ensuring accurate detection and robust application in practical scenarios.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Assessment of HEMM Operators’ Risk Exposure due to Whole-Body Vibration in Underground Metalliferous Mines Using Machine Learning Techniques\n",
            "Authors: Sakinala V.\n",
            "Abstract: Whole-body vibration (WBV) is a substantial occupational health and safety hazard to heavy earth-moving machinery (HEMM) operators. There is a need to appraise the effect of WBV jeopardize and the factors influencing the WBV risk exposure on the HEMM operators. Seven machine learning (ML) models were tested on 81 data samples collected from seven underground metalliferous mines. The study considered nine factors which have substantial role behind the intensity of the WBV risk exposure of HEMM operators. RReleifF algorithm was used for dimensionality reduction and ranking the features. Compared to other ML techniques, ANN model was determined to be the most effective approach. The nine considered features were reduced to five features using RReleifF algorithm. The ranking of the five features selected was in order of awkward posture, the machine age, haul road condition, speed, and seat thickness based on their weights. Finally, a predictive equation was developed using the aforementioned five features. This study will help the seven underground mines authority to evaluate the WBV risk exposure effortlessly without the usage of scientific instrument and also helps in adopting immediate control measures to mitigate WBV risk exposure of HEMM operators.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: 3D pose estimation dataset and deep learning-based ergonomic risk assessment in construction\n",
            "Authors: Fan C.\n",
            "Abstract: Pose estimation of construction workers is critical to ensuring safe construction and protecting construction workers from ergonomic risks. Computer vision (CV)-based 3D pose estimation for construction workers is increasingly used in ergonomic risk assessment (ERA) due to its considerable practicability and accuracy. Currently, the deficiencies of (1) dedicated datasets for construction activities and (2) informative 3D biomechanical models to both Rapid Entire Body Analysis (REBA) and Rapid Upper Limb Analysis (RULA) impede the performance of CV-based ERA in construction sectors. Therefore, this study introduces a deep learning-based ERA by introducing a new dataset, ConstructionPose3D (CP3D), that follows a proposed 3D biomechanical skeletal model to support REBA and RULA. This dataset contains approximately 421,000 accurate 3D poses and annotations for construction activities. The results indicate that the proposed deep learning ERA models trained with CP3D outperform those without CP3D in accurately estimating the poses of construction workers, leading to improved ERA.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Vision-Based Real-Time Posture Tracking for Multiple Construction Workers\n",
            "Authors: Lin X.\n",
            "Abstract: Tracking the postures of construction workers can provide precious information for safety management, occupational illness prevention, and productivity investigation. However, the posture data of construction workers is rarely utilized due to a lack of appropriate methods to track it. This research proposes a real-time multiworker posture tracking (MWPT) method to accurately track the postures of multiple workers onsite from video streams. It consists of three elements: image enhancement to adapt varying light conditions, posture detection for obtaining workers' postures, and matching for tracking and retracking postures. In the field experiment, MWPT performed satisfactorily with an average of two ID switches (IDS), an average frame per second (FPS) of 11.0, and an average precision (AP@50) of 86.33. The results prove the capability of MWPT for tracking multiworker postures in real construction environments with high robustness and effectiveness. This research not only contributes an innovative tracking algorithm but also lays a stepping stone toward further worker posture-related research.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Exo skeleton pertinence and control techniques: A state-of-the-art review\n",
            "Authors: Rangan R P.\n",
            "Abstract: Exo-Skeleton is a wearable robotic device which was emerged in later 1960s that has a multitude of applications ranging from weightlifting to wearer’s stability improvement. This paper makes a novel approach in reviewing the various exo-skeleton models that are available at the present. The idea of this paper is to study and compare the models in terms of medical applicability like gait rehabilitation, physiotherapy, human strength augmentation, various control strategies of exo-skeleton, ergonomic study, and need for exo-skeleton system for enhancing the life of humans. Since exo-skeletons are wearable devices, it requires precise controlling of the actuators and repeatability, and accuracy plays a vital role. The paper elucidated with a detailed analysis, reviewed and summarized the core essence of 300 research papers and patents in the field of exo-skeleton with the aforesaid aspects of application and drive system with their control methodologies from 2007 to 2022 and shown a trend with year-wise data from which it is clear that the future of industrial work will become a collaborative activity involving the exo-skeleton system with human labours. Human – robot interaction is vital and must for enabling an integration which can be achieved with the amelioration in the control and actuation techniques for precise control. With the furtherance in the technology the exo-skeletons can be purpose built that can be of rigid or flexible structures with active, passive, or quasi-passive controls based on the user needs. Joint handed operation of Exo-skeleton with the alternative treatment methodologies will yield a plethora of benefits in the near future in comparison with the present conventional treatment modes that could result in reduction of surgeries.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Integrating OpenPose and SVM for Quantitative Postural Analysis in Young Adults: A Temporal-Spatial Approach\n",
            "Authors: Lee P.\n",
            "Abstract: Noninvasive tracking devices are widely used to monitor real-time posture. Yet significant potential exists to enhance postural control quantification through walking videos. This study advances computational science by integrating OpenPose with a Support Vector Machine (SVM) to perform highly accurate and robust postural analysis, marking a substantial improvement over traditional methods which often rely on invasive sensors. Utilizing OpenPose-based deep learning, we generated Dynamic Joint Nodes Plots (DJNP) and iso-block postural identity images for 35 young adults in controlled walking experiments. Through Temporal and Spatial Regression (TSR) models, key features were extracted for SVM classification, enabling the distinction between various walking behaviors. This approach resulted in an overall accuracy of 0.990 and a Kappa index of 0.985. Cutting points for the ratio of top angles (TAR) and the ratio of bottom angles (BAR) effectively differentiated between left and right skews with AUC values of 0.772 and 0.775, respectively. These results demonstrate the efficacy of integrating OpenPose with SVM, providing more precise, real-time analysis without invasive sensors. Future work will focus on expanding this method to a broader demographic, including individuals with gait abnormalities, to validate its effectiveness across diverse clinical conditions. Furthermore, we plan to explore the integration of alternative machine learning models, such as deep neural networks, enhancing the system’s robustness and adaptability for complex dynamic environments. This research opens new avenues for clinical applications, particularly in rehabilitation and sports science, promising to revolutionize noninvasive postural analysis.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Novel IMU-Based System for Work-Related Musculoskeletal Disorders Risk Assessment\n",
            "Authors: Baklouti S.\n",
            "Abstract: This study introduces a novel wearable Inertial Measurement Unit (IMU)-based system for an objective and comprehensive assessment of Work-Related Musculoskeletal Disorders (WMSDs), thus enhancing workplace safety. The system integrates wearable technology with a user-friendly interface, providing magnetometer-free orientation estimation, joint angle measurements, and WMSDs risk evaluation. Tested in a cable manufacturing facility, the system was evaluated with ten female employees. The evaluation involved work cycle identification, inter-subject comparisons, and benchmarking against standard WMSD risk assessments like RULA, REBA, Strain Index, and Rodgers Muscle Fatigue Analysis. The evaluation demonstrated uniform joint patterns across participants ((Formula presented.)) and revealed a higher occurrence of postures warranting further investigation, which is not easily detected by traditional methods such as RULA. The experimental results showed that the proposed system’s risk assessments closely aligned with the established methods and enabled detailed and targeted risk assessments, pinpointing specific bodily areas for immediate ergonomic interventions. This approach not only enhances the detection of ergonomic risks but also supports the development of personalized intervention strategies, addressing common workplace issues such as tendinitis, low back pain, and carpal tunnel syndrome. The outcomes highlight the system’s sensitivity and specificity in identifying ergonomic hazards. Future efforts should focus on broader validation and exploring the relative influence of various WMSDs risk factors to refine risk assessment and intervention strategies for improved applicability in occupational health.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An Ergonomic Risk Assessment System Based on 3D Human Pose Estimation and Collaborative Robot\n",
            "Authors: Menanno M.\n",
            "Abstract: Human pose estimation focuses on methods that allow us to assess ergonomic risk in the workplace and aims to prevent work-related musculoskeletal disorders (WMSDs). The recent increase in the use of Industry 4.0 technologies has allowed advances to be made in machine learning (ML) techniques for image processing to enable automated ergonomic risk assessment. In this context, this study aimed to develop a method of calculating joint angles from digital snapshots or videos using computer vision and ML techniques to achieve a more accurate evaluation of ergonomic risk. Starting with an ergonomic analysis, this study explored the use of a semi-supervised training method to detect the skeletons of workers and to estimate the positions and angles of their joints. A criticality index, based on RULA scores and fuzzy rules, is then calculated to evaluate possible corrective actions aimed at reducing WMSDs and improving production capacity using a collaborative robot that supports workers in carrying out critical operations. This method is tested in a real industrial case in which the manual assembly of electrical components is conducted, achieving a reduction in overall ergonomic stress of 13% and an increase in production capacity of 33% during a work shift. The proposed approach can overcome the limitations of recent developments based on computer vision or wearable sensors by performing an assessment with an objective and flexible approach to postural analysis development.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: What occupational risk factors significantly affect miners’ health: Findings from meta-analysis and association rule mining\n",
            "Authors: Zhang B.\n",
            "Abstract: Introduction: The workplace's health hazard remains a significant concern to workers in the mining industry, where miners are continually exposed to various kinds of exposure sources. Method: First, the determinants of miners’ health were systematically extracted from 259 publications, comprising chemical, physical, ergonomic, and psychosocial stressors, vulnerability factors, and common health outcomes. Then, 16 meta-analyses were performed to ascertain the epidemiological evidence for associations between four stressors and three health outcomes. The seven top contributing factors affecting miners’ health were identified through 166 available prospective studies. Finally, based on the classic and domestic measurement scales, a cross-sectional survey of 559 Chinese miners was conducted to determine the core psychosocial predictors. In addition to the traditional mechanisms, complex interactive networks among the antecedents and consequences and the reversed effects of consequences were also obtained, where 379 strong association rules were yielded via the Apriori algorithm. Results: The results showed that occupational dust, NO2, heavy metals, heat, vibration, awkward posture, and job stress are significant risk factors associated with individuals’ health conditions. Psychological capital, coping style, job demand, social support, organizational support, justice, and culture are core psychosocial predictors of miners. Conclusions: This study presents a case for identifying the most significant occupational risk factors related to individuals’ health, which could be extended and applied to other industries, as working populations around the world are suffering from various chemical, physical, ergonomic, and psychosocial stressors. Practical Applications: Identifying the significant occupational risk factors affecting workers’ health conditions is essential for comprehensive occupational health risk assessment and management. Therefore, this study could be important for health management in mines and other industries.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Role of contributing factors on health risks of whole-body vibration exposure of heavy equipment and vehicle operators: A critical review\n",
            "Authors: Singh K.J.\n",
            "Abstract: Whole-body vibration (WBV) is a recognized health hazard that primarily affects the musculoskeletal system of human beings. Although research works on WBV are documented, for the past few decades or so, researchers are still attempting to explore the role of contributing factors of WBV for the causation of musculoskeletal disorders (MSDs). Therefore, this paper synthesizes up-to-date knowledge on WBV with respect to measurement methods, critical vibration magnitudes, contributing factors, and effects on human health. The present review is based on PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyzes) that includes 112 studies on WBV exposure and its contributing factors. It also summarizes the contributing factors of MSDs that include personal factors, environmental factors, machine-related factors, and WBV exposure of the heavy vehicles and equipment operators across various industries. Most of the studies reported lower back pain as the most common MSDs experienced by the vehicle operators exposed to WBV, followed by upper back pain. However, it is apparent from the prevailing literature that musculoskeletal health risks do not result from exposure to WBV alone. The role of multivariate contributing factors should also be considered, analyzed, assessed, and understood to establish correlations between these factors with the development of MSDs. In addition to the measurement and assessment of WBV as per the ISO guidelines to evaluate the potential and likely health risks faced by the heavy equipment operators, researchers should also focus on studying various impacts of WBV, and understanding the role of its contributing factors on human health using advanced machine learning tools.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Improving Workers’ Musculoskeletal Health During Human-Robot Collaboration Through Reinforcement Learning\n",
            "Authors: Xie Z.\n",
            "Abstract: Objective: This study aims to improve workers’ postures and thus reduce the risk of musculoskeletal disorders in human-robot collaboration by developing a novel model-free reinforcement learning method. Background: Human-robot collaboration has been a flourishing work configuration in recent years. Yet, it could lead to work-related musculoskeletal disorders if the collaborative tasks result in awkward postures for workers. Methods: The proposed approach follows two steps: first, a 3D human skeleton reconstruction method was adopted to calculate workers’ continuous awkward posture (CAP) score; second, an online gradient-based reinforcement learning algorithm was designed to dynamically improve workers’ CAP score by adjusting the positions and orientations of the robot end effector. Results: In an empirical experiment, the proposed approach can significantly improve the CAP scores of the participants during a human-robot collaboration task when compared with the scenarios where robot and participants worked together at a fixed position or at the individual elbow height. The questionnaire outcomes also showed that the working posture resulted from the proposed approach was preferred by the participants. Conclusion: The proposed model-free reinforcement learning method can learn the optimal worker postures without the need for specific biomechanical models. The data-driven nature of this method can make it adaptive to provide personalized optimal work posture. Application: The proposed method can be applied to improve the occupational safety in robot-implemented factories. Specifically, the personalized robot working positions and orientations can proactively reduce exposure to awkward postures that increase the risk of musculoskeletal disorders. The algorithm can also reactively protect workers by reducing the workload in specific joints.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Rapid upper limb assessment method based on adaptive neuro fuzzy inference system optimization\n",
            "Authors: Bai Z.\n",
            "Abstract: Traditional methods have low sensitivity to changes in input variables for the risk assessment of work-related musculoskeletal diseases, resulting in insufficient accuracy and reliability of the risk assessment outputs. To conduct human factors engineering risk assessment in a more accurate way, a Rapid Upper Limb Assessment(RULA) method was proposed based on Adaptive Neuro Fuzzy Inference System (ANFIS). Based on the convolutional neural network, the key points of the human working posture were detected and recognized in the video, with the joint angles calculated. Because of the ANFIS, the method was improved in the rapid upper limb assessment, and a risk assessment framework was constructed for work-related musculoskeletal diseases to solve the problem of obtaining the same score when different postures were evaluated. The joint angle data of different working postures were randomly selected to train and test the network, and it was adjusted the optimal parameters of the work-related musculoskeletal disease risk prediction model according to the ANFIS as well as the rapid upper limb assessment method. The first 15 working postures in the joint angle dataset were selected for correlation verification, whose results were compared with those of the original rapid upper limb assessment method. Also, the operation process of the branch pruning tool was applied to analyze the case to achieve real-time dynamic assessment of risk scores. The results showed that the optimized rapid upper limb assessment method was more sensitive than the original one, which verified that the adaptive neuro fuzzy inference system could effectively improve the rapid upper limb assessment method and predict risk scores in real time.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Siting Posture Recognition and Feedback: A Literature Review\n",
            "Authors: Krauter C.\n",
            "Abstract: Extensive sitting is unhealthy; thus, countermeasures are needed to react to the ongoing trend toward more prolonged sitting. A variety of studies and guidelines have long addressed the question of how we can improve our sitting habits. Nevertheless, sitting time is still increasing. Here, smart devices can provide a general overview of sitting habits for more nuanced feedback on the user's sitting posture. Based on a literature review (N=223), including publications from engineering, computer science, medical sciences, electronics, and more, our work guides developers of posture systems. There is a large variety of approaches, with pressure-sensing hardware and visual feedback being the most prominent. We found factors like environment, cost, privacy concerns, portability, and accuracy important for deciding hardware and feedback types. Further, one should consider the user's capabilities, preferences, and tasks. Regarding user studies for sitting posture feedback, there is a need for better comparability and for investigating long-term effects.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: pARam: Leveraging Parametric Design in Extended Reality to Support the Personalization of Artifacts for Personal Fabrication\n",
            "Authors: Stemasov E.\n",
            "Abstract: Extended Reality (XR) allows in-situ previewing of designs to be manufactured through Personal Fabrication (PF). These in-situ interactions exhibit advantages for PF, like incorporating the environment into the design process. However, design-for-fabrication in XR often happens through either highly complex 3D-modeling or is reduced to rudimentary adaptations of crowd-sourced models. We present pARam, a tool combining parametric designs (PDs) and XR, enabling in-situ configuration of artifacts for PF. In contrast to modeling- or search-focused approaches, pARam supports customization through embodied and practical inputs (e.g., gestures, recommendations) and evaluation (e.g., lighting estimation) without demanding complex 3D-modeling skills. We implemented pARam for HoloLens 2 and evaluated it (n = 20), comparing XR and desktop conditions. Users succeeded in choosing context-related parameters and took their environment into account for their configuration using pARam. We reflect on the prospects and challenges of PDs in XR to streamline complex design methods for PF while retaining suitable expressivity.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Exploring Effective Real-Time Ergonomic Guidance Methods for Immersive Virtual RealityWorkspaces\n",
            "Authors: Ji R.\n",
            "Abstract: Studying andworking in Virtual Reality (VR) provides an immersive experience and enables free body movement for input. However, poor working posture in VR can result in discomfort and even lead to musculoskeletal problems over time. In this work, we explore how to use Mediapipe Blazepose to provide effective real-time ergonomic posture guidance methods in a virtual office environment using (1) auditory, (2) visual, and (3) combined auditory-visual cues. We do this in a within-subject design user study comparing these three conditions and a baseline condition where no guidance is provided. Our results indicate that all three guidance conditions significantly improved users' ergonomic posture maintenance compared with the baseline condition. However, we found that the combined auditory-visual guidance is the most effective and preferred method. We also discuss multi-modal interaction methods, privacy concerns, and directions for future research.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Evaluation of Ergonomic Risks for Construction Workers Based on Multicriteria Decision Framework with the Integration of Spherical Fuzzy Set and Alternative Queuing Method\n",
            "Authors: Tao Y.\n",
            "Abstract: Ergonomic risks critically impact workers’ occupational health, safety, and productivity, and thereby the sustainability of a workforce. In the construction industry, the physical demands and dynamic environment exposes workers to various ergonomic hazards. While previous research has mainly focused on postural risks, there is a need to broaden the scope to include more relevant factors and assess them systematically. This study introduces a multi-criteria decision framework integrating the Spherical Fuzzy Sets (SFSs) and Alternative Queuing Method (AQM) to evaluate and prioritize ergonomic hazards. First, SFSs are employed to quantify the linguistic expressions of experts, addressing the inherent vagueness and uncertainty. Then, an entropy-based objective weighting method is adopted to determine the criteria weights. Finally, AQM is utilized to generate the risk priority. The proposed method has been implemented in a real-life construction project, where “overexertion due to unreasonable task organization”, “hypertension and heart diseases”, and “existing WMSD record” are identified as the top three ergonomic hazards. Then, a thorough discussion of intervention strategies regarding different risk categories is presented to facilitate ergonomic interventions. This proposed decision support system can promote effective ergonomic risk management, benefiting workers’ health and well-being and contributing to the sustainable workforce development of the construction industry.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Smart Sensing Chairs for Sitting Posture Detection, Classification, and Monitoring: A Comprehensive Review\n",
            "Authors: Odesola D.F.\n",
            "Abstract: Incorrect sitting posture, characterized by asymmetrical or uneven positioning of the body, often leads to spinal misalignment and muscle tone imbalance. The prolonged maintenance of such postures can adversely impact well-being and contribute to the development of spinal deformities and musculoskeletal disorders. In response, smart sensing chairs equipped with cutting-edge sensor technologies have been introduced as a viable solution for the real-time detection, classification, and monitoring of sitting postures, aiming to mitigate the risk of musculoskeletal disorders and promote overall health. This comprehensive literature review evaluates the current body of research on smart sensing chairs, with a specific focus on the strategies used for posture detection and classification and the effectiveness of different sensor technologies. A meticulous search across MDPI, IEEE, Google Scholar, Scopus, and PubMed databases yielded 39 pertinent studies that utilized non-invasive methods for posture monitoring. The analysis revealed that Force Sensing Resistors (FSRs) are the predominant sensors utilized for posture detection, whereas Convolutional Neural Networks (CNNs) and Artificial Neural Networks (ANNs) are the leading machine learning models for posture classification. However, it was observed that CNNs and ANNs do not outperform traditional statistical models in terms of classification accuracy due to the constrained size and lack of diversity within training datasets. These datasets often fail to comprehensively represent the array of human body shapes and musculoskeletal configurations. Moreover, this review identifies a significant gap in the evaluation of user feedback mechanisms, essential for alerting users to their sitting posture and facilitating corrective adjustments.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Assessment of Surgeons’ Stress Levels with Digital Sensors during Robot-Assisted Surgery: An Experimental Study\n",
            "Authors: Takács K.\n",
            "Abstract: Robot-Assisted Minimally Invasive Surgery (RAMIS) marks a paradigm shift in surgical procedures, enhancing precision and ergonomics. Concurrently it introduces complex stress dynamics and ergonomic challenges regarding the human–robot interface and interaction. This study explores the stress-related aspects of RAMIS, using the da Vinci XI Surgical System and the Sea Spikes model as a standard skill training phantom to establish a link between technological advancement and human factors in RAMIS environments. By employing different physiological and kinematic sensors for heart rate variability, hand movement tracking, and posture analysis, this research aims to develop a framework for quantifying the stress and ergonomic loads applied to surgeons. Preliminary findings reveal significant correlations between stress levels and several of the skill-related metrics measured by external sensors or the SURG-TLX questionnaire. Furthermore, early analysis of this preliminary dataset suggests the potential benefits of applying machine learning for surgeon skill classification and stress analysis. This paper presents the initial findings, identified correlations, and the lessons learned from the clinical setup, aiming to lay down the cornerstones for wider studies in the fields of clinical situation awareness and attention computing.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Biomechanical Posture Analysis in Healthy Adults with Machine Learning: Applicability and Reliability\n",
            "Authors: Roggio F.\n",
            "Abstract: Posture analysis is important in musculoskeletal disorder prevention but relies on subjective assessment. This study investigates the applicability and reliability of a machine learning (ML) pose estimation model for the human posture assessment, while also exploring the underlying structure of the data through principal component and cluster analyses. A cohort of 200 healthy individuals with a mean age of 24.4 ± 4.2 years was photographed from the frontal, dorsal, and lateral views. We used Student’s t-test and Cohen’s effect size (d) to identify gender-specific postural differences and used the Intraclass Correlation Coefficient (ICC) to assess the reliability of this method. Our findings demonstrate distinct sex differences in shoulder adduction angle (men: 16.1° ± 1.9°, women: 14.1° ± 1.5°, d = 1.14) and hip adduction angle (men: 9.9° ± 2.2°, women: 6.7° ± 1.5°, d = 1.67), with no significant differences in horizontal inclinations. ICC analysis, with the highest value of 0.95, confirms the reliability of the approach. Principal component and clustering analyses revealed potential new patterns in postural analysis such as significant differences in shoulder–hip distance, highlighting the potential of unsupervised ML for objective posture analysis, offering a promising non-invasive method for rapid, reliable screening in physical therapy, ergonomics, and sports.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Construction posture recognition with primitive joints extended planar normal vector quaternions\n",
            "Authors: Sun X.\n",
            "Abstract: Recognizing postures in construction activities is crucial for preventing long-term work-related illnesses, such as musculoskeletal disorders. While Inertial Measurement Units (IMUs) are commonly used to track workers' movements, their use in posture recognition creates complex networks of sensing nodes and large amounts of data. This leads to high memory consumption and challenges real-time posture recognition efficiency. To address this, the study introduces a novel feature processing method that combines multiple body joint data into plane normal vector quaternions, along with the original joint data. This approach achieves impressive recognition accuracy similar to the original dataset while reducing the feature count by nearly 50%. Validated with a test of six typical postures, the proposed method suggests a new research potential of using equivalent planar vectors for more effective, reliable, and flexible solutions for detecting and diagnosing work-related activities.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Real-time ergonomic risk assessment in construction using a co-learning-powered 3D human pose estimation model\n",
            "Authors: Chen W.\n",
            "Abstract: Work-related musculoskeletal disorders pose significant health risks to construction workers, making it essential to monitor their postures and identify physical exposure to mitigate these risks. This study presents a novel framework for real-time ergonomic risk assessment of workers in construction environments. Specifically, this study develops a lightweight human pose estimation (HPE) model with a residual log-likelihood estimation head and adopts pose-tracking technology to enable real-time recognition of workers’ three-dimensional (3D) postures. In particular, this study proposes a novel co-learning method that enables the HPE model to learn two-dimensional (2D) and 3D features from multi-dimension datasets simultaneously, substantially enhancing the model's ability to capture 3D postures from 2D images. The proposed framework facilitates real-time ergonomic risk assessment, reducing potential risks to construction workers and offering promising practical applications.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A systematic review of research on sitting and working furniture ergonomic from 2012 to 2022: Analysis of assessment approaches\n",
            "Authors: Bai Y.\n",
            "Abstract: This study analyses which aspects of sitting and working furniture ergonomics that may be influenced and how they are assessed. To gather information on the types and assessment techniques connected with influencing furniture ergonomics, a systematic review of the literature was conducted. The papers in the systematic review were published between 2012 and 2022. The articles applied the Systematic Reviews and Meta-Analyses (PRISMA) statement guidelines to limit the 41 papers that were eventually included (N = 41) to those containing keywords like ergonomics, human factors, comfort, working furniture, Chair, assessment and evaluation. The research objective of this systematic review is to provide a comprehensive overview of sitting and working furniture and the main findings, obtaining common assessment techniques for this type of furniture and their suitability. According to the relevant studies, the publications were categorized by summarizing factors like region, gender, research methods, ergonomic assessment techniques and methods used, correlation between assessment techniques and methods, etc. Summaries of the data extracted from the included papers are provided and the applicability of some approaches are assessed. Only a small number of authors have evaluated the ergonomics of furniture used in homes. One of the research gaps is the paucity of research on gender segregation, secular trends, and cultural contexts. These studies heavily rely on quantitative research techniques, and the articles may lack credibility due to the homogeneity of the evaluation techniques. Finally, the authors offer some suggestions for the appropriate ergonomic analysis of furniture.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Exploring relationship between EMG, confusion and smoothness of work progress in assembly tasks\n",
            "Authors: Wang T.Y.\n",
            "Abstract: Analyzing an operator's mental state is an important issue in manufacturing. In this paper, we focused on confusion and perceived smoothness of work progress. A 40-participant experiment was conducted in which participants performed two 50-minute assembly tasks and answered two self-report questions about perceived confusion and perceived smoothness of work progress after each step. The results showed that there was a moderate correlation between the two variables and the duration of the steps. In addition, our preliminary EMG analysis showed that there was a moderate correlation between EMG and perceived confusion.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Unveiling Gender-Based Musculoskeletal Disorders in the Construction Industry: A Comprehensive Analysis\n",
            "Authors: Paramasivam S.K.\n",
            "Abstract: Without physically intensive building, modern infrastructure development would be impossible. Musculoskeletal diseases (MSDs) and other occupational health issues may arise in such a demanding environment. Construction workers often develop MSDs from repeated actions, uncomfortable postures, and heavy lifting. Musculoskeletal disorders may damage muscles, bones, tendons, ligaments, etc. The effect of MSDs is well known; occupational health studies increasingly include gender-specific aspects. Despite being in the minority, the number of female construction employees is growing. However, physiological variations and occupational activities and environments may provide distinct obstacles. Thus, identifying gender-specific MSDs in construction is essential for worker safety. This research proposes a gender-specific machine learning (ML)-based musculoskeletal disorder detection framework (GS-ML-MSD2F) in the construction industry. A simple random selection procedure chose 250 female and 250 male rebar workers with at least six months of experience for the dataset. In January and June 2023, face-to-face interviews and ergonomic evaluations were undertaken. The data were analyzed using different machine learning methods, and the effectiveness of the methods was studied. The data showed that 60% of female rebar workers had MSD symptoms. The lower back and shoulders accounted for 40% of cases. Multiple machine learning methods revealed two significant factors related to musculoskeletal disorders: lengthy working hours and uncomfortable postures, and long working hours had an adjusted odds ratio of 8.5%, whereas awkward posture had an adjusted odds ratio of 42.5%. These results emphasize the relevance of working hours and posture in MSD prevention for female rebar workers in the construction sector.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An attention-based CNN for automatic whole-body postural assessment\n",
            "Authors: Ding Z.\n",
            "Abstract: Fully automatic postural assessment is highly useful, but has been challenging. Conventional methods either require manual assessment by ergonomists or depend on special devices that are intrusive, thus being hardly feasible in daily activities and workplaces. In this work, an attention-based convolutional neural network (CNN) is developed for automatic whole-body postural assessment. The proposed network learns to identify highly relevant regions (or body parts) and extract features automatically. Risk of the posture is estimated from the extracted features accordingly. To evaluate the proposed method, a postural dataset, referred to as pH36M, is created by re-targeting Human3.6M, one of the largest publicly available datasets for pose estimation using the Rapid Entire Body Assessment (REBA) criteria. Experimental results on pH36M demonstrate that proposed method achieves promising performance in comparison to baselines and the average assessment scores are substantially aligned with human assessment with a Kappa value of 0.73.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Utilization of Anthropometric Data to Determine Strap Length for Rattan Shoulder Bag Products in Indonesia\n",
            "Authors: Cahyadi D.\n",
            "Abstract: The straps of rattan bag handicraft products in Indonesia have different shapes and sizes. This can be observed from the straps of rattan shoulder bags designed to have a permanent size, leading to the lack of flexibility in increasing or decreasing the length of the bag to fit the height of the users. Therefore, this study aimed to design a standard ergonomic strap length for rattan shoulder bags in order to ensure compatibility with small, medium, and large-sized users in Indonesia. The process was conducted through the retrieval of anthropometric data for women between the ages of 17 and 45 years for calculations. The results showed that 60 cm was the appropriate length for small-sized users, 85 cm for medium, and 100 cm for large. The implication of the results was to provide support for the production of different strap length designs based on the differences in the type of bag and body size. Moreover, the results contributed to the rattan handicraft industry by providing recommendation on the standard strap lengths for shoulder bags to be produced.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automated Posture Analysis Proposal Based on REBA Evaluation Tool\n",
            "Authors: Jae-Hyuk C.\n",
            "Abstract: In the construction industry, there is a gradual increase in the application of computer vision for field management and safety analysis of workers. Computer vision is employed for tasks like monitoring the use of safety helmets, verifying the fastening of safety rings, and automatically recognizing the behavior of heavy equipment. However, research specifically addressing the postures leading to musculoskeletal disorders is relatively limited. The construction site, being labor-intensive and involving various professionals and equipment in each process, requires continuous management and monitoring to minimize musculoskeletal diseases among workers and ensure their safety. Managing such a large construction site with diverse tasks for each process poses challenges for effective oversight. In this study, risk postures were defined based on REBA, and key joint points were identified using Posenet. Using this data, a model was developed to classify workers' postures using Teachable Machine, demonstrating high accuracy in recognizing different risk postures.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Application of wearable technology for the ergonomic risk assessment of healthcare professionals: A systematic literature review\n",
            "Authors: Sabino I.\n",
            "Abstract: Healthcare professionals are exposed to multiple physical risk factors related to the development of work-related musculoskeletal disorders (WRMSD), which significantly affect their quality of life. Several ergonomic methods have been developed for identifying risk factors in the workplace. Among these, wearable devices that perform direct measurements have demonstrated outstanding potential in recent years to provide reliable, non-invasive, and continuous exposure assessment. Therefore, this systematic review aims to describe the use of wearable technology for the ergonomic risk assessment of healthcare professionals. Twenty-nine publications were selected following PRISMA guidelines based on the inclusion and exclusion criteria set. Most of the articles were published in the last three years, confirming a growing trend in the research on this topic. Most wearable devices, which were used isolated or combined, consist of inertial sensors used to measure and assess the exposure to awkward postures and sEMG sensors, which provide the measurement of muscle activity parameters related to the force applied while performing work activities. The main results and respective analyses provided insights into the strengths and limitations of using wearable technology to acquire data on several work activities performed by healthcare professionals. Future research is needed to widen and validate the applicability of wearable technology in support of ergonomic interventions aimed at preventing the development of WRMSD among healthcare professionals.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A real-time posture assessment system based on motion capture data for manual maintenance and assembly processes\n",
            "Authors: Zhou D.\n",
            "Abstract: As manufacturing processes of complex products become automated, manual operations still occupy a considerable portion of industrial maintenance and assembly (IMA), especially in the machinery and aerospace fields. Workers often exhibit awkward posture in IMA activities. In these scenarios, posture assessment is critical for improving the well-being of workers because awkward postures can lead to work-related musculoskeletal disorder (WMSD). Although there are several categorized WMSD risk assessment methods, limited evidence suggests that these methods are compliant for modern complex IMA scenarios. In this paper, a posture analysis system for manual operation (PASMO) is presented to monitor working postures and evaluate WMSD risks in IMA processes. The noninvasive depth sensor Kinect v2 and the rapid upper limb analysis (RULA) method are integrated to achieve this purpose. In the PASMO, the RULA is optimized and driven by motion capture (MoCap) data to make evaluating the WMSD risk of working postures more effective and accurate. Industrial and laboratory experiments are designed to verify the effectiveness and system performance of the PASMO. The results show that for the overall body and most joints, the scores obtained by the PASMO substantially agree with those obtained by the ground truth data (p < 0.01, κ = 0.65) under the real industrial environment. Because the experiments are conducted in real IMA scenarios with body occlusion, the results preliminarily prove the effectiveness of the PASMO for WMSD risk assessment in continuous IMA tasks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A deep learning model for ergonomics risk assessment and sports and health monitoring in self-occluded images\n",
            "Authors: Aghamohammadi A.\n",
            "Abstract: Ergonomic assessments and sports and health monitoring play a crucial role and have contributed to sustainable development in many areas such as product architecture, design, health, and safety as well as workplace design. Recently, visual ergonomic assessments have been broadly employed for skeleton analysis of human joints for body postures localization and classification to deal with musculoskeletal disorders risks. Moreover, monitoring players in a sports activity helps to analyze their actions to help maximize body performance. However, body postures identification has some limitations in self-occlusion joint postures. In this study, a visual ergonomic assessment technique employing a multi-frame and multi-path convolutional neural network (CNN) is presented to assess ergonomic risks in the presence of free-occlusion and self-occlusion conditions. Our model has four inputs that accept four sequential frames to overcome the problems of the missing joints and classify the input into one of four risk categories. Our pipeline was evaluated on a video with 5 min ~ 300 s (that could be 9000 frames) duration time and showed that our architecture has competitive results (recall = 0.8925, precision = 0.8743, F-score = 0.8837).\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Compensation Method for Missing and Misidentified Skeletons in Nursing Care Action Assessment by Improving Spatial Temporal Graph Convolutional Networks\n",
            "Authors: Han X.\n",
            "Abstract: With the increasing aging population, nursing care providers have been facing a substantial risk of work-related musculoskeletal disorders (WMSDs). Visual-based pose estimation methods, like OpenPose, are commonly used for ergonomic posture risk assessment. However, these methods face difficulty when identifying overlapping and interactive nursing tasks, resulting in missing and misidentified skeletons. To address this, we propose a skeleton compensation method using improved spatial temporal graph convolutional networks (ST-GCN), which integrates kinematic chain and action features to assess skeleton integrity and compensate for it. The results verified the effectiveness of our approach in optimizing skeletal loss and misidentification in nursing care tasks, leading to improved accuracy in calculating both skeleton joint angles and REBA scores. Moreover, comparative analysis against other skeleton compensation methods demonstrated the superior performance of our approach, achieving an 87.34% REBA accuracy score. Collectively, our method might hold promising potential for optimizing the skeleton loss and misidentification in nursing care tasks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Skeleton-Based Activity Recognition for Process-Based Quality Control of Concealed Work via Spatial–Temporal Graph Convolutional Networks\n",
            "Authors: Xiao L.\n",
            "Abstract: Computer vision (CV)-based recognition approaches have accelerated the automation of safety and progress monitoring on construction sites. However, limited studies have explored its application in process-based quality control of construction works, especially for concealed work. In this study, a framework is developed to facilitate process-based quality control utilizing Spatial–Temporal Graph Convolutional Networks (ST-GCNs). To test this model experimentally, we used an on-site collected plastering work video dataset to recognize construction activities. An ST-GCN model was constructed to identify the four primary activities in plastering works, which attained 99.48% accuracy on the validation set. Then, the ST-GCN model was employed to recognize the activities of three extra videos, which represented a process with four activities in the correct order, a process without the activity of fiberglass mesh covering, and a process with four activities but in the wrong order, respectively. The results indicated that activity order could be clearly withdrawn from the activity recognition result of the model. Hence, it was convenient to judge whether key activities were missing or in the wrong order. This study has identified a promising framework that has the potential to the development of active, real-time, process-based quality control at construction sites.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Wearables for Monitoring and Postural Feedback in the Work Context: A Scoping Review\n",
            "Authors: Figueira V.\n",
            "Abstract: Wearables offer a promising solution for simultaneous posture monitoring and/or corrective feedback. The main objective was to identify, synthesise, and characterise the wearables used in the workplace to monitor and postural feedback to workers. The PRISMA-ScR guidelines were followed. Studies were included between 1 January 2000 and 22 March 2023 in Spanish, French, English, and Portuguese without geographical restriction. The databases selected for the research were PubMed®, Web of Science®, Scopus®, and Google Scholar®. Qualitative studies, theses, reviews, and meta-analyses were excluded. Twelve studies were included, involving a total of 304 workers, mostly health professionals (n = 8). The remaining studies covered workers in the industry (n = 2), in the construction (n = 1), and welders (n = 1). For assessment purposes, most studies used one (n = 5) or two sensors (n = 5) characterised as accelerometers (n = 7), sixaxial (n = 2) or nonaxial inertial measurement units (n = 3). The most common source of feedback was the sensor itself (n = 6) or smartphones (n = 4). Haptic feedback was the most prevalent (n = 6), followed by auditory (n = 5) and visual (n = 3). Most studies employed prototype wearables emphasising kinematic variables of human movement. Healthcare professionals were the primary focus of the study along with haptic feedback that proved to be the most common and effective method for correcting posture during work activities.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Torsobarography: Intra-Observer Reliability Study of a Novel Posture Analysis Based on Pressure Distribution\n",
            "Authors: Stecher N.\n",
            "Abstract: Postural deformities often manifest themselves in a sagittal imbalance and an asymmetric morphology of the torso. As a novel topographic method, torsobarography assesses the morphology of the back by analysing pressure distribution along the torso in a lying position. At torsobarography’s core is a capacitive pressure sensor array. To evaluate its feasibility as a diagnostic tool, the reproducibility of the system and extracted anatomical associated parameters were evaluated on 40 subjects. Landmarks and reference distances were identified within the pressure images. The examined parameters describe the shape of the spine, various structures of the trunk symmetry, such as the scapulae, and the pelvic posture. The results showed that the localisation of the different structures performs with a good (ICC > 0.75) to excellent (ICC > 0.90) reliability. In particular, parameters for approximating the sagittal spine shape were reliably reproduced (ICC > 0.83). Lower reliability was observed for asymmetry parameters, which can be related to the low variability within the subject group. Nonetheless, the reliability levels of selected parameters are comparable to commercial systems. This study demonstrates the substantial potential of torsobarography at its current stage for reliable posture analysis and may pave the way as an early detection system for postural deformities.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Impact of unilateral mastectomy on body posture: A prospective longitudinal observational study\n",
            "Authors: Liu R.\n",
            "Abstract: Objective: Unilateral mastectomy is known to induce postural alterations, yet the temporal development pattern of these changes remains elusive. This study aimed to explore the impact of unilateral mastectomy on body posture. Methods: A prospective, longitudinal, observational study with a one-group repeated-measures design was conducted. Patients undergoing unilateral mastectomy were recruited from a university-affiliated hospital in Western China and monitored for 12 months post-surgery. A trained nurse assessed seven postural baseline parameters on the day of suture removal and at 3, 6, and 12 months after unilateral mastectomy. Two parameters were in the sagittal plane (forward head posture and trunk rotation angle), and five were in the coronal plane (neck tilt, shoulder asymmetry, scapular asymmetry, scapular asymmetry relative to the spine, and pelvic tilt). Results: The final analysis included 159 patients. Baseline prevalence of most postural abnormalities ranged from 50.94% to 59.75%, with mean deviations between 2.74 and 4.51 mm. At 12 months post-mastectomy, prevalence and mean deviations increased by more than 30% and 3.50 mm, respectively, compared to baseline. Postural abnormalities increased gradually in the first 3 months, notably between the 3rd and 6th months, and slowed between the 6th and 12th months. On the mastectomy side, coronal plane abnormalities significantly increased within 12 months: earlobe to acromion distance (Wald χ2 = 45.283, P < 0.001), depressed shoulder height (Wald χ2 = 42.253, P < 0.001), depressed scapula height (Wald χ2 = 31.587, P < 0.001), scapula to spine distance (Wald χ2 = 45.283, P < 0.001), and elevated pelvic height (Wald χ2 = 48.924, P < 0.001). Conclusions: Postural changes are common post-unilateral mastectomy, with prevalence and deviation increasing gradually, particularly between 3 and 6 months post-mastectomy. Early rehabilitation initiation is recommended to mitigate postural changes. Trial registration: ChiCTR2000040897\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Lightweight deep learning framework for recognizing construction workers' activities based on simplified node combinations\n",
            "Authors: Tian Y.\n",
            "Abstract: Monitoring construction workers' activities is vital to effective construction project management. However, most existing studies on skeleton-based worker activity recognition use full-body skeleton data, which involve inconvenient movement and high computational demands. This research aimed to identify simplified skeleton node combinations at various scales and develop a framework that reduces computational demands without sacrificing accuracy for the combinations. To this end, this study selected five node combinations at different scales using five deep learning algorithms and developed a lightweight deep learning framework by reducing input features and sample frequencies and stacking temporal convolution network (TCN) blocks. The results demonstrate that this framework outperforms the original deep learning algorithm utilizing the entire skeleton by approximately 1.94%–6.75%. This research contributes to the field of automated construction workers' activity recognition by reducing inconvenient movements and computational demands. Further research needs to investigate the relationships between sensor locations and specific types of motions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Crafting Safe and Efficient Masonry Practices: Quantitative Assessment of Postural Characteristics in Movement Strategies\n",
            "Authors: McFarland T.C.\n",
            "Abstract: Musculoskeletal disorders are prevalent in the construction industry, particularly among masons who are at risk of overexertion and back injuries due to the physical demands of their jobs. Previous research established that expert masons employ different work strategies that reduce joint loads and increase productivity; however, it was unclear which movement strategies they used. This study analyzed the movements of novice, apprentice, and expert masons to identify their postural characteristics. Specifically, the postures and motions of novice, apprentice, and expert masons are analyzed during a standard wall building activity using concrete masonry units, and the key markers of their techniques, such as trunk flexion and twisting, are investigated. Our findings describe the movement strategies experts use in comparison to inexpert groups. Through the analysis of expert motion techniques, the intrinsic movement knowledge of expert masons can be translated into numeric joint thresholds and coaching feedback for training programs.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Model for predicting the angles of upper limb joints in combination with sEMG and posture capture\n",
            "Authors: Wang Z.Y.\n",
            "Abstract: Since poor man-machine interaction and insufficient coupling occur in the processes of angle prediction and rehabilitation training based purely on the surface electromyography (sEMG) signal, a model for predicting the angles of upper limb joints was presented and validated by experiments. The sEMG and posture capture features were combined to build a hybrid vector, and the intentions of upper limb movements were characterized. The original signals were pre-treated with debiasing, filtering, and noise reduction, and then they were integrated to obtain signal characteristics. Then, feature values in the time domain, frequency domain, time-frequency domain, and entropy were extracted from the treated signals. The snake optimizer least squares support vector machine (SO-LSSVM) was modeled to predict the angles of upper limb joints to improve the poor precision and slow velocity of existing models in the movement control field. Experimental results showed that the prediction model performed well in predicting the motion trails of human upper limb joints from the sEMG signal and attitude information. It effectively reduced both skewing and error in prediction. Hence, it holds great promise for improving the man-machine coupling precision and velocity. Compared to the conventional LSSVM model, the proposed SO-LSSVM model reduced the training time, execution time, and root mean square error of evaluation parameters by 65%, 11%, and 76%, respectively. In summary, the proposed SO-LSSVM model satisfied the real-time requirement for rehabilitation robots and showed high accuracy and robustness.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Spatial relationship-aware rapid entire body fuzzy assessment method for prevention of work-related musculoskeletal disorders\n",
            "Authors: Huang K.\n",
            "Abstract: In the advent of Industry 5.0, advances in human-centered smart manufacturing (HSM) accentuate the role of humans in human–machine collaboration. This development has catapulted human health in human-machine systems to the forefront of the conversation. Although various tools have emerged to mitigate work-related musculoskeletal disorders (WMSDs), combining biomechanics with human morphology, the extant methods primarily hinge on expert scoring. Such methods display a step-wise change between risk levels, yielding inadequate assessment accuracy and posing challenges to human health assurance in HSM. To address these issues, this study proposes a spatial relationship-aware rapid entire body fuzzy assessment technique. The proposed method enhances the rapid entire body assessment (REBA) by enacting a dynamic evaluation of WMSD-related risk via a deep learning-based 3D pose reconstruction. Contrary to the step-wise transitions between REBA's different risk levels, the proposed method actualizes a fuzzy assessment of WMSD risk by introducing weights between these levels. This innovation allows for a more accurate risk assessment for workers engaged in HSM. Validation through experiments conducted on data from an automobile production line demonstrates that the proposed method can achieve a precision rate of 99.31%. Demo videos and code are available at https://github.com/giim-hf-lab/REBA-PLUS.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Origami-Inspired Conductive Paper-Based Folded Pressure Sensor with Interconnection Scaling at the Crease for Novel Wearable Applications\n",
            "Authors: Karmakar R.S.\n",
            "Abstract: Drawing inspiration from origami structures, a pressure sensor was developed with unique interconnection scaling at its creases crafted on a conductive paper substrate, paving the way for advanced wearable technology. Two screen-printed conductive paper substrates were combined face-to-face, and specific folds were introduced to optimize the sensor structure. The Electrical Contact Resistance (ECR) was systematically analyzed across different fold numbers and crease gaps, revealing a notable trade-off: while increasing the number of folds expanded the sensing area, it also influenced the ECR, reaching a performance plateau. Strategic modifications in the sensor’s design, including refining interconnections at the crease, enhanced its sensitivity and stability, culminating in a remarkable sensitivity of 3.75 kPa-1 at subtle pressure levels (0-0.05 kPa). This sensor’s real-world applications proved to be transformative, from detecting bruxism and aiding in neck posture correction to remotely sensing trigger finger locking phenomena, highlighting its potential as a pivotal tool in upcoming medical diagnostics and treatments.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A lightweight and high-precision fatigue driving detection method based on video visual perception\n",
            "Authors: Zhang T.\n",
            "Abstract: Fatigue driving threatens traffic safety, making research on fatigue detection a pivotal focus in intelligent transportation. Despite advancements in deep learning for fatigue driving detection, current methods predominantly rely on fatigue features extracted from single images, constraining model accuracy. Simultaneously, while complex deep learning algorithms enhance accuracy, they pose challenges in terms of computational resources and time, making it difficult to meet real-time requirements. To address these challenges, this paper proposes a lightweight fatigue driving detection method utilizing the FatigueYOLO model for fatigue region identification, coupled with DLIB for keypoint detection to construct a more comprehensive single-frame fatigue feature vector. Building upon this, the AFF-Bi-LSTM model (Introducing the Bidirectional Long Short-Term Memory Network with Adaptively Feature Fusion.) is introduced to analyze the temporal relationships of video frames, significantly improving the accuracy of fatigue detection. Experimental results demonstrate that the proposed method achieves an 86.4% accuracy in fatigue detection on the dataset. Simultaneously, the lightweight design ensures high detection accuracy in fatigue region identification. This approach exhibits significant advantages in fatigue driving detection, enhancing both accuracy and real-time performance, and providing substantial support for the future development of intelligent transportation systems.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Heater-Integrated Flexible Piezoresistive Pressure Sensor Array for Smart-Car Seats\n",
            "Authors: Park Y.\n",
            "Abstract: With the growing popularity of autonomous vehicles, the need for real-time monitoring of occupant posture has led to the requirement for a pressure sensor array. Moreover, heated car seats not only offer drivers comfort but also prevent cramped postures, allowing pressure sensors to accurately measure drivers' pressure distribution and enhance safety in autonomous driving. Herein, we propose a heater-integrated pressure sensor array designed specifically for seats in a commercially available GV80 car. The unique signal lines in our sensor enable the implementation of both sensing and heating functionalities within a single substrate, streamlining the fabrication process for the heater-integrated sensor. The sensor was characterized in terms of sensitivity, linearity, response time, repeatability, hysteresis, body temperature effect, and pressure interference among sensing elements. Our sensor exhibited a wide linearity region of 17.06 kPa with a maximum linearity error of 4.4% and a fast response time of less than 4 ms. It operated reliably with a maximum relative standard deviation (RSD) of 5.2% and a hysteresis error of 12.2%. The maximum resistance difference affected by the body temperature was as small as 8.5%, and the resistance changes of one sensing element were almost constant, regardless of the pressure applied to the other sensing element. Additionally, we studied the variations in sensor characteristics with respect to heater temperatures. Furthermore, we customized the embedded system and graphical user interface (GUI) to demonstrate sensor responses according to five different postures. Thus, our heater-integrated sensor shows promise as a potential device for emerging smart-car seats.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Permutation-Aware Activity Segmentation via Unsupervised Frame-to-Segment Alignment\n",
            "Authors: Tran Q.H.\n",
            "Abstract: This paper presents an unsupervised transformer-based framework for temporal activity segmentation which leverages not only frame-level cues but also segment-level cues. This is in contrast with previous methods which often rely on frame-level information only. Our approach begins with a frame-level prediction module which estimates framewise action classes via a transformer encoder. The frame-level prediction module is trained in an unsupervised manner via temporal optimal transport. To exploit segment-level information, we utilize a segment-level prediction module and a frame-to-segment alignment module. The former includes a transformer decoder for estimating video transcripts, while the latter matches frame-level features with segmentlevel features, yielding permutation-aware segmentation results. Moreover, inspired by temporal optimal transport, we introduce simple-yet-effective pseudo labels for unsupervised training of the above modules. Our experiments on four public datasets, i.e., 50 Salads, YouTube Instructions, Breakfast, and Desktop Assembly show that our approach achieves comparable or better performance than previous methods in unsupervised activity segmentation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic Risk Assessment in Construction: Integrating Vision-based Postural Assessment and EMG-based Fatigue Analysis\n",
            "Authors: Tao Y.\n",
            "Abstract: Work-related musculoskeletal disorders (WMSDs) are prevalent among construction workers, negatively impacting their occupational health, safety, and working performance. Though various ergonomic risk assessment methods have been developed, limited of them have integrated different indicators to provide a more comprehensive assessment scheme based on diverse data sources. Thus, this study proposes a framework that considers both postural and physiological perspectives to narrow this research gap. It integrates the computer vision-based postural assessment and the cumulative muscle fatigue analysis using electromyography (EMG) sensors. Then, the fused results can be obtained through a knowledge-based risk matrix. The proposed method has been applied in a realistic case study to demonstrate its effectiveness and feasibility. This study contributes to enriching the ergonomic risk assessment methods based on data fusion and the adoption of different digital technologies. It has the potential to facilitate effective ergonomic risk management, thereby promoting OHS in the construction industry.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Real-Time Ergonomic Risk Assessment Using Inertial Measurement Units: A Case Study in the Manufacturing Industry\n",
            "Authors: Salem N.\n",
            "Abstract: This study presents a novel method utilizing wearable technology for ergonomic risk assessment, specifically targeting the mitigation of work-related musculoskeletal disorders (WMSDs) within industrial settings. It employs Inertial Measurement Units (IMUs) to capture and analyze joint angles in real time, with a detailed focus on the shoulder, elbow, and wrist during repetitive tasks. A significant advancement involves converting IMU data into a comprehensive 3D orientation model using quaternions, significantly aiding in visualizing limb movements and detecting potential ergonomic risks. A case study from the automotive industry highlights the importance of closely monitoring wrist movements to manage ergonomic risks effectively. By advancing the understanding of ergonomic risks and facilitating targeted interventions, this study contributes to integrating innovative solutions for improving productivity and worker well-being, in line with Industry 5.0 principles. Additionally, we propose future directions for integrating AI and machine learning to enhance predictive ergonomic risk assessment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Wireless Wearable System to Monitor Posture when Using Ergonomic Setups\n",
            "Authors: Buelt A.\n",
            "Abstract: Ergonomic office setups are often used to prevent chronic pain caused by sitting at a desk for long periods of time. However, these setups are only effective if used correctly. This paper explores a solution that identifies poor posture in the three areas of the body. More ergonomic work office strategies include movements, such as transitioning from sitting to standing and vice versa. A user of this kind of system may need to monitor their posture for different setups. Previous studies have looked at monitoring human activities and static posture. However, most research focuses on one typical setup. The solution in this paper can be applied to three different ergonomic setups - a standing desk, a kneeling chair, and a typical office chair. The system consists of a wearable device, a stationary computer, and a simple user interface. The wearable device has accelerometers that monitor posture points on the upper legs, the torso, the shoulders, and the head. The data is sent wireless to be processed using a machine learning decision tree model. The result of the processed data is shown to the user in real-time. The result corresponds with a picture that helps the user visualize the posture issue detected. Five decision tree models were developed with at least 92 % accuracy. For each ergonomic setup, for each of the three sections of the body monitored, a model would be needed to be developed, resulting in nine different models. However, some of the body positions share similar posture positions across the three ergonomic setups. Reducing the number of models required less training data to be collected. This reduction did not seem to impact the accuracy of the models negatively.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Comparative Analysis of Wearable and Computer Vision-Based Methods for Human Torso Posture Estimation\n",
            "Authors: Muntean E.\n",
            "Abstract: This paper conducts a comparative analysis of human torso posture estimation methodologies, focusing on an inertial measurement unit (IMU) sensor coupled with an Arduino UNO as a wearable approach, and Kinect V2, utilizing OpenCV for posture analysis. The core objective of this study is to ascertain which method yields greater precision in the estimation of human torso posture. The IMU sensor, characterized by its wearability, provides the distinct advantage of unobtrusiveness and the capability to record motion across diverse environments. Conversely, Kinect V2 leverages computer vision techniques to derive posture estimations from visual data in real-time. Through comprehensive experimentation, this research evaluates the accuracy of both methodologies by juxtaposing their posture estimation outcomes. The findings of this investigation aim to significantly contribute to the enhancement of human posture estimation systems, with wide-ranging implications for health, sports, and ergonomics.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A HUMAN-ROBOT INTERACTION PLATFORM FOR OPERATOR WELL-BEING: A CASE-STUDY\n",
            "Authors: Venkateswaran S.\n",
            "Abstract: This article presents a Human-Robot Interaction (HRI) platform for the assembly process of a condensate pump. An ergonomic analysis using the Rapid Upper Limb Assessment (RULA) is carried out using a simulation package to identify the fatigue levels in the upper-arm region during the assembly process of the pump. From the operator feedback and the RULA score, an HRI platform using a collaborative robot (cobot) is proposed for the assembly process. Based on complexity and dexterity, the screwdriving operation was assigned to the cobot. The RULA analysis was revisited for this platform and it showed an improvement in the ergonomic scores from 7 to 3. The magnitude of fatigue imposed on the upper-arm was then analyzed experimentally using Electromyography (EMG) sensors. By using the Support Vector Machine (SVM) technique, the fatigue levels were interpreted before and after the implementation of the HRI platform. The results suggest that the HRI platform helps to mitigate musculoskeletal problems in the future, thereby promoting a healthier and safer worker environment. By exploiting the capabilities of a cobot, a synergy between humans and automation technologies can be achieved, leading to a sustainable and ergonomic future in manufacturing.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: IoT-Health: A Framework for Integrating IoT Devices for Monitoring Back Posture\n",
            "Authors: Kazim H.\n",
            "Abstract: In the modern era, healthcare monitoring has emerged as a critical aspect of preventive medicine, enabling early detection of health issues and timely intervention. The evolution of technologies ranging from wearable devices to remote sensing systems revolutionized healthcare by enabling continuous and non-invasive tracking of vital signs, activity levels, and physiological parameters. The wide adoption of healthcare monitoring technologies challenges the ability to integrate and analyze the high volume of data within multiple health care applications. This paper proposes a framework that integrates healthcare monitoring devices and the collected data for analysis. The proposed framework was validated by implementing a back posture monitoring application for early diagnosis and treatment. The collected data was analyzed through two different models: A time dependent model through Long Short-Term Memory (LSTM) and a time independent model using K-nearest neighbor (KNN). Both models showcased high prediction accuracies, with LSTM and KNN achieving a 99.2% and 92.9% accuracy rates, respectively.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Biomechanical Risk Evaluation Through Machine Learning Algorithms Fed with Features Extracted From sEMG of Neck Extensors\n",
            "Authors: Prisco G.\n",
            "Abstract: Work-related musculoskeletal disorders (WRMDs) affect millions of workers worldwide, posing substantial economic burdens on industries and healthcare systems. Prolonged exposure, repetitive tasks, awkward postures and intensive efforts are keys factors contributing to the development of WRMDs. Several quantitative or semi-quantitative methodologies are employed to evaluate the biomechanical risk and to prevent WRMDs in the occupational ergonomics field. However, these methods are still time-consuming and operator-dependent. Recently, the application of wearable sensors combined with artificial intelligence is providing remarkable results in terms of biomechanical risk assessment in the occupational ergonomics field. Therefore, in the present work, we examined the potential of Machine Learning (ML) models to differentiate between biomechanical risk categories as defined by the Revised NIOSH Lifting Equation (RNLE). The ML models were trained using time-domain and frequency-domain features extracted from surface electromyographic (sEMG) signals obtained from the neck extensor muscles of four healthy subjects during weight-lifting tasks. The study findings indicated that the Support Vector Machine algorithm performed the best, achieving an accuracy of 83.6% and an area under the receiver operating characteristic curve of 89.9%. However, the study was limited by its small sample size and the restricted age range of the volunteers. Future research involving a larger and more diverse population in terms of age and number of subjects could further validate the effectiveness of the proposed methodology.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Optimization of Ergonomics in Industrial Companies Based on Artificial Intelligence: Literature Review\n",
            "Authors: Bouriche L.\n",
            "Abstract: The objective of the ergonomics assessment is to improve general well-being at work by establishing an environment adapted to humans in terms of safety, health, and productivity. An in-depth analysis of physical ergonomics helps to determine the risk factors by job, quantify, prioritize, and subsequently develop appropriate control actions to control and reduce these factors. However, the use of traditional observation methods in ergonomics remains insufficient in terms of evaluating the working posture from the point of view of stability and measurement precision. The majority of methods are based on filling out questionnaires to collect information from the workstation. Artificial intelligence has demonstrated its essential contribution to work situations. Projects integrating AI have demonstrated a significant contribution in this type of situation and thus constitute a challenge for ergonomics. This paper will seek to analyze the contributions of the combination of the technologies offered by AI and the sciences of ergonomics. To do this, we will carry out a literature review on the impact of the introduction of new technologies to remedy the shortcomings of traditional methods used in ergonomics and the comparison between technologies. They are currently used.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Preliminary Development of a Gesture Recognition System for Posture Monitoring in Chainsaw Cutting: A Step Towards Enhanced Safety for Forestry Workers\n",
            "Authors: Massotti C.\n",
            "Abstract: Hand-Arm Vibration (HAV) is a prevalent occupational hazard affecting millions of workers, leading to various health issues. Among them, Musculoskeletal Disorders (MSDs) are frequently observed in workers who engage in repetitive tasks and adopt awkward postures. Training workers and monitoring their fatigue levels are essential measures to prevent injuries and the onset of occupational diseases. This study contribute to the first stage in the developing a gesture recognition system using Inertial Measurement Units (IMUs) for posture and movements monitoring in chainsaw cutting. Experiments were conducted simulating different cutting operations, and acquiring signals of body joint rotations. An algorithm combining autoencoder and random forest classifier was developed to classify the cutting conditions leading to an accuracy close to 95%, even when using just four sensors. Despite the limited data available, the findings are promising for future research into how injuries or occupational diseases affect the way forestry workers use chainsaws or other hand-held powered tools.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Evaluating ERAIVA – a software for video-based awkward posture identification\n",
            "Authors: Elango V.\n",
            "Abstract: The convergence of the focus of Industry 5.0 on human well-being and the prevalent problem of work-related musculoskeletal disorders necessitates advanced digital solutions due to limitations in manual risk assessment methods. This research aimed to compare usability of a newly developed video-based awkward posture identification software, the ergonomist assistant for evaluation (ERAIVA) with a conventional manual method. The risk assessment tool utilised in this study, integrated into the ERAIVA digital platform, is the risk management assessment tool for manual handling proactively (RAMP). Four assessors evaluated video-recorded tasks using both methods (manual and ERAIVA). The usability was assessed through the post-study system usability questionnaire, time consumption, number of video replays and video annotation deletions. The impact on identification of awkward posture durations was also studied. ERAIVA exhibited the highest usability score; it showed a higher number of video replays of specific sequences and annotations without significant differences in time consumption.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Real-Time Ergonomic Risk Assessment Approach for Construction Workers Based on Computer Vision\n",
            "Authors: Fan C.\n",
            "Abstract: Computer vision (CV) has been widely applied in many fields, including construction safety. As a factor of construction safety, ergonomic risk is receiving more and more attention. Although there are a few ergonomic risk assessment frameworks based on CV, the current mainstream CV-based ergonomic risk assessments cannot monitor and estimate the ergonomic risk of the human using all the necessary ergonomic risk information, such as the wrist angle. Most existing methods are based on detecting key points of the human body in images and give the two-dimensional (2D) pixel coordinates of the key points instead of the actual three-dimensional (3D) coordinates. Discrepancies exist between the skeletal angles calculated based on 2D and exact 3D coordinates. Rapid Entire Body Analysis (REBA) is one of the most common risk assessment tools researchers use, requiring accurate 3D joint angles. Therefore, this paper presents a comprehensive ergonomic risk assessment method based on CV and REBA. In addition to capturing coordinates throughout the body, it can estimate wrist angles in real time; thus, this method addresses the research gap. The proposed method utilizes CV to infer ten joints and six key points (e.g., head, thorax, etc.) throughout the body. With the estimated joints and key points, it can calculate six angles between different body segments and the twists of five body joints for REBA calculations. Data were collected in a laboratory with a retro-reflective marker-based motion capture system to simulate the operations of construction workers. The data were used to evaluate the accuracy of the proposed method. In total, the evaluation data consists of 80,300 annotated images. Results show that the proposed framework, in conjunction with the deep neural network models we have trained, can accurately estimate REBA-related key points of construction workers; therefore, the accurate ergonomics risk score for REBA can be obtained. It is worth noting that the proposed method can also be applied to workers in other fields beyond construction sites.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Biomechanical analysis of musicians’ posture and movement patterns for optimizing performance and reducing injury risk\n",
            "Authors: Yao X.\n",
            "Abstract: Musicians often face unique physical demands that can lead to musculoskeletal disorders (MSDs) and performance-related injuries due to repetitive movements and poor postural alignment. This study examines the biomechanical factors contributing to these issues and explores the relationship between posture, movement efficiency, and performance quality across various instrument types. Using advanced motion capture technology, force plates, and electromyography (EMG), this research analyzes joint angles, ground reaction forces (GRF), muscle activation levels, and kinematic patterns in 84 musicians. Key findings include significant differences in joint angles across career stages, with mid-career musicians exhibiting the highest deviations in shoulder and elbow alignment (p < 0.05), suggesting that posture improves with experience but still presents a risk. GRF analysis revealed that standing musicians experience a significantly higher load (mean GRF = 489.6 N, p = 0.012), leading to greater postural instability and reduced performance quality. The study also found a positive correlation between movement efficiency and auditory performance (r = 0.61, p = 0.004), emphasizing the importance of efficient, fluid movements in producing high-quality musical output. Multivariate regression analysis indicated that violinists and cellists experience the highest muscle activation and fatigue rates, with violinists showing a fatigue rate of 0.29 %MVC/min (p < 0.05), highlighting the physical strain on string players. Pressure distribution analysis for seated pianists identified asymmetries in posture, with a significant imbalance in left and right side pressure (p = 0.023), contributing to discomfort and potential long-term injury risks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Technological Surrogate Physiotherapy to Improve Knee Health Through Exercise: Human-Computer Interaction to Build Trust and Acceptance Notwithstanding Pain\n",
            "Authors: Or C.K.\n",
            "Abstract: A machine-learning system is constructed to alleviate chronic knee pain through exercise and muscle strengthening. Three user-focused features are offered: video-based exercise demonstrations, real-time posture analysis and feedback, and performance and progress tracking. This system, which functions as an artificially-intelligent “technological surrogate physiotherapist,” applies human-computer incentive compatibility and joint learning-by-doing to reify and strengthen motivation, trust and acceptance and to increase effectiveness and efficacy, initial exacerbation of knee pain notwithstanding. In a 3-week experiment involving 60 individuals carrying chronic knee pain, positive and statistically significant outcomes were recorded regarding the Western Ontario and McMaster Universities Osteoarthritis Index physical function (p = 0.001), quality of life (EQ-5D-5L: < 0.001; EQ VAS: p = 0.004), exercise engagement (p < 0.001), system usability, and system acceptance. Technology-based solutions hold significant promise for improving future clinical practice by reducing professional resource demand and increasing the accessibility and caregiver-patient incentive compatibility under physiological healthcare.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Semiautomatic rapid upper limb assessment methods: validation of AzKRULA\n",
            "Authors: Lolli F.\n",
            "Abstract: In the Industry 5.0 era, optimising working posture is crucial to reduce musculoskeletal disorder risks. Rapid upper limb assessment (RULA) is a common evaluation method, but traditional approaches are often subjective, and wearable sensors can be costly and intrusive. Optical sensors offer a more practical alternative for industrial environments. This study compares the effectiveness of an in-house application, AzKRULA based on Microsoft Azure Kinect, with Siemens Jack Tat Suit software for RULA assessment. We evaluated 15 static postures with both AzKRULA and the Jack Tat Suit software, using expert assessments as a reference. The results showed a high level of agreement between AzKRULA, expert evaluations, and the commercial software, highlighting AzKRULA as a cost-effective, rapid tool for ergonomic assessment. Thus, AzKRULA can support ergonomists and health and safety managers in assessing upper-body ergonomic risks in repetitive tasks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Differences in Natural Standing Posture Are Associated With Antisocial and Manipulative Personality Traits\n",
            "Authors: Wainio-Theberge S.\n",
            "Abstract: In humans and animals, body posture is used in social and affective contexts to communicate social information, signal intentions, and prepare the individual for adaptive action. However, though stable individual differences in affect and social cognition are well studied, body posture continues to be typically studied in the context of state variation, and it remains unknown if trait-level differences in body posture exist and carry information about the individual. In our article, we show in a large sample (total N = 608 across five studies) that individual differences in body posture measured in a natural, baseline context are robustly associated with individual differences in personality. Through a series of studies, we characterize this relationship as reflecting individual differences in postural dominance and submission, which are associated with attitudes toward competition, power, and social hierarchy. We also validate our measure of natural posture by correlating it with physiological data from relevant musculature and showing its stability over a 1-month interval. Our work suggests that postural signaling of social rank occurs not just in brief displays in social contexts but exists as a stable individual trait with consequences for socioaffective processing.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Test–Retest Reliability and Responsiveness of the Machine Learning-Based Short-Form of the Berg Balance Scale in Persons With Stroke\n",
            "Authors: Chen P.T.\n",
            "Abstract: Objective: To examine the test–retest reliability, responsiveness, and clinical utility of the machine learning-based short form of the Berg Balance Scale (BBS-ML) in persons with stroke. Design: Repeated-measures design. Setting: A department of rehabilitation in a medical center. Participants: This study recruited 2 groups: 50 persons who were more than 6 months post-stroke to examine the test–retest reliability, and 52 persons who were within 3 months post-stroke to examine the responsiveness. Test–retest reliability was investigated by administering assessments twice at a 2-week interval. Responsiveness was investigated by gathering data at admission and discharge from the hospital. Interventions: Not applicable. Main Outcome Measure: BBS-ML. Results: The BBS-ML exhibited excellent test–retest reliability (intraclass correlation coefficient=0.99), acceptable minimal random measurement error (minimal detectable change %=13.6%), and good responsiveness (Kazis’ effect size and standardized response mean values≥1.34). On average, the participants completed the BBS-ML in around 6 minutes per administration. Conclusions: Our findings indicate that the BBS-ML appears an efficient measure with excellent test–retest reliability and responsiveness. Moreover, the BBS-ML may be used as a substitute for the original BBS to monitor the progress of balance function in persons with stroke.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A comparison between Multilayer Perceptrons and Kolmogorov-Arnold Networks for multi-task classification in sitting posture recognition\n",
            "Authors: Carneros-Prado D.\n",
            "Abstract: Prolonged incorrect sitting postures can lead to various health issues, including musculoskeletal disorders and reduced quality of life. Efficient and accurate methods for monitoring and assessing sitting postures are crucial for promoting overall well-being in our increasingly sedentary society. This study compares the performance of Kolmogorov-Arnold Networks (KANs) and Multilayer Perceptrons (MLPs) in sitting posture recognition, utilizing a multi-task classification approach to simultaneously identify upper and lower body positions. A comprehensive dataset of sitting postures was developed using MediaPipe for skeletal extraction, labeled for both body regions, and encompassing a range of common scenarios. The models were implemented and evaluated using Leave-One-Subject-Out (LOSO) cross-validation to assess generalization capability across different individuals. Results indicated that the KAN model achieved higher accuracy (97.03% for upper body and 92.11% for lower body) with fewer parameters (4,320) compared to the MLP (93.87% and 91.47% respectively, with 7,662 parameters). Although the MLP demonstrated faster inference, both models achieved accuracies exceeding 91% in LOSO validation, suggesting their potential for real-time applications. This study significantly contributes to the field of automatic posture recognition, offering insights into the applicability of KANs and MediaPipe-based pose estimation in ergonomic recognition systems and demonstrating the effectiveness of a multi-task approach for comprehensive sitting posture analysis.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Facial Feature Analysis for Anxiety Detection in People with Drug Addiction: Establishment and Validation of Machine Learning Models\n",
            "Authors: Zhong X.\n",
            "Abstract: Dynamic monitoring of anxiety levels of drug addicts can help improve the effectiveness of drug addiction treatment. However, traditional psychological measurement methods have limitations and cannot effectively meet these needs. There is an urgent need to explore novel measurement methods. In view of this, this study collected and analyzed facial movements and anxiety level data of 279 male drug addicts using image sensor devices and psychological questionnaires, respectively. The aim was to establish and validate prediction models of anxiety levels in drug addicts based on facial feature analysis using machine learning methods. Results showed that prediction models had good predictive effects (the highest split-half reliability level: r=0.976; the highest criterion-related validity level: r=0.390). The results of this study can provide novel and reliable research methods and measurement tools for dynamic monitoring of the mental health of drug addicts.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Systematic Review: Advancing Ergonomic Posture Risk Assessment through the Integration of Computer Vision and Machine Learning Techniques\n",
            "Authors: Yang Z.\n",
            "Abstract: Integrating computer vision and machine learning with observation-based ergonomic posture risk assessment methods represents a significant advancement in occupational health and safety, which is essential in reducing work-related musculoskeletal disorders. This collaboration has enhanced the efficiency and scope of ergonomic posture risk assessments. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses guideline was utilized to select relevant papers in this review. A total of 583 research articles were retrieved from the Web of Science and IEEE Xplore databases, and 30 articles meeting the screening criteria were selected for detailed analysis. The results were organized into three distinct stages: Data Preparation, Pose Estimation, and Risk Assessment. During the Data Preparation Stage, the data acquisition devices, datasets, experimental conditions, and observation-based ergonomic posture risk assessment tools utilized in each article were discussed. Subsequently, in the Pose Estimation Stage, the human pose estimation techniques employed and their ability to detect wrist details were outlined. Finally, the risk assessment methods were presented, encompassing Directly Assess Risk Levels, Predict Risk Levels Using Traditional Machine Learning Algorithms, and Advanced Risk Prediction Using Deep Learning Algorithms. We propose several directions for future research. By synthesizing the current literature and identifying critical areas for future development, this review aims to provide a comprehensive overview of the intersection between computer vision, machine learning, and observational ergonomic posture risk assessment, with implications for improving occupational health and safety.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An Exploration of Human Pose Estimation Based Cheating Tools for FPS Video Game and its Defense Solution\n",
            "Authors: Liu C.\n",
            "Abstract: Modern computer vision and AI algorithms have become highly effective in analyzing high-dimensional image and video content for various tasks. Recently, some have exploited the power of computer vision to develop cheating tools for video games, which pose a serious threat to the gaming community and the game industry. Using human pose estimation algorithms, these cheating tools can assist players by automatically targeting and shooting with very high precision and accuracy. Compared to classic cheating methods, these tools are generally much more undetectable as they can mimic real 'competent' players. To counter this threat, we propose a machine learning-based approach that leverages the concept of adversarial attacks to generate perturbations that fool such human pose estimation algorithms, preventing cheaters from gaining unfair advantages. In this work, we first implement the video game cheating systems and then we propose and implement our solution. In the end, we use the cheating system to evaluate the efficiency of our proposed algorithms in defending against such cheating tools. Experimental results show that our algorithm can effectively deceive advanced human pose estimation algorithms by adding invisible perturbations to the characters in the video game, maintaining a fair and healthy gaming environment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Auto-AzKNIOSH: an automatic NIOSH evaluation with Azure Kinect coupled with task recognition\n",
            "Authors: Lolli F.\n",
            "Abstract: Standard Ergonomic Risk Assessment (ERA) from video analysis is a highly time-consuming activity and is affected by the subjectivity of ergonomists. Motion Capture (MOCAP) addresses these limitations by allowing objective ERA. Here a depth camera, one of the most commonly used MOCAP systems for ERA (i.e. Azure Kinect), is used for the evaluation of the NIOSH Li fting Equation exploiting a tool named AzKNIOSH. First, to validate the tool, we compared its performance with those provided by a commercial software, Siemens Jack TAT, based on an Inertial Measurement Units (IMUs) suit and found a high agreement between them. Secondly, a Convolutional Neural Network (CNN) was employed for task recognition, automatically identifying the lifting actions. This procedure was evaluated by comparing the results obtained from manual detection with those obtained through automatic detection. Thus, through automated task detection and the implementation of Auto-AzKNIOSH we achieved a fully automated ERA. Practitioner Summary: The standard evaluation of the NIOSH Lifting Equation is time-consuming and subjective, thus a new automatic tool is designed, which integrates motion captures provided by Azure Kinect and task recognition. We found a high agreement between our tool and Siemens Jack TAT suit, the golden standard technology for motion capture.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic Evaluation of a Walk-Behind AI-Based Cotton Fertilizer Applicator\n",
            "Authors: Chouriya A.\n",
            "Abstract: The mechanization of agricultural operations greatly influences both the efficiency of farming operations and the health and safety of farm workers. Human exposure to working environments represents a significant hazard associated with machines and the environment. This research focuses on evaluating the ergonomic aspects of the newly developed artificial intelligence (AI)-based cotton fertilizer applicator, aiming to assess the potential impact on workers' health, safety, and overall exertion. Ergonomic factors such as heart rate (HR), oxygen consumption rate (OCR), energy expenditure rate (EER), physiological work cost, as well as discomfort and posture during use, were assessed at three different operating speeds of the applicator. Results showed that HRs, OCR, and EER ranged from 86 to 109 beats/min, 0.44 to 0.83 L/min, and 9.3 to 17.45 kJ/min, respectively, indicating that the physical demands on workers were within manageable limits. Discomfort was predominantly noted in the palms, attributed to the necessity of controlling the applicator with both hands. Analysis of cardiac effort revealed that 93.75%, 92.70%, and 94.67% of effort was expended during work at speeds of 0.5, 0.8, and 1 km/h, respectively, with the remainder during recovery periods. The workload on the middle deltoid muscle during field operation varied between 10.15%–14.58% for left-hand controls and 1.85%–3.5% for right-hand controls. Statistical analysis highlighted significant differences in physiological responses among participants, with ergonomic parameters closely linked to the applicator's forward speed. The study concludes using the developed AI-based cotton fertilizer applicator does not pose significant health risks to operators, suggesting its ergonomic design effectively mitigates physical strain.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Driver Posture Recognition: A Review\n",
            "Authors: Mahomed A.S.\n",
            "Abstract: Driver Posture Recognition Systems (DPRS) are indispensable for advancement in vehicle safety by tracking driver posture using sensors and cameras. These systems monitor the driver's position, movements, and posture to promote safe driving behaviour and take action if needed using a variety of approaches to driver posture analysis. Sensor based approaches involved the utilisation of sensors such pressure sensors, accelerometers, and gyroscopes, to collect information on the driver's posture when seated in vehicle. Vision based approaches consisted mainly of cameras to monitor and assess the driver's position using advanced computer vision methods associated with facial landmark detection and body posture analysis. Hybrid approaches is the merging of both sensor-based and vision-based approaches to provide improved precision through the integration of various data sources using fusion tactics, feature extraction methods, and machine learning algorithms. The implementation of DPRS in vehicles is centred on monitoring driver posture in real-Time without intrusion, providing prompt alerts to reduce risks related to incorrect seating or positioning. This article provides a general review of most aspects related to DPRS design, emphasizing the significance of accurate posture recognition that give priority to driver health and safety.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Objective assessment of cognitive fatigue: a bibliometric analysis\n",
            "Authors: Han J.C.\n",
            "Abstract: Aim: The objective of this study was to gain insight into the nature of cognitive fatigue and to identify future trends of objective assessment techniques in this field. Methods: One thousand and eighty-five articles were retrieved from the Web of Science Core Collection database. R version 4.3.1, VOSviewer 1.6.20, CiteSpace 6.2.R4, and Microsoft Excel 2019 were used to perform the analysis. Results: A total of 704 institutes from 56 countries participated in the relevant research, while the People’s Republic of China contributed 126 articles and was the leading country. The most productive institute was the University of Gothenburg. Johansson Birgitta from the University of Gothenburg has posted the most articles (n = 13). The PLOS ONE published most papers (n = 38). The Neurosciences covered the most citations (n = 1,094). A total of 3,116 keywords were extracted and those with high frequency were mental fatigue, performance, quality-of-life, etc. Keywords mapping analysis indicated that cognitive fatigue caused by continuous work and traumatic brain injury, as well as its rehabilitation, have become the current research trend. The most co-cited literature was published in Sports Medicine. The strongest citation burst was related to electroencephalogram (EEG) event-related potential and spectral power analysis. Conclusion: Publication information of related literature on the objective assessment of cognitive fatigue from 2007 to 2024 was summarized, including country and institute of origin, authors, and published journal, offering the current hotspots and novel directions in this field.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Optimization design of biomechanical parameters based on advanced mathematical modelling\n",
            "Authors: Wen Y.\n",
            "Abstract: In recent years the use of biomechanics in athletic training and performance has received a lot of attention, especially in university sports programs. Biomechanics is the study of the mechanical principles that control how biological things move or are constructed. It is critical for understanding the intricate relationships between physical performance, body mechanics, and injury prevention. The objective of this study is to establish how biomechanical variables can be designed and optimized in universities using mathematical modeling. In this study, a novel Emperor Penguin Search-driven Dynamic Feedforward Neural Network (EPSO-DFNN) is proposed to optimize the biomechanical parameters of athletes. Various biomechanical data are utilized from athletes participating in different sports. Biomechanical parameters include muscle activation patterns, joint angles, forces, and movement. The data was preprocessed using Z-score normalization from the obtained data. The Fast Fourier Transform (FFT) using features is extracted from preprocessed data. The proposed method is to identify the optimal configurations for athlete’s movements tailored to their sports and individual biomechanical profiles. The proposed method is the performance of various evaluation metrics such as F1-score (92.76%), precision (91.42%), accuracy (90.02%), and recall (89.69%). The result demonstrated that the proposed method effectively improved the performance in athletic capabilities compared to other traditional algorithms. This study demonstrates how mathematical modeling may be used to optimize biomechanical characteristics, providing insightful information that can be used to improve athletic performance and encourage safer behaviors in athletic settings.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Analyzing Worker Videos for Quantifying Motion Amounts Through Computer Vision\n",
            "Authors: Iyer H.\n",
            "Abstract: This study proposes a computer vision framework to monitor worker joint motion from task videos. The framework focuses on landmark features, particularly those associated with participants’ upper and lower limbs, to extract spatial joint movements. By utilizing the Hotelling T-squared statistic, multivariate joint motion distributions were monitored. The application of control chart techniques involved two phases: Phase I (offline) and Phase II (online) monitoring. For implementation, task videos were strategically partitioned into two segments. The first segment was designated for offline training, allowing for the establishment of baseline patterns. The second was allocated for online monitoring, enabling the real-time evaluation of worker demand levels during operational activities. The correlation between the amount of motion and task perception aligns with participants’ ratings from the perception survey, validating the framework’s effectiveness. Understanding how workers interact with products and equipment allows designers to create tools that are easier and more comfortable to use.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Vision-based Postural Risk Auto-assessment Method for Sit-stand Office Working using REBA\n",
            "Authors: He Q.\n",
            "Abstract: Sit-stand workstations are increasingly used to reduce the occupational sitting of office workers. However, there is a lack of auto-assessment methods for musculoskeletal disorders (MSDs) related to postures during daily sit-stand office work. This study proposes an automatic posture risk assessment method using an RGB camera, aimed at evaluating MSDs risks in the real workplace. The proposed method utilizes MediaPipe for pose estimation, and the Rapid Entire Body Assessment (REBA) for evaluating MSDs risks of full-body posture and local body parts. Data collected from 12 participants in a 60-minute sit-stand work indicate that the REBA score for sitting postures is slightly higher than that for standing, particularly in the trunk region. The main contribution is to provide a practical and markerless automatic REBA method and to expand the research on postural assessments in sit-stand workstations. It provides an effective way to identify high-risk postures during sit-stand working.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic and sustainable posture for gynecological laparoscopic surgeons determined based on images analyzed using artificial intelligence\n",
            "Authors: Ogawa M.\n",
            "Abstract: Studies have reported the emergence of work-related musculoskeletal disorders (WMSD) due to surgery. In fact, the usfige of long-shafted instruments has been suspected to induce WMSD in laparoscopic surgery. The present study therefore investigated whether differences in the range of motion of the face and neck, and the shoulder, elbow and hand on the dominant hand side, existed when using short- and long-shafted laparoscopic coagulation shears (LCS) during a gynecological laparoscopic surgery, based on images analyzed using artificial intelligence. After identifying the corresponding body parts in the video, the range of motion was illustrated graphically for each joint coordinate, followed by statistical analysis for changes in the position of each part. The range of motion for the face and neck did not significantly differ, whereas those for the shoulder, elbow and hand became noticeably broader when using the 36-cm long-shafted LCS than when using the 20-cm short-shafted LCS. Overall, the shorter LCS promoted a narrower range of motion compared with the 36-cm LCS, suggesting its potential for reducing the physical strain placed on the surgeon's body during gynecological laparoscopic surgery.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Online Rapid Job Analysis and Evaluation Using Particle Swarm Optimized Random Forest\n",
            "Authors: Hu X.\n",
            "Abstract: Manual laborers are often at an increased risk for work-related musculoskeletal disorders (WMSDs) due to improper work postures or the lifting of excessively heavy objects. Therefore, conducting an effective ergonomic assessment of workers is crucial for enhancing productivity and minimizing the occurrence of WMSDs. The Ergonomic Posture Risk Assessment (EPRA) is a widely used method for this assessment. However, traditional EPRA methods rely on human or sensor input, leading to subjective bias, instability, and reduced accuracy. This study addresses these issues by proposing an objective machine-learning approach. It employs a non-intrusive computer vision technique for posture capture, enabling rapid analysis of the worker's activities through Random Forest analysis. The dataset for risk assessment is generated from the worker's skeletal joint posture data, collected using Movenet Thunder in conjunction with an inertial motion capture device and the Rapid Entire Body Assessment (REBA) standard. The Particle Swarm Optimization Random Forest (PSO-RF) model is then utilized to predict risk scores for various postures, incorporating limb length ratios to tackle challenges associated with observing torsional joints. The model's effectiveness in detecting poor posture is subsequently evaluated. The findings indicate that the PSO-RF model successfully identifies poor postures and computes the corresponding REBA scores with 89% accuracy, 93% precision, 91% F1 score, 89% recall, and a kappa value of 82%. This research demonstrates that the machine learning approach, utilizing computer vision and Random Forest, can effectively conduct EPRA to prevent musculoskeletal injuries, providing a data-driven and accurate method for enhancing workplace safety and health.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Pasteables: A Flexible and Smart 'Stick-and-Peel' Wearable Platform for Fitness and Athletics\n",
            "Authors: Dizon-Paradis R.N.\n",
            "Abstract: Wearable technologies, such as smartwatches and health monitoring bands, are becoming increasingly popular and transforming our fitness and sports industry. Monitoring health parameters and body activity can help achieve fitness goals, improve sports performance, and aid in physiotherapy. However, state-of-the-art wearable devices are often not flexible (i.e., targeted to a specific use case), expensive, hard to setup, or have privacy concerns. They are designed and optimized for a specific application with tight hardware software integration, and it is hard or impossible to repurpose them for diverse use cases. In this article, we propose a flexible, reconfigurable human body movement and health monitoring platform, called Pasteables. It is a stick-and-peel device (which acts like a band-aid) that attaches to the skin or clothing and can create an on-body network of smart wearables. Given an application, Pasteables can be easily adapted to its requirements while ensuring good performance and privacy. We present the overall architecture, system design steps, and the configuration process. We have designed a set of functional prototypes and configured them for performing a variety of cameraless pose and posture detection tasks, which are important for athletes, professional dancing, physiotherapy, and fitness workouts. We note that the Pasteables can perform pose/posture detection without external stationary reference at low cost and high accuracy.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: How Do Exoskeletons Affect Balance During Intermittently Performed Sustained Bending Tasks?\n",
            "Authors: Kuber P.M.\n",
            "Abstract: Exoskeletons are beneficial in reducing effort and risk of overexertion-related injury, yet they can also induce side-effects in their wearers. The added weight, as well as interplay of assistive forces of the device can affect wearers’ body posture while performing tasks. Factors like fatigue and awkward postures can affect neuromuscular systems, eventually affecting balance. We examined how back-support exoskeletons (BSEs) affect whole-body stability in wearers. Twelve participants performed multiple trials of intermittent wire grasping tasks with 450 trunk flexion, until they reached a medium-high fatigue level with/without BSE in symmetric and with/without 450 (left side) asymmetry. Participants were asked their fatigue level using ratings of perceived exertion (RPE) in back and legs on the Borg CR-10 scale as they stood with one foot on each of two floor-embedded force plates. Findings revealed that both maximum deviation and mean velocity of center of pressure (COP) were ~39% (p-value<0.01) and 133% (p-value<0.05) lower respectively with assistance vs. without in asymmetric posture and remained lower at both low and medium fatigue level in legs. Overall, the difference between ground reaction forces in left vs. right foot was ~28% lower (p-value<0.01) while wearing BSE. Findings from this study may be beneficial in understanding the risk of fall while performing tasks with wearable assistive devices.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Leg postural identification framework based on one-dimensional force data using machine learning models\n",
            "Authors: Adalarasu K.\n",
            "Abstract: Indeed, human postural identification has become increasingly significant in various areas, especially when it comes to monitoring the health status of older adults, predicting their next movements, assessing sitting behavior, and implementing surveillance systems. Understanding and analyzing human posture can provide valuable insights into an individual's physical condition, movement patterns, and potential health risks. An attempt is made to identify these postures using machine learning models with the help of one-dimensional (1D) data to avoid the computational burden of gathering images using Kinect V2 cameras. The preferred method encompasses the use of 1D force data in x, y, z (vertical ground reaction force [VGRF]) and moment data in x, y, z directions. Twenty-five subjects are assessed for their three static postures (sitting, double support standing, squat standing) for 15seconds each (two trails) consecutively using a SENSIX force platform. The study involves performing postures in different orders for each trial using the force platform for collecting force and moment data on three axes each: Fx, Fy, Fz, Mx, My, and Mz, with a sampling rate of 1000Hz. The raw analog data obtained from the force platform is filtered using a low-pass Butterworth filter with a cutoff frequency of 10Hz (second order with zero latency). Three statistical features and two nonlinear time domain features are extracted from VGRF. Logistic regression (LR), ensemble (EN), support vector machine (SVM), decision trees (DT), K-nearest neighbors (KNN) models in MATLAB classifier learning App have been used and tested to assess these three postures. Among which EN model provided the best accuracy of about 88% in classifying the postures. These machine learning (ML) models allow for the recognition of human postures, which might be used for remote monitoring, rehabilitation, and human-computer interaction.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The Impact of Individual Differences in Developing Computational Thinking and Sensor Data Analytics Skills in Construction Engineering Education\n",
            "Authors: Khalid M.\n",
            "Abstract: The construction industry is a hazardous environment with a high prevalence of work-related musculoskeletal disorders, compromising workers’ physical and emotional well-being. Construction practitioners can leverage sensor-based safety assessment systems to track and identify workers’ awkward postures, preventing potential injuries. Educational sensor data practices with block programming can enable higher-order learning of the required computational skills for sensor data analytics. However, limited research exists on the factors influencing the acquisition of these skills in training graduating construction students. Through a sensor-based risk assessment intervention, this study explores how individual characteristics (demographics) influence students’ learning. Assessments included perceived self-efficacy of data analytics skills, analytical performance scores, and user acceptance of the educational platform. The results suggest: (a) women show higher self-efficacy gains, while Hispanic/Latino students and those without construction or programming experience report lesser gains, (b) students reach similar performance levels, but those with construction experience excel in reflection reports, and (c) students without construction experience perceive higher utility and lower risks, while Hispanic/Latino students show greater future intent to use the pedagogical tool. The findings contribute to Aptitude-Treatment Interaction Theory by highlighting how individual differences can impact the efficacy of pedagogical interventions in acquiring technical skills in construction education.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: VR Devices in Ayurvedic Care: Understanding Influential Factors for User Behavior and Continuance Intention\n",
            "Authors: Ismail N.M.\n",
            "Abstract: Virtual reality (VR) devices are being increasingly integrated into training, clinical practice, and healthcare treatment. While existing research predominantly focuses on modern medicine, this study investigated the factors influencing the intention to utilize VR devices within the context of Ayurvedic yoga and meditation practices. Employing an extended technology acceptance model (TAM) and incorporating elements from social cognitive theory, this study explores the impact of perceived intelligence, technological self-efficacy, and conventional TAM factors on Ayurvedic physicians’ usage behavior, continuance intention, and recommendation intention regarding VR devices. Data were collected from 275 Ayurvedic doctors and analyzed using PLS-SEM. The findings revealed a robust association between these constructs and medical practitioners’ adoption of VR in Ayurvedic yoga and meditation practices. Additionally, the study demonstrated a positive influence on the continuance and recommendation intentions of VR devices. The research also identifies demographic differences, such as age and gender disparities, which underscore distinct VR utilization patterns among these cohorts.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic risks in university engineering students during the pandemic\n",
            "Authors: Tupayachy-Quispe D.\n",
            "Abstract: The objective of this research work was to determine the existence of ergonomic risks in students, who carried out their studies in virtual mode in Industrial Engineering at the Catholic University of Santa María. It was carried out through surveys, observation and the application of the ROSA methodology. The results determine that the students' performance was not optimal, with different causes being psychosocial factors such as stress, anxiety and fatigue; as well as physical factors such as musculoskeletal disorders developed by a sedentary lifestyle, academic load, workplace conditions, lack of physical activity and others.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Artificial intelligence applications in bone fractures: A bibliometric and science mapping analysis\n",
            "Authors: Zhong S.\n",
            "Abstract: Background: Bone fractures are a common medical issue worldwide, causing a serious economic burden on society. In recent years, the application of artificial intelligence (AI) in the field of fracture has developed rapidly, especially in fracture diagnosis, where AI has shown significant capabilities comparable to those of professional orthopedic surgeons. This study aimed to review the development process and applications of AI in the field of fracture using bibliometric analysis, while analyzing the research hotspots and future trends in the field. Materials and methods: Studies on AI and fracture were retrieved from the Web of Science Core Collections since 1990, a retrospective bibliometric and visualized study of the filtered data was conducted through CiteSpace and Bibliometrix R package. Results: A total of 1063 publications were included in the analysis, with the annual publication rapidly growing since 2017. China had the most publications, and the United States had the most citations. Technical University of Munich, Germany, had the most publications. Doornberg JN was the most productive author. Most research in this field was published in Scientific Reports. Doi K's 2007 review in Computerized Medical Imaging and Graphics was the most influential paper. Conclusion: AI application in fracture has achieved outstanding results and will continue to progress. In this study, we used a bibliometric analysis to assist researchers in understanding the basic knowledge structure, research hotspots, and future trends in this field, to further promote the development of AI applications in fracture.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Application of Human Posture Recognition and Classification in Performing Arts Education\n",
            "Authors: Shen J.\n",
            "Abstract: This review explores the integration of human posture recognition and classification technologies in performing arts education, focusing on the advancements in deep learning, neural networks, and computer vision. It traces the evolution of these technologies and highlights their significance in developing personalized teaching methods for performing arts. Following this, we examine various posture recognition technologies, emphasizing data acquisition and processing methods while revealing their strengths and limitations, particularly in their adaptability to performing arts. Moreover, the review discusses posture classification methods, addressing the processing and interpretation of data, and the challenges in achieving classification accuracy and efficiency. Illustrative case studies demonstrate the application of these technologies in enhancing teaching and creativity in performing arts, significantly contributing to the skill development and expressiveness of artists and students. Concluding with a critical assessment of the current feasibility of these technologies in performing arts education, the review suggests potential improvements and future directions. It emphasizes the indispensable role of human posture recognition in advancing performing arts education and underscores the need for continued interdisciplinary research in this evolving field.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Recognition of Forward Head Posture Through 3D Human Pose Estimation With a Graph Convolutional Network: Development and Feasibility Study\n",
            "Authors: Lee H.\n",
            "Abstract: Background: Prolonged improper posture can lead to forward head posture (FHP), causing headaches, impaired respiratory function, and fatigue. This is especially relevant in sedentary scenarios, where individuals often maintain static postures for extended periods—a significant part of daily life for many. The development of a system capable of detecting FHP is crucial, as it would not only alert users to correct their posture but also serve the broader goal of contributing to public health by preventing the progression of chronic injuries associated with this condition. However, despite significant advancements in estimating human poses from standard 2D images, most computational pose models do not include measurements of the craniovertebral angle, which involves the C7 vertebra, crucial for diagnosing FHP. Objective: Accurate diagnosis of FHP typically requires dedicated devices, such as clinical postural assessments or specialized imaging equipment, but their use is impractical for continuous, real-time monitoring in everyday settings. Therefore, developing an accessible, efficient method for regular posture assessment that can be easily integrated into daily activities, providing real-time feedback, and promoting corrective action, is necessary. Methods: The system sequentially estimates 2D and 3D human anatomical key points from a provided 2D image, using the Detectron2D and VideoPose3D algorithms, respectively. It then uses a graph convolutional network (GCN), explicitly crafted to analyze the spatial configuration and alignment of the upper body’s anatomical key points in 3D space. This GCN aims to implicitly learn the intricate relationship between the estimated 3D key points and the correct posture, specifically to identify FHP. Results: The test accuracy was 78.27% when inputs included all joints corresponding to the upper body key points. The GCN model demonstrated slightly superior balanced performance across classes with an F1-score (macro) of 77.54%, compared to the baseline feedforward neural network (FFNN) model’s 75.88%. Specifically, the GCN model showed a more balanced precision and recall between the classes, suggesting its potential for better generalization in FHP detection across diverse postures. Meanwhile, the baseline FFNN model demonstrates a higher precision for FHP cases but at the cost of lower recall, indicating that while it is more accurate in confirming FHP when detected, it misses a significant number of actual FHP instances. This assertion is further substantiated by the examination of the latent feature space using t-distributed stochastic neighbor embedding, where the GCN model presented an isotropic distribution, unlike the FFNN model, which showed an anisotropic distribution. Conclusions: Based on 2D image input using 3D human pose estimation joint inputs, it was found that it is possible to learn FHP-related features using the proposed GCN-based network to develop a posture correction system. We conclude the paper by addressing the limitations of our current system and proposing potential avenues for future work in this area.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Prevalence and risk factors of work-related musculoskeletal disorders among male bus drivers in a mega-city\n",
            "Authors: Bi M.\n",
            "Abstract: [Background] Bus drivers are a high-risk group for work-related musculoskeletal disorders (WMSDs). There are a large number of bus drivers in mega-cities. High volumes of passenger traffic and complexity of road conditions may elevate their risk of WMSDs, but there are few studies related to this group. [Objective] To investigate the prevalence of WMSDs among bus drivers in a mega-city and to analyze potential influencing factors. [Methods] Based on cross-sectional study design and self-administered questionnaire, the prevalence of WMSDs in past 12 months were estimated by stratified cluster sampling among bus drivers in a mega-city. Pearson χ2 and logistic regression models were used to analyze the influencing factors for the body regions with a high prevalence. [Results] The overall prevalence of WMSDs in past 12 months among bus drivers in a mega-city was 49.5% (551/1 113). The prevalence of WMSDs by body regions ranged from 4.0% to 38.5%, and led by neck pain (38.5%), lower back pain (25.5%), and shoulder pain (20.8%). The results of logistic regression showed that the risk factors for neck pain were age (> 50 years), smoking, tiredness after work (moder-ate, severe), long sitting (frequently), awkward postures (sometimes, often, frequently), overtime(occasionally, often), workplace temperature (uncomfortable), and noise (severe) (OR=2.014、1.577、2.793、3.025、2.708、2.032、3.406、2.746、1.442、2.998、1.456、3.506； P < 0.05); the lower back pain risk factors were current work experience (6-10 years, 11-15 years, and 16-20 years), smoking, tiredness after work (moderate, severe), and awkward postures(sometimes, often, frequently)(OR=1.777、 2.130、 2.400、 1.503、 2.951、 3.364、 1.836、 4.569、 2.786，P < 0.05); and the shoulder pain risk factors were age (46-50 years, and > 50 years), smoking, tiredness after work (moder-ate, severe), vehicle type (hybrid power, diesel oil), awkward postures (often, frequently), overtime (often), and workplace temperature (uncomfortable) (OR=1.737、 2.357、 1.553、 2.259、 2.489、 1.659、 3.295、 2.777、 3.320、 2.266、 1.426，P < 0.05). Identified protective factors for neck and lower back pain were off-duty physical activity (1-2 times per week, and ≥3 times per week) (OR=0.553、 0.470、 0.586、 0.485，P < 0.05). [Conclusion] Nearly half of the bus drivers in the mega-city report symptoms of WMSDs, mainly in the neck, lower back, and shoulders. The prevalence is related to individual and occupational factors, and prevention and intervention measures should be actively taken.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Action Segmentation Using 2D Skeleton Heatmaps and Multi-Modality Fusion\n",
            "Authors: Hyder S.W.\n",
            "Abstract: This paper presents a 2D skeleton-based action segmentation method with applications in fine-grained human activity recognition. In contrast with state-of-the-art methods which directly take sequences of 3D skeleton coordinates as inputs and apply Graph Convolutional Networks (GCNs) for spatiotemporal feature learning, our main idea is to use sequences of 2D skeleton heatmaps as inputs and employ Temporal Convolutional Networks (TCNs) to extract spatiotemporal features. Despite lacking 3D information, our approach yields comparable/superior performances and better robustness against missing keypoints than previous methods on action segmentation datasets. Moreover, we improve the performances further by using both 2D skeleton heatmaps and RGB videos as inputs. To our best knowledge, this is the first work to utilize 2D skeleton heatmap inputs and the first work to explore 2D skeleton+RGB fusion for action segmentation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Unobtrusive machine learning based leg position detection during seated office work\n",
            "Authors: Ong L.\n",
            "Abstract: Musculoskeletal disorders (MSD) affect more than 1.63 billion people worldwide. Office workers are at high risk of developing MSD due to prolonged sitting during office work. Technical aids that provide users with insights into their sitting behaviour are useful for the prevention of MSD. Despite the fact that leg position is known to influence spine curvature, most position detection devices focus on upper body posture. In comparison, we recorded contact force with the chair using pressure sensors with the additional information from videos that showed the sitting position in 30 participants. Each participant was recorded during 5 working days resulting in a median recording time of 22 hours and 53 minutes. The active number of sensors, mean value and area under the curve of sensors in specific areas, feature extraction with convolution filters, and center of pressure were extracted from the force sensor values. An XGboost classification algorithm was trained on these features to discriminate between four different leg positions and the absence of a user. This algorithm obtained an overall accuracy of 73% on the test set consisting of 6 participants. The f1-scores for the classes 'away', 'no cross', 'knee cross', and 'ankle cross' were 0.96, 0.54, 0.76, and 0.44 respectively. The class legs on the chair, which rarely occurred in the monitored population, were mistaken for 'no cross' and could not be identified correctly in the test set. A second XGboost classifier was able to differentiate between symmetric and asymmetric sitting leg positions and away with a weighted accuracy of 85%. Overall pressure mats are a promising technology for observing common leg postures in office environments.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Posture Correction Device Based on IMU Sensors and CNN\n",
            "Authors: Ionica D.\n",
            "Abstract: In our daily lives, good posture is important to prevent complications and promote good health. This paper introduces an innovative approach that integrates wearable technology with Convolutional Neural Networks (CNNs) to address the general issue of body posture. The proposed system comprises a lightweight wearable device embedded with sensors, continuously monitoring and capturing real-time posture data. Leveraging deep learning algorithms, a powerful CNN processes this data to accurately classify and identify various posture patterns. Unlike traditional methods, our approach offers personalized and immediate feedback through an intuitive mobile app. Users receive real-time posture assessments, visualizations, and corrective recommendations, empowering them to proactively improve their posture habits. This not only enhances posture correction but also fosters a sustainable approach to musculoskeletal health. The proposed method contributes to a more proactive approach to preventive healthcare, significantly improving musculoskeletal health and enhancing the quality of life.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic Risk Assessment with RULA and OCRA Method in a Garment Workshop. Case Study\n",
            "Authors: Araujo K.E.\n",
            "Abstract: This research focused on micro and small enterprises (MSEs) which comprise 96% of the textile industry in Peru. This sector is the most important manufacturing activity. Work-related musculoskeletal disorders (MSD) were identified with methods such as RULA and OCRA, which evaluates upper extremities. The purpose of this research is to reduce MSDs generated by activities performed in garment workshops by making use of ergonomic methods for the detection of inadequate postures and subsequently propose an improvement by applying engineering methodologies such as workstation redesign and ergonomics. After implementing the improvements, all the garment makers improved their score in the RULA method, reducing the risk by up to 42.9%. On the other hand, the OCRA method reduced the exposure index from a very high risk to a medium risk.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Investigating musculoskeletal risks in manual mushroom harvesting: An ergonomic field study in canadian farms\n",
            "Authors: Anwar A.\n",
            "Abstract: Canada's annual production of 132,000 metric tonnes of mushrooms relies on manual harvesting, posing risks of work-related musculoskeletal disorders (WMSDs). This study employs ergonomic evaluation techniques, including Rapid Upper Limb Assessment (RULA) and Cumulative Trauma Disorder (CTD) index, along with a discomfort assessment questionnaire, to analyze workers' postural loads and self-reported discomfort. Results indicate that immediate alterations are needed in 85% of picking postures to reduce WMSD risks (RULA score: 6–7). The overall process shows a CTD index of 1.16, indicating potential repetitive strain injuries. Pickers report discomfort, particularly in the hand and shoulder. The study underscores the need for alternatives like redesigned growing beds to enhance worker safety in mushroom harvesting.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Improving the Recognition and Analysis of the Surendra Algorithm in Athletes' Motion Capture\n",
            "Authors: Liu Z.\n",
            "Abstract: With the development of computer technology, its application in athletes' motion capture is more and more extensive, which can be used to design suitable sensors by the Surendra algorithm. In recent years, more and more scholars have begun to use motion capture technology to study human motion posture, analyze and study human motion posture data and apply it to people's work, study and life. Motion capture technology has also become a key technology in the field of human motion posture research and is playing an increasingly important role. In this paper, a three-dimensional skeletal model of the athlete's body is first established based on dynamics, and the athlete's movement characteristics are simulated by this model. Then, the athlete's movement posture is judged to determine the appropriate form of movement expression. Then, the improved Surendra algorithm is used to detect the movement movements.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Design of a CNN Based Autonomous Sitting Posture Recognition System\n",
            "Authors: Gupta Y.\n",
            "Abstract: The identification and characterization of sitting postures are crucial for various applications, particularly in addressing issues related to postural abnormalities, and muscu-loskeletal symptoms. This study presents a novel seat-mounted sitting posture detection system comprising 15 Pressure Sensitive Conductive (PSC) sensors. These sensors are strategically positioned within a seat, that interfaces with an edge computing system to run a convolutional neural network (CNN) model and predict one among 8 different sitting postures. A dataset consisting of all 15 sensory time-series signals was captured for each of the 8 postures, for training the model. The trained CNN model demonstrated superior accuracy compared to SVM, KNN, ANN, and CNN+LSTM models, leveraging spatio-temporal features for precise posture identification. High classification accuracy was achieved when applied to an unseen dataset. This camera-less system offers real-time sitting posture prediction without compromising user privacy. Its adaptability and scalability make it an innovative solution for medical, domestic, and clinical applications, aiding in posture-related concerns. The dataset, CNN model, and source-codes are made freely available for easy adoption and further usage by the designers and scientific community.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The effectiveness of ergonomic rice transplanter in reducing awkward posture, physical workload and working duration among farmers during the manual transplanting process\n",
            "Authors: Butmee T.\n",
            "Abstract: In the manual rice transplanting process, a farmer needs repetitive movements with awkward postures. This research aimed to investigate the effectiveness of an ergonomic rice transplanter to reduce awkward posture, physical workload and working duration during manual transplanting process. The awkward posture (REBA scores), physical workload (%CVL) and working duration were compared between three rice transplanting methods. Twenty rice farmers participated in this study. The REBA scores while using ergonomic-tool rice planting was significantly lower than tool assisted rice planting and Traditional rice planting. In addition, the physical workload (%CVL), while using ergonomic-tool rice planting was significantly lower than using tool assisted rice planting and traditional rice planting. The results clearly indicated that the ergonomic rice transplanter had high efficiency in eliminating the awkward posture and significantly reduced the physical workload. It could be suggested that rice farmers should use ergonomic rice planters to prevent ergonomic risk factors.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: AuraPose: Accurate Human Pose Detection and Behavior Recognition via Enhanced OpenPose with Angular Measurement\n",
            "Authors: Liu H.\n",
            "Abstract: The rapid progress in computer vision and deep learning technology has positioned human posture detection and estimation as a hot spot research area with sustained development. Nevertheless, prevalent detection technologies frequently encounter issues related to accuracy and robustness which hinders their further practical adoption. In this paper, an enhanced OpenPose algorithm incorporates angular measure-ment is proposed to tackle above challenges. Firstly, OpenPose is utilized to detect and locate key points of human body. Subsequently, the connections between these points according to the specified posture are optimization. Finally, ultimate angles are measured to deliver the accurate pose detection and behavior recognition. Qualitative analysis on recorded videos illustrate the applicability and robustness of proposed method. Furthermore, quantitative results on COCO2017 dataset compared with the state-of-the-art methods also show competitive performance of proposed method, in which our AR, AP and mAP reached 89.2%, 79.8% and 81.8%, respectively. Through meticulous optimization, our method has the potential to further enhance vision-based human posture detection and measurement tech-nologies, particularly within the domains of medical, biomedical and healthcare systems.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Systematic Review on Custom Data Gloves\n",
            "Authors: Belcamino V.\n",
            "Abstract: Hands are a fundamental tool humans use to interact with the environment and objects. Through hand motions, we can obtain information about the shape and materials of the surfaces we touch, modify our surroundings by interacting with objects, manipulate objects and tools, or communicate with other people by leveraging the power of gestures. For these reasons, sensorized gloves, which can collect information about hand motions and interactions, have been of interest since the 1980s in various fields, such as human-machine interaction and the analysis and control of human motions. Over the last 40 years, research in this field explored different technological approaches and contributed to the popularity of wearable custom and commercial products targeting hand sensorization. Despite a positive research trend, these instruments are not widespread yet outside research environments and devices aimed at research are often ad hoc solutions with a low chance of being reused. This article aims to provide a systematic literature review for custom gloves to analyze their main characteristics and critical issues, from the type and number of sensors to the limitations due to device encumbrance. The collection of this information lays the foundation for a standardization process necessary for future breakthroughs in this research field.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: AI-Embedded Motion Sensors for Sports Performance Analytics\n",
            "Authors: Yu X.\n",
            "Abstract: Motion sensing technology is widely used in healthcare, sports, consumer electronics, etc. On the other hand, Artificial intelligence (AI) enables the development of wearable sensors that can recognize and analyze human motions. In this study, we developed a wearable wireless motion sensing system with AI-embedded inertial measurement units (AIMUs), combined with visual analysis, to evaluate and optimize athletes' performance in sports such as gymnastics. In the experiment, a gymnast performed an entire vaulting routine while wearing 11 AIMUs, and the motion data were transmitted to a cloud server through Bluetooth gateways. This system can achieve the segmentation of vaulting phases and the evaluation of detailed movements. The experimental results showed a 4.57% estimation error in flight height. This AI-embedded motion sensor system has the potential to provide an intuitive and easy-To-understand way to present athlete performance to coaches and athletes themselves. Furthermore, its continued development could assist athletes' training, provide quantitative sports performance indicators, significantly improve elite athletes' training efficiency, and monitor their health regularly.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A ROS-Integrated Skeleton Detection Framework Enabling Human-Centered Robotic Applications\n",
            "Authors: Mora A.\n",
            "Abstract: The escalating demand for assistive robots, fueled by an aging population and the quest for technological solutions to enhance quality of life, requires an effective comprehension of data coming from users interacting with robots. This paper proposes a holistic solution to the challenge of human skeleton detection and analysis by integrating a 3D skeleton detector and RGBD camera spatial data within the Robot Operating System (ROS) middleware. This integration facilitates the publication of user pose and location, forming a versatile foundation for diverse assistive applications. Additionally, a whole-body joint analysis method based on analytical geometry is introduced, expanding the robot's understanding of the user's body and enabling a broader range of applications. The paper showcases the framework's versatility through two applications: humanoid robot pose retargeting and pose classification for user behavior study, proving that the proposed solution works in real time and serves as a modular, adaptable solution for diverse assistive robotic applications.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A compact mathematical representation of human body silhouettes from frontal and lateral views\n",
            "Authors: Rajbdad F.\n",
            "Abstract: Human body silhouettes are used extensively in three-dimensional body shape modelling, activity recognition, apparel design, obesity, and posture assessment. These applications require efficient storage of human body images for future use and comparison. We proposed a novel one-dimensional mathematical representation of human body silhouettes from frontal and lateral views using a discrete cosine transform. Our method saved 75% of the storage space, significantly reducing costs, and achieved a compression ratio of 4:1 with an average reconstruction accuracy of 90% for all views of male and female images. Additionally, segment-wise silhouette representation decreased the average reconstruction complexity four times. Human body silhouettes are also modelled for the first time using polynomial curve fitting, discrete wavelet transform, and discrete Fourier transform with a systematic comparison. The polynomial curve fitting achieved the highest average space saving of 84%; however, reconstruction accuracy decreased by 12% compared to the discrete cosine transform. In addition, our novel method attained 46% additional storage space saving compared to standard two-dimensional JPEG and PNG image compression methods. Our work can be used to assess human body fat distribution, detect pose abnormalities and classify body shapes, ages, and genders.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automated Kinect-based posture evaluation method for work-related musculoskeletal disorders of construction workers\n",
            "Authors: Li H.\n",
            "Abstract: Construction workers often suffer from musculoskeletal disorders due to awkward postures and weight-carrying in hot environments. Previous studies have focused on posture, neglecting weight-carrying or the environment. This study develops an automated real-time version of the RULA-based posture assessment method, identifying a worker’s posture and load weight using an RGB-D Microsoft Kinect sensing camera. The method includes ambient workplace temperature and is tested on a small-scale bricklaying and reinforcement task. Laboratory tests show the method improves assessment efficiency significantly. This is the first of its kind to fully automate the assessment of construction worker WMSD propensity, providing a continuous warning system to replace manual supervision.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: WLSCMS: Wearable Lumbar Spine Curve Monitoring System Based on Integrated Sensors\n",
            "Authors: Kim J.\n",
            "Abstract: Monitoring the curvature of the lumbar spine is important for determining the incidence of lower back pain and other spinal disorders in individuals undergoing physical therapy and rehabilitation and in the field of sports medicine. Especially, to recognize and prevent habitual incorrect spinal curves, a well-suited measurement system is required. In this study, a wearable smart sensing system integrating four flexible sensors and three inertial measurement unit sensors with machine learning was developed. The proposed system was tested on 20 subjects to evaluate its performance. In the experiment, 11 postures were tested using five classes as targets. A feature extraction algorithm was proposed for generating 52 features based on a combination of seven different sensor signals and building classification algorithms for detecting spine events based on the extracted features. The accuracies for classifying five levels of spine curves were 99.38% overall and 99.79% in a tenfold cross-validation test, respectively. The proposed method can estimate spine curve class levels without personalized calibrations.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Addressing Ergonomic Challenges in Agriculture through AI-Enabled Posture Classification\n",
            "Authors: Kapse S.\n",
            "Abstract: In this study, we explored the application of Artificial Intelligence (AI) for posture detection in the context of ergonomics in the agricultural field. Leveraging computer vision and machine learning, we aim to overcome limitations in accuracy, robustness, and real-time application found in traditional approaches such as observation and direct measurement. We first collected field videos to capture real-world scenarios of workers in an outdoor plant nursery. Next, we labeled workers’ trunk postures into three distinct categories: neutral, slight forward bending and full forward bending. Then, through CNNs, transfer learning, and MoveNet, we investigated the effectiveness of different approaches in accurately classifying trunk postures. Specifically, MoveNet was utilized to extract key anatomical features, which were then fed into various classification algorithms including DT, SVM, RF and ANN. The best performance was obtained using MoveNet together with ANN (accuracy = 87.80%, precision = 87.46%, recall = 87.52%, and F1-score = 87.41%). The findings of this research contributed to the integration of computer vision techniques with ergonomic assessments especially in the outdoor field settings. The results highlighted the potential of correct posture classification systems to enhance health and safety prevention practices in the agricultural industry.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Basketball Free Throw Posture Analysis and Hit Probability Prediction System Based on Deep Learning\n",
            "Authors: Luo Y.\n",
            "Abstract: With the continuous progress of basketball technology and tactics, educators need to adopt new teaching methods to cultivate high-quality athletes who meet the needs of modern basketball development. In basketball teaching, the accuracy of free throw techniques directly affects teaching effectiveness. Therefore, the automated prediction of free throw hits is of great significance for reducing manual labor and improving training efficiency. In order to automatically predict the free throw hits and reduce manual fatigue, the study conducts an in-depth analysis for the criticality of free throw in basketball. In this study, the target detection model of target basketball players is constructed based on YOLOv5 and CBAM, and the basketball free throw hit prediction model is constructed based on the OpenPose algorithm. The main quantitative results showed that the proposed model could accurately recognize the athlete posture in free throw actions and save them as video frames in practical applications. Specifically, when using the free throw keyframe limb angle as features, the model achieved a prediction accuracy of 71% and a recall rate of 86% in internal testing. In external testing, the prediction accuracy was improved to 89% and the recall rate was 77%. In addition, combining the relative position difference and angle characteristics of joint points, the accuracy of internal testing was significantly improved to 80%, and the recall rate was increased to 96%. The accuracy of external testing was improved to 95%, with a recall rate of 75%. The experimental results showed that the various functional modules of the system basically meet the expectations, confirming that the basketball penalty posture analysis and hit probability prediction system based on deep learning can effectively assist basketball teaching and meet the practical teaching application needs. The contribution of the research lies in providing a scientific basketball free throw training tool, which helps coaches and athletes better understand and improve free throw techniques, thereby improving free throw hits accuracy. Meanwhile, this study also provides new theoretical and practical references for the application of deep learning in motor skill analysis and training, which has potential value for updating the basketball education system and reducing teacher workload.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A study on the Real-Time Biomechanical Analysis of Lumbar Burden Utilizing Stereoscope Cameras\n",
            "Authors: Hidayat Soesilo T.\n",
            "Abstract: Lumbar region is susceptible to strain and stress due to various physical activities and occupational task. To study about the lumbar burden, researchers have developed many tools but most of existing design can only use static imaging or doesn’t provide real-time update. The proposed system records and examines the change of body posture in real time by utilizing the capabilities of stereoscope cameras. By using Media Pipe algorithms, 2D key-points representing body joint can be extracted from images. Afterward, using the Direct Linear Transform (DLT) the corresponding 3D key-points can be calculated using obtained 2D key-points. With the 3D key-points the body angles can be computed and used to calculate the wight of the lumbar burden using JACK calculation. Finally, the proposed system reached to its aim to study about lumbar burden and adjust the person needs in real-time.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Postural Assessment Criteria for Manual Material Handling\n",
            "Authors: Ryu J.H.\n",
            "Abstract: The construction industry is one of the industries with the highest rates of musculoskeletal disorders (MSDs). Masons are particularly susceptible to overexertion and back injuries due to the physical demands of their jobs and, thus, are more susceptible to MSDs. While previous research established that expert masons use different strategies to perform their work while experiencing reduced joint loads and increased productivity, it was unclear which movement strategies they used. This study analyzed the movements of novice, apprentice, and expert masons to characterize the postural characteristics of expert and in-expert techniques. Novice, apprentice, and expert masons' kinematics are analyzed for a standard concrete masonry unit wall-building activity and investigated the key markers of these techniques, such as trunk flexion and twisting. Masonry movement techniques refer to the kinematics and postures that the expert journeymen adopt while working. The results of this study describe the movement strategies experts use in comparison to inexpert groups (novices and apprentices).\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Physiological Signal Analysis for Awkward Working Postures of Construction Workers Using Wearable Biosensors\n",
            "Authors: Younesi Heravi M.\n",
            "Abstract: Awkward working postures are deviations of body parts from their neutral position. Construction workers who hold these postures for a long term are exposed to discomfort, reducing safety and productivity. While several studies have been conducted to assess the effect of awkward postures on human physical and musculoskeletal system like muscles and joints, little research has attempted to explore the impact of awkward posture selection on physiological system. This investigation is necessary for a broader comprehension of risky factors resulting from the awkward working postures of construction workers. Accordingly, this study aims to evaluate if and how physiological responses such as heart rate and skin temperature will be affected by awkward working postures. The study utilizes a non-invasive wearable wristband biosensor to measure and monitor participants' physiological signals during performing construction tasks in a simulated laboratory experiment. Signals in natural and awkward postures are then analyzed, and further comparisons are discussed. The results show that postures have significant impacts on physiological patterns, specifically when sustained for a longer duration. The findings of this study are expected to be used for the recognition of awkward working postures and further for the safety management interventions of worker behavior.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Computer Vision Approach to Assessing Work-Related Musculoskeletal Disorder (WMSD) Risk in Construction Workers\n",
            "Authors: Halder S.\n",
            "Abstract: Work-related musculoskeletal disorders (WMSDs) are a group of painful disorders of muscles, tendons, and nerves caused due to improper work postures prevalent in construction workers. These disorders can cause temporary and/or permanent disabilities and seriously affect workers' livelihoods. Previous research has applied machine learning (ML) for the recognition of WMSD risk. However, previous research used inertial sensors strapped to the body to measure the angle of the body parts. These sensors are expensive and uncomfortable to wear while working. This research aims to eliminate the need for additional hardware through the use of computer vision. In this project, an ML pipeline was built to identify WMSD risk from workers' images. A pre-trained ML framework called Mediapipe Pose was used to generate features from the images. The relative positions of these landmarks were then used as the input for an artificial neural network (ANN) to classify ergonomic and non-ergonomic postures using the supervised learning approach. After hyper-parameter tuning, 100% training and 99.96% validation accuracy were achieved. Finally, the trained model was tested on real-life videos of construction workers and found to perform satisfactorily.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Clinical Decision Support System Used in Spinal Disorders: Scoping Review\n",
            "Authors: Toh Z.A.\n",
            "Abstract: Background: Spinal disorders are highly prevalent worldwide with high socioeconomic costs. This cost is associated with the demand for treatment and productivity loss, prompting the exploration of technologies to improve patient outcomes. Clinical decision support systems (CDSSs) are computerized systems that are increasingly used to facilitate safe and efficient health care. Their applications range in depth and can be found across health care specialties. Objective: This scoping review aims to explore the use of CDSSs in patients with spinal disorders. Methods: We used the Joanna Briggs Institute methodological guidance for this scoping review and reported according to the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews) statement. Databases, including PubMed, Embase, Cochrane, CINAHL, Web of Science, Scopus, ProQuest, and PsycINFO, were searched from inception until October 11, 2022. The included studies examined the use of digitalized CDSSs in patients with spinal disorders. Results: A total of 4 major CDSS functions were identified from 31 studies: preventing unnecessary imaging (n=8, 26%), aiding diagnosis (n=6, 19%), aiding prognosis (n=11, 35%), and recommending treatment options (n=6, 20%). Most studies used the knowledge-based system. Logistic regression was the most commonly used method, followed by decision tree algorithms. The use of CDSSs to aid in the management of spinal disorders was generally accepted over the threat to physicians’ clinical decision-making autonomy. Conclusions: Although the effectiveness was frequently evaluated by examining the agreement between the decisions made by the CDSSs and the health care providers, comparing the CDSS recommendations with actual clinical outcomes would be preferable. In addition, future studies on CDSS development should focus on system integration, considering end user’s needs and preferences, and external validation and impact studies to assess effectiveness and generalizability.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Combining artifícial intelligence fór diagnosing adolescent idiopathic scoliosis\n",
            "Authors: Shangyu G.\n",
            "Abstract: As the most common type of scoliosis,adolescent idiopathic scoliosis (AIS) occurs predominantly in adolescents. Lateral spinal curvature &gt; 100 is the most common type of scoliosis. An early diagnosis and a timely intervention are essential for reducing complications and optimizing outcomes. Although mass screening for AIS has remained controversial at schools, it is also widely implemented. Currenüy a routine tool for evaluating scoliosis is using a scoliometer for Adam test. First proposed in 1948, manual radiographic measurement of Cobb angle has remained a gold standard. However,this diagnostic modality is radioactive and it relies heavily on the professional capability of an examiner. Thus it is quite imperative to seek early screening and diagnostic modalities with high sensitivity, high specificity, non-radiation and high efficiency. In recent yeais, with a rapid development of artificial intelligence (Al) ,it has also accelerated the progress of medical imaging and diagnostics. This review focused upon three-dimensional spinal imaging based upon ultrasound, scoliosis detection system based upon three-dimensional camera or sensor, combination of two-dimensional digital camera and Al and posture analysis system based upon computer vision for applying artificial intelligence to AIS screening. It was intended to offer new rationales for clinical scientific researches and development directions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Digital REBA System Based on Kinect and Its Benefits for Ergonomic Assessment\n",
            "Authors: Reyes-Zárate G.G.\n",
            "Abstract: The evaluations of potential risks at physical workstations provide data on the workers’ postures and can assist in reducing such risks. Rapid Entire Body Assessment (REBA) is one of the methods used for ergonomic assessments. In this method, observers evaluate the posture of the trunk, neck, legs, wrists, and arms. As digitalization advances, real-time data provides ergonomic assessments with the benefit of analyzing a sequence of postures during manufacturing processes. This study aimed to determine whether continuous ergonomic evaluations using Kinect significantly reduce time and are flexible, useful tools in this field. The study demonstrated that it is possible to conduct this type of ergonomic study in an agricultural company where essential oils are extracted from plants.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Smart-Wear Device for Postural Real-Time Feedback in Industrial 4.0 Settings Using DREAM Approach\n",
            "Authors: de Sousa Coelho A.\n",
            "Abstract: Concepts underlying the so-called Industry 4.0 are an opportunity to develop strategies based on the merging of the physical, digital, and biological worlds, enabled by new technologies. This work reports the design proposal for an upside body wear involving industry workers to capture body signs, including real-time postural assessment, that could indicate risk for musculoskeletal disorders. Discover, Research, Engage, Approve, Make methodology allows us to consider factors such as situations, contexts, company employees, and workers (pe, gender, age, or type of task) to have a complete representation of the system. A series of participatory observations were performed in the industrial context which contributed to establishing a deeper relationship between the stakeholders involved around the theme with the analytical portion of the model enabling work in tandem with industrial partners. From participatory observation and worker feedback, the team developed a soft wearable to monitor the body conditions to prevent work-related injuries, instead of an exoskeleton to enhance the body. Nevertheless, the design team started to create concepts of soft wearables, always paying attention to the limitation of the components being used by the upper body device, designing where the circuits would be located around the body, resorting to a life-sized dummy as a model, and testing its arm movements. Future developments include the integration of several partial prototypes that will generate a final device that will integrate all the functions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Improved REBA: deep learning based rapid entire body risk assessment for prevention of musculoskeletal disorders\n",
            "Authors: Jiao Z.\n",
            "Abstract: Preventing work-related musculoskeletal disorders (WMSDs) is crucial in reducing their impact on individuals and society. However, the existing mainstream 2D image-based approach is insufficient in capturing the complex 3D movements and postures involved in many occupational tasks. To address this, an improved deep learning-based rapid entire body assessment (REBA) method has been proposed. The method takes working videos as input and automatically outputs the corresponding REBA score through 3D pose reconstruction. The proposed method achieves an average precision of 94.7% on real-world data, which is comparable to that of ergonomic experts. Furthermore, the method has the potential to be applied across a wide range of industries as it has demonstrated good generalisation in multiple scenarios. The proposed method offers a promising solution for automated and accurate risk assessment of WMSDs, with implications for various industries to ensure the safety and well-being of workers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Using an Optimal then Enhanced YOLO Model for Multi-Lingual Scene Text Detection Containing the Arabic Scripts\n",
            "Authors: Turki H.\n",
            "Abstract: In recent years, significant advancements have been made in deep learning and the recognition of text in images of natural scenes, thanks to the advancements in machine learning and artificial intelligence. The limited availability of diverse datasets containing multiple languages and scripts often restricts the effectiveness of deep learning and text detection in the wild, particularly when it comes to Arabic language as an additional challenge. Despite notable progress, this scarcity remains a constraint. The deep learning neural network known as YOLO (You Only Look Once) has become widely popular due to its versatility in addressing a wide range of machine learning tasks, particularly in the domain of computer vision. The YOLO algorithm has gained increasing acknowledgment for its outstanding ability to tackle complex problems in conjunction with complex backgrounds of an image captured from nature, handle noisy data, and overcome various challenges encountered in real-world situations. Our experiments offer a succinct analysis of text detection algorithms that rely on convolutional neural networks (CNNs); In particular, we focus on various iterations of the YOLO models, employing same specific data augmentation techniques on both SYPHAX dataset and ICDAR MLT-2019 dataset, which comprise Arabic scripts in real natural scene images. The aim of this article is to identify the most effective YOLO algorithm for detecting text containing the Arabic scripts in the wild then to enhance this optimal model obtained in addition to explore potential research avenues that can enhance the capabilities of the most robust architecture in this field.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Comparative Study of Different Unorganized Sectors’ Workers in India to Identify Musculoskeletal Disorder Prevalence through Empirical Survey and Deep Learning Methods\n",
            "Authors: Meena A.\n",
            "Abstract: Background: Musculoskeletal disorders (MSDs) are a group of non-fatal injuries that can occur as a result of various repetitive workplace activities, mainly in unorganized sectors. Workers who engage in highly repetitive activities involving constant hand effort, localized mechanical pressure, and vibration are more prone to developing these disorders. Objective: The objective of this research was to determine the prevalence of MSDs among workers in various unorganized sectors in India who perform hand-intensive occupations. Method: A cross-sectional study was conducted, involving 340 workers from diverse groups such as sugarcane farmers, footwear industry workers, and tarpaulin weavers, to accomplish this goal. Data for the survey was collected using a questionnaire. Additionally, a comprehensive time study and a deep learning-based posture detection study were conducted on the different activities performed during the workers' occupational tasks. The chi-square test was used to assess the relationship between discomfort and work repetitiveness. Result: The data analysis revealed that the working activities (especially cutting/harvesting, rubber cutting, etc.) of unorganized sector workers were repetitive, with more than half of each activity’s work cycle involving a similar usage pattern. Furthermore, a significant association was observed between the level of discomfort and work repetitiveness among workers in different sectors (sugarcane farmers: p < 0.01, footwear industry workers: p < 0.05, tarpaulin weavers: p < 0.05). Consequently, it can be concluded that prolonged occupational activities involving repetitive and prolonged standing may contribute to the occurrence of MSDs. Conclusion: Ergonomic interventions/modifications in the form of patent work will be necessary to prevent these issues in the near future.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An Empirical and Deep Learning Investigation of Working Conditions and Musculoskeletal Outcomes in Wheat Farmers\n",
            "Authors: Bairwa R.C.\n",
            "Abstract: Background: In developing countries, various farming activities are performed manually with the help of traditional hand tools. Therefore, agriculture is recognized as one of the risky occupations. Objective: This research study aims to identify the critical working conditions of wheat farmers in Rajasthan state, India. Method: Data were collected through the survey conducted on 75 randomly selected wheat farmers of Rajasthan. The survey questionnaire gathered information related to demographic, occupational, and musculoskeletal discomfort faced by the farmers. In addition, a deep learning-based posture detection study of the workers was performed to assess the postural risks through a rapid upper limb assessment score. Result: The collected data were analyzed further for fruitful insights. The survey outcomes showed that awkward posture (41%) and repetitive movement (35%) were the most reported reasons for the severe risks of musculoskeletal disorders among farmers. The posture evaluation-based patent study outcomes showed that approximately 51% of subjects lie in the action category 4, which shows the higher level of risks in the activities performed by farmers. Conclusion: It is suggested to apply the principles of physical ergonomics in the agriculture sector and spread awareness among the farmers about the agriculture risks associated with farming activities.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Assessment of Ergonomic Risk Factors among Metal Sculpture Workers and Future Scope of AI Applications in Ergonomic Evaluation\n",
            "Authors: Mishra Y.\n",
            "Abstract: Background: Handicraft workers usually carry out daily activities by adopting awkward postures. The most prevailing health issues among handicraft workers are musculoskeletal disorders (MSDs). Objective: The current research aims to assess the occurrence of musculoskeletal symptoms and investigate risk factors associated with musculoskeletal disorders among metal sculpture artisans. Subsequently, the study highlighted the future scope of AI applications in ergonomic evaluation. Methods: 144 male metal sculpture workers participated in the study. A modified Nordic question-naire was adopted to determine the musculoskeletal problems among metal sculpture workers. The probable risk elements for MSD symptoms were identified by applying binary logistic regression. Results: Most workers faced discomfort in various body parts, particularly the wrist, lower back, and shoulders. The outcome of the logistic regression model revealed that job-related factors have significantly contributed to the development of MSD symptoms. Conclusion: This study concedes that awkward working postures for prolonged periods highly af-fect the health of metal sculpture workers, and there is a need for ergonomic intervention to mini-mize the risks of musculoskeletal disorders. The study also emphasizes the future scope of Artificial Intelligence (AI) applications that can be used in ergonomically assessing working postures.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Assessing workers operational postures via egocentric camera mapping\n",
            "Authors: Liu Z.\n",
            "Abstract: Construction tasks involve extensive and repetitive physically demanding activities, which results in a higher risk of work-related musculoskeletal disorders (WMSDs) compared to other industries. Thus, assessing construction workers' postural ergonomics during construction occupational tasks is critical to evaluating workers' postural stresses and reducing the potential risk of WMSDs. Recent developments in machine learning-based computer vision methods have attracted an increasing attention of construction researchers as it is an effective tool for assessing postural ergonomics. However, existing computer vision-based ergonomic assessments in the construction research field are still mainly based on multiple-view motion tracking systems or fixed-position stand-Alone cameras. These types of motion-Tracking methods are limited by resource-expensive and serious occlusion issues. As an alternative approach, this paper proposes an economical and scalable machine learning enabled egocentric postural ergonomic assessment (EPEA) system that integrates the fisheye camera mounted to the hard hat to identify and assess workers' postural ergonomics via a convolutional 3D pose estimation neural network. We tested the EPEA with multiple construction operational tasks. Results show that the EPEA can correctly identify users' key joint parts and classify different postures. The results confirmed the usability and feasibility of the proposed system, and it has the potential to help construction workers to identify the potential WMSDs risks during repetitive and forceful construction works.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Vision-Based Ergonomic Risk Assessment of Back-Support Exoskeleton for Construction Workers in Material Handling Tasks\n",
            "Authors: Liu Y.\n",
            "Abstract: Work-related musculoskeletal disorders (WMSDs) are a leading cause of injury for workers who are performing physically demanding and repetitive construction tasks. With recent advances in robotics, wearable robots are introduced into the construction industry to mitigate the risk of WMSDs by correcting the workers' postures and reducing the load exerted on their body joints. While wearable robots promise to reduce the muscular and physical demands on workers to perform tasks, there is a lack of understanding of the impact of wearable robots on worker ergonomics. This lack of understanding may lead to new ergonomic injuries for workers wearing exoskeletons. To bridge this gap, this study aims to assess the workers' ergonomic risk when using a wearable robot (back-support exoskeleton) in one of the most common construction tasks, material handling. In this research, a vision-based pose estimation algorithm was developed to estimate the pose of the worker while wearing a back-support exoskeleton. As per the estimated pose, joint angles between connected body parts were calculated. Then, the worker's ergonomic risk was assessed from the calculated angles based on the Rapid Entire Body Assessment (REBA) method. Results showed that using the back-support exoskeleton reduced workers' ergonomic risk by 31.7% by correcting awkward postures of the trunk and knee during material handling tasks, compared to not using the back-support exoskeleton. The results are expected to facilitate the implementation of wearable robots in the construction industry.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Study on the Development of Professional Training in Physical Education in Colleges and Universities under Information Technology\n",
            "Authors: Zhang Z.\n",
            "Abstract: The deep integration of technology and college sports professional training can effectively stimulate the enthusiasm of students for sports training and, to a certain extent, reduce the danger of professional training. This paper first introduces the virtual reality technology under information technology to build a virtual sports training framework, and through virtual sports training, can effectively realize the immersive training of participants. Secondly, we use LiDAR to obtain point cloud data for the virtual scene of college sports professional training and reconstruct the virtual scene using the Poisson surface 3D reconstruction algorithm. Based on the OpenPose human posture estimation algorithm, the training movements of students in the virtual scene are identified, which helps coaches to better formulate standardized training movements. Finally, to verify the effectiveness of the method given in this paper in college physical education training, a series of quantitative analyses was carried out. The results show that the training loss of the Poisson surface 3D reconstruction algorithm is about 0.087 after 180 rounds of iteration, the verification accuracy is about 87.62%, and the training loss of the OpenPose algorithm is about 0.04% when the number of iterations reaches about 130 times. After using VR technology to carry out professional training in sports, the score of students in the experimental group in terms of active learning interest is 4.487±0.324 points, which is about 1 point higher than that of the control group. Virtual reality technology can effectively promote the innovation and reform of sports professional training in colleges and universities, enhance the student's interest in learning sports training, and provide a guarantee for improving students' physical quality.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Review on Wearable Product Design and Applications\n",
            "Authors: Minaoglou P.\n",
            "Abstract: In recent years, the rapid advancement of technology has caused an increase in the development of wearable products. These are portable devices that can be worn by people. The main goal of these products is to improve the quality of life as they focus on the safety, assistance and entertainment of their users. The introduction of many new technologies has allowed these products to evolve into many different fields with multiple uses. The way in which the design of wearable products/devices is approached requires the study and recording of multiple factors so that the final device is functional and efficient for its user. The current research presents an in-depth overview of research studies dealing with the development, design and manufacturing of wearable products/devices and applications/systems in general. More specifically, in this review, a comprehensive classification of wearable products/devices in various sectors and applications was carried out, resulting in the creation of eight different categories. A total of 161 studies from the last 13 years were analyzed and commented on. The findings of this review show that the use of new technologies such as 3D scanning and 3D printing are essential tools for the development of wearable products. In addition, many studies observed the use of various sensors through which multiple signals and data could be recorded. Finally, through the eight categories that the research studies were divided into, two main conclusions emerged. The first conclusion is that 3D printing is a method that was used the most in research. The second conclusion is that most research directions concern the safety of users by using sensors and recording anthropometric dimensions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Assessing illumination fatigue in tunnel workers through eye-tracking technology: A laboratory study\n",
            "Authors: Li J.\n",
            "Abstract: Considering the vigorous development of the tunnel transportation industry, research on improving the health and comfort of tunnel workers has become important. Requirements for tunnel construction illumination vary worldwide, and the use of inappropriate illumination can lead to increased worker fatigue. This study used virtual-reality simulation of tunnel construction environments, with illumination intensity as the sole variable, combined with eye-tracking technology to record and analyze the performance of eight indicators across four categories under nine illumination conditions. The optimal illumination range was found to be 100–150 lx. The potential significance of each indicator was explored based on the varying interpretative capacities. A random forest algorithm was employed to construct a classification prediction model for illumination fatigue, achieving an accuracy rate of 75.5%. Noticeable fatigue was predicted with an accuracy of 85%, and that of mild fatigue was 80%. The significance of this study lies in the successful application of eye-tracking technology to detect and classify illumination fatigue in tunnel construction environments. However, illumination fatigue is not confined to underground environments. The experimental methods and results presented in this paper can aid in conducting research in various construction environments with limited natural light.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: IoT-Based Solution for Detecting and Monitoring Upper Crossed Syndrome\n",
            "Authors: Shaheen A.\n",
            "Abstract: A sedentary lifestyle has caused adults to spend more than 6 h seated, which has led to inactivity and spinal issues. This context underscores the growing sedentary behavior, exemplified by extended sitting hours among adults and university students. Such inactivity triggers various health problems and spinal disorders, notably Upper Crossed Syndrome (UCS) and its association with thoracic kyphosis, which can cause severe spinal curvature and related complications. Traditional detection involves clinical assessments and corrective exercises; however, this work proposes a multi-layered system for a back brace to detect, monitor, and potentially prevent the main signs of UCS. Building and using a framework that detects and monitors signs of UCS has facilitated patient–doctor interaction, automated the detection process for improved patient–physician coordination, and helped improve patients’ spines over time. The smart wearable brace includes inertial measurement unit (IMU) sensors targeting hunched-back postures. The IMU sensors capture postural readings, which are then used for classification. Multiple classifiers were used where the long short-term memory (LSTM) model had the highest accuracy of 99.3%. Using the classifier helped detect and monitor UCS over time. Integrating the wearable device with a mobile interface enables real-time data visualization and immediate feedback for users to correct and mitigate UCS-related issues.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Transparency as a Means to Analyse the Impact of Inertial Sensors on Users during the Occupational Ergonomic Assessment: A Systematic Review\n",
            "Authors: García-Luna M.A.\n",
            "Abstract: The literature has yielded promising data over the past decade regarding the use of inertial sensors for the analysis of occupational ergonomics. However, despite their significant advantages (e.g., portability, lightness, low cost, etc.), their widespread implementation in the actual workplace has not yet been realized, possibly due to their discomfort or potential alteration of the worker’s behaviour. This systematic review has two main objectives: (i) to synthesize and evaluate studies that have employed inertial sensors in ergonomic analysis based on the RULA method; and (ii) to propose an evaluation system for the transparency of this technology to the user as a potential factor that could influence the behaviour and/or movements of the worker. A search was conducted on the Web of Science and Scopus databases. The studies were summarized and categorized based on the type of industry, objective, type and number of sensors used, body parts analysed, combination (or not) with other technologies, real or controlled environment, and transparency. A total of 17 studies were included in this review. The Xsens MVN system was the most widely used in this review, and the majority of studies were classified with a moderate level of transparency. It is noteworthy, however, that there is a limited and worrisome number of studies conducted in uncontrolled real environments.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Effect of a confidence-based weighted 3D point reconstruction for markerless motion capture with a reduced number of cameras\n",
            "Authors: Chaumeil A.\n",
            "Abstract: Markerless motion capture has been made available by the development of pose estimation algorithms that provide both an estimate of the location of body keypoints in two-dimensional images and its associated confidence. It seems relevant to use this additional information for three-dimensional (3D) point reconstruction. Yet, it has been little described, nor has its influence on 3D point reconstruction. Eight participants performed a manual material handling task, which was recorded by 10 video cameras. Each video was processed using OpenPose. Different 3D point reconstruction methods were compared: direct linear transform (DLT) and weighted DLT (wDLT), with 10 cameras and with a subset of 4 cameras. For each keypoint, confidence and position deviation from the 3D reconstructed point with 10 cameras projected in the image reference frame were assessed. Results suggest that using confidence information reduces both average and maximum 3D distance between 3D points reconstructed with 4 and 10 cameras.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Evaluation of the gross motor abilities of autistic children with a computerised evaluation method\n",
            "Authors: Liu X.\n",
            "Abstract: To effectively evaluate the gross motor ability of autistic children, we proposed a method of computerised evaluation of gross motor skills (CEGM). The CEGM integrates Dynamic Time Warping (DTW) method and OpenPose technology to automatically detect key joints and return a score. Ten items were selected for evaluation based on the gross motor subtest of the Psychoeducational Profile–Third Edition (PEP-3) scale, including upper limb movement, lower limb movement, and body coordination performance. 30 autistic participants (males: 23, female: 7) with an average age of 5.00 years were recruited in this study. Then we compared the results of evaluation using CEGM and the original PEP-3 gross motor subtest in autistic children. The results showed that in the evaluations using CEGM and PEP-3, Cronbach’s α coefficients and Spearman-rank correlation coefficients were all greater than 0.80, intraclass correlation coefficient (ICC) were all greater than 0.90, indicating good agreement in evaluating the gross motor ability of autistic children. Moreover, compared to the PEP-3, the evaluation using CEGM provided precise quantitative indicators (trajectory, velocity, and angle of joint). Therefore, our findings demonstrate that CEGM can be used in the initial evaluation of the gross motor ability of autistic children.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Review of Human Pose Estimation Methods in Markerless Motion Capture\n",
            "Authors: Ji H.\n",
            "Abstract: Human pose estimation aims at detecting human joint points from input data such as images and videos, or building a human body model for motion analysis. However, due to the ambiguities of human occlusion, depth blurring and the lack of training data, the accuracy of motion capture is still far from satisfactory. This paper reviews the advances of human pose estimation methods in markerless motion capture since 2019. We propose three types of representations for the human body, and detect that a unified volumetric model provides more detailed motion representation. We introduce datasets and evaluation metrics widely used for 2D and 3D pose estimation. Comparisons and discussions are conducted on different model frameworks for human pose estimation based on accuracy, robustness, and speed, summarizing the strengths and weaknesses of various methods. We discover that pose estimation methods based on the Transformer framework exhibit better accuracy and robustness, while kinematic and physical knowledge greatly assist in solving 3D pose estimation. Additionally, lightweight methods are often overlooked in research. In conclusion, this paper serves as a guide for researchers interested in the field and assists newcomers in selecting and developing human pose estimation methods.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Soft computing applications in the field of human factors and ergonomics: A review of the past decade of research\n",
            "Authors: Çakıt E.\n",
            "Abstract: The main objectives of this study were to 1) review the literature on the applications of soft computing concepts to the field of human factors and ergonomics (HFE) between 2013 and 2022 and 2) highlight future developments and trends. Multiple soft computing methods and techniques have been investigated for their ability to address various applications in HFE effectively. These techniques include fuzzy logic, artificial neural networks, genetic algorithms, and their combinations. Applications of these methods in HFE have been highlighted in one hundred and four articles selected from 406 papers. The results of this study help address the challenges of complexity, vagueness, and imprecision in human factors and ergonomics research through the application of soft computing methodologies.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic investigations on novel dynamic postural estimator using blaze pose and transfer learning\n",
            "Authors: Chidambaram V.\n",
            "Abstract: The aim is to develop a computer-based assessment model for novel dynamic postural evaluation using RULA. The present study proposed a camera-based, three-dimensional (3D) dynamic human pose estimation model using ‘BlazePose’ with a data set of 50,000 action-level-based images. The model was investigated using the Deep Neural Network (DNN) and Transfer Learning (TL) approach. The model has been trained to evaluate the posture with high accuracy, precision, and recall for each output prediction class. The model can quickly analyse the ergonomics of dynamic posture online and offline with a promising accuracy of 94.12%. A novel dynamic postural estimator using blaze pose and transfer learning is proposed and assessed for accuracy. The model is subjected to a constant muscle loading factor and foot support score that could evaluate one person with good image clarity at a time. Practitioner summary: A detailed investigation of dynamic work postures is largely missing in the literature. Experimental analysis has been performed using transfer learning, BlazePose, and RULA action levels. An overall accuracy of 94.12% is achieved for dynamic postural assessment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Vision- and Tactile-Based Continuous Multimodal Intention and Attention Recognition for Safer Physical Human-Robot Interaction\n",
            "Authors: Wong C.Y.\n",
            "Abstract: Employing skin-like tactile sensors on robots enhances both the safety and usability of collaborative robots by adding the capability to detect human contact. Unfortunately, simple binary tactile sensors alone cannot determine the context of the human contact - whether it is a deliberate interaction or an unintended collision that requires safety manoeuvres. Many published methods classify discrete interactions using more advanced tactile sensors or by analysing joint torques. Instead, we propose to augment the intention recognition capabilities of simple binary tactile sensors by adding a robot-mounted camera for human posture analysis. Different interaction characteristics, including touch location, human pose, and gaze direction, are used to train a supervised machine learning algorithm to classify whether a touch is intentional or not with an F1-score of 86%. We demonstrate that multimodal intention recognition is significantly more accurate than monomodal analyses with the collaborative robot Baxter. Furthermore, our method can also continuously monitor interactions that fluidly change between intentional or unintentional by gauging the user's attention through gaze. If a user stops paying attention mid-task, the proposed intention and attention recognition algorithm can activate safety features to prevent unsafe interactions. We also employ a feature reduction technique that reduces the number of inputs to five to achieve a more generalized low-dimensional classifier. This simplification both reduces the amount of training data required and improves real-world classification accuracy. It also renders the method potentially agnostic to the robot and touch sensor architectures while achieving a high degree of task adaptability.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Experiences from the implementation of physical therapy via telehealth for individuals with Parkinson disease during the COVID-19 pandemic\n",
            "Authors: Colón-Semenza C.\n",
            "Abstract: Purpose: To (1) determine the characteristics and participation rate of adults with Parkinson disease (PD) in physical therapy (PT) delivered via telehealth, (2) identify the outcome measures and interventions implemented, (3) determine the safety of and (4) patient and therapist satisfaction with PT via telehealth in a clinic specializing in the care of people with PD during the coronavirus pandemic. Materials & Methods: A retrospective analysis of PT services via telehealth was conducted. Participating patients completed a satisfaction survey. Physical therapists (PTs) who delivered this care were interviewed. Three coders conducted thematic analysis of interviews. Descriptive statistics described the participation rate, demographics, outcome measures, interventions, and safety. Results: There was a 71.4% participation rate. Participants (n = 55) were white (96%), non-Hispanic (100%), older adult (mean = 69.5 years (8.3)) males (65.5%). Non-participants (n = 22) had similar demographics. Therapists selected patient-reported measures more often than performance-based measures. Therapeutic exercise was the most common intervention. All patients (80% response rate) reported satisfaction with their experience. PTs reported the home enhanced specificity of training but impeded evaluation. Therapists endorsed a hybrid model for future practice. Conclusions: Patients reported satisfaction with PT via telehealth during the pandemic. A hybrid model may support optimal delivery of PT.IMPLICATIONS FOR REHABILITATION Physical therapy via telehealth for patients with Parkinson disease was acceptable to patients and physical therapists in our study. Physical therapy via telehealth was safe for people with Parkinson disease in our study, although availability and benefits may not be reaching all populations equitably. Both physical therapists and patients endorse a hybrid model of care (a combination of in-person and remote assessment and treatment) to profit from the strengths of in-person and virtual formats while minimizing barriers to access.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic Risk Assessment of Manufacturing Works in Virtual Reality Context\n",
            "Authors: Sardar S.K.\n",
            "Abstract: Industry 4.0 is potentially innovative in the workers’ role, which is becoming increasingly involved in smart activities. In this situation, it is necessary to improve highly repetitive uncomfortable working postures to reduce physical risks. This study intends to assess physical risks during VR interaction for manufacturing work. Posture-related physical risk levels were calculated using ergonomic risk assessment tools RULA, REBA, and OWAS. Three task conditions were considered for the experiment in a VR-based car-assembly environment. An analysis of variance was applied to investigate significant differences between task conditions, and it suggested that a higher risk level was obtained while working in the overhead position for RULA and REBA, whereas the squatting position obtained a higher risk level for OWAS. Sensitivity analysis identified that the upper arm and neck were responsible for the highest risk level for RULA, the upper arm, neck, and trunk for REBA, and the back posture parameter for OWAS.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: LifeChair-X Posture Based Gaming using an IoT Cushion and Serious Game for Workplace Wellness\n",
            "Authors: Ishac K.\n",
            "Abstract: This paper presents LifeChair-X, an IoT cushion for posture-based gaming and Serious Game for improving workplace wellness in a post-pandemic world of sedentarianism. The LifeChair posture models are used as input to a game in which a user moves an avatar using postural shifts. Through consultations with medical professionals at the University of Tsukuba Hospital, we developed the game for guiding seated exercises for core training. The system is evaluated with 12 adult participants. Experiments showed the LifeChair-X average response time was within 0.15 s (SD=0.21) of a conventional gamepad. A gameplay study demonstrated an average score of 53.50% using LifeChair-X which was less than 25% difference to a gamepad. Elevated heart rates were observed across all participants when using LifeChair-X suggesting light-intensity exercise. A system usability score of 88.96 (SD=10.12) was achieved suggesting excellent usability levels. The LifeChair-X is an effective system for exergaming and can improve workplace wellness.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Visualization of Caregiving Posture and Risk Evaluation of Discomfort and Injury\n",
            "Authors: Han X.\n",
            "Abstract: There is a high risk of musculoskeletal discomfort and injury due to the lack of professional guidance and training in caregiving postures. This study aimed to develop a risk assessment and visualization method by analyzing caregiving postures. Participants with (n = 8) and without (n = 10) caregiving experience were recruited to simulate patient transfer from bed to wheelchair. The Rapid Entire Body Assessment (REBA) method lacked sensitivity in distinguishing the experienced and inexperienced groups. We found that the visualization of the center of gravity (COG) trajectory could represent distinct posture differences between the two groups. Based on this finding, we considered a modified REBA method combining the COG trajectory, load-bearing time, and asymmetric load parameters, named the Caregiving-REBA (C-REBA) method. Our results demonstrated that C-REBA could effectively distinguish experienced and inexperienced caregivers, especially in caregiving task Stages 2–4. In conclusion, the present work explored adjusting to the parameters of the REBA method. The proposed C-REBA method could be easily imbedded into the Internet of Things (IoT) device to assess the caregiving posture for providing visual guidance and warning of the risk of discomfort or injury.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Recent Advances and Applications of Textile Technology in Patient Monitoring\n",
            "Authors: Stern L.\n",
            "Abstract: Sleep monitoring has become a prevalent area of research where body position and physiological data, such as heart rate and respiratory rate, are monitored. Numerous critical health problems are associated with poor sleep, such as pressure sore development, sleep disorders, and low sleep quality, which can lead to an increased risk of falls, cardiovascular diseases, and obesity. Current monitoring systems can be costly, laborious, and taxing on hospital resources. This paper reviews the most recent solutions for contactless textile technology in the form of bed sheets or mats to monitor body positions, vital signs, and sleep, both commercially and in the literature. This paper is organized into four categories: body position and movement monitoring, physiological monitoring, sleep monitoring, and commercial products. A detailed performance evaluation was carried out, considering the detection accuracy as well as the sensor types and algorithms used. The areas that need further research and the challenges for each category are discussed in detail.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Feature-Level Fusion-Based Multimodal Analysis of Recognition and Classification of Awkward Working Postures in Construction\n",
            "Authors: Xiahou X.\n",
            "Abstract: Developing approaches for recognition and classification of awkward working postures is of great significance for proactive management of safety risks and work-related musculoskeletal disorders (WMSDs) in construction. Previous efforts have concentrated on wearable sensors or computer vision-based monitoring. However, certain limitations need to be further investigated. First, wearable sensor-based studies lack reliability due to vulnerability to environmental interferences. Second, conventional computer vision-based recognition demonstrates classification inaccuracy under adverse environmental conditions, such as insufficient illumination and occlusion. To address the above limitations, this study presents an innovative and automated approach for recognizing and classifying awkward working postures. This approach leverages multimodal data collected from various sensors and apparatuses, allowing for a comprehensive analysis of different modalities. A feature-level fusion strategy is employed to train deep learning-based networks, including a multilayer perceptron (MLP), recurrent neural network (RNN), and long short-term memory (LSTM). Among these networks, the LSTM model achieves optimal performance, with an impressive accuracy of 99.6% and an F1-score of 99.7%. A comparison of metrics between single-modality and multimodal-fused training methods demonstrates that the incorporation of multimodal fusion significantly enhances the classification performance. Furthermore, the study examines the performance of the LSTM network under adverse environmental conditions. The accuracy of the model remains consistently above 90% in such conditions, indicating that the model's generalizability is enhanced through the multimodal fusion strategy. In conclusion, this study mainly contributes to the body of knowledge on proactive prevention for safety and health risks in the construction industry by offering an automated approach with excellent adaptability in adverse conditions. Moreover, this innovative attempt integrating diverse data through multimodal fusion may provide inspiration for future studies to achieve advancements.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Biomechanical investigation of tasks concerning manual materials handling using response surface methodology\n",
            "Authors: Adhaye A.M.\n",
            "Abstract: In typical manual material handling, the variations in walking pattern are decided by various factors, such as load being handled, frequency of handling, walking surface, etc. Traditional gait analysis protocols commonly evaluate individual factor within specified ranges associated with particular activities or pathologies. However, existing literature underscores the concurrent impact of multiple factors on gait. This study identifies five pivotal factors—walking speed, surface slope, load carried, carrying method, and footwear—as contributors to gait alterations. To address risk factors in manual material handling activities, we propose a unique design-of-experiment-based approach for multi-task gait analysis. Unraveling the relationship between manual handling attributes and human gait holds paramount importance in formulating effective intervention strategies. We optimized the five input factors across a cohort of 15 healthy male participants by employing a face-centered central composite design experimentation. A total of 29 input factor combinations were tested, yielding a comprehensive dataset encompassing 18 kinematic gait parameters (such as cadence, step length etc., measured using inertial measurement system), the isolated impacts of factors, and the interplay of two-factor interactions with corresponding responses. The results illuminate the optimal scenarios of input factors that enhance individual gait performance—these include wearing appropriate footwear, employing a backpack for load carriage, and maintaining a moderate walking pace on a medium slope with minimal load. The study identifies walking speed and load magnitude as primary influencers of gait mechanics, followed by the chosen carrying method. In consequence, the insights gained advocate for the refinement of manual material handling tasks based on the outcomes, effectively mitigating the risk of musculoskeletal disorders by suggesting the interventions for posture correction.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Multiple-input streams attention (MISA) network for skeleton-based construction workers' action recognition using body-segment representation strategies\n",
            "Authors: Tian Y.\n",
            "Abstract: With the rapid growth of deep learning algorithms, graph convolutional networks (GCNs) have become a common choice for skeleton-based human action recognition, boasting impressive performance. However, existing GCN-based models often rely on physical human body connections, which may not suit complex construction tasks involving various body parts and hand movements. To address this concern, the human body is modeled in this paper through topological graphs at varying levels, designed based on body-segment strategies. A multiple-input streams attention (MISA) network is introduced, incorporating GCN and temporal convolutional network (TCN) components to enhance the body-structure topology graph of GCNs with more comprehensive input graphs. Additionally, two-modality motion data and three attention blocks are integrated to capture more discerning features. Finally, experimental results using the Construction Motion Library (CML) dataset demonstrated the superiority of the developed method, reaching approximately 84.94% recognition accuracy.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A case study of motion data-driven biomechanical assessment for identifying and evaluating ergonomic interventions in reinforced-concrete work\n",
            "Authors: Seo H.\n",
            "Abstract: Physical ergonomic intervention (e.g., use of tools) is adopted to improve working postures in the reinforced-concrete trade. However, evaluating its effectiveness often focuses on a specific body part mostly concerned although posture modification in one part may physically affect another. This paper presents a case study to comprehensively examine the effectiveness of existing ergonomic interventions. In the experiment, a subject repeated typical motions 15 times, which served as the baseline of biomechanical simulation with the 50th percentile of the anthropometric size of the U.S. population. 3D-motion-capture and biomechanical simulation were then adopted to collect full-body posture data and compute the load exerted on body parts with population strength capability. The results indicated that the disc compressions and joint moments were reduced by 45.41% and 31.86% whereas the effectiveness varied among the body parts (e.g., elbow, shoulder, knee). These results suggest that ergonomic interventions can lessen physical demands by carefully selecting an appropriate intervention for specific tasks and body parts in practice.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Machine learning approach to determine the decision rules in ergonomic assessment of working posture in sewing machine operators\n",
            "Authors: Su J.M.\n",
            "Abstract: Introduction: There are some inherent problems with the use of observation methods in the ergonomic assessment of working posture, namely the stability and precision of the measurements. This study aims to use a machine learning (ML) approach to avoid the subjectivity bias of observational methods in ergonomic assessments and further identify risk patterns for work-related musculoskeletal disorders (WMSDs) among sewing machine operators. Methods: We proposed a decision tree analysis scheme for ergonomic assessment in working postures (DTAS-EAWP). First, DTAS-EAWP used computer vision-based technology to detect the body movement angles from the on-site working videos to generate a dataset of risk scores through the criteria of Rapid Entire Body Assessment (REBA) for sewing machine operators. Second, data mining techniques (WEKA) using the C4.5 algorithm were used to construct a representative decision tree (RDT) with paths of various risk levels, and attribute importance analysis was performed to determine the critical body segments for WMSDs. Results: DTAS-EAWP was able to recognize 11,211 samples of continuous working postures in sewing machine operation and calculate the corresponding final REBA scores. A total of 13 decision rules were constructed in the RDT, with over 95% prediction accuracy and 83% path coverage, to depict the possible risk tendency in the working postures. Through RDT and attribute importance analysis, it was identified that the lower arm and the upper arms exhibited as critical segments that significantly increased the risk levels for WMSDs. Conclusions: This study demonstrates that ML approach with computer vision-based estimation and DT analysis are feasible for comprehensively exploring the decision rules in ergonomic assessment of working postures for risk prediction of WMSDs in sewing machine operators. Practical Applications: This DTAS-EAWP can be applied in manufacturing industries to automatically analyze working postures and identify risk patterns of WMSDs, leading to the development of effectively preventive interventions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Effectiveness of a theory-based educational intervention on work-related musculoskeletal disorders preventive behaviors among assembly-line female workers: a study protocol for a randomized controlled trial\n",
            "Authors: Hosseini Z.S.\n",
            "Abstract: Background: The use of preventive behaviors of musculoskeletal disorders (MSDs) requires proper training, which leads to correct decisions regarding maintaining postures at work and performing stretching exercises. Due to very repetitive work, applying manual force, improper postures, and static contractions of proximal muscles, assembly-line female workers suffer from musculoskeletal pains. It is assumed that structured and theory-based educational intervention using a learning-by-doing (LBD) approach may increase the preventive behaviors against MSDs and reduce the consequences of these disorders. Methods: This randomized controlled trial (RCT) will be conducted in three phases: phase 1: validation of the compiled questionnaire, phase 2: determining the social cognitive theory (SCT) constructs that predict the preventive behaviors of MSDs in assembly-line female workers, and phase 3: designing and implementing the educational theory. The educational intervention is based on the LBD approach, and the study population includes assembly-line female workers in electronic industries of Iran, who are randomly divided into two intervention and control groups. The intervention group received the educational intervention in the workplace and the control group does not receive any intervention. The theory-based educational intervention includes evidence-based information along with pictures, fact sheets, and published literature about a good posture at work and the need to perform proper stretching exercises. The educational intervention aims to improve the knowledge, skills, self-efficacy, and intention of assembly-line female workers to adopt preventive behaviors of MSDs. Discussion: The present study will evaluate the effects of maintaining a good posture at work and performing stretching exercises on the adherence to preventive behaviors of MSDs among assembly-line female workers. The developed intervention is easily implemented and evaluated in a short period of time based on the improved score of the rapid upper limb assessment (RULA) method and the mean score of adherence to stretching exercises and can be provided by a health, safety, and environment (HSE) expert. Trial registration: ClinicalTrials.gov IRCT20220825055792N1. Registered on 23 September 2022 with the IRCTID.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A machine learning approach for detecting fatigue during repetitive physical tasks\n",
            "Authors: Liu G.\n",
            "Abstract: Prolonged and repetitive stress on muscles, tendons, ligaments, and nerves can have long-term adverse effects on the human body. This can be exasperated while working if the environment and nature of the tasks puts significant strain on the body, which may lead to work-related musculoskeletal disorders (WMSDs). Workers with WMSDs can experience generalized pain, loss of muscle strength, and loss of ability to continue working. Most WMSDs injuries are caused by ergonomic risks, such as repetitive physical movements, awkward postures, inadequate recovery time, and muscular stress. Fatigue can be seen as a detector of ergonomic risk, as the accumulation of fatigue can significantly increase the possibility of injury. Thirty participants completed a series of repetitive physical tasks over a six-hour period while wearing sensors to capture data related to heart rate and movement, while external embedded sensors captured ground reaction and hand exertion force. They also provided subjective ratings of fatigue at the start and end of the experiment. Classifiers for fatigue (high vs low) were constructed using three methods: linear discriminant analysis (LDA), k-nearest neighbor (kNN), and polynomial kernel-based SVM (P-SVM) and were validated using a tenfold cross-validation technique that was repeated a hundred times. Results of our supervised machine learning approach demonstrated a maximum accuracy of 94.15% using P-SVM for the binary classification of fatigue.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: SPECTRE: a deep learning network for posture recognition in manufacturing\n",
            "Authors: Ciccarelli M.\n",
            "Abstract: Work-related musculoskeletal disorders are a very impactful problem, both socially and economically, in the manufacturing sector. To control their effect, standardised methods and technologies for ergonomic assessment have been developed. The main technologies used are inertial sensors and vision-based systems. The former are accurate and reliable, but invasive and not affordable for many companies. The latter use machine learning algorithms to detect human pose and assess ergonomic risks. In this paper, using data collecting by reproducing the working environment in LUBE, the major Italian kitchen manufacturer, we propose SPECTRE (Sensor-independent Parallel dEep ConvoluTional leaRning nEtwork): a fully sensor-independent learning model based on convolutional networks to classify postures in the workplace. This system assesses ergonomic risks in major body segments through Deep Learning with a minimal impact. SPECTRE’s performance is evaluated using established metrics for imbalanced data (precision, recall, F1-score and area under the precision-recall curve). Overall, SPECTRE shows good performance and, thanks to an agnostic explainable machine learning method, is able to extrapolate which patterns are significant in the input.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Static and dynamic validation of kinect for ergonomic postural analysis using electro-goniometers as a gold standard: A preliminary study\n",
            "Authors: Bhatia V.\n",
            "Abstract: BACKGROUND: Evaluation of the working postures and development of new techniques are paramount in reducing the awkward postures and occurrence of musculoskeletal disorders (MSDs). The Kinect sensor, a portable and cost-effective device, appears to be a promising alternative to study work postures. OBJECTIVE: The current study aimed to evaluate the validity of Kinect against the gold-standard instrument (electro-goniometers) for body joint angle measurements. METHODS: A unique software application was developed to measure the critical body joint angles for postural evaluation by using the Kinect’s skeletal tracking feature. The body joint angle data of ten volunteers were measured simultaneously by both Kinect and electro-goniometers. The validation analysis was conducted in both static and dynamic domains of application. RESULTS: Minimal variation was observed between the two techniques, and the Kinect correlated well for upper-arm joint angles of 45◦, 60◦ and 90◦; lower-arm joint angles of 30◦, 45◦, 60◦, and 90◦; straight neck position, neck joint angle at maximum possible flexion; straight trunk position, trunk bend angle at full flexion. In dynamic analysis, four out of five ICC values were > 0.75 except for the upper arm. Discrepancies in the results indicated the disapproval of Kinect for only wrist measurements. CONCLUSION: The results of the static and dynamic studies gave a sufficient basis to consider the Kinect tool as an alternative to contemporary posture-based ergonomic evaluation methods.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Estimation of the knee joint load using plantar pressure data measured by smart socks: A feasibility study\n",
            "Authors: Daugulis P.\n",
            "Abstract: BACKGROUND: Unsupervised sports activities could cause traumas, about 70% of them are those of the low extremities. To avoid traumas, the athlete should be aware of dangerous forces acting within low extremity joints. Research in gait analysis indicated that plantar pressure alteration rate correlates with the gait pace. Thus, the changes in plantar pressure should correlate with the accelerations of extremities, and with the forces, acting in the joints. Smart socks provide a budget solution for the measurement of plantar pressure. OBJECTIVE: To estimate the correlation between the plantar pressure, measured using smart socks, and forces, acting in the joints of the lower extremities. METHODS: The research is case study based. The volunteer performed a set of squats. The arbitrary plantar pressure-related data were obtained using originally developed smart socks with embedded knitted pressure sensors. Simultaneously, the lower extremity motion data were recorded using two inertial measurement units, attached to the tight and the ankle, from which the forces acted in the knee joint were estimated. The simplest possible model of knee joint mechanics was used to estimate force. RESULTS: The estimates of the plantar pressure and knee joint forces demonstrate a strong correlation (r = 0.75, P < 0.001). The established linear regression equation enables the calculation of the knee joint force with an uncertainty of 22% using the plantar pressure estimate. The accuracy of the classification of the joint force as excessive, i.e., being more than 90% of the maximal force, was 82%. CONCLUSION: The results demonstrate the feasibility of the smart socks for the estimation of the forces in the knee joints. Smart socks therefore could be used to develop excessive joint force alert devices, that could replace less convenient inertial sensors.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: RULA-based work posture evaluation for Indonesian workers: A comparison between office and manufacturing\n",
            "Authors: Lukodono R.P.\n",
            "Abstract: The high number of use Indonesian workers for manufacturing and office will impact safety and health issues in the future. Human body posture in the work become one of factor influence that because in daily life human spends more time doing work with more than 1/3 portion. Using bad posture for a long duration will impact human performance in the work. Moreover, some musculoskeletal disorders (MSDs) problems are affected by improper working posture. Using the physiological approach evaluation for the posture will give information about the risk for workers with their current posture of work. RULA analysis was collected from 103 posture evaluations of office and manufacturing workers. The regression and analysis of variance were done to evaluate the significant impact of the human upper body segment for the RULA evaluation score. Comparing the office and manufacturing conditions of work will give information about the risk for Indonesian workers and their status. The result shows that manufacturing workers has a higher risk than office worker with 6 and 4 scores respectively. There is also a similar result for the office and the manufacturing worker for the body segment effect which mentions that trunk, neck, upper arm, lower arm, and neck had a significant effect.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An Innovative Wearable Sensing System Based on Flexible Piezoresistive Sensors to Estimate Upper Body Joint Angle Using a Nonlinear AutoRegressive eXogenous Neural Model\n",
            "Authors: Laaraibi A.R.A.\n",
            "Abstract: The widespread adoption of instrumented textiles has made a significant impact on various domains, encompassing health monitoring, rehabilitation, biomechanics, and sports. This study specifically focuses on the development and evaluation of a smart garment that employs low-energy flexible sensors embedded within the fabric to effectively monitor upper body movements. These sensors utilize a piezoresistive polymer integrated into the garment and establish a connection with an electronic board for data acquisition. Wireless data transmission is achieved through the utilization of Bluetooth low energy (BLE) technology, with the garment showcasing an impressive average power consumption of approximately 10 μW. To ensure the sensor's performance and reliability, a comprehensive characterization process is meticulously conducted utilizing a dedicated test bench. Furthermore, this study conducts a comparative analysis between two distinct estimators utilized for determining the flexion/extension angles of the upper body joint. The first estimator leverages a nonlinear AutoRegressive eXogenous (NARX) neural network model, while the second estimator employs a viscoelastic model. Through extensive evaluation, it becomes evident that the NARX neural network model outperforms the viscoelastic model, showcasing superior accuracy with a root-mean-square error of 4.85°. Consequently, the NARX neural network model emerges as the preferred option for accurately estimating the flexion/extension angles of the upper body joint.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Risk factors associated with work-related musculoskeletal disorders among dumper operators: A machine learning approach\n",
            "Authors: Kar M.B.\n",
            "Abstract: Aims: This study aimed to determine the risk factors associated with work-related musculoskeletal disorders (WRMSDs) among dumper operators working in Indian iron ore mines. Methods: A total of 246 dumper truck operators meeting inclusion and exclusion criteria were chosen for data collection. A self-report custom and the standard Nordic questionnaire were used for collecting data about risk factors and WRMSDs. The data were pre-processed and analyzed using machine learning (ML) algorithms (such as logistic regression ( LR), support vector machines (SVM), decision trees (DT), gradient boosting machine (GBM) and random forest (RF)). Results: RF model was found to outperform the other algorithms with high accuracy (0.71), precision (0.75), recall (0.78), F1 score (0.76), and area under the receiver operating characteristic curve (0.82). The mean rank of the risk factors showed that age is the most critical parameter, followed by awkward posture, experience in mines, job demand, alcohol consumption, smoking cigarettes, work design, and marriage status. Conclusion: Overall, the study provides valuable insights into the risk factors associated with WRMSDs among dumper operators and suggests that measures should be taken to address these risk factors to prevent WRMSDs in the dumper operator population.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Investigation and analysis of the safety risk factors of aging construction workers\n",
            "Authors: Fan X.\n",
            "Abstract: The proportion of middle-aged and aging workers is increasing year by year in the construction industry. Affected by their physical functions and other conditions, the death rate of aging construction workers is higher than that of the workers in other age groups, which brings higher risks to the safety of the industry. Therefore, the paper aims to determine the main risk factor of safety brought on by the aging construction workers, and the degree of influence of safety risk factor on aging construction workers. Through the design of the questionnaire, the number and type of index to be studied are selected. The 6 first-level indexes and 30 second-level indexes were selected from 100 indexes. The AHP method was used to evaluate the influence of aging construction workers on the safety risk factor. The classification of work contents of aging construction workers in different age groups is proposed to reduce safety risks and provide an effective basis for management. The significance of this study is as follows: (1) The concrete analysis of index affecting the safety risk of aging construction workers has enriched the existing academic research; (2) the quantitative risk index system in the study, provides a reference value for further research in the academic circle; (3) The study of this paper has certain reference significance for construction companies and government regulatory departments to formulate policies and measures, such as job classification of aging workers in different ages and restrictive conditions for high-risk work.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Measurement of human body parameters for human postural assessment via single camera\n",
            "Authors: Yan Z.\n",
            "Abstract: We present a camera-based human body parameters measurement approach and develop a human postural assessment system. The approach combines the conventional contact measurement method and the non-contact measurement method to overcome some shortcomings in terms of time, expense, and professionalism in early methods. The entire measurement system consists of a computer, a high-definition camera, and the sticky points that are applied to the participant's body before the measurement. The camera captures the triple view image of human body. Then, the human body outline and the joint points of the human skeleton are extracted to locate the bone feature points. Finally, measurements and extractions of the human parameters are made. Experimental results demonstrate that the global postural assessment system provides quantitative guidance for human postural evaluation, and it completely changes how human postural is evaluated. The postural assessment system is significant for early diagnosis of diseases and medical rehabilitation treatment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Modelling for design and evaluation of industrial exoskeletons: A systematic review\n",
            "Authors: Ma T.\n",
            "Abstract: Industrial exoskeletons are developed to relieve workers’ physical demands in the workplace and to alleviate ergonomic issues associated with work-related musculoskeletal disorders. As a safe and economical alternative to empirical/experimental methods, modelling is considered as a powerful tool for design and evaluation of industrial exoskeletons. This systematic review aims to provide a comprehensive understanding of the current literature on the design and evaluation of industrial exoskeletons through modelling. A systematic study was conducted by general keyword searches of five electronic databases over the last two decades (2003–2022). Out of the 701 records initially retrieved, 33 eligible articles were included and analyzed in the final review, presenting a variety of model inputs, model development, and model outputs used in the modelling. This systematic review study revealed that existing modelling methods can evaluate the biomechanical and physiological effects of industrial exoskeletons and provide some design parameters. However, the modelling method is currently unable to cover some of the main evaluation metrics supported by experimental assessments, such as task performance, user experience/discomfort, change in metabolic costs etc. Standard guidelines for model construction and implementation, as well as validation of human-exoskeleton interactions, remain to be established.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: PosturAll: A Posture Assessment Software for Children\n",
            "Authors: Neves A.B.\n",
            "Abstract: From an early age, people are exposed to risk factors that can lead to musculoskeletal disorders like low back pain, neck pain and scoliosis. Medical screenings at an early age might minimize their incidence. The study intends to improve a software that processes images of patients, using specific anatomical sites to obtain risk indicators for possible musculoskeletal problems. This project was divided into four phases. First, markers and body metrics were selected for the postural assessment. Second, the software’s capacity to detect the markers and run optimization tests was evaluated. Third, data were acquired from a population to validate the results using clinical software. Fourth, the classifiers’ performance with the acquired data was analyzed. Green markers with diameters of 20 mm were used to optimize the software. The postural assessment using different types of cameras was conducted via the blob detection method. In the optimization tests, the angle parameters were the most influenced parameters. The data acquired showed that the postural analysis results were statistically equivalent. For the classifiers, the study population had 16 subjects with no evidence of postural problems, 25 with mild evidence and 16 with moderate-to-severe evidence. In general, using a binary classification with the train/test split validation method provided better results.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Classifying Poor Postures of the Neck and Spine in Computer Work by Using Image and Skeleton Analysis\n",
            "Authors: Lee J.\n",
            "Abstract: When using a desktop computer, people tend to adopt postures that are detrimental to their bodies, such as text neck and the L-posture of leaning forward with their buttocks out and their shoulders against the backrest of the chair. These two postures cause chronic problems by bending the cervical and thoracic spines and can have detrimental effects on the body. While there have been many studies on text neck posture, there were limited studies on classifying these two postures together, and there are limitations to the accuracy of their classification. To address these limitations, we propose an algorithm for classifying good posture, text neck posture, and L-posture, the latter two of which may negatively affect the body when using a desktop computer. The proposed algorithm utilizes a skeleton algorithm to calculate angles from images of the user’s lateral posture, and then classifies the three postures based on the angle values. If there is sufficient space next to the computer, the method can be implemented anywhere, and classification can be performed at low cost. The experimental results showed a high accuracy rate of 97.06% and an F1-score of 95.23%; the L posture was classified with 100% accuracy.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: VR-RET: A Virtual Reality-Based Approach for Real-Time Ergonomics Training on Industrialized Construction Tasks\n",
            "Authors: Dias Barkokebas R.\n",
            "Abstract: Real-time assessment of the ergonomic risks to which workers are exposed at a workstation and the provision of real-time corrective feedback intervention to workers play an essential role in improving safety in the workplace through the reduction of long-term exposure of workers to the ergonomically hazardous postures associated with physical fatigue and work-related musculoskeletal disorders. This study proposes a framework, virtual reality-based real-time ergonomics training (VR-RET), that integrates virtual reality (VR) and an inertia motion capture system to rapidly assess postures, providing the following inputs in real time: (1) full-body postural ergonomic risk assessment that deploys existing rule-based methods such as rapid upper limb assessment (RULA) and rapid entire body assessment (REBA); (2) auditory feedback, triggered when the exposure to ergonomic risks is higher than a predefined threshold; and (3) visual feedback intervention to correct ergonomically hazardous postures through the provision of recommendations during training on industrialized construction tasks. The proposed framework is verified through a pretest/posttest procedure in conjunction with a randomized control group experiment involving 37 subjects. Based on the comparison of the pretest and posttest data, a reduction of 35% in the percentage of time spent being subjected to ergonomic risks in the high-risk range is observed when training is administered using VR-RET and RULA is deployed as the risk assessment method; in contrast, a significant reduction is not observed when rapid entire body assessment is used. This study's contributions are twofold: (1) a framework for providing ergonomic and operational training through VR simulation based on real-time acquisition and processing of body motion data (with the objective of mitigating worker behaviors that increase exposure to the ergonomically hazardous postures that can lead to a work-related musculoskeletal disorder); and (2) updated evaluation of the effectiveness of real-time RULA and REBA assessments integrated with real-time auditory and visual postural feedback intervention for ergonomic risk reduction.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Robust and breathable all-textile gait analysis platform based on LeNet convolutional neural networks and embroidery technique\n",
            "Authors: Zhao M.\n",
            "Abstract: Repetitive Strain Injury (RSI) and its related Musculoskeletal Disorders (MSDs) symptoms not only bring pathological pains to people, but also limit their physical activities and work abilities. The pathological changes in the footprints and other gait features provide a new way for the real-time monitoring and nursing of the recovery degrees of MSDs symptoms. In this work, based on the conformable, breathable, and lightweight all-fabric pressure sensing material, a novel highly robust universal platform ATPSA-LeNet, consisting of the all-textile pressure sensors array (ATPSA) and LeNet convolutional neural networks, has been proposed. Standing postures and authentication of volunteers have been identified from their gait characteristics with high accuracy. The ATPSA-LeNet platform could directly convert foot pressure values into input data for the deep learning networks through the ATPSA, which greatly reduces the artificial errors arose from the spatial arranging of the sensors array and image data processing. Besides, ATPSA is more seamless and comfortable due to its improved compactness and breathability. Failures of sensing units also did not significantly decrease the overall accuracy. The proposed ATPSA-LeNet platform would provide a great prospect for extracting the high-dimensional spatial information contained in human gait features in many fields, such as clinical medicine, authentication, and criminal investigation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Computer vision applications in offsite construction\n",
            "Authors: Alsakka F.\n",
            "Abstract: The field of computer vision has undergone rapid growth in recent years, yet the use of computer vision in offsite construction remains an under-researched area of study. Given the current momentum around the adoption of this technology, this article presents a scoping review of computer vision applications in offsite construction. It provides (1) summaries of and discussions on the research areas in which computer vision is used in offsite construction, the computer vision tasks undertaken, the algorithms used, and related performance evaluation results and limitations, (2) a tabulated summary of performance-related terms commonly used in computer vision applications (to facilitate understanding of the performance evaluation results reported in the review), and (3) potential avenues of future research. The review provides a useful point of reference for practitioners and researchers in the offsite construction industry, aiding their understanding of current practice, limitations, research gaps, and potential opportunities to apply computer vision.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Analysis of Adolescents’ Head to Shoulder Region during Tablet Use from Sagittal and Frontal RGB Images\n",
            "Authors: Kramer I.\n",
            "Abstract: As schools go digital, the use of tablet computers is increasing. Concerns are raised that the extensive use of tablets and the associated bent-over posture may negatively affect the individual’s health. In order to analyse the possible effects of prolonged tablet use on physical health, a detailed analysis of the posture during tablet use is needed so that appropriate preventive measures can be taken to prevent degenerative changes. Therefore, the aim of this study was to measure and report the posture of 56 students while working with a tablet computer and compare it with an upright posture. Sagittal and frontal images were used for measurements of the subjects’ postures while seated, using the tablet, and in a neutral sitting position looking straight ahead. The body position during tablet use was recorded in two different user configurations: tablet flat on the table and tablet in individual freely chosen user configuration. After appropriate annotation of the data, the following parameters were evaluated in different planes. The craniovertebral angle (CVA), head tilt angle (HTA), and forward shoulder angle (FSA) are measurements that describe the extent to which the head bends forward and downward and how the shoulders are aligned in the sagittal plane. On the other hand, the head shoulder angle (HSA), lateral head tilt angle (LHTA), and trunk flexion angle (TFA) are angles measured in the frontal plane, which indicate the degree of head tilt and trunk bending to the right or left side. The measurement results clearly showed that the use of a tablet had a pronounced effect on the positions and rotations of the participants’ head, neck, and shoulders. This was evident through strong deviations observed in the angles measured between the sitting straight posture and the postures while using the tablet. For example, depending on the body posture class, the mean CVA values were 45.76° for straight sitting posture, 28.25° for holding the tablet individually posture, and 26.04° for the posture adopted while using a tablet placed flat on the table.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic Evaluation of Different Working Posture and Handle Designs of Mason Trowel during Wall Plastering Work based on Shoulder and Arm Muscle Activity\n",
            "Authors: Kumar R.N.\n",
            "Abstract: This study aims to identify the impact of the three ergonomically designed mason trowel handles at two working postures on the arm and shoulder muscles activation through experimental and subjective analysis. Prolonged usage, poor ergonomic design of trowels, and working at awkward postures results in Work-related Musculoskeletal Disorders (WMSD) among workers performing wall plastering task. Three mason trowels with different handle shapes were designed by modifying existing mason trowels and developed with 3D printing technology. Twelve student volunteers took part in this experimental study and simulated the wall plastering work at two commonly adopted working postures. Muscle activation and fatigue characteristics of five muscles on the arms and shoulder region were studied using Electromyography sensor (sEMG) sensors. Borg's CR-10 scale was employed to carry out the subjective analysis to find mean discomfort among the models. The results revealed that handle shape and working position have an influence on the shoulder muscle engagement and less effect on the arm muscles. Subjective analysis results revealed that Model B and Model C were rated with higher preference by the participants. Results have revealed that shoulder muscle is activated more and subjected high muscle fatigue while performing wall plastering tasks. Also, circular-shaped handles with varying cross sections and curved shape handles were rated as highly compared to wall plastering work. Findings from this study can be used for studying the relationship between mason trowel designs and working posture with muscle activation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: sEMG Spectral Analysis and Machine Learning Algorithms Are Able to Discriminate Biomechanical Risk Classes Associated with Manual Material Liftings\n",
            "Authors: Donisi L.\n",
            "Abstract: Manual material handling and load lifting are activities that can cause work-related musculoskeletal disorders. For this reason, the National Institute for Occupational Safety and Health proposed an equation depending on the following parameters: intensity, duration, frequency, and geometric characteristics associated with the load lifting. In this paper, we explore the feasibility of several Machine Learning (ML) algorithms, fed with frequency-domain features extracted from electromyographic (EMG) signals of back muscles, to discriminate biomechanical risk classes defined by the Revised NIOSH Lifting Equation. The EMG signals of the multifidus and erector spinae muscles were acquired by means of a wearable device for surface EMG and then segmented to extract several frequency-domain features relating to the Total Power Spectrum of the EMG signal. These features were fed to several ML algorithms to assess their prediction power. The ML algorithms produced interesting results in the classification task, with the Support Vector Machine algorithm outperforming the others with accuracy and Area under the Receiver Operating Characteristic Curve values of up to 0.985. Moreover, a correlation between muscular fatigue and risky lifting activities was found. These results showed the feasibility of the proposed methodology—based on wearable sensors and artificial intelligence—to predict the biomechanical risk associated with load lifting. A future investigation on an enriched study population and additional lifting scenarios could confirm the potential of the proposed methodology and its applicability in the field of occupational ergonomics.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Fast Three-Dimensional Posture Reconstruction of Motorcyclists Using OpenPose and a Custom MATLAB Script\n",
            "Authors: Barberi E.\n",
            "Abstract: Ergonomics focuses on the analysis of the interaction between human beings and their working environment. During the riding of a motorbike, ergonomics studies the rider’s posture on the motorbike. An incorrect posture can lead to physical and psychological discomfort, and can affect the perception of risk and the handling of the motorcycle. It is important for motorcyclists to adopt a good riding posture, for their health and road safety. The aim of this work is to propose a fast, cheap, and sufficiently robust method for the 3D reconstruction of the posture assumed by a motorcyclist. The stereo vision and the application of OpenPose made it possible to obtain a 3D reconstruction of the key points, and their evolution over time. The evaluation of the distances between the 3D key points, which represent the length of the various parts of the body, appears to remain sufficiently stable over time, and faithful to the real distances, as taken on the motorcyclist themself. The 3D reconstruction obtained can be applied in different fields: ergonomics, motorsport training, dynamics, and fluid dynamics analysis.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Manual patient handling in the healthcare setting: a scoping review\n",
            "Authors: Johnson K.\n",
            "Abstract: Background: Manual patient handling is the most frequently reported risk factor for work related musculoskeletal disorders in healthcare. Patient handling tasks are routinely performed manually without assistive devices and can create awkward postures and high loads for nurses and allied health professionals (AHPs). However, AHPs, notably physiotherapists, also utilize therapeutic handling to facilitate patient movement during rehabilitation. Objectives: To comprehensively map the literature surrounding manual patient handling (without assistive devices) by healthcare practitioners. Methods: AMED, CINAHL, MEDLINE, SPORTDiscus, and EMBASE databases were searched. Grey literature was sourced from Google Scholar, EThOS, Open Grey, Health and Safety Executive, National Institute for Occupational Safety and Health and Work Safe Australia. Literature published in English between 2002 and 2021 was included. Results: Forty-nine records were included: 36 primary research studies, 1 systematic review and 12 ‘other’ including narrative and government reports. Primary research was predominantly observational cross-sectional (n = 21). The most common settings included laboratories (n = 13) and hospitals (n = 13). Seven research questions were identified, with patient handling practices (n = 13) the most common. Nurses formed the largest practitioner population (n = 13) and patients were often simulated (n = 12). Common outcomes included tasks performed (n = 13) and physical demands during patient handling (n = 13). Conclusion and implications of key findings: This comprehensive scoping review identified that most research was observational, investigating nurses in hospitals or laboratories. More research on manual patient handling by AHPs and investigation of the biomechanics involved in therapeutic handling is needed. Further qualitative research would allow for greater understanding of manual patient handling practices within healthcare. Contribution of the paper: • Much of the research remains observational cross-sectional, investigating patient handling tasks, movement and loading in laboratory settings. Although, the number of studies being performed in hospital settings has increased recently to equal the number performed in controlled laboratory environments. • Manual handling has been identified as a significant biomechanical factor in development of WRMSD, however, this scoping review identified a lack of literature investigating the relationship between the effect of staff training on incidence of WRMSD. • This review identified a need for more qualitative research related to moving and handling of patients, to facilitate a deeper understanding of the topic.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A holistic evaluation of ergonomics application in health, safety, and environment management research for construction workers\n",
            "Authors: Liao L.\n",
            "Abstract: The construction industry is one of the industries with worst safety records. With the increasing application of ergonomics, health, safety, and environment (HSE) management of construction workers has been improved. However, a thorough evaluation of ergonomics application in HSE management research for construction workers remains unavailable. This study aims to fill this gap by evaluating relevant peer-reviewed journal papers published from 2000 to 2021 to ascertain the status of this research area and identify future directions. After a literature search in Scopus and Web of Science and careful manual screening, a total of 252 articles were identified. The papers were analyzed in terms of contributing journals, prominent scholars, and critical articles as well as keyword co-occurrence, burst detection, and term clustering. A conceptual framework linking five research themes (ergonomic interventions, ergonomic training, ergonomic risk factors identification and evaluation, ergonomic posture recognition, and physiological monitoring) into corresponding future research directions was proposed based on a qualitative evaluation. The findings of this study provide useful references for future application of ergonomics in the enhanced HSE management of construction workers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: AI-enabled farm-friendly automatic machine for washing, image-based sorting, and weight grading of citrus fruits: Design optimization, performance evaluation, and ergonomic assessment\n",
            "Authors: Chakraborty S.K.\n",
            "Abstract: The modernization of postharvest operations and penetration of emerging technologies in horticultural processing have provided intelligent solutions for reducing postharvest losses. Work environmental and occupational health issues require immediate attention as the awkward posture and continuous drudgery-prone on-farm sorting and grading activities may lead to musculoskeletal disorders. The main objective of this study was to develop an automatic farm-friendly machine for real-time citrus fruit washing, image-based sorting, and weight grading; designed optimally and equipped with an embedded system comprising a lightweight convolutional neural network (CNN) model. Also included in this study was a thorough ergonomic assessment of the developed machine in a real work environment. The parametric choice of the fruit washing and singulation system was performed by employing computational fluid dynamics modeling and response surface methodology designed optimization. It was observed that under steady-state conditions, the water jet would arrive at a velocity of 11.36 m/s which would eventually suit a singulation conveyor with a slope of 25°. A noninvasive grading and sorting approach for citrus fruits is presented in this paper that leverages deep learning to classify the fruits into “accept” and “reject” classes. The custom lightweight CNN model “SortNet” has shown excellent classification results with an overall accuracy of 97.6%. The ergonomic evaluation shows that the average body part discomfort score in case of operating an automatic fruit grading machine was much lower (12.3 ± 2.0) than the traditional method (30.9 ± 3.3). Further, in the case of machine operation, the percentage load on the muscles ranged from 28.67 to 34.31 reflecting that subjects can work for longer duration on the machine without fatigue as compared with the traditional manual operation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of an automated mobile robotic sprayer to prevent workers' exposure of agro-chemicals inside polyhouse\n",
            "Authors: Jat D.\n",
            "Abstract: Automated spraying practices are inevitable for modern polyhouse management to attain a broader objective of minimizing human exposure to agrochemicals. In the present study, an automated mobile robotic sprayer (AMRS) was developed to combat the increased human intervention and safeguard agricultural workers from potential health hazards. The system mainly comprises embedded sensors (ultrasonic, proximity, XBee) and controllers (Arduino, PLC). The controller drives the system on a piping track between the rows as well as on the head space achieving end-to-end automation for spraying operations. The system performance was evaluated on the tomato crop with respect to the physiological traits, yield and economics. Additionally, the study leveraged response surface methodology to optimize forward speed, spray distance, and working pressure of AMRS on the responses, droplet density, coverage, volume mean diameter (VMD) and application rate. Optimization of forward speed (0.79 km/h), spray distance (250 mm) and working pressure (0.40 MPa) resulted in 90.7 droplets/cm2 droplet density, 47.1% coverage, 170.2 μm VMD and 86.0 mL/m2 of application rate. Ergonomic aspects of AMRS were assessed by the parameters, human exposure, discomfort and postural assessment with respect to knapsack sprayer. The working heart rate of 103 beats/min, work pulse of 12 beats/min, oxygen consumption rate of 916 mL/min and energy expenditure rate of 18.7 kJ/min recorded during the ergonomic evaluation of the AMRS were 25%, 75%, 42%, and 41% lower compared to manual spraying, respectively. Moreover, three–six times higher work pulse, cardiac cost, body part discomfort score and overall discomfort rating were observed which indicated more drudgery involved in manual spraying. State-of-the-art system developed for polyhouses would minimize the drudgery and health hazards, significantly. The system's resilience and effectiveness pave the way for its wider deployment where the use of agrochemicals are prevalent, particularly in small-size polyhouses.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: SELECTION OF WEARABLE SENSORS FOR HEALTH AND SAFETY USE IN THE CONSTRUCTION INDUSTRY\n",
            "Authors: Aksüt G.\n",
            "Abstract: Construction industry workers; are exposed to serious safety and health risks, hazardous work environments, and intense physical work. This situation causes fatal and non-fatal accidents, reduces productivity, and causes a loss of money and time. Construction safety management can use wearable sensors to improve safety performance. Since there are many types of sensors and not all sensors can be used in construction applications, it is necessary to identify suitable and reliable sensors. This requirement causes a sensor selection problem. The study aims to determine the priority order of physiological and kinematic sensors in preventing risks in the construction industry. Within the scope of this purpose, five criteria and seven alternatives were determined in line with the literature research and expert opinions. The criteria weights were calculated with the AHP method, and the alternatives were ranked with PROMETHEE and AHP. Providing a proactive approach to the use of sensors in the construction industry will provide safer working conditions, identify workers at risk, and help identify and predict potential health and safety risks. It will contribute to the literature on improving construction health and safety management.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A force plate analysis of sitting postures on a Risshin chair (Zazen-like, upright-support seating furniture) during lectures: An exploratory and preliminary study\n",
            "Authors: Sugamura G.\n",
            "Abstract: Background. “Posture” refers to both physical stance and mental attitude in both the East and West. Psychological research has demonstrated that posture reflects and alters emotions. In Japan, a tradition of regulating the body and mind by aligning posture exists, as exemplified by Zen meditation, and an upright sitting posture has been emphasized in school and home education. We developed the risshin chair, a modified version of the traditional school chair that helps students maintain an upright posture, and examined its educational effectiveness. Purpose. However, postural assessment in posture education involves various body parts, and holistic validation has been challenging. We propose the use of a force plate as a more quantitative and comprehensive method for measuring learners’ macro-and microscopic body movements. This study aimed to obtain basic data on how the center of pressure (COP) changes between a risshin chair and a regular school chair in a quasi-educational setting in a laboratory and to preliminarily verify the effectiveness of force plate in postural education research. Method. Eleven students participated in the experiment, of whom 10 were included in the analysis. Each participant sat in a risshin chair or regular school chair and watched the lecture video in a counterbalanced order. Their COP changes were recorded during these trials, and they answered six questions on their reactions to the lecture. Results. Although we found no significant differences between chair conditions in subjective reports and in total COP length and others, the mean COP path length (p = .033, d = 0.80) and mean COP area length (p = .021, d = 0.88) were shorter, and the COP displacement (in the anterior-posterior direction) was also smaller (p = .006, d = 1.14) in the risshin chair than in the regular school chair. Conclusions. The results suggested that the risshin chair suppresses minute, rapid swaying and results in more leisurely body movements. This study provides initial insight into the effectiveness of force plates in quantifying sitting postures with little visible movement.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Comfort Study of General Aviation Pilot Seats Based on Improved Particle Swam Algorithm (IPSO) and Support Vector Machine Regression (SVR)\n",
            "Authors: Zhang M.\n",
            "Abstract: Little work has been carried out to predict the comfort of aircraft seats, a component in close contact with the human body during travel. In order to more accurately predict the nonlinear and complex relationship between subjective and objective evaluations of comfort, this paper proposes a prediction method based on the Improved Particle Swarm Algorithm (IPSO) and optimized Support Vector Machine Regression (SVR). Focusing on the problems of the too-fast convergence and low accuracy of the traditional particle swarm algorithm (PSO), the improved particle swarm algorithm (IPSO) is obtained by linearly decreasing the dynamic adjustments of inertia weight (Formula presented.), self-learning factor (Formula presented.), and social factor (Formula presented.) ; then, the penalty parameter C and kernel function parameter σ of SVR are optimized by the IPSO algorithm, and the comfort prediction of IPSO-SVR is established. The prediction accuracy of IPSO-SVR was 94.00%, the root mean square error RMSE was 0.37, the mean absolute value error MAE was 0.32, and the goodness of fit R2 was 0.92. The results show that the optimized IPSO-SVR prediction model can more accurately predict seat comfort under different angles and backrest tilt angles and can provide reference and research value for related industries. The results show that the optimized nonlinear prediction model of IPSO-SVR has higher accuracy, and its prediction method is feasible and generalizable, meaning it can provide a reliable basis for the prediction of seat comfort under different angles and backrest inclinations, as well as providing reference and research value for related industries.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Bibliometric Review on Safety Risk Assessment of Construction Based on CiteSpace Software and WoS Database\n",
            "Authors: Junjia Y.\n",
            "Abstract: As urbanization continues to grow around the world, the risks associated with construction are increasing. Scientific and practical risk assessments help reduce safety risks and achieve healthy, long-term growth, so there has been much research in this field. Through a review of the literature, this study aims to reveal the state and trends of research in the field of safety risk assessment. We searched 473 articles on construction risk assessment from the Web of Science (WoS) in the last decade, bibliometrically analyzed them, and then uncovered their significance using CiteSpace software (6.1. R6 (64-bit) Basic). The primary topics of conversation are countries, institutions, authors, and keywords, followed by references. According to the co-authorship analysis, the current research in this field is mainly from China, the USA, and Australia. Most influential authors currently have teaching or research positions at educational institutions; the most notable of which include Huazhong University of Science and Technology, Hong Kong Polytechnic University, and Tsinghua University. They form a relatively close network of institutional cooperation. Based on the results of the co-term analysis, this study found that the current research hotspots are mainly focusing on “multi-objective optimization”, “risk management”, “mechanical characterization”, “mental fatigue”, “accident prevention”, and many others. Data-driven, AI-assisted, and multi-stakeholder participation are the future trends in this field.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Blockchain-enabled cyber-physical system for construction site management: A pilot implementation\n",
            "Authors: Xiao J.\n",
            "Abstract: Prefabricated construction has become one of the most innovative methods to address the pressing housing demands. However, conventional prefabricated construction projects often suffer from challenges of managing numerous paper-based documentation, non-standardized management and intricate stakeholders in construction site management (CSM). The current design approaches lack sufficient consideration of the activity-based user relationships. To facilitate the system framework design and implementation for CSM, this study proposes a generic Cyber-physical Centered (CCD) Design, illustrating an effective and systematic approach to identify user-activity relationships in a cross-collaborative context. The consideration of entity, value chain and user-activity relationships facilitate identity management and value chain management services. The proposed approach was then utilized to a pilot project to design and implement the Blockchain-enabled Cyber-physical Site Management System (BCSMS) integrated with Digital Work Supervision System (DWSS), incorporating considerations on multi-source information flow and user-centric applications design. The implemented BCSMS decentralized two types of fundamental documents in CSM - Request for Inspection and Survey Checking (RISC) form and site diary. It addresses information fragmentation and asymmetry in a cross-collaborative environment caused by manual-input and error-prone records. The proposed system was evaluated by two important system performance indicators in terms of average response time and transaction per second. The system performance test shows that the accountability of BCSMS is significant compared to DWSS, given the p-value 0.01. Blockchain effectively improves DWSS with enhanced data submission, identity management and data-driven site performance evaluation functions. This study also qualitatively analyzed the pros and cons of proposed blockchain-enabled cyber-physical system (CPS) from society-economy-technology aspects for technical practitioners, construction stakeholders and governments.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A comparative neural networks and neuro-fuzzy based REBA methodology in ergonomic risk assessment: An application for service workers\n",
            "Authors: Yalcin Kavus B.\n",
            "Abstract: Non-ergonomic working conditions are the leading causes of musculoskeletal disorders that seriously affect human health. REBA is widely used tool due to its convenience and consideration of all body parts. However, it heavily relies on the subjective judgments of the assessor, leading to inconsistencies in results, and lacks sensitivity in detecting small changes in ergonomic risk factors. Therefore, there is a need to improve the REBA method by integrating it with new technologies. While a few studies have proposed integrating ergonomic risk measurement tools with ANNs, there is a research gap in comparing different types of neural networks and membership functions to determine the most effective approach for improving the performance of REBA. Additionally, there is a need to apply these integrations to real-life case studies to demonstrate their effectiveness in practice. This study proposes a comparative neural network and neuro-fuzzy-based REBA method that includes various types of neural networks and membership functions. The proposed method is applied to service employee who have experienced increased workloads due to the Covid-19 pandemic. The results show that the neuro-fuzzy method is more accurate than the REBA and provides greater flexibility in defining which member belongs to which risk level cluster. This study is critical because it addresses research gaps in integrating neural networks and REBA and applies these integrations to a real-life case study. By comparing different types of neural networks and membership functions, the study provides insights into which approaches are most effective for improving the performance of REBA.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Abnormal Behavior Detection Based on Dynamic Pedestrian Centroid Model: Case Study on U-Turn and Fall-Down\n",
            "Authors: Zhao R.\n",
            "Abstract: With the increasing number of video surveillance cameras in public buildings, it has become challenging, yet significant to detect abnormal pedestrian behaviors in crowd management, to prevent crowd accidents. Although current advancements in human action recognition based on computer vision can help detect abnormal behaviors after their incidence, majority of them lack the ability to detect potential characteristics prior to the occurrence of real abnormal behaviors. Hence, in this study, we addressed this issue by proposing a novel dynamic centroid model (DCM) of a human body, and rebuilding pedestrian joint sub-segments from human skeleton key nodes obtained in camera images. We built a weighted centroid-combined force model based on Newton's second law, considering acceleration, mass inertial of human body sub-segments, and internal constraints. Thereafter, pedestrian kinematic and dynamic parameters were analyzed, such as speed, trajectory, force. Furthermore, abnormal behavior detection criteria were constructed for typical abnormal-behavior cases: U-turn and fall-down. Comparative experiments between the proposed DCM and the state-of-the-art methods were conducted. The experimental results showed that the model was capable of detecting abnormal behaviors, with mean values of lead time of 277 ms in U-turn behavior, and 562 ms in fall-down behavior, prior to the captured occurrence of these two abnormal behaviors. Finally, a de-occlusion algorithm was designed and jointly used with DCM, validated by a fall-down detecting experiment including partial occlusion. Therefore, this study holds significant value for the prevention of abnormal pedestrian behaviors in public places.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Skeleton-based automatic assessment and prediction of intrusion risk in construction hazardous areas\n",
            "Authors: Huang H.\n",
            "Abstract: Intrusion behavior in hazardous areas is one of the major causes of construction safety accidents including falls from height, strikes by objects, etc. Implementing automatic and precise assessment of intrusions to enhance safety performance is of great importance in construction areas. Due to the large area of construction sites and diverse human behaviors, it is difficult to accurately predict worker behavior, resulting in many intrusions detected after the occurrence. Notably, computer vision-based skeleton extraction can provide a promising non-contact solution for assessing intrusions. This paper presents a novel intrusion behavior detection and evaluation approach by defining a safety buffer zone and using two key quantitative elements, i.e. the motion state and orientation posture of intruders. An indoor experiment was conducted by employing skeleton detection technology with safety knowledge to demonstrate the feasibility and effectiveness of the assessment method. The participants’ risk levels were evaluated separately and simultaneously based on the motion and posture. The risk level was compared based on various evaluated methods and the ground truth. The results show that a satisfying accuracy of intrusion assessment can be achieved at different risk levels. Appropriate warning and intervention methods can be implemented to mitigate the occurrence or reduce the severity of intrusions and thus reduce safety accidents with the use of the proposed method.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Using RGBD cameras for classifying learning and teacher interaction through postural attitude\n",
            "Authors: Hincapié M.\n",
            "Abstract: Globally the improvement and evaluation of the academic performance of students has been a priority, however the way in which the quality of learning process is evaluated within the classroom is based on traditional methods such as grades or perception surveys. Additionally, measuring continuously the performance of the student, teacher and its interaction in the classroom is difficult because there are several internal and external factors that can affect the pedagogical practice in the classroom or e-learning environments, and currently, their effects are not completely understood. Currently, advances in motion tracking through low cost devices such RGBD cameras allows the real-time monitoring of persons posture inside closed spaces such a classroom. Some research projects have associated posture with affective and cognitive state, but as far as we know none have proposed an approach to classify learning and teacher interaction using posture. An approach that uses a set of performance metrics of the student and teacher, in order to classify whether learning and teacher-student interaction was successful is developed and tested. This was an experimental design using an experimental and control group in order to evaluate if it is possible to classify between poor and good interaction between teacher and student. The results showed that it is possible to classify between poor and good interaction between teacher and student, besides the best method of classification is the approach based on neural networks with an accuracy of 76%. The proposed approach could classify whether an interaction between the student and the teacher was good or not. The results showed that the best method of classification was the approach based on neural networks with an accuracy of 78%.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic Improvement to Reduce the Risk of Musculoskeletal Disorders (MSDS) in a Furniture Production Workshop\n",
            "Authors: MacHado D.C.\n",
            "Abstract: The present research work has the purpose of simulating an ergonomic improvement in the furniture production workshop for the areas that show a higher risk of musculoskeletal disorders. In this sense, ergonomics methods and instruments such as the Nordic questionnaire were used to measure the body areas, due to the increase in cases of MSDs related to physical work in the upholstery sector. These disorders develop due to the lack of an adequate ergonomic design and the lack of early identification that prioritizes the well-being of workers. Thus, NIOSH, RULA and OWAS methodologies were applied to evaluate the level of risk and lifting index before and after. These values were contrasted with Ergosoft Pro and 3DSSPP software to validate the design proposal. Thus, the risk level was reduced from a value of 4 to 1 and the uplift index from 3.8 to 0.99. In addition, artificial intelligence was employed through the application of Open Pose to achieve the estimation of the arm angles in real time.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Unconstrained Identification of the Positions of Chest and Abdomen and Detection of Respiratory Motions in Sleep by Using a Bed-Size Tactile Sensor Sheet\n",
            "Authors: Song Y.\n",
            "Abstract: Respiratory diseases can be effectively screened by monitoring chest and abdominal motions during respiration. Respiratory inductance plethysmography (RIP) is commonly used for this purpose in clinics. However, RIP has strong constraints on human body, limiting its daily use. Several unconstrained methods have been developed, but they cannot replace RIP due to their inability to accurately distinguish between chest and abdominal motions. The authors' group proposed an unconstrained method that has the potential to replace RIP by using a bed-size tactile sensor sheet. To increase its accuracy, the present work investigates the personalized identification method of optimal measurement regions of the chest and abdomen based on the body pressure distribution measured by the tactile sensor sheet. A new discriminative feature procedure and a corresponding mathematical model were proposed, and tests were conducted on 16 healthy subjects. The results demonstrate that the proposed method can enhance the measurement accuracy of the sensor sheet method, providing a convenient and practical way to early screening of respiratory diseases.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Study on the Interaction Behaviors Identification of Construction Workers Based on ST-GCN and YOLO\n",
            "Authors: Li P.\n",
            "Abstract: The construction industry is accident-prone, and unsafe behaviors of construction workers have been identified as a leading cause of accidents. One important countermeasure to prevent accidents is monitoring and managing those unsafe behaviors. The most popular way of detecting and identifying workers’ unsafe behaviors is the computer vision-based intelligent monitoring system. However, most of the existing research or products focused only on the workers’ behaviors (i.e., motions) recognition, limited studies considered the interaction between man-machine, man-material or man-environments. Those interactions are very important for judging whether the workers’ behaviors are safe or not, from the standpoint of safety management. This study aims to develop a new method of identifying construction workers’ unsafe behaviors, i.e., unsafe interaction between man-machine/material, based on ST-GCN (Spatial Temporal Graph Convolutional Networks) and YOLO (You Only Look Once), which could provide more direct and valuable information for safety management. In this study, two trained YOLO-based models were, respectively, used to detect safety signs in the workplace, and objects that interacted with workers. Then, an ST-GCN model was trained to detect and identify workers’ behaviors. Lastly, a decision algorithm was developed considering interactions between man-machine/material, based on YOLO and ST-GCN results. Results show good performance of the developed method, compared to only using ST-GCN, the accuracy was significantly improved from 51.79% to 85.71%, 61.61% to 99.11%, and 58.04% to 100.00%, respectively, in the identification of the following three kinds of behaviors, throwing (throwing hammer, throwing bottle), operating (turning on switch, putting bottle), and crossing (crossing railing and crossing obstacle). The findings of the study have some practical implications for safety management, especially workers’ behavior monitoring and management.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Measurement of Shoulder Abduction Angle with Posture Estimation Artificial Intelligence Model\n",
            "Authors: Kusunose M.\n",
            "Abstract: Substantial advancements in markerless motion capture accuracy exist, but discrepancies persist when measuring joint angles compared to those taken with a goniometer. This study integrates machine learning techniques with markerless motion capture, with an aim to enhance this accuracy. Two artificial intelligence-based libraries—MediaPipe and LightGBM—were employed in executing markerless motion capture and shoulder abduction angle estimation. The motion of ten healthy volunteers was captured using smartphone cameras with right shoulder abduction angles ranging from 10° to 160°. The cameras were set diagonally at 45°, 30°, 15°, 0°, −15°, or −30° relative to the participant situated at a distance of 3 m. To estimate the abduction angle, machine learning models were developed considering the angle data from the goniometer as the ground truth. The model performance was evaluated using the coefficient of determination R2 and mean absolute percentage error, which were 0.988 and 1.539%, respectively, for the trained model. This approach could estimate the shoulder abduction angle, even if the camera was positioned diagonally with respect to the object. Thus, the proposed models can be utilized for the real-time estimation of shoulder motion during rehabilitation or sports motion.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An Automated Sitting Posture Recognition System Utilizing Pressure Sensors\n",
            "Authors: Tsai M.C.\n",
            "Abstract: Prolonged sitting with poor posture can lead to various health problems, including upper back pain, lower back pain, and cervical pain. Maintaining proper sitting posture is crucial for individuals while working or studying. Existing pressure sensor-based systems have been proposed to recognize sitting postures, but their accuracy ranges from 80% to 90%, leaving room for improvement. In this study, we developed a sitting posture recognition system called SPRS. We identified key areas on the chair surface that capture essential characteristics of sitting postures and employed diverse machine learning technologies to recognize ten common sitting postures. To evaluate the accuracy and usability of SPRS, we conducted a ten-minute sitting session with arbitrary postures involving 20 volunteers. The experimental results demonstrated that SPRS achieved an impressive accuracy rate of up to 99.1% in recognizing sitting postures. Additionally, we performed a usability survey using two standard questionnaires, the System Usability Scale (SUS) and the Questionnaire for User Interface Satisfaction (QUIS). The analysis of survey results indicated that SPRS is user-friendly, easy to use, and responsive.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Test–Retest Repeatability of Human Gestures in Manipulation Tasks\n",
            "Authors: Digo E.\n",
            "Abstract: The importance of performance excellence and operator’s safety is fundamental not only when operators perform repetitive and controlled industrial tasks, but also in case of abrupt gestures due to inattention and unexpected circumstances. Since optical systems work at frequencies that are too low and they are not able to detect gestures as early as possible, combining the use of wearable magneto-inertial measurement units (MIMUs) with the adoption of deep learning techniques can be useful to instruct the machine about human motion. To improve the initial training phase of neural networks for high classification performance, gesture repeatability over time has to be verified. Since the test–retest approach has been poorly applied based on MIMUs signals in a context of human–machine interaction, the aim of this work was to evaluate the repeatability of pick-and-place gestures composed of both normal and abrupt movements. Overall, results demonstrated an excellent test–retest repeatability for normal movements and a fair-to-good test–retest repeatability for abrupt movements. In addition, results suggested important information about the application of deep learning to identify the types of movements: the test showed how to improve reinforcement learning for the identification of onset gestures, whereas the retest allowed for defining the time necessary to retrain the network.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Hi-ROS: Open-source multi-camera sensor fusion for real-time people tracking\n",
            "Authors: Guidolin M.\n",
            "Abstract: This paper presents Hi-ROS (Human Interaction in ROS), an open source framework focused on real-time accurate assessment of human motion. The system offers a series of tools to track multiple people in real-time by exploiting a calibrated camera network. No assumptions are made about the typology or number of cameras, nor about the body pose estimation algorithm used to extract the 3D poses of the people in the scene. The tools provided by Hi-ROS include a Skeleton Tracker to ensure temporal consistency of the detected poses, a Skeleton Merger to fuse the tracks from multiple cameras, thus limiting flickering phenomena, a Skeleton Optimizer to ensure limb length consistency, and a Skeleton Filter to perform real-time smoothing of the detected joint trajectories. Accuracy, tracking robustness, and real-time performance of the proposed system were evaluated on a public dataset, containing both single-person and multi-person sequences with up to 4 people interacting. The results obtained using different subsets of the proposed tools show how the complete Hi-ROS pipeline provides accurate and reliable estimates also in challenging scenarios, with a reduction of the RMSE of up to 27% with respect to a pure tracking approach. This work aims to push forward the development of unobtrusive human–robot interaction applications, multi-person automated posture analyses, rehabilitation performance assessments, and any possible application enabled by real-time accurate assessment of human motion via markerless motion capture.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An RGB-D sensor-based instrument for sitting balance assessment\n",
            "Authors: Bartlett K.A.\n",
            "Abstract: Sitting balance is an important aspect of overall motor control, particularly for individuals who are not able to stand. Typical clinical assessment methods for sitting balance rely on human observation, making them subjective, imprecise, and sometimes time-consuming. The primary objective of this study is to develop an improved system for assessing sitting balance in clinical settings. We designed a software tool that takes input from an RGB-D camera system to track human movement during sitting balance assessment. We validated the system by tracking subject’s movements during two seated balance exercises. To assess the accuracy of our system’s measurements, we compared them with measurements taken using a ruler and measurements captured from still images from a video recording. The agreement of body angle measurement was an average of 2.19 ± 2.29 degrees, and agreement of forward reach distance was an average of 0.1 ± 0.25 in. The results show that our approach can track a person’s body movements with clinically relevant accuracy, suggesting that this RGB-D camera-based system could offer advantages over existing observational methods of sitting balance assessment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: OPERATIONAL AND INTELLIGENT ANALYSIS UNDER THE ERGONOMICS APPROACH OF THE PREVALENCE OF MUSCULOSKELETAL DISORDERS IN CONTAINER OPERATORS\n",
            "Authors: da Silva R.L.A.\n",
            "Abstract: This study aims to evaluate the prevalence of musculoskeletal disorders and possibly associated working conditions among dockworkers operating quay cranes. The data on working posture were collected through direct observations, photographs, and videos used in the Rapid Entire Body Assessment. The data on discomfort were collected using the Nordic Musculoskeletal Symptom Questionnaire. First, the questionnaire results showed that musculoskeletal symptoms are highly prevalent, particularly in the lumbar spine, cervical spine, shoulder, and neck. These data were ratified by machine learning analyses that, using logistic regression, achieved a big root mean square error, showing a correlation in the neck, wrists and hands, hip and thigh, and cervical region. Secondly, the final Rapid Entire Body Assessment score was 6, which reveals the median to the high-risk level of worker posture while performing the task.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Evaluation Methods and Measurement Challenges for Industrial Exoskeletons\n",
            "Authors: Li-Baboud Y.S.\n",
            "Abstract: In recent years, exoskeleton test methods for industrial exoskeletons have evolved to include simulated laboratory and field environments. Physiological, kinematic, and kinetic metrics, as well as subjective surveys, are used to evaluate exoskeleton usability. In particular, exoskeleton fit and usability can also impact the safety of exoskeletons and their effectiveness at reducing musculoskeletal injuries. This paper surveys the state of the art in measurement methods applied to exoskeleton evaluation. A notional classification of the metrics based on exoskeleton fit, task efficiency, comfort, mobility, and balance is proposed. In addition, the paper describes the test and measurement methods used in supporting the development of exoskeleton and exosuit evaluation methods to assess their fit, usability, and effectiveness in industrial tasks such as peg in hole, load align, and applied force. Finally, the paper includes a discussion of how the metrics can be applied towards a systematic evaluation of industrial exoskeletons, current measurement challenges, and future research directions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Innovative Technologies for Occupational Health and Safety: A Scoping Review\n",
            "Authors: Flor-Unda O.\n",
            "Abstract: Technological advancements have allowed for the design and development of multiple intelligent devices that monitor the health and safety status of workers in the industry in general. This paper reviews and describes the alternative technologies and their potential for monitoring risk situations, vital signs, physical variables, worker positions, and behavioral trends of workers in their work activities in the workplace. A scoping review was conducted using PRISMA ScR in which information was extracted from 99 scientific articles related to these technological advances. The operational characteristics and utilities of devices whose primary function is to control better and monitor worker safety and health were identified. It was concluded that technology strongly improves the acquisition and sending of information. This information can be used to provide alerts and feedback to workers so that they act more safely and protect their health. In addition, technological developments have resulted in devices that eliminate operational risks by replacing manual activities with automated and autonomous tasks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Science Mapping the Knowledge Domain of Construction Workers’ Safety Behavior\n",
            "Authors: Cheng B.\n",
            "Abstract: The examination of construction workers’ safety behavior (CWSB) is a critical factor in mitigating the occurrence of construction accidents. This study conducted a scientometric and critical review of 3280 CWSB-related articles indexed in the Web of Science database. Scientometric analyses (e.g., co-authorship, co-word, co-citation, citation-burst analysis, and clustering) objectively visualized the current research landscape, while the critical review identified key research topics and challenges within the CWSB research. The findings reveal that over half of CWSB research originates from three countries: the USA, China, and Australia. Concurrently, the Hong Kong Polytechnic University, the City University of Hong Kong, and the University of Michigan stand out as the most productive institutions in the CWSB domain. It is noteworthy that China shows a high burst strength in 2022–2023, indicating that the development of the CWSB field in China is gaining global attention. The terms ‘performance’, ‘model’, and ‘management’ appear with the highest frequency, while keywords such as ‘deep learning’ and ‘simulation’ have experienced an increase in citations in recent years. Furthermore, 13 co-citation clusters were identified, with cluster analysis and critical reviews converging on three principal research themes: ‘conception and dimension’, ‘critical influence factors’, and ‘emerging technologies’. This study also proposes three research gaps and potential avenues for future investigation, including a comprehensive understanding of CWSB impact mechanisms, the long-term efficacy of safety interventions, and the incorporation of novel technologies into safety programs. This review offers valuable insights into extant CWSB research and pinpoints emerging trends within this research area. It provides essential information for industry policymakers, researchers, and practitioners in the global CWSB context and assists stakeholders in identifying and comprehending trends and patterns.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Current Status and Future Research Trends of Construction Labor Productivity Monitoring: A Bibliometric Review\n",
            "Authors: Lee T.Y.\n",
            "Abstract: Construction labor productivity (CLP) is a critical measure of efficiency in the construction industry. This bibliometric review comprehensively analyzes global research trends in CLP monitoring over the past 56 years. The review identifies the top journals, authors, and nations contributing to this field and highlights a significant increase in publications since 2000. The co-authorship bibliometric map illustrates how different nations collaborate in research, with Europe and Asia being the most engaged regions in the study of CLP monitoring. The author keyword co-occurrence analysis indicated the need for more consistent and reliable measurements of CLP in the field. Furthermore, the review highlights the importance of factors such as occupational health and safety, change orders, and the adoption of lean construction principles and innovative technologies for monitoring and improving CLP. Finally, we evaluated the characteristics of different modeling approaches utilized in CLP monitoring studies, considering factors such as data availability, the complexity of relationships, and the required expertise. This study highlights the need for real-time and transparent CLP monitoring methods. Overall, this study contributes to the research field by offering insightful information on the current state of CLP monitoring and proposing potential future directions for research.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automated Classification of the Phases Relevant to Work-Related Musculoskeletal Injury Risks in Residential Roof Shingle Installation Operations Using Machine Learning\n",
            "Authors: Dutta A.\n",
            "Abstract: Awkward kneeling in sloped shingle installation operations exposes roofers to knee musculoskeletal disorder (MSD) risks. To address the varying levels of risk associated with different phases of shingle installation, this research investigated utilizing machine learning to automatically classify seven distinct phases in a typical shingle installation task. The classification process relied on analyzing knee kinematics data and roof slope information. Nine participants were recruited and performed simulated shingle installation tasks while kneeling on a sloped wooden platform. The knee kinematics data were collected using an optical motion capture system. Three supervised machine learning classification methods (i.e., k-nearest neighbors (KNNs), decision tree (DT), and random forest (RF)) were selected for evaluation. The KNN classifier provided the best performance for overall accuracy. The results substantiated the feasibility of applying machine learning in classifying shingle installation phases from workers’ knee joint rotation and roof slope angles, which may help facilitate method and tool development for automated knee MSD risk surveillance and assessment among roofers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A bibliometric analysis of patient-reported outcome measures in adult spinal deformity, and the future of patient-centric outcome assessments in the era of predictive analytics\n",
            "Authors: Kurland D.B.\n",
            "Abstract: Surgical treatment of adult spinal deformity (ASD) is associated with high resource utilization, high costs, and potential complications. In order to generate consensus for treatment paradigms and to demonstrate value, it is crucial to accurately assess clinical outcomes. Historically, objective assessments in ASD were performed by providers, and in recent decades the use of patient-reported outcome measures (PROMs) have become widely incorporated. Here, we report results of a bibliometric analysis of PROMs in ASD, synthesizing a global view of the topic and mapping trends in the field. In the modern era, enabling advancements in predictive modeling and machine learning, along with technology within smartphones and wearables, may supplement traditional patient-centric outcomes assessments and overcome some of their limitations.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic Risk Assessment of Construction Workers and Projects Based on Fuzzy Bayesian Network and D-S Evidence Theory\n",
            "Authors: Tao Y.\n",
            "Abstract: Work-related musculoskeletal disorders (WMSDs) are the main causes of physical diseases of workers in the construction industry. The occurrence of WMSDs can result in project delays, cost overruns, workers' worsened health status, and even unanticipated safety risks. Ergonomic rules and instrument-based methods have enabled automatic postural ergonomic evaluation and intervention, while a research gap lies in how to consider more comprehensive personalized factors and how to integrate individual risks for project-level risk control. This study developed a two-hierarchy method to assess the ergonomic risk for both individual workers and the entire project. To alleviate the problems of data insufficiency and imprecision in real-life construction projects, experts' evaluations were incorporated with existing instrument-based methods. A methodology combining fuzzy theory, D-S evidence theory, and Bayesian network was employed to deal with fuzziness, uncertainty, and conflicting judgments, and to provide a probabilistic assessment. To measure the potential impact on projects from the perspectives both of cost and productivity, this study also developed a practical framework for project integration. A real-life case study was conducted to validate the approach and demonstrated its applicability. The results of sensitivity analysis indicate that previous WMSD records, age, working posture, and working intensity are the top critical risk factors that have the most significant impact on individuals' WMSD risk status. This study provides deeper insights into WMSD risk assessment, which can facilitate personalized instructions and intervention for individual WMSD risk control, and support managerial initiatives and decisions to mitigate the negative effects on construction projects.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A science mapping-based review of work-related musculoskeletal disorders among construction workers\n",
            "Authors: Antwi-Afari M.F.\n",
            "Abstract: Introduction: Work-related musculoskeletal disorders (WMSDs) are recognized as a leading cause of nonfatal injuries in construction, but no review of existing studies has systematically analyzed and visualized the trends of WMSDs among construction workers. The current science mapping-based review summarized research published between 2000 and 2021 related to WMSDs among construction workers through co-word, co-author, and citation analysis. Method: A total of 63 bibliographic records retrieved from the Scopus database were analyzed. Results: The results identified influential authors with high impacts in this research domain. Moreover, the results indicated that MSDs, ergonomics, and construction not only had the highest occurrence of been studied, but also the highest impact in terms of total link strength. In addition, the most significant contributions to research relating to WMSDs among construction workers have originated primarily from the United States, Hong Kong, and Canada. Furthermore, a follow-up in-depth qualitative discussion was conducted to focus on summarizing mainstream research topics, identifying existing research gaps, and proposing directions for future studies. Conclusions: This review provides an in-depth understanding of related research on WMSDs among construction workers and proposes the emerging trends in this research field.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Personalized stability monitoring based on body postures of construction workers working at heights\n",
            "Authors: Duan P.\n",
            "Abstract: Fall from heights accidents are one of the most frequent causes of death in the construction industry. Many fall-from-height accidents are related to stability issues and stability is critical for construction workers working at heights. Thus, stability monitoring of workers is important for proactive accident prevention. However, workers’ stability is highly personalized due to differences in workers’ physical characteristics and habits. Little attention has been paid to the personalized posture-based stability analysis of workers working at heights. This study proposes a personalized stability monitoring framework based on workers' body posture patterns when working at heights. The proposed method includes two main components: posture recognition and stability monitoring. First, OpenPose is used to extract the coordinates of workers’ posture key points from video clips. Two posture features, duration and count, are extracted to reflect workload and frequency. Secondly, a two-stage stability monitoring framework, including instability detection and instability evaluation, is designed based on the Gaussian model and Gaussian mixture model. Finally, the proposed framework is validated by on-site construction videos of workers working at height. The validation results showed the accuracy of 84.38% and the precision of 81.25% in identifying the stable status of a subject. The robustness of the personalised monitoring method was validated through comparisons with five other workers. The study provides a practical reference for active safety monitoring for workers with high fall-from-height risk. It also helps to extend personalized and adaptive behaviour-based safety training for construction workers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Artificial Intelligence in Biomechanics Pose Estimation and the Applications in Human-Related Engineering\n",
            "Authors: Ngali M.Z.\n",
            "Abstract: Human related engineering principally deals with how human factors such as physiology, psychology and nature could affect systems being handled or interact with human being. Physiological effect on this matter usually measured via biomechanics analyses especially in the evaluations of productivity performance and ergonomics. Artificial Intelligence on the other hand has evolved tremendously on the past few years in dealing with image recognition and this advancement has a huge impact on how biomechanics are being used and analyzed via pose estimation. Conventional biomechanics analyses of sports and rehabilitation activities has now extended to more human related engineering advancement such as robotic recognition, assisted living, character animation, intelligent driving assisting system, virtual gaming and advanced medical applications. This work comprehensively reviews prominent works done in this matter in terms of accuracy, effectiveness and practicality of Artificial Intelligence in human pose estimation as compared to the gold standard of optical-based pose measurement in biomechanics analyses. Comprehensive reviews show that the conventional pose measurement system such as VICON motion capture system remains relevant for biomechanics analyses including motion performance, safety- and health-related engineering that require accurate measurement. Other human related engineering such as posture monitoring, robotic vision of human detection, animation, gaming and posture analyses might directly leverage the advantages of more feasible and practical Artificial Intelligence based pose estimation systems. When practicality over accuracy is considered, Artificial Intelligence based pose estimation systems is expected to take over the task of biomechanics analyses in many human related engineering applications.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: IoT System for Real-Time Posture Asymmetry Detection\n",
            "Authors: La Mura M.\n",
            "Abstract: The rise of the Internet of Things (IoT) has enabled the development of measurement systems dedicated to preventing health issues and monitoring conditions in smart homes and workplaces. IoT systems can support monitoring people doing computer-based work and avoid the insurgence of common musculoskeletal disorders related to the persistence of incorrect sitting postures during work hours. This work proposes a low-cost IoT measurement system for monitoring the sitting posture symmetry and generating a visual alert to warn the worker when an asymmetric position is detected. The system employs four force sensing resistors (FSR) embedded in a cushion and a microcontroller-based read-out circuit for monitoring the pressure exerted on the chair seat. Java-based software performs the real-time monitoring of the sensors’ measurements and implements an uncertainty-driven asymmetry detection algorithm. The shifts from a symmetric to an asymmetric posture and vice versa generate and close a pop-up warning message, respectively. In this way, the user is promptly notified when an asymmetric posture is detected and invited to adjust the sitting position. Every position shift is recorded in a web database for further analysis of the sitting behavior.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Wearable Multi-Modal Digital Upper Limb Assessment System for Automatic Musculoskeletal Risk Evaluation\n",
            "Authors: Tahir A.\n",
            "Abstract: Continuous ergonomic risk assessment of the human body is critical to avoid various musculoskeletal disorders (MSDs) for people involved in physical jobs. This paper presents a digital upper limb assessment (DULA) system that automatically performs rapid upper limb assessment (RULA) in real-time for the timely intervention and prevention of MSDs. While existing approaches require human resources for computing the RULA score, which is highly subjective and untimely, the proposed DULA achieves automatic and objective assessment of musculoskeletal risks using a wireless sensor band embedded with multi-modal sensors. The system continuously tracks and records upper limb movements and muscle activation levels and automatically generates musculoskeletal risk levels. Moreover, it stores the data in a cloud database for in-depth analysis by a healthcare expert. Limb movements and muscle fatigue levels can also be visually seen using any tablet/computer in real-time. In the paper, algorithms of robust limb motion detection are developed, and an explanation of the system is provided along with the presentation of preliminary results, which validate the effectiveness of the new technology.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The Classification of Movement in Infants for the Autonomous Monitoring of Neurological Development\n",
            "Authors: Turner A.\n",
            "Abstract: Neurodevelopmental delay following extremely preterm birth or birth asphyxia is common but diagnosis is often delayed as early milder signs are not recognised by parents or clinicians. Early interventions have been shown to improve outcomes. Automation of diagnosis and monitoring of neurological disorders using non-invasive, cost effective methods within a patient’s home could improve accessibility to testing. Furthermore, said testing could be conducted over a longer period, enabling greater confidence in diagnoses, due to increased data availability. This work proposes a new method to assess the movements in children. Twelve parent and infant participants were recruited (children aged between 3 and 12 months). Approximately 25 min 2D video recordings of the infants organically playing with toys were captured. A combination of deep learning and 2D pose estimation algorithms were used to classify the movements in relation to the children’s dexterity and position when interacting with a toy. The results demonstrate the possibility of capturing and classifying children’s complexity of movements when interacting with toys as well as their posture. Such classifications and the movement features could assist practitioners to accurately diagnose impaired or delayed movement development in a timely fashion as well as facilitating treatment monitoring.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Wearable Motion Capture Devices for the Prevention of Work-Related Musculoskeletal Disorders in Ergonomics—An Overview of Current Applications, Challenges, and Future Opportunities\n",
            "Authors: Lind C.M.\n",
            "Abstract: Work-related musculoskeletal disorders (WMSDs) are a major contributor to disability worldwide and substantial societal costs. The use of wearable motion capture instruments has a role in preventing WMSDs by contributing to improvements in exposure and risk assessment and potentially improved effectiveness in work technique training. Given the versatile potential for wearables, this article aims to provide an overview of their application related to the prevention of WMSDs of the trunk and upper limbs and discusses challenges for the technology to support prevention measures and future opportunities, including future research needs. The relevant literature was identified from a screening of recent systematic literature reviews and overviews, and more recent studies were identified by a literature search using the Web of Science platform. Wearable technology enables continuous measurements of multiple body segments of superior accuracy and precision compared to observational tools. The technology also enables real-time visualization of exposures, automatic analyses, and real-time feedback to the user. While miniaturization and improved usability and wearability can expand the use also to more occupational settings and increase use among occupational safety and health practitioners, several fundamental challenges remain to be resolved. The future opportunities of increased usage of wearable motion capture devices for the prevention of work-related musculoskeletal disorders may require more international collaborations for creating common standards for measurements, analyses, and exposure metrics, which can be related to epidemiologically based risk categories for work-related musculoskeletal disorders.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Modeling and Calibration of Pressure-Sensing Insoles via a New Plenum-Based Chamber\n",
            "Authors: Belli I.\n",
            "Abstract: This paper proposes a novel method to reliably calibrate a pair of sensorized insoles utilizing an array of capacitive tactile pixels (taxels). A new calibration setup is introduced that is scalable and suitable for multiple kinds of wearable sensors and a procedure for the simultaneous calibration of each of the sensors in the insoles is presented. The calibration relies on a two-step optimization algorithm that, firstly, enables determination of a relevant set of mathematical models based on the instantaneous measurement of the taxels alone, and, then, expands these models to include the relevant portion of the time history of the system. By comparing the resulting models with our previous work on the same hardware, we demonstrate the effectiveness of the novel method both in terms of increased ability to cope with the non-linear characteristics of the sensors and increased pressure ranges achieved during the experiments performed.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Current and future applications of mobile health technology for evaluating spine surgery patients: A review\n",
            "Authors: Greenberg J.K.\n",
            "Abstract: Mobile health (mHealth) technology has assumed a pervasive role in healthcare and society. By capturing real-time features related to spine health, mHealth assessments have the potential to transform multiple aspects of spine care. Yet mHealth applications may not be familiar to many spine surgeons and other spine clinicians. Consequently, the objective of this narrative review is to provide an overview of the technology, analytical considerations, and applications of mHealth tools for evaluating spine surgery patients. Reflecting their near-ubiquitous role in society, smartphones are the most commonly available form of mHealth technology and can provide measures related to activity, sleep, and even social interaction. By comparison, wearable devices can provide more detailed mobility and physiological measures, although capabilities vary substantially by device. To date, mHealth evaluations in spine surgery patients have focused on the use of activity measures, particularly step counts, in an attempt to objectively quantify spine health. However, the correlation between step counts and patient-reported disease severity is inconsistent, and further work is needed to define the mobility metrics most relevant to spine surgery patients. mHealth assessments may also support a variety of other applications that have been studied less frequently, including those that prevent postoperative complications, predict surgical outcomes, and serve as motivational aids to patients. These areas represent key opportunities for future investigations. To maximize the potential of mHealth evaluations, several barriers must be overcome, including technical challenges, privacy and regulatory concerns, and questions related to reimbursement. Despite those obstacles, mHealth technology has the potential to transform many aspects of spine surgery research and practice, and its applications will only continue to grow in the years ahead.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic assessment based on monocular RGB camera in elderly care by a new multi-person 3D pose estimation technique (ROMP)\n",
            "Authors: Yuan H.\n",
            "Abstract: Nursing staff members are at high risk of work-related musculoskeletal disorders (WMSDs), which not only threaten their health but also impact the quality of elderly care. Ergonomic posture risk assessment (EPRA) is usually employed to identify potential WMSD risks such as extreme posture and repetitive movements. A monocular RGB camera has been used for the EPRA in recent years due to its short time requirements and low cost. However, most work scenarios do not involve multi-person situations. Therefore, based on the latest 3D pose estimation algorithm—Monocular, One-stage Regression of Multiple 3D People (ROMP)—this study proposes a method that uses one monocular RGB camera to conduct the EPRA in multi-person and occluded scenarios. The accuracy of our method was calculated through 12 care tasks involving multi-person and occlusion, using the Noitom motion capture (MoCap) system. The results show that our method performed well, with an average accuracy of 83.8% and 90.7%, respectively, using two EPRA scoring tools, RULA and OWAS. The mean absolute error (MAE) of each joint angle was 9.4°. Thus, ROMP seems to be a potential method for conducting the EPRA in nursing workspaces with unsatisfactory conditions using a single monocular RGB camera.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Method of recognizing sleep postures based on air pressure sensor and convolutional neural network: For an air spring mattress\n",
            "Authors: Chao Y.\n",
            "Abstract: The present study aimed to develop a sleep postures recognition system based on the hardness adjustment system for a specific air spring mattress. To the end, an air spring mattress prototype and its embedded system was manufactured. Then the supine and lateral postures were defined, and the sleep posture images generated by the relative change rate of air pressure matrix were filtered. At last, a convolutional neural network (CNN) model was proposed and analyzed by ablation experiment. Furthermore, the CNN model was compared with a CNN-SVM fusion model and a ResNet50 model to valid the performance. The results indicate that it is feasible to define sleep postures with the air pressure, and the images smoothed by a Gaussian filter contains significant features. The F1-score of the CNN model determined by the ablation experiment is 0.981, while the F1-score values of the CNN-SVM fusion model and the ResNet50 model are 0.932 and 0.954, respectively. Therefore, the generalization ability of the CNN model proposed outperformed the other two. Finally, the F1-score of the SSA-CNN model optimized by Sparrow Search Algorithm (SSA) increased to 0.992. It concludes that sleep posture recognition can be achieved using only the inherent structure of the air spring mattress without additional sensors, reducing the cost and complexity of the system. In addition, the air pressure signal can be processed by the proposed CNN model to recognize sleep postures with a high accuracy.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Assessment of a Multi-Sensor FBG-Based Wearable System in Sitting Postures Recognition and Respiratory Rate Evaluation of Office Workers\n",
            "Authors: Zaltieri M.\n",
            "Abstract: Due to prolonged incorrect sitting posture, upper body musculoskeletal disorders (UBMDs) are largely widespread among sedentary workers. Monitoring employees' sitting behaviors could be of great help in minimizing UBMDs' occurrence. In addition, being primarily influenced by psycho-physical stress conditions, respiratory rate (RR) would be a further useful parameter to delineate the workers' state of health. Wearable systems have emerged as a viable option for sitting posture and RR monitoring since enable continuous data collecting with no posture disturbances. Nevertheless, the main limits are poor fit, cumbersomeness, and movement restriction resulting in discomfort for the user. In addition, only few wearable solutions can track both these parameters contextually. To address these problems, in this study a flexible wearable system composed of seven modular sensing elements based on fiber Bragg grating (FBG) technology and designed to be worn on the back has been proposed to recognize the most common sitting postures (i.e., kyphotic, upright and lordotic) and estimate RR. The assessment was performed on ten volunteers showing good performances in postures recognition via Naïve Bayes classificator (accuracy >96.9%) and agreement with the benchmark in RR estimation (MAPE ranging between 0.74% and 3.83%, MODs close to zero, and LOAs between 0.76 bpm and 3.63 bpm). The method was then successfully tested on three additional subjects under different breathing conditions. The wearable system could offer great support for a better understanding of the workers' posture attitudes and contribute to gathering RR information to depict an overall picture of the users' state of health.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A wearable real-time kinetic measurement sensor setup for human locomotion\n",
            "Authors: Wang H.\n",
            "Abstract: Current laboratory-based setups (optical marker cameras + force plates) for human motion measurement require participants to stay in a constrained capture region which forbids rich movement types. This study established a fully wearable system, based on commercially available sensors (inertial measurement units + pressure insoles), that can measure both kinematic and kinetic motion data simultaneously and support wireless frame-by-frame streaming. In addition, its capability and accuracy were tested against a conventional laboratory-based setup. An experiment was conducted, with 9 participants wearing the wearable measurement system and performing 13 daily motion activities, from slow walking to fast running, together with vertical jump, squat, lunge, and single-leg landing, inside the capture space of the laboratory-based motion capture system. The recorded sensor data were post-processed to obtain joint angles, ground reaction forces (GRFs), and joint torques (via multi-body inverse dynamics). Compared to the laboratory-based system, the established wearable measurement system can measure accurate information of all lower limb joint angles (Pearson's r = 0.929), vertical GRFs (Pearson's r = 0.954), and ankle joint torques (Pearson's r = 0.917). Center of pressure (CoP) in the anterior-posterior direction and knee joint torques were fairly matched (Pearson's r = 0.683 and 0.612, respectively). Calculated hip joint torques and measured medial-lateral CoP did not match with the laboratory-based system (Pearson's r = 0.21 and 0.47, respectively). Furthermore, both raw and processed datasets are openly accessible (https://doi.org/10.5281/zenodo.6457662). Documentation, data processing codes, and guidelines to establish the real-time wearable kinetic measurement system are also shared (https://github.com/HuaweiWang/WearableMeasurementSystem).\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Graph Neural Networks in IoT: A Survey\n",
            "Authors: Dong G.\n",
            "Abstract: The Internet of Things (IoT) boom has revolutionized almost every corner of people's daily lives: healthcare, environment, transportation, manufacturing, supply chain, and so on. With the recent development of sensor and communication technology, IoT artifacts, including smart wearables, cameras, smartwatches, and autonomous systems can accurately measure and perceive their surrounding environment. Continuous sensing generates massive amounts of data and presents challenges for machine learning. Deep learning models (e.g., convolution neural networks and recurrent neural networks) have been extensively employed in solving IoT tasks by learning patterns from multi-modal sensory data. Graph neural networks (GNNs), an emerging and fast-growing family of neural network models, can capture complex interactions within sensor topology and have been demonstrated to achieve state-of-The-Art results in numerous IoT learning tasks. In this survey, we present a comprehensive review of recent advances in the application of GNNs to the IoT field, including a deep dive analysis of GNN design in various IoT sensing environments, an overarching list of public data and source codes from the collected publications, and future research directions. To keep track of newly published works, we collect representative papers and their open-source implementations and create a Github repository at GNN4IoT.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Related factors of abnormal body posture among urban primary school students in Yinchuan/\n",
            "Authors: Yin D.\n",
            "Abstract: Objective To investigate the incidence and influencing factors of abnormal body posture among urban primary school students in Yinchuan City and to provide evidence for the prevention and treatment of abnormal body posture. Methods A multistage stratified cluster random sampling method was adopted to select 1 947 urban primary school students aged 7-12 years from 9 schools in Yinchuan City. Body Style Model.S-8.0 instrument was used to screen abnormal body posture and questionnaire was designed to investigate related factors. Results The comprehensive body posture score of urban primary school students in Yinchuan City was 22.07±2.87 and the detection rate of abnormal posturing was 71.29% which varied significantly by gender age body mass index BMI χ2 = 9.84 13.47 6.46 P<0.05 . Specially the rate of girls 73.54% was higher than that of boys 69.07% the abnormal rate of children aged 7-8 68.24% was lower than that of 9-10 72.17% and 11-12 73.54% obese children 74.91% was higher than that of overweight 72.64% and normal weight children 70.28% . The high and low shoulders 40.73% pelvis forward 39.39% and X/ O legs 38.57% were the most common indicators of abnormal posture the composition of the overall body posture abnormalities was higher in mild 54.32% than moderate 37.82% and severe 7.85% .Multivariate Logistic regression analysis showed that girls OR = 1.23 being older 9-10 years old OR = 1.89 11-12 years old OR = 2.48 overweight OR= 1.39 and obesity OR= 2.34 occasionally participate in physical exercise OR = 2.96 exercise duration <30 minutes daily OR= 2.77 video duration ≥2 h daily OR= 2.84 almost no dairy products OR= 1.79 almost no food Fish consumption OR= 1.77 almost no vegetables OR= 2.14 drinking carbonated beverages daily OR= 2.97 and sleeping time <6 h daily OR= 2.56 were the related factors of body posture development of urban primary school students P<0.05 . Conclusion The abnormal body posture of urban primary school students in Yinchuan City is prevalent which is related to the timely length of physical exercise nutrition video screen and sleep duration and should be paid enough attention.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Evaluation of In-Cloth versus On-Skin Sensors for Measuring Trunk and Upper Arm Postures and Movements\n",
            "Authors: Hoareau D.\n",
            "Abstract: Smart workwear systems with embedded inertial measurement unit sensors are developed for convenient ergonomic risk assessment of occupational activities. However, its measurement accuracy can be affected by potential cloth artifacts, which have not been previously assessed. Therefore, it is crucial to evaluate the accuracy of sensors placed in the workwear systems for research and practice purposes. This study aimed to compare in-cloth and on-skin sensors for assessing upper arms and trunk postures and movements, with the on-skin sensors as the reference. Five simulated work tasks were performed by twelve subjects (seven women and five men). Results showed that the mean (±SD) absolute cloth–skin sensor differences of the median dominant arm elevation angle ranged between 1.2° (±1.4) and 4.1° (±3.5). For the median trunk flexion angle, the mean absolute cloth–skin sensor differences ranged between 2.7° (±1.7) and 3.7° (±3.9). Larger errors were observed for the 90th and 95th percentiles of inclination angles and inclination velocities. The performance depended on the tasks and was affected by individual factors, such as the fit of the clothes. Potential error compensation algorithms need to be investigated in future work. In conclusion, in-cloth sensors showed acceptable accuracy for measuring upper arm and trunk postures and movements on a group level. Considering the balance of accuracy, comfort, and usability, such a system can potentially be a practical tool for ergonomic assessment for researchers and practitioners.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of Serious Games for the Rehabilitation of the Human Vertebral Spine for Home Care\n",
            "Authors: Gonçalves R.S.\n",
            "Abstract: With the occurrence of pandemics, such as COVID-19, which lead to social isolation, there is a need for home rehabilitation procedures without the direct supervision of health professionals. The great difficulty of treatment at home is the cost of the conventional equipment and the need for specialized labor to operate it. Thus, this paper aimed to develop serious games to assist health professionals in the physiotherapy of patients with spinal pain for clinical and home applications. Serious games integrate serious aspects such as teaching, rehabilitation, and information with the playful and interactive elements of video games. Despite the positive indication and benefits of physiotherapy for cases of chronic spinal pain, the long treatment time, social isolation due to pandemics, and lack of motivation to use traditional methods are some of the main causes of therapeutic failure. Using Unity 3D (version 2019.4.24f1) software and a personal computer with a webcam, we developed aesthetically pleasing, smooth, and attractive games, while maintaining the essence of seriousness that is required for rehabilitation. The serious games, controlled using OpenPose (version v1.0.0alpha-1.5.0) software, were tested with a healthy volunteer. The findings demonstrated that the proposed games can be used as a playful tool to motivate patients during physiotherapy and to reduce cases of treatment abandonment, including at home.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Action Recognition Based on 3D Skeleton and LSTM for the Monitoring of Construction Workers' Safety Harness Usage\n",
            "Authors: Guo H.\n",
            "Abstract: Fall from height (FFH) is the most common construction accident in the construction industry, thus it is significant to monitor the use of safety harnesses, which are critical to the prevention of FFH. Sensing or computer vision technologies have been adopted to identify workers' safety harness usage. However, previous research focused mainly on whether a worker wears a safety harness rather than on whether he or she properly fixes it to a lifeline, which is vital to prevent FFH but difficult to monitor. This research establishes an action recognition method based on a three-dimensional (3D) skeleton and long short-term memory (LSTM) to aid in automatically monitoring whether safety harnesses are fixed properly on site. An indoor experiment, which considered the features of a common real construction scenario - working on scaffolding - was conducted to test the effectiveness and feasibility of the proposed method. The result shows that the method achieves an acceptable precision and recall rate and can be used to detect the incorrect use of safety harnesses by combining multiple actions. This will contribute to the prevention of FFH in practice as well as to the body of knowledge of construction safety management.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Flexible job shop scheduling problem under Industry 5.0: A survey on human reintegration, environmental consideration and resilience improvement\n",
            "Authors: Destouet C.\n",
            "Abstract: The Job Shop Scheduling Problem (JSSP) has been widely studied in recent decades. Various approaches have been proposed to support scheduling decisions according to the evolving production environment. The emergence of technological advancements in the context of Industry 4.0 has brought many changes and made production scheduling more and more efficient. Today's Industry 5.0 environment pays much attention to human considerations, sustainability, and resilience. These modern production environments can be accurately represented by the flexible shop floor scheduling problem in which various coordinating machines (with many alternative routing possibilities) and different operators are challenging. Recent literature on JSSP, which considers the human in the loop, has shown that the well-being and skills of workers significantly affect scheduling performance. In addition, knowing that industries are responsible for a significant part of the world's energy consumption and greenhouse gas (GHG) emissions, new studies in scheduling focus on environmental factors. This paper introduces the Sustainable Flexible Scheduling Problem (SFJSSP) as a human and energy-efficiency-centered scheduling problem. First, we review the last decade's literature on Flexible Job Shop Scheduling Problems (FJSSP) with human and/or environmental considerations. Next, we analyze the development trends in manufacturing scheduling problems. Finally, we discuss future research challenges to move towards scheduling 5.0 and suggest a mathematical model that considers human and environmental factors (in addition to the factors considered by the Classical Flexible Job Shop Scheduling Problem (CFJSSP)).\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomics assessment of critical work posture in construction industries - A state of art review\n",
            "Authors: Venkatachalam S.\n",
            "Abstract: Nowadays, physical pain is playing a major role in construction industry workers. Discomforts force masons to have a disharmonious and unpleasant atmosphere which affects their interest in finishing their work. It is important to know about the risk factors and its mandatory to bring a comfortable and pleasing working environment to workers. Ergonomics is selected for this study. The main purpose of ergonomics is to analyse the awkward working postures during building construction and finally, to provide techniques to prevent discomfort/pain. By doing so, a comfortable, pleasant and safe setting can be created for workers. Analysis can be done using numerous methods and some of the easy and eco-friendly techniques were specifically studied. For example, asking questions to workers helps in gaining practical knowledge in that particular work and this method does not affect workers' mentality. Different results and conclusions have been made. Ultimately, these help in minimizing future risk in workers, which in turn increases their capability and curiosity in doing work.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Are artificial intelligence and machine learning suitable to tackle the COVID-19 impacts? An agriculture supply chain perspective\n",
            "Authors: Nayal K.\n",
            "Abstract: Purpose: This article aims to model the challenges of implementing artificial intelligence and machine earning (AI-ML) for moderating the impacts of COVID-19, considering the agricultural supply chain (ASC) in the Indian context. Design/methodology/approach: 20 critical challenges were modeled based on a comprehensive literature review and consultation with experts. The hybrid approach of “Delphi interpretive structural modeling (ISM)-Fuzzy Matrice d' Impacts Croises Multiplication Applique'e à un Classement (MICMAC) − analytical network process (ANP)” was used. Findings: The study's outcome indicates that “lack of central and state regulations and rules” and “lack of data security and privacy” are the crucial challenges of AI-ML implementation in the ASC. Furthermore, AI-ML in the ASC is a powerful enabler of accurate prediction to minimize uncertainties. Research limitations/implications: This study will help stakeholders, policymakers, government and service providers understand and formulate appropriate strategies to enhance AI-ML implementation in ASCs. Also, it provides valuable insights into the COVID-19 impacts from an ASC perspective. Besides, as the study was conducted in India, decision-makers and practitioners from other geographies and economies must extrapolate the results with due care. Originality/value: This study is one of the first that investigates the potential of AI-ML in the ASC during COVID-19 by employing a hybrid approach using Delphi-ISM-Fuzzy-MICMAC-ANP.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Camera- and Viewpoint-Agnostic Evaluation of Axial Postural Abnormalities in People with Parkinson’s Disease through Augmented Human Pose Estimation\n",
            "Authors: Aldegheri S.\n",
            "Abstract: Axial postural abnormalities (aPA) are common features of Parkinson’s disease (PD) and manifest in over 20% of patients during the course of the disease. aPA form a spectrum of functional trunk misalignment, ranging from a typical Parkinsonian stooped posture to progressively greater degrees of spine deviation. Current research has not yet led to a sufficient understanding of pathophysiology and management of aPA in PD, partially due to lack of agreement on validated, user-friendly, automatic tools for measuring and analysing the differences in the degree of aPA, according to patients’ therapeutic conditions and tasks. In this context, human pose estimation (HPE) software based on deep learning could be a valid support as it automatically extrapolates spatial coordinates of the human skeleton keypoints from images or videos. Nevertheless, standard HPE platforms have two limitations that prevent their adoption in such a clinical practice. First, standard HPE keypoints are inconsistent with the keypoints needed to assess aPA (degrees and fulcrum). Second, aPA assessment either requires advanced RGB-D sensors or, when based on the processing of RGB images, they are most likely sensitive to the adopted camera and to the scene (e.g., sensor–subject distance, lighting, background–subject clothing contrast). This article presents a software that augments the human skeleton extrapolated by state-of-the-art HPE software from RGB pictures with exact bone points for posture evaluation through computer vision post-processing primitives. This article shows the software robustness and accuracy on the processing of 76 RGB images with different resolutions and sensor–subject distances from 55 PD patients with different degrees of anterior and lateral trunk flexion.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Using Digital Human Modelling to Evaluate the Risk of Musculoskeletal Injury for Workers in the Healthcare Industry\n",
            "Authors: Ji X.\n",
            "Abstract: Background: Hospital nurses and caregivers are reported to have the highest number of workplace injuries every year, which directly leads to missed days of work, a large amount of compensation costs, and staff shortage issues in the healthcare industry. Hence, this research study provides a new technique to evaluate the risk of injuries for healthcare workers using a combination of unobtrusive wearable devices and digital human technology. The seamless integration of JACK Siemens software and the Xsens motion tracking system was used to determine awkward postures adopted for patient transfer tasks. This technique allows for continuous monitoring of the healthcare worker’s movement which can be obtained in the field. Methods: Thirty-three participants underwent two common tasks: moving a patient manikin from a lying position to a sitting position in bed and transferring the manikin from a bed to a wheelchair. By identifying, in these daily repetitive patient-transfer tasks, potential inappropriate postures that can be conducive to excessive load on the lumbar spine, a real-time monitoring process can be devised to adjust them, accounting for the effect of fatigue. Experimental Result: From the results, we identified a significant difference in spinal forces exerted on the lower back between genders at different operational heights. Additionally, we revealed the main anthropometric variables (e.g., trunk and hip motions) that are having a large impact on potential lower back injury. Conclusions: These results will lead to implementation of training techniques and improvements in working environment design to effectively reduce the number of healthcare workers experiencing lower back pain, which can be conducive to fewer workers leaving the healthcare industry, better patient satisfaction and reduction of healthcare costs.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Non-intrusive RF sensing for early diagnosis of spinal curvature syndrome disorders\n",
            "Authors: Mustafa A.\n",
            "Abstract: The recent developments in communication and information ease people's lives to sit in one place and access any information from anywhere. However, the longevity of sitting and sitting in different postures raises the issues of spinal curvature. It necessitates a physical examination to identify the spinal illness in its early stages. This article aims to develop an intelligent monitoring framework for detecting and monitoring spinal curvature syndrome problems based on Software Defined Radio Frequency (SDRF) sensing and verify its feasibility for diagnosing actual patients. The proposed SDRF-based system identifies irregular spinal curvature syndrome and offers feedback signals when an incorrect posture is identified. We design the system using wireless university software-defined radio peripheral (USRP) kits to transmit and receive RF signals and record the wireless channel state information (WCSI) for kyphosis, Lordosis, and scoliosis spinal disorders. The statistical measures are extracted from the WCSI and apply machine learning algorithms to identify and classify the type of disorders. We record and test the system using 11 subjects with the spinal disorders kyphosis, Lordosis, and scoliosis. We acquire the WCSI, extract various statistical measures in terms of time and frequency domain features, and evaluate machine learning classifiers to identify and classify the spinal disorder. The performance comparison of the machine learning algorithms showed overall and each spinal curvature disorder recognition accuracy of more than 99%.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Classification of human movements by using Kinect sensor\n",
            "Authors: Açış B.\n",
            "Abstract: In recent years, studies have been carried out to classify human movements in many areas such as health and safety. To classify human movements, image processing methods have also started to be used in recent years. With the help of learning-based algorithms, human posture can be defined in the images obtained by various imaging methods. The predecessor methods of these classification algorithms are machine learning and deep learning. In addition, in recent years, the use of sensors that can detect human joints in perceiving human posture has also increased. The Kinect sensor, developed by Microsoft, is one of the most frequently used sensors because it is not wearable and can detect joints with infrared rays and transfer this information directly to the computer via USB connection. This study used a dataset called CAD60 that included real-time human posture information and images obtained using a Microsoft Kinect sensor, which is available in the literature. This dataset contains data that includes different movements/postures of different people. Within the scope of this study, the performances of these algorithms were obtained by using classification algorithms with the MATLAB program and these performances were compared. The classification algorithms have been used to try to improve the results by using different architectures. When raw data is used, classification accuracy is obtained as 72.60% with one of the machine learning methods, the Cosine K-Nearest Neighbor method. With the feature selection method, this success value has been increased to 74.18%. In addition, when classified by the Support Vector Machines method after the feature extraction process using the Long Short Term Memory method from the deep network architectures, which is the method proposed in this study, the accuracy rate was increased to 98.95%. The best method of classifying human posture was investigated by using different methods and a method was proposed by comparing it with the literature.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A visual ergonomic assessment approach using Kinect and OWAS in real workplace environments\n",
            "Authors: Li X.\n",
            "Abstract: Ergonomics plays an important role and has contributed to sustainable development in many areas such as product design, architecture, health, safety, and workplace design. An ergonomic assessment is a crucial task in real workplace environments to prevent potential musculoskeletal disorders. Recently, visual ergonomic assessment has been widely utilized for skeleton analysis of human joints for body posture identification to deal with musculoskeletal disorders risks. However, posture identification has limitations in self-occlusion joint postures. This study presents a visual ergonomic assessment approach for posture identification in free- and self-occlusion conditions. For self-occlusion detection, as the main focus of this study, an algorithm is proposed to overcome this limitation to detect the joints’ location when other relative joints block the joints. After the self-occlusion is detected, the location of a blocked joint is identified using the primary data collected in body data extraction in the joint location estimation process. Then, the identified location of the joint is used for posture identification in the free and self-occlusion detection process. The posture identification is based on the OWAS standard for posture and category identification. Finally, experimental results and performance evaluation are presented in individual and integrated procedures. In individual evaluation, the performance of the algorithm is reported for the self- and free-occlusion detection, posture, and category identification processes separately. The results are collected for the overall proposed approach in integrated evaluation, and the performance is measured using standard evaluation metrics. As experimental results show, the proposed approach can effectively detect the postures and identify the associated category in the OWAS standard for both self- and free occlusions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An integrated multi-criteria decision-making approach for identifying the risk level of musculoskeletal disorders among handheld device users\n",
            "Authors: Jain R.\n",
            "Abstract: In work-from-home (WFH) situation due to coronavirus (COVID-19) pandemic, the handheld device (HHD) users work in awkward postures for longer hours because of unavailability of ergonomically designed workstations. This problem results in different type of musculoskeletal disorders (MSDs) among the HHD users. An integrated multi-criteria decision-making approach was offered for identifying the risk level of MSDs among HHD users. A case example implemented the proposed approach in which, firstly, the best–worst method (BWM) technique was used to prioritize and determine the relative importance (weightage) of the risk factors. The weightages of the risk factors further used to rank the seven alternatives (HHD users) using Vlse Kriterijumska Optimizacija Kompromisno Resenje (VIKOR) technique. The outcomes of the BWM investigation showed that the three most significant risk factors responsible for MSDs are duration of working, poor working posture and un-ergonomic design. The outcome of the VIKOR technique exhibited that computer professionals were at the highest risk among all users. The risk factor priority must be used for designing a working strategy for the WFH situation which will help to mitigate the risks of MSDs.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Healthcare Monitoring Using Low-Cost Sensors to Supplement and Replace Human Sensation: Does It Have Potential to Increase Independent Living and Prevent Disease?\n",
            "Authors: Liu Z.\n",
            "Abstract: Continuous monitoring of health status has the potential to enhance the quality of life and life expectancy of people suffering from chronic illness and of the elderly. However, such systems can only come into widespread use if the cost of manufacturing is low. Advancements in material science and engineering technology have led to a significant decrease in the expense of developing healthcare monitoring devices. This review aims to investigate the progress of the use of low-cost sensors in healthcare monitoring and discusses the challenges faced when accomplishing continuous and real-time monitoring tasks. The major findings include (1) only a small number of publications (N = 50) have addressed the issue of healthcare monitoring applications using low-cost sensors over the past two decades; (2) the top three algorithms used to process sensor data include SA (Statistical Analysis, 30%), SVM (Support Vector Machine, 18%), and KNN (K-Nearest Neighbour, 12%); and (3) wireless communication techniques (Zigbee, Bluetooth, Wi-Fi, and RF) serve as the major data transmission tools (77%) followed by cable connection (13%) and SD card data storage (10%). Due to the small fraction (N = 50) of low-cost sensor-based studies among thousands of published articles about healthcare monitoring, this review not only summarises the progress of related research but calls for researchers to devote more effort to the consideration of cost reduction as well as the size of these components.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Recognizing Human Activity of Daily Living Using a Flexible Wearable for 3D Spine Pose Tracking\n",
            "Authors: Haghi M.\n",
            "Abstract: The World Health Organization recognizes physical activity as an influencing domain on quality of life. Monitoring, evaluating, and supervising it by wearable devices can contribute to the early detection and progress assessment of diseases such as Alzheimer’s, rehabilitation, and exercises in telehealth, as well as abrupt events such as a fall. In this work, we use a non-invasive and non-intrusive flexible wearable device for 3D spine pose measurement to monitor and classify physical activity. We develop a comprehensive protocol that consists of 10 indoor, 4 outdoor, and 8 transition states activities in three categories of static, dynamic, and transition in order to evaluate the applicability of the flexible wearable device in human activity recognition. We implement and compare the performance of three neural networks: long short-term memory (LSTM), convolutional neural network (CNN), and a hybrid model (CNN-LSTM). For ground truth, we use an accelerometer and strips data. LSTM reached an overall classification accuracy of 98% for all activities. The CNN model with accelerometer data delivered better performance in lying down (100%), static (standing = 82%, sitting = 75%), and dynamic (walking = 100%, running = 100%) positions. Data fusion improved the outputs in standing (92%) and sitting (94%), while LSTM with the strips data yielded a better performance in bending-related activities (bending forward = 49%, bending backward = 88%, bending right = 92%, and bending left = 100%), the combination of data fusion and principle components analysis further strengthened the output (bending forward = 100%, bending backward = 89%, bending right = 100%, and bending left = 100%). Moreover, the LSTM model detected the first transition state that is similar to fall with the accuracy of 84%. The results show that the wearable device can be used in a daily routine for activity monitoring, recognition, and exercise supervision, but still needs further improvement for fall detection.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Flight Controller as a Low-Cost IMU Sensor for Human Motion Measurement\n",
            "Authors: Iluk A.\n",
            "Abstract: Human motion analysis requires information about the position and orientation of different parts of the human body over time. Widely used are optical methods such as the VICON system and sets of wired and wireless IMU sensors to estimate absolute orientation angles of extremities (Xsens). Both methods require expensive measurement devices and have disadvantages such as the limited rate of position and angle acquisition. In the paper, the adaptation of the drone flight controller was proposed as a low-cost and relatively high-performance device for the human body pose estimation and acceleration measurements. The test setup with the use of flight controllers was described and the efficiency of the flight controller sensor was compared with commercial sensors. The practical usability of sensors in human motion measurement was presented. The issues related to the dynamic response of IMU-based sensors during acceleration measurement were discussed.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Multimodal data-based deep learning model for sitting posture recognition toward office workers’ health promotion\n",
            "Authors: Zhang X.\n",
            "Abstract: Recognizing sitting posture is significant to prevent the development of work-related musculoskeletal disorders for office workers. Multimodal data, i.e., infrared map and pressure map, have been leveraged to achieve accurate recognition while preserving privacy and being unobtrusive for daily use. Existing studies in sitting posture recognition utilize handcrafted features with machine learning models for multimodal data fusion, which significantly relies on domain knowledge. Therefore, a deep learning model is proposed to fuse the multimodal data and recognize the sitting posture. This model contains modality-specific backbones, a cross-modal self-attention module, and multi-task learning-based classification. Experiments are conducted to verify the effectiveness of the proposed model using 20 participants’ data, achieving a 93.08% F1-score. The high-performance result indicates that the proposed model is promising for sitting posture-related applications.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Towards an integrated framework to measure user engagement with interactive or physical products\n",
            "Authors: Castiblanco Jimenez I.A.\n",
            "Abstract: Building great products or services is not easy; users want products and services that exceed their expectations and evolve with their needs; it is not just about building the right features. Knowing the user engagement (UE) towards a physical, virtual product or service can give valuable information that could be used as feedback for the design, enhancing its chances of success. In the context of user-centered design, UE is the assessment of the user experience characterized by the study of the individual's cognitive, affective, and behavioral response to some stimulus, such as a product, a service, or a website. UE considers not only the users’ requirements and wishes but also their perceptions and reactions during and after an interaction with a product, system, or service. Many studies looking to quantify the UE are available. Still, a framework that provides a generic view of the most commonly used methods and metrics to measure UE does not yet exist in the literature. Aiming to understand the UE better, in this research, we developed a conceptual framework summarizing the available metrics and techniques used across different contexts, including good practices of self-report methods and physiological approaches. We expect this study will allow future researchers, developers, and designers to consider the UE as one of the most prominent product/service success indicators and use this guideline to find the more appropriate method, technique, and metric for its measurement.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic human-robot collaboration in industry: A review\n",
            "Authors: Lorenzini M.\n",
            "Abstract: In the current industrial context, the importance of assessing and improving workers’ health conditions is widely recognised. Both physical and psycho-social factors contribute to jeopardising the underlying comfort and well-being, boosting the occurrence of diseases and injuries, and affecting their quality of life. Human-robot interaction and collaboration frameworks stand out among the possible solutions to prevent and mitigate workplace risk factors. The increasingly advanced control strategies and planning schemes featured by collaborative robots have the potential to foster fruitful and efficient coordination during the execution of hybrid tasks, by meeting their human counterparts’ needs and limits. To this end, a thorough and comprehensive evaluation of an individual’s ergonomics, i.e. direct effect of workload on the human psycho-physical state, must be taken into account. In this review article, we provide an overview of the existing ergonomics assessment tools as well as the available monitoring technologies to drive and adapt a collaborative robot’s behaviour. Preliminary attempts of ergonomic human-robot collaboration frameworks are presented next, discussing state-of-the-art limitations and challenges. Future trends and promising themes are finally highlighted, aiming to promote safety, health, and equality in worldwide workplaces.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic risk assessment in lifting activities with Azure Kinect: an industrial case study\n",
            "Authors: Coruzzolo A.M.\n",
            "Abstract: Work related musculoskeletal disorders (WMDs) are common in industrial activities and their impacts on society are not negligible. To reduce them recently some motion capture technologies (MOCAP) are applied to semi automatically calculate the ergonomic risk to which operators are subjected. In this paper we present an industrial case study where an application based on a depth camera, the new Azure Kinect, is exploited to semi-automatically calculate the ergonomic risk involved in picking activities. The case study took place in a warehouse and regarded three different activities. The semi-automatic evaluation of the ergonomic risk highlighted some criticalities on how picking activities are carried out. For this reason, some modifications of the activities are proposed and tested revealing a statistically significant ergonomic risk reduction.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Comparison of Different Risk Assessment Tools to Manage Musculoskeletal Disorders among Workers in an Automobile Manufacturing Company\n",
            "Authors: Jafarian M.\n",
            "Abstract: Awkward postures and manual material handling activities are important risk factors for musculoskeletal disorders in workers. To avoid the harm and costs caused by these injuries, there are several ergonomics (e.g., MAC, ManTRA, NIOSH, OWAS, QEC, REBA, WISHA, Snook, and V3) and biomechanical (i.e., biomechanical models such as AnyBody Modeling System, Jack, Regression equations, HCBCF and 3DSSPP) risk assessment tools. This study is conducted to compare these tools to evaluate working conditions in the cylinder finishing unit of Malleable Saipa Company as well as to suggest interventions to reduce the risk of injury. Results indicate that our case study work situation has a high risk of musculoskeletal injuries due to the cylinder's heavy weight and workers' improper posture; therefore, job interventions are required. The recommended interventions, including load height adjustment, worker training, job rotation, and team working significantly reduced the risk of injury. Comparisons between the risk assessment tools indicate that QEC, ManTRA, and V3 tools are more comprehensive than other ergonomics tools. Moreover, all methods show compression more than 50% higher than AnyBody which is the most accurate method. The fact that the load's weight (36 kg) exceeded the maximum permissible load for these tools (20 kg) is probably what caused this issue.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Conditional Variational Auto-encoder Model for Reducing Musculoskeletal Disorder Risk during a Human-Robot Collaboration Task\n",
            "Authors: Qing L.\n",
            "Abstract: In recent years, there has been a trend to adopt human-robot collaboration (HRC) in the industry. In previous studies, computer vision-aided human pose reconstruction is applied to find the optimal position of point of operation in HRC that can reduce workers’ musculoskeletal disorder (MSD) risks due to awkward working postures. However, the reconstruction of human pose through computer-vision may fail due to the complexity of the workplace environment. In this study, we propose a data-driven method for optimizing the position of point of operation during HRC. A conditional variational auto-encoder (cVAE) model-based approach is adopted, which includes three steps. First, a cVAE model was trained using an open-access multimodal human posture dataset. After training, this model can output a simulated worker posture of which the hand position can reach a given position of point of operation. Next, an awkward posture score is calculated to evaluate MSD risks associated with the generated postures with a variety of positions of point of operation. The position of point of operation that is associated with a minimum awkward posture score is then selected for an HRC task. An experiment was conducted to validate the effectiveness of this method. According to the findings, the proposed method produced a point of operation position that was similar to the one chosen by participants through subjective selection, with an average difference of 4.5 cm.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: XAI in human motion recognition and analysis for envisioning society: A systematic review\n",
            "Authors: Chaudhari P.\n",
            "Abstract: The imminent smart society demands the applications of diverse emerging innovative technologies that involve the analysis of human movements and interpretation of it for further decisions. Industry 5.0 demands efficient frameworks for applications such as human-robot co-working, smart surveillance, smart old age homes, smart homes, smart education portals, smart automation systems, gaming and entertainment, smart health diagnosis, and gesture and posture analysis. Interpretation and understanding of human movement are an important part of smart society applications. With advancements in various computer-related domains, there are many systems that use machine learning and deep learning algorithms for automated analysis of human movement. In critical applications safety, security and reliability are of utmost demand. By using traditional methods of AI, some critical interpretations of human movements, postures, and gestures are unable to recognize accurately and efficiently. Human motion analysis with interfacing XAI, which examines human posture, shows potential for understanding the human movements employed with explanations. In this chapter, we focus on the technical overview of the budding sector of motion analysis with interpretable machine learning and deep learning frameworks, various datasets, invariant frameworks, and 2D and 3D motion analysis approaches. In the transformation of the new era, intelligent systems will develop with transparency and expandability, that is, along with explainable AI. The study comprises recent human motion analysis models and XAI-based deep learning models. In forthcoming years, this survey will contribute to further studies and upcoming research models. Human motion analysis with explainable AI is in demand due to its state-of-the-art applications and is becoming the most popular and challenging area of research. There are multiple systems in deep learning, but in critical applications, it requires safety and security. Surveillance plays a crucial role in building an upcoming smart and secure society. Integration of XAI and machine learning advancement needs to be appended in various applications such as smart surveillance and movement analysis in sports.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Smart Posture Analyzer for Exercise\n",
            "Authors: Dhaigude S.\n",
            "Abstract: Going to the gym on your own is, of course, possible, but a personal trainer can really help you increase your endurance. In this day and age, many people rely on YouTube tutorial videos to figure out what works best for them. However, if done unsupervised or incorrectly, it can be ineffective and potentially dangerous. During exercise, sudden movements and poor posture can result in temporary or permanent disability. So, we devised this smart exercise posture analyzer concept. By alerting the user and providing alternative actions, the system warns the user about poor posture. This would allow the user to focus on the exercise rather than the mobile screen. The idea is to track the body posture of the user while they are doing exercise and recommend changes simultaneously. The system will also keep track of reps the user is doing. The proposed system does not consider more than 3 exercises. Algorithms based on machine learning are used to predict and guide users when performing specific workouts.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Motion Posture Detection Based on Image Recognition through Deep Learning Algorithm\n",
            "Authors: Hou W.\n",
            "Abstract: In computer vision, image recognition and action detection are two very important tasks. These two tasks can be viewed as two different techniques: feature-based methods and model-based methods. Image recognition techniques represent objects or objects in an image as a vector of numbers, which can be viewed as a set of features. However, when there is a certain relationship between these vectors and poses or actions, these vectors are called feature vectors. The article adopts a method based on deep learning algorithm to realize motion posture detection. This method can collect video stream through camera for motion detection. The experimental results show that the detection accuracy of the motion posture detection method based on image recognition can reach up to 94.5% through the deep learning algorithm.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Postural Ergonomic Assessment of Construction Workers Based on Human 3D Pose Estimation and Machine Learning\n",
            "Authors: Tao Y.\n",
            "Abstract: Work-related musculoskeletal disorders (WMSDs) have been the major cause of occupational injuries among construction workers. The traditional observational assessment is time-consuming and subjective, while the sensor-based postural analysis is usually associated with high setup costs and intrusiveness. This study proposed an automated ergonomic risk assessment method based on computer vision and machine learning focusing on lower body postural risks. It provided a comprehensive risk dashboard, including posture detection and rule-based extreme flexion examination. Specifically, with raw video input, the postural feature extraction module can identify skeleton coordinates frame by frame by adopting a state-of-art 3D pose estimation algorithm. In the ergonomic assessment module, the knee angles can be calculated using skeleton coordinates, and the support vector machine (SVM) classifier was trained for posture recognition. The illustration based on a real-life example demonstrated the applicability and reliability of the proposed method, with nearly 95% accuracy for posture detection. In summary, the study provided a more comprehensive and in-depth postural analysis of construction activities, which has great potential to facilitate intervention strategies for WMSD prevention with quantified evidence.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: WAREHOUSE AND LOGISTICS ERGONOMICS OPTIMIZATION THROUGH REAL-TIME EVALUATION OF THE NIOSH INDEX\n",
            "Authors: Lanzoni D.\n",
            "Abstract: Logistic activities can cause long-term musculoskeletal problems due to repetitive and incorrect movements, heavy loads, and uncomfortable positions. Ergonomic evaluations are conducted to prevent these risks, optimize workstations, and work processes. Some studies use automatic evaluation of ergonomic indices or frameworks for optimizing workstations and logistics reorganization. However, optimization is often disconnected from real-world case studies. This research work validates a new approach that integrates an automatic ergonomic evaluation and optimization in real-world scenarios, comparing this analysis with traditional manual evaluation method. Our approach is applied to a real logistics case study using a wearable motion capture system and an interactive interface that displays the Digital Twin of the analyzed task. Results show that our approach provides a more accurate evaluation of the ergonomics and an evident time-saving.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: IMPROVING AUTONOMOUS VEHICLE AUTOMATION THROUGH HUMAN-SYSTEM INTERACTION\n",
            "Authors: Puertas-Ramirez D.\n",
            "Abstract: Self-driving cars (a.k.a. Autonomous Vehicles) have many challenges to tackle before having them fully deployed in our roads and cities. A critical one, which has been somehow neglected till recently, is to consider the driver in the system-user loop of vehicle performance. The purpose here is to tackle some of the current pending challenges involved in scaling up the level of autonomy of these systems. We have designed two user-vehicle experiences in two different sites with a common methodology that serves as an umbrella to collect all features required to model the driver-user. These two sites allow us to contrast and fine-tune this modelling issue. The approach consists in following a Learning Apprentice approach, where both the user behaviour and the system behaviour are learned and improved in a symbiotic ecosystem. This paper focuses on discussing the advantages of this approach and the main issues that require further research.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Effect of different postures and loads on joint motion and muscle activity in older adults during overhead retrieval\n",
            "Authors: Zhou C.\n",
            "Abstract: Introduction: Pain is a common health problem among older adults worldwide. Older adults tend to suffer from arm, lumbar, and back pain when using hanging cabinets. Methods: This study used surface electromyography to record muscle activity and a motion capture system to record joint motion to research effects of different loads and retrieval postures on muscle activity and joint range of motion when older adults retrieve objects from a high place, to provide optimised feedback for the design of hanging cabinet furniture. Results: We found that: 1) The activity of BB (Biceps brachii) on the side of the body interacting with the cabinet door was greater than that of UT (Upper trapezius) and BR (Brachial radius) when retrieving objects from a high place, the activity of UT on the side of the body interacting with a heavy object was greater than that of BB and BR. 2) The activity of UT decreases when the shoulder joint angle is greater than 90°, but the activity of BB increases as the angle increases. In contrast, increasing the object’s mass causes the maximum load on the shoulder joint. 3) Among the different postures for overhead retrieval, alternating between the right and left hand is preferable for the overhead retrieval task. 4) Age had the most significant effect on overhead retrieval, followed by height (of person), and load changes were significantly different only at the experiment’s left elbow joint and the L.BR. 5) Older adults took longer and exerted more effort to complete the task than younger adults, and static exercise in older adults may be more demanding on muscle activity in old age than powered exercise. Conclusion: These results help to optimise the design of hanging cabinet furniture. Regarding the height of hanging cabinets, 180 cm or less is required for regular retrieval movements if the human height is less than 150 cm. Concerning the depth of the hanging cabinets, different heights chose different comfort distances, which translated into the depth of the hanging cabinets; the greater the height, the greater the depth of the hanging cabinets to use.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Comprehensive Defense Approach Targeting The Computer Vision Based Cheating Tools in FPS Video Games\n",
            "Authors: Nhu A.\n",
            "Abstract: Video games is one of the most popular multimedia forms and generate higher profits than the traditional film industry. In the meantime, with the advances of deep learning, computer vision algorithms have become more powerful for analyzing the video content and have been applied in the FPS video games as an advanced cheating tools, which have taken the video games industry by storm. Such algorithms, including the object detection and human pose estimations, could analyze and understand the video content in each frame and further help the player to automatically identify and aim at the enemies with extremely fast reaction. Compared to the classic cheating tools, computer-vision-based cheating tools are harder to detect and defend against because they do not need to manipulate the software or the system but purely simulate how a well trained and skilled human gamer plays the video game. In this paper, we propose a proactive and comprehensive defense approach, which generates perturbations that are not perceptible to humans yet can still mislead the computer vision algorithms. More specifically, this comprehensive approach includes two parts, the defense approach aims to fail the computer vision-based cheating tools to detect the in-game characters while the penalty approach aims to fool the computer vision-based cheating tools to detect the fake regions as in-game characters, which not only worsen the cheating experience but also serve as a trigger for detecting the cheating behavior. In this work, we first implement the object detection based cheating tools as the evaluation environment. Then, we implement our proposed defense, penalty and comprehensive approaches and evaluate the performance with four popular video games. The results show that our comprehensive approach obtains a high success rate with minor impact to user experience quality.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Effects of Robotic Expertise and Task Knowledge on Physical Ergonomics and Joint Efficiency in a Human-Robot Collaboration Task\n",
            "Authors: Pantano M.\n",
            "Abstract: With the trend of low batch manufacturing, more and more small and medium enterprises are leaning towards adopting collaborative robots to increase productivity and improve operator well-being. However, robots are often programmed by robot experts rather than the operators effectively working with the machine. Therefore, operators may perceive low levels of task autonomy due to the unpredictability of robot motions. Empowering operators to make their own choices regarding robot motions can improve such feelings. However, research in cognitive science shows that allowing operators to decide on robot motions in a collaborative task could be influenced by how people consider their travel path and their partner's action. To better understand these relations, considering preliminary results from a previous study, we designed a user study where we tested operators' decisions in a collaborative task where groups of robot experts and novices were asked to choose their preferred task configuration among four possible options that differed in terms of operators' physical ergonomics and robot travel path. Our results show that robotic experts prioritize joint team work rather than their ergonomics. Contrarily, novices prioritize individual efforts and tend to reduce the robot travel path while keeping their travel path constant, maintaining good physical ergonomics. In conclusion, providing operators with task decision autonomy can be advantageous, but operator background must be considered to ensure optimal physical ergonomics and travel paths.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Correction of Two Human Key-Points Estimations for Medical Applications\n",
            "Authors: Luo H.\n",
            "Abstract: Anatomical key-points recognition is essential in many medical image analyses and clinical healthcare applications. Successfully identifying these anatomical key points provides multiple advantages, such as assisting medical experts in making treatment adjustments and offering information that helps to position surgical instruments at the appropriate locations. However, manual anatomical key-point recognition is subjective, slow, and time-consuming, especially when processing many medical images in clinical institutions. To overcome these limitations, this study aims to establish the correlation between human anatomical key points based on OpenPose and Baidu AI key-point detection techniques and the truth ground anatomical key-points marked by therapists in human medical images. This relationship will help to optimize the detection performance, reduce cost, decrease human error, and accelerate the process. The Sichuan Cancer Hospital provided five whole-body scan images obtained from a clinical CT scanner. A medical expert subsequently identified 14 anatomical key points from each scan. Finally, the datasets were reconstructed into 3-dimensional volume models to visualize whole-body skin models and the skeletons. The human-Annotated 14 key points were then used as ground truth compared to the computer vision techniques: OpenPose and Baidu AI. Both OpenPose and Baidu AI were found to have systematic offsets from the ground true reference points. These findings are reported in this work and can be used as a correction method.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A CAD-Based Tool to Support the Configuration of Parts Storage Shelving in Assembly Workstations\n",
            "Authors: Cicconi P.\n",
            "Abstract: The supply of parts to the workstations of assembly lines is a critical design and operational issue. Even though automation and collaborative robots are increasingly used in industry, human operators are frequently employed in the picking and assembly of manual parts. These are time-consuming activities required to be efficiently performed at a high rate and for prolonged periods. Therefore, ergonomic analysis is necessary to reduce the risk of work-related musculoskeletal injuries due to the biomechanical loads. The proper layout of shelves storing part containers along the production line, and the location of the containers on the shelves, may improve picking efficiency and reduce biomechanical risk. Several manufacturing companies use computer-aided ergonomic tools to improve the design of manual production lines, racking, shelving, and workstations. This paper describes the development of a support tool to configure industrial light shelves for feeding the assembly lines. The approach includes the development of a knowledge base to support the geometrical configuration of the shelving and an ergonomic analysis based on the RULA method, considering the shelf’s position and the operator’s postures. As a test case, the model has been used to evaluate the ergonomic score of some configured shelving based on a prescribed picking sequence. The results show that the proposed approach can help in comparing the ergonomic score of candidate shelving layouts to improve the design of parts storage systems to reduce operators’ workload and ergonomic risk.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Physical Key Point Detection Algorithm Based on Multi-scale Feature Fusion\n",
            "Authors: Wang X.\n",
            "Abstract: Physical posture is a reflection of the orderly arrangement of the body’s bones and the proper functioning of its muscle tissue, and it is also a guarantee of good health. Evaluating physical posture generally involves detecting key points on the human body, which is essentially a dense detection task in machine vision. This paper proposes a new key point detection method for evaluating physical posture, based on multi-scale feature fusion and self-attention mechanism. The self-attention mechanism is added in the algorithm to capture global feature dependencies, while the patching merging down-sampling structures help reduce information loss during the down-sampling process. Additionally, a de-convolution module is added in the prediction phase to generate higher quality feature maps and improve the spatial accuracy of the key points. The proposed algorithm achieves an average mAP of 85.5% on key point detection models for the front, side, and back of the body on a self-built dataset. The results demonstrate the algorithm’s good performance in the field of physical posture health evaluation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An App for the Registration of Traffic Injuries\n",
            "Authors: Suarez D.\n",
            "Abstract: We present the development of an application as a mobile tool to carry out the assessment of bodily damage suffered by a traffic accident. The scale used to assess traffic accidents can be used for any other circumstance that produces injury or bodily sequelae. The software developed will allow the expert to be guided through all the cases to generate a report where the corresponding compensation is obtained, both for bodily harm and possible disabilities. In the event of death, it also makes it possible to determine compensation to relatives and relatives based on kinship and circumstances. Of course, the role of the expert does not disappear. In many cases, forks appear, and compensation must be argued. However, this application will allow it to be operated by a physician without much experience in this legislation. The application will ask you for the details of the accident and will indicate the compensation ranges that can be applied. On the other hand, the application allows you to collect all kinds of documents that can be attached to the final report. These include medical reports and all kinds of expenses caused as an accident (hospitalization, prothesis, transportation, repatriation). A mobile application is proposed that allows automating this process, which can be used by personnel without previous experience and drastically reducing the time necessary to carry out the measurements. Another advantage is that the software runs on a mobile device using the mobile device's camera. This allows the system to be used in any location and with minimal economic cost. On the other hand, a complete patient registration system has been implemented, and the possibility of keeping a history of each one, to assess their evolution.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: HUMAN ACTION DETECTION AND ERGONOMIC RISK ASSESSMENT AT CONSTRUCTION SITES, BY USE OF MACHINE VISION AND DEEP LEARNING\n",
            "Authors: Lambrides E.\n",
            "Abstract: The research work described herein focuses on the realtime detection and pose analysis of human activities at construction sites, as well as on the evaluation of the ergonomics of these activities. The pose detection and ergonomic analysis utilize machine vision (MV) and deep learning technologies for the processing of images and/or video streams, and a “skeletonization” mechanism that upon detection of a worker pose, measures the geometric properties of the pose’s keypoints in the skeletal shape and then calculates the corresponding scores according to the Rapid Entire Body Assessment (REBA) methodology. The utilized approach, which was successfully tested on several typical construction activities, (1) has the potential of providing fast ergonomic assessment at construction sites; and (2) it contributes to the knowledge of occupational safety and health in the construction industry, by providing a low-cost and accurate approach for assessing the risk factors of Work-related Musculoskeletal Disorders (WMSDs).\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: SocialWell-Being: An IndustrialWorkplace Alerting and Monitoring Platform\n",
            "Authors: Adhikesaven S.\n",
            "Abstract: Workplace accidents are a critical problem that causes many deaths, injuries, and financial losses. Given this impact on a large amount of people, it is important to proactively find unsafe environments where injuries could occur by detecting the use of personal protective equipment (PPE) and identifying unsafe activities. Thus, we propose an industrial workplace alerting and monitoring platform to detect PPE use and classify unsafe activity in group settings involving multiple humans and objects over a long period of time. Our proposed method is the first to analyze prolonged actions involving multiple people or objects. It benefits from combining pose estimation with PPE detection in one platform. Additionally, we propose the first open source annotated data set with video data from industrial workplaces annotated with the action classifications and detected PPE. The proposed system can be implemented within the surveillance cameras already present in industrial settings, making it a practical and effective solution. If accepted, we hope to present this work as a short paper or as a poster.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Enhancing Driving Safety Through Real-Time Posture Detection and Analysis Using Machine Vision\n",
            "Authors: Salke P.\n",
            "Abstract: This paper proposes an innovative technique for evaluating the driver's posture in All-Terrain Vehicles (ATVs) by making use of OpenCV and the Mediapipe Framework using Python. Real-time video streams of driver's posture are captured and processed to determine joint angles, which are then compared to a REBA scorecard for further analysis. The results are displayed on a web page which is built using React and Python backend which runs locally on a computer. This approach has also been verified by using sensors to detect the angles between the joints. By accessing the level of risk from REBA Table, the vehicle design is optimized and the vehicle is made invulnerable. This automatic calculation saves considerable amount of time during the development phase. This approach offers a user-friendly way to detect and analyze driver's posture, predict risk to the driver using the REBA standardized scorecard, and to design interventions to optimize driver comfort and reduce the risk of injuries in All Terrain Vehicles during long hours of driving duration.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic Risk Prediction for Awkward Postures From 3D Keypoints Using Deep Learning\n",
            "Authors: Hossain M.S.\n",
            "Abstract: Work-related musculoskeletal ailments are injuries or disorders of the joints, muscles, nerves, or tendons caused by repetitive tasks and jobs that require uncomfortable postures. REBA (Rapid Entire Body Assessment) is a widely used assessment method for examining occupational ergonomics in areas where musculoskeletal disorders (MSDs) are common. REBA assessment necessitates the presence of a professional evaluator who monitors workers' motions and postures, which takes time and has limitations in terms of real-world implementation. With the progress of deep learning-based human posture estimate algorithms, postural risk assessment has become an important and complex research area. We present a technique for forecasting REBA risk levels using 3D coordinates of human body position as input data in this study. We calculated REBA risk scores for various body segments and overall risk rating for corresponding action level for each body position using 3D keypoints from the widely renowned Human 3.6M dataset, which is a significant contribution for future research work in this arena. Using this vast ground truth dataset, a unique DNN model was created to forecast the REBA risk level for measuring the full body's postural risk. REBA Ground Truth dataset is highly imbalanced which coped with data augmentation for the rare classes. To determine the optimal model configuration based on highest accuracy, ablation study is conducted by tuning different hyper-parameters. The proposed model, post-ablation study, attained 89.07% accuracy score on a test set of 128,046 samples from Nadam optimizer with a learning rate of 0.001 and batch size of 512.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Wearable Devices for Gait Measurement-A Case for Textile-Based Devices\n",
            "Authors: Raji R.K.\n",
            "Abstract: Wearable devices for gait measurement are devices worn on the body to measure the gait of the wearers. During gait measurement, several parameters are measured and the choice of parameters is influenced by the application and by extension the gait index. Two approaches have been adopted in this research. One is the provision of an overview of wearable devices for gait measurement with a bias towards textile-based “soft” smart wearable systems using information from varied academic sources and databases. The second approach is to map out key scientific research trends within the wearable device classes using the Web of Science database. The focus is to make a case for textile-based gait measurement devices and systems while exploring the key determinants of wearable gait sensor placements and application efficiency. These soft smart wearable systems describe flexible material sensor-based systems which have their sensing mechanisms based on material deformation after being subjected to stress or pressure. This study could therefore serve as an apt reference for the development of soft smart wearable gait measurement systems as it throws light on the various soft wearable gait measurement applications, the bottlenecks in soft wearable device design, opportunities for developing new devices and the merit that soft gait analysis systems possess over their hard gait measurement counterparts.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Review of Sensing Modalities for Physical Competency Assessment\n",
            "Authors: Loh D.M.K.\n",
            "Abstract: Physical competency assessments are vital in the fields such as sports and medicine to study and predict sports incurred injuries and long-term musculoskeletal injuries. These assessments have been attempted by various sensor modalities such as vision based sensors, ambient sensors and wearable sensors. These sensors are used exclusively to collect information on the human body characteristic and human kinematics to assess fitness of the athletes. This paper reviews and compares the capabilities of wearable and non-wearable sensing modalities in sports domain. Wearable sensors such as impact force sensors, mechanical-based measurement and electrophysiological measurement are popular to extract ground contact and muscle activity with the attached markers. Non-wearable sensors such as force insole, radio frequency measurement and vision-based measurement can detect human motions and joint angle without the requirement of body contact. These sensors are compared in term of its complexity of the assessments and its utility within the algorithms of a single modal and multi-modal system.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Comfort Wearables for In-Flight Sitting Posture Recognition\n",
            "Authors: Yao X.\n",
            "Abstract: Wearables are used to recognize human activities in various applications. However, there is limited evidence on the comfort feelings in using wearables, which is crucial for the adoption and long-term engagement of users in those applications. In this paper, we propose the concept of comfort wearables in the context of in-flight posture recognition. A comfort wearable and a tight-fit version, using identical hardware and software architecture, were prototyped and tested by 35 participants in a Boeing 737 cabin. During the usage of each wearable, participants were asked to perform seven frequently observed in-flight sitting postures and report their overall comfort/discomfort afterwards. A multilayer perceptron neural network was used to classify those activities. Experiment results indicated that participants appreciated the comfort wearable, rating it with significantly higher comfort scores and lower discomfort scores. Cross-validation results also revealed that using the comfort wearable achieved even better accuracy (74.8%) than using the tight-fit wearable (65.8%) in posture recognition. Outcomes of the study demonstrate that ergonomic design and technical accuracy are not competing factors in the wearable design and highlight the opportunities for designing and using comfort wearables in broader contexts.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Comparison of Wearable Inertial Sensors and RGB-D Cameras for Ergonomic Risk Assessment\n",
            "Authors: Ciccarelli M.\n",
            "Abstract: The increasingly high rate of work-related musculoskeletal disorders among workers is leading to the necessity for innovative systems for risk assessment. Although traditional methods for physical ergonomics assessment, based on the observation of working activity and manual compilation of standard analysis, are easy-to-use and very widespread, they provide a subjective evaluation and require a well-trained ergonomist. These factors lead to the requirement for objective evaluation and the new technologies can support the development of real-time risk assessment tools. Nowadays, the main technologies used for ergonomic assessment are inertial sensors and markerless depth cameras. Despite their reliability, the former are intrusive and expensive. This paper aims at comparing the accuracy and reliability of (1) wearable inertial sensors (as a reference) and (2) a markerless system composed of three RGB-D cameras. Using Machine Learning algorithms and open-source libraries, the system can track and record the operator movements and postures rebuilding the human skeleton. The proposed system has been tested in the laboratory where different static postures have been recorded. The preliminary experimentation provided satisfactory results in terms of accuracy and reliability.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Effects of Seat Tray Table Height and Body Anthropometry Dimensions on Passengers’ In-Flight Comfort\n",
            "Authors: Hamil M.H.F.\n",
            "Abstract: In-flight sitting comfort has become a key selection criterion for aircraft passengers when choosing their travel options among available flight services. This comfort feeling can often be associated with the ease of passengers in performing their typical in-flight activities. In view of this notion, having an appropriate height of the seat tray table that aptly matches the passengers’ body anthropometry is imperative to enable them to adopt comfortable sitting posture while doing their in-flight activities. In this study, an activity-based sitting comfort experiment is conducted in an aircraft cabin mock-up where the participants were asked to rate their comfort level when they used the seat tray table during eating, writing and typing activities at seven different settings of the tray table’s height: 66 cm, 69 cm, 72 cm, 75 cm, 78 cm, 81 cm and 84 cm. A total of 15 volunteers participated in the experiment and the collected sitting comfort data is then statistically analyzed through ANOVA method using the MINITAB software. The analysis results have indicated that the height of seat tray table and several passengers’ anthropometry parameters have high influences on their in-flight comfort level while performing their common in-flight activities. Additionally, the findings also suggested that there is a potential optimum setting of seat tray table’s height that can maximize the passengers’ comfort level.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Integration of capillaric strain sensors toward recognition of human movements\n",
            "Authors: Gasvoda H.\n",
            "Abstract: Capillaric strain sensors (CSSs) operate based on the volume expansion of closed microfluidic networks in response to linear strain and have tunable directionality and sensitivity in a large range. The unique advantages of CSSs for integrated sensor development can simplify the human movement recognition by eliminating the need for intensive computational power and reliance on machine learning algorithms. We borrowed strategies from electrical digital circuits for the integration of CSSs in OR and AND configurations. We have fabricated devices according to these strategies. To validate their functionality, we first performed tests on a benchtop model. We have mapped the strain field on the sensors using digital image correlation and used it in combination with a mathematical procedure that we have developed to accurately predict the response of the integrated CSSs (iCSSs). Finally, we have skin mounted the iCSS patches (2 × 2 cm2) and conducted tests on a human subject. The results demonstrate that skin-strain-field mapping will be an enabling tool for iCSS design toward the recognition of human movements.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Designing dual ontological products for human factors: a machine learning and harmonistic knowledge-based computational support tool\n",
            "Authors: Agius S.\n",
            "Abstract: The physical construct of a dual ontological product is essential for those products which physically interact directly with humans, whereas the product's emotional construct interconnects with human cognition. Multitude of human factor aspects must be considered when designing dual ontological products. To increase the product's impact and reach, designers should also understand the requirements of potential users. Designers find it difficult to achieve the right compromise between these constructions. This research therefore contributes a novel harmonistic knowledge-based computational support tool which makes designers aware of design stage conflicts and consequences of commitments made on human factors in the use phase of the artefact. This paper describes in detail the machine learning and harmonistic knowledge-based system which exploits information collected directly from potential users to proactively assist, guide, and motivate product designers. The paper takes the motorcycle artefact as a case of dual ontological product. The prototype support tool has been evaluated with 28 motorcycle design engineers. The results obtained from this evaluation have shown that the approach and design computational-based tool meet their goals, are beneficial, and are required in design engineering practice.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Critical Review on Risk Assessment Methods of Musculoskeletal Disorder (MSD)\n",
            "Authors: Siddhaiyan V.\n",
            "Abstract: The construction industry, even though equipped with advanced tools and machineries, is highly labour-intensive. Safety guidelines are rarely enforced in developing countries, resulting in a high rate of workplace accidents and illnesses. To execute the project on time, workers are urged to carry out repetitively for prolonged periods of time. Lower back pain is frequent in construction workers as a result of tasks that require a lot of energy, such as bending, as well as repeated uncomfortable positions or repetitive movements and standing for a long period. The current study paper reviewed the investigation of human physical movements, which lead to low back pain (LBP) among construction workers. Disabilities and missing workdays in those sectors are mainly due to LBP. This review article is started by retrieving and categorizing around 80 related research papers. It begins with an in-depth examination of current measurement systems for assessing the physical movements of workers on construction sites. Following that, various techniques for calculating work postures and movements are examined and correlated with technical advancements, and short comings and differences are highlighted. Finally, a few types of exoskeletons and their effects while performing tasks are discussed. Different postures are discussed to reduce the low back pain of workers while working in tasks like repetitive lifting and prolonged standing.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Research on intelligent recognition technology of gymnastics posture based on KNN fusion DTW algorithm based on sensor technology\n",
            "Authors: Fu D.\n",
            "Abstract: In order to realise the scientific and intelligent training of gymnasts, a research on the intelligent recognition algorithm of human movement and posture in the process of gymnastics using Kinect sensor technology is proposed this time. Firstly, Kinect sensor is used to obtain the basic data of human posture, and the relative distance and angle sequence of human joint points are taken as the basic characteristic parameters of posture recognition. After completing the training of the sample set, the KNN algorithm is used to recognise the gymnastics posture, match the standard target of the best angle curve and realise the evaluation of the movement. The DTW difference is used as the experimental parameter to obtain the final action score. This time, ten gymnasts are selected for simulation. The results of simulation analysis show that the proposed method can well realise the recognition and quantitative evaluation of gymnastic movements.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Operator 5.0: Enhancing the Physical Resilience of Workers in Assembly Lines\n",
            "Authors: Pilati F.\n",
            "Abstract: The human factor represents the most fragile and valuable resource in modern and low-standardized manufacturing environments. Indeed, the Operator 5.0 concept aims at achieving socially-inclusive workplaces by monitoring the well-being of workers during production cycles. To accomplish this challenging aim, this manuscript proposes a digital industrial Internet-of-Things architecture to monitor the physical resilience of Operator 5.0 in assembly lines. While a markerless motion capture camera is adopted to evaluate the ergonomic exposure, a superficial electromyography wearable acquires muscular contractions of upper limbs to perform a machine learning-based recognition of fatigue status. In this preliminary investigation, the main focus of the analysis is to digitize the European Assembly Worksheet to evaluate the worker's postures during the assembly of home furniture. Exploiting such ergonomic measurements, a Monte Carlo-based sensitivity analysis is leveraged to evaluate the noise in bending scenarios. Finally, a reference system is leveraged to assess the measurement error of the motion capture camera.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Technologies in Home-Based Digital Rehabilitation: Scoping Review\n",
            "Authors: Arntz A.\n",
            "Abstract: Background: Due to growing pressure on the health care system, a shift in rehabilitation to home settings is essential. However, efficient support for home-based rehabilitation is lacking. The COVID-19 pandemic has further exacerbated these challenges and has affected individuals and health care professionals during rehabilitation. Digital rehabilitation (DR) could support home-based rehabilitation. To develop and implement DR solutions that meet clients' needs and ease the growing pressure on the health care system, it is necessary to provide an overview of existing, relevant, and future solutions shaping the constantly evolving market of technologies for home-based DR. Objective: In this scoping review, we aimed to identify digital technologies for home-based DR, predict new or emerging DR trends, and report on the influences of the COVID-19 pandemic on DR. Methods: The scoping review followed the framework of Arksey and O'Malley, with improvements made by Levac et al. A literature search was performed in PubMed, Embase, CINAHL, PsycINFO, and the Cochrane Library. The search spanned January 2015 to January 2022. A bibliometric analysis was performed to provide an overview of the included references, and a co-occurrence analysis identified the technologies for home-based DR. A full-text analysis of all included reviews filtered the trends for home-based DR. A gray literature search supplemented the results of the review analysis and revealed the influences of the COVID-19 pandemic on the development of DR. Results: A total of 2437 records were included in the bibliometric analysis and 95 in the full-text analysis, and 40 records were included as a result of the gray literature search. Sensors, robotic devices, gamification, virtual and augmented reality, and digital and mobile apps are already used in home-based DR; however, artificial intelligence and machine learning, exoskeletons, and digital and mobile apps represent new and emerging trends. Advantages and disadvantages were displayed for all technologies. The COVID-19 pandemic has led to an increased use of digital technologies as remote approaches but has not led to the development of new technologies. Conclusions: Multiple tools are available and implemented for home-based DR; however, some technologies face limitations in the application of home-based rehabilitation. However, artificial intelligence and machine learning could be instrumental in redesigning rehabilitation and addressing future challenges of the health care system, and the rehabilitation sector in particular. The results show the need for feasible and effective approaches to implement DR that meet clients' needs and adhere to framework conditions, regardless of exceptional situations such as the COVID-19 pandemic.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Sitting posture Analysis using CNN and RCNN\n",
            "Authors: Nishitha R.\n",
            "Abstract: Based to statistics, about 80 percent of the population follows incorrect sitting posture. From the year 2020, due to the Covid-19 curfew, the traditional work office of many professionals turned into Work from home and remote office lifestyle. Many of the working professionals has no proper ergonomic workplace setup in their house leading to improper sitting position. Monitoring the sitting posture is needed to avoid chronic complication of MSD, neck, and spine related injuries. Many techniques were emerged for correcting and monitoring the posture. Neural Network based posture detection is being into the field of research as the come with more range of accuracy. This paper discusses about the various Neural Networks used and their accuracies.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A unified fuzzy system for evaluating work related postural risk score of discomfort prone body parts of workers through rapid upper limb assessment\n",
            "Authors: Ghosh B.\n",
            "Abstract: A unified fuzzy system has been developed in this paper for assessing weighted postural risk score (PRS) of body parts by reducing errors relating to human perception in measuring exact body joint angles corresponding to different working postures used as inputs of rapid upper limb assessment (RULA) process. In the proposed method a Mamdani fuzzy inference system is generated using two input parameters based on modified Nordic questionnaire and RULA. Fuzzy analytic hierarchy process is incorporated to calculate the weight of postural risk associated with each body part using the body part discomfort scale. Finally, weighted PRS of each body part is evaluated to identify the discomfort prone body parts for taking preventive strategies well in advance. To establish application potentiality of the proposed methodology a case study is performed for assessing weighted PRS of different discomfort prone body parts of female brick moulders engaged in several brick fields.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Utilization of Depth Camera to Ease Posture-Risk Assessment of Related Sitting Work\n",
            "Authors: Widodo R.B.\n",
            "Abstract: Sitting work posture is often used in office work. Work position failures when sitting can cause Musculoskeletal Disorders. Therefore, ergonomists are necessary for the workplace to assist workers' posture. However, these needs cannot be met due to the limited number of ergonomists and costs. So a practical and inexpensive semi-automatic application is needed. One method for assessing upper body work posture is RULA. This study aims to develop a posture assessment application for sitting work and suggest improvement. In addition, the effect of changes in room brightness, the variability of chair height, and types of office-work tasks were explored in this study to determine the accuracy level of the depth camera to measure the worker's posture. Research design uses empirical research with independent variables: room illuminance, chair height, and four types of office-work tasks. The two levels of room illuminance are 32 lux and 60 lux; the seat height consists of three levels, i.e., 40, 45, and 50cm, while four types of tasks include writing, typing, writing with a cheat sheet, and typing with a cheat sheet beside the Subject. The experiment tests the difference between the application's RULA estimation results and the ergonomist's RULA value. The experiment results showed that the proposed application successfully assessed RULA with the same results as the calculations by the ergonomist. This study makes posture assessment easier for sitting work and provides suggestions for posture improvement. In addition, automation of posture assessment using a depth camera helps provide evaluations and recommendations for improving posture while working sitting.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Visual Analytics for Automated Behavior Understanding in Learning Environments: A Review of Opportunities, Emerging Methods, and Challenges\n",
            "Authors: Syed Z.S.\n",
            "Abstract: Individuals' actions, interactions, and reactions to events involving them are referred to as human behavior. Traditional research in understanding human behavior has been dominated by psychology and sociology. However, in the age of Artificial Intelligence, it has evolved into a multidisciplinary research domain. The goal is to bring together computer scientists, engineers, psychologists, and sociologists to develop automated tools that use computer vision, computer audition, natural language processing, and machine-learning approaches that can assess verbal and nonverbal behavioral indicators of human behavior. Given that The student behavior is representative of their progress in learning and student-teacher behavioral synchrony indicates teaching quality. Thus, the automated behavior research understanding has great potential to do tremendous good. Behavioral computing approaches may be used to recognize student actions such as hand raising, standing, sitting, note-taking, but also to infer behavioral cues such as body posture, facial expressions, head nods, and eye-gaze direction. Such actions can be used to measure the latent behavior states such as attention, concentration, and engagement. These approaches may also be used to study various teaching strategies and identify the ones which improve attention and engagement. Human behavior understanding, therefore, has a great potential to revolutionize how students and teachers engage in learning environments. It can also be used to improve teaching quality. This chapter examines the potential applications of visual sensing in classroom-based learning environments. We review current trends for data collection and data annotation to identify their limitations along with possible solutions. To complete the machine-learning pipeline, we review several domain-knowledge-based features alongside automated feature engineering and machine-learning algorithms to identify their merits and demerits. Finally, we present emerging methods from other domains of human behavior research that may also be used for classroom behavior understanding.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Real time enhancement of operator's ergonomics in physical human - robot collaboration scenarios using a multi-stereo camera system\n",
            "Authors: Arvanitis G.\n",
            "Abstract: In collaborative tasks where humans work alongside machines, the robot's movements and behaviour can have a significant impact on the operator's safety, health, and comfort. To address this issue, we present a multi-stereo camera system that continuously monitors the operator's posture while they work with the robot. This system uses a novel distributed fusion approach to assess the operator's posture in real-time and to help avoid uncomfortable or unsafe positions. The system adjusts the robot's movements and informs the operator of any incorrect or potentially harmful postures, reducing the risk of accidents, strain, and musculoskeletal disorders. The analysis is personalized, taking into account the unique anthropometric characteristics of each operator, to ensure optimal ergonomics. The results of our experiments show that the proposed approach leads to improved human body postures and offers a promising solution for enhancing the ergonomics of operators in collaborative tasks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Visual-Inertial Fusion-Based Human Pose Estimation: A Review\n",
            "Authors: Li T.\n",
            "Abstract: Human pose estimation provides valuable information for biomedical research on human movement and applications, such as entertainment and physical exercise. The fusion of visual and inertial data has been increasingly studied in the past two decades to take advantage of these two naturally complementary sensing modalities. In this article, we systematically reviewed the advances in visual-inertial fusion-based human pose estimation with a thorough search for related studies in five mainstream literature databases. A total of 54 studies were identified and included by screening 4586 records retrieved in the review process. The estimation targets, hardware design, fusion methods, evaluation metrics, and system accuracy of these included studies were summarized and categorized for analysis. From these state-of-the-art studies, challenges in terms of mobility, calibration, real-time estimation, and evaluation methods are further discussed in depth and possible directions to overcome these issues are recommended. We expect that this systematic review can provide researchers and engineers with a thorough idea of the progress and performance in visual-inertial fusion-based human pose estimation. We also hope that the discussions on challenges and possible future directions can facilitate future work to improve such systems and promote their applications in real life.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Towards a User-specific Ergonomics-based Approach for an Activity Assessment Tool\n",
            "Authors: Martins D.\n",
            "Abstract: Work-related musculoskeletal disorders (WRMSDs) are the most reported work-related health problem in European Union. These are multifactorial disorders, influenced not only by sustained or repeated awkward postures but also by each worker's individual and psychosocial context. Thus, it becomes crucial to quantify and automatize risk assessment, in an attempt to prevent and reduce WRMSD. This work presents the design of a solution for a user-specific assessment based on ergonomics for posture correction through an intuitive haptic feedback strategy to increase posture self-awareness and guide the user into a more neutral posture. The user's angular configurations are continuously evaluated with a risk score, based on an ergonomic method, and then associated with the postures where those risks occurred. Posture is intended to be predicted by a deep learning model. Moreover, a joint kinematic wear index is used to carry out a cumulative assessment, taking into account the past postures' scores. Inertial data from three individuals was collected and analyzed to perform movement analysis and define the ground truth of the recognition model. The resulting kinematic parameters' ranges are presented. An offline risk assessment was also conducted, showing the potential of the cumulative approach for a more complete and meaningful evaluation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Workability and productivity among CTL machine operators–associations with sleep, fitness, and shift work\n",
            "Authors: Kymäläinen H.\n",
            "Abstract: Operational performance of fully mechanized cut-to-length (CTL) harvesting varies greatly due to the human factor i.e. the machine operator. This study investigated how CTL machine operators’ workability index (WAI), personal lifestyle choices, seasons, and shift work affected operational performance. Research evaluated 14 volunteer CTL machine operators for a longitudinal study with continuous data collection of productivity, activity level, sleep, and follow-up on a workability index questionnaire and fitness test every three months over a year. The study analyzed the production of 152 745.5 m3 of timber combined with self-tracking data. Operators’ relative productivity (Pr) had an increasing trend whilst WAI increased, thus WAI seems to work well also for forestry applications. Physical fitness (VO2max) didn’t seem to connect with Pr and WAI had only a slightly increasing trend when VO2max increased. The participants slept longer in the evening shift than in the morning shift (p < 0.000) consequently catching up on their sleep deficit from the morning shift period. Furthermore, operators’ higher sleep value (SV) in the evening shift increased Pr in the final fellings. The results should be of interest to both practitioners and researchers interested in the productivity of harvesting operations.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Postures anomaly tracking and prediction learning model over crowd data analytics\n",
            "Authors: Aljuaid H.\n",
            "Abstract: Innovative technology and improvements in intelligent machinery, transportation facilities, emergency systems, and educational services define the modern era. It is difficult to comprehend the scenario, do crowd analysis, and observe persons. For e-learning-based multiobject tracking and predication framework for crowd data via multilayer perceptron, this article recommends an organized method that takes e-learning crowd-based type data as input, based on usual and abnormal actions and activities. After that, super pixel and fuzzy c mean, for features extraction, we used fused dense optical flow and gradient patches, and for multiobject tracking, we applied a compressive tracking algorithm and Taylor series predictive tracking approach. The next step is to find the mean, variance, speed, and frame occupancy utilized for trajectory extraction. To reduce data complexity and optimization, we applied T-distributed stochastic neighbor embedding (t-SNE). For predicting normal and abnormal action in e-learning-based crowd data, we used multilayer perceptron (MLP) to classify numerous classes. We used the three-crowd activity University of California San Diego, Department of Pediatrics (USCD-Ped), Shanghai tech, and Indian Institute of Technology Bombay (IITB) corridor datasets for experimental estimation based on human and nonhuman-based videos. We achieve a mean accuracy of 87.00%, USCD-Ped, Shanghai tech for 85.75%, and IITB corridor of 88.00% datasets.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Novel Computationally Efficient Approach to Identify Visually Interpretable Medical Conditions from 2D Skeletal Data\n",
            "Authors: Jesudhas P.\n",
            "Abstract: Timely identification and treatment of medical conditions could facilitate faster recovery and better health. Existing systems address this issue using custom-built sensors, which are invasive and difficult to generalize. A low-complexity scalable process is proposed to detect and identify medical conditions from 2D skeletal movements on video feed data. Minimal set of features relevant to distinguish medical conditions: AMF, PVF and GDF are derived from skeletal data on sampled frames across the entire action. The AMF (angular motion features) are derived to capture the angular motion of limbs during a specific action. The relative position of joints is represented by PVF (positional variation features). GDF (global displacement features) identifies the direction of overall skeletal movement. The discriminative capability of these features is illustrated by their variance across time for different actions. The classification of medical conditions is approached in two stages. In the first stage, a low-complexity binary LSTM classifier is trained to distinguish visual medical conditions from general human actions. As part of stage 2, a multi-class LSTM classifier is trained to identify the exact medical condition from a given set of visually interpretable medical conditions. The proposed features are extracted from the 2D skeletal data of NTU RGB + D and then used to train the binary and multi-class LSTM classifiers. The binary and multi-class classifiers observed average F1 scores of 77% and 73%, respectively, while the overall system produced an average F1 score of 69% and a weighted average F1 score of 80%. The multi-class classifier is found to utilize 10 to 100 times fewer parameters than existing 2D CNN-based models while producing similar levels of accuracy.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Validation of non-radiographic APECS software in comparison with standard radiographic measurement of full-length lower limb hip-knee-ankle angle in elderly obese women\n",
            "Authors: Welling A.\n",
            "Abstract: Introduction. Evidence suggests that obesity and ageing in women are linked to angular knee abnormalities. The hip-kneeankle (HKA) angle on a full-limb radiograph is the gold standard measure of lower limb alignment. The AI Posture Evaluation and Correction System (APECS) software is a non-radiographic mobile application designed for whole-body posture assessment. Since exposure to X-ray is associated with harmful effects, there is a need to find a safe and valid alternative for measuring HKA angle. The objective of this research was to determine the validity of the non-radiographic APECS software in comparison with standard radiographic measurement of HKA angle. Methods. The present cross-sectional diagnostic accuracy study was conducted in a tertiary care hospital of Belagavi, Karnataka, India. Overall, 45 elderly obese females aged 60-80 years with a body mass index of ≥25 were included. HKA angle was marked bilaterally. Full-limb radiographs were taken and angles were marked with 2.0 version software, DXM model. For the APECS software, full-limb photographs were taken with landmarks indicated with radiant markers and angles were autogenerated by the software. Results. The Pearson correlation coefficient between the APECS application and the gold standard (X-ray) was 0.9874 (98.74% of matching). The agreement between standard radiograph and the average of all examiners' APECS Pro measurements (including right and left sides) equalled 94.64% (kappa = 0.8323; p = 0.001), which suggests very good agreement. Conclusions. The APECS application demonstrated a high percentage of matching (98.74%) and agreement (94.64%), indicating its excellent validity in measuring HKA angle.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The Application of Multimedia and Deep Learning in the Integration of Professional and Innovative Education in Colleges\n",
            "Authors: Xu S.\n",
            "Abstract: In this paper, the authors study the assessment of professional practice courses in the integrated education of specialization and innovation, and use the multimedia and deep learning technology to complete the action recognition of students in practice courses. Firstly, the skeletal features are extracted from multimedia video data by Openpose algorithm, which is used for subsequent classification while ensuring privacy; then the LSTM method is used to recognize typical motions in student practice, and the average recognition result exceeds 89%; finally, practical application tests are conducted for laboratory and office scenes, and the results illustrate that the proposed framework performs well in the tests with recognition rate exceeding 80%. The algorithm framework provides a new idea for the curriculum setting and evaluation method of professional practice education, and gives data guarantee for their integration and innovation education.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Computer Users Sitting Posture Classification Using Distinct Feature Points and Small Scale Convolutional Neural Network for Humana Computer Intelligent Interactive System During COVID-19\n",
            "Authors: Estrada J.\n",
            "Abstract: The sudden change in our workplace practices from face-to-face work to work from home setup due to the pandemic has brought positive and negative impacts on our overall health. In literature, the use of deep learning and specialized cameras in the estimation of the human pose is popular even if there is a need for high computational resources and complex models. For this purpose, this study developed an intelligent and interactive system utilizing a human estimation model with the use of distinct keypoint such as thoracic, thoraco lumbar, and lumbar points in the spine. An objective type of a dataset captured in a work from home environment with the knowledge and guidance of Licensed Physical Therapists to assess proper and improper sitting posture was developed. The study developed and implemented a small-scale convolutional network and low-cost smartphone camera to recognize body key points. Once all the feature points' locations were extracted, additional features such as cosine similarity and point distances were calculated. Next, feature selection and optimization were utilized to classify proper and improper sitting postures. As a result, the study developed (2) datasets and (2) models with an accuracy of 85.18 and 92.07% and kappa of 0.691 and 0.838 respectively.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Bad Sitting Posture Detection and Alerting System using EMG Sensors and Machine Learning\n",
            "Authors: Laidi R.\n",
            "Abstract: Poor sitting posture can lead to a variety of serious diseases raging from spinal disorders to psychological stress. This paper aims to design a sitting posture monitoring system that detects improper postures and notifies the user in real time through a mobile application. The system leverages the use of low-cost EMG sensors, and relies on energy-efficient communication via Bluetooth Low energy (BLE). To ensure bad posture detection, different machine learning algorithms are tested and compared, namely support vector machine (SVM), K-nearest neighbours (KNN), decision tree (DT), random forest (RF), and multi-layer perception (MLP). We formulated the problem as a binary classification (good vs. bad posture) and multi-class classification (good, tilted to the front, right and left). The results of the training performed on a real dataset showed that KNN have the best accuracy (91% accuracy) and execution time (0.0066 ms).\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Classification of Yoga Poses Using Integration of Deep Learning and Machine Learning Techniques\n",
            "Authors: Kundu K.\n",
            "Abstract: Pose estimation is a classical problem in computer vision. With the recent change across the globe, there is much focus on self-care with the help of yoga. To derive the desired benefits of yoga, the poses must be done as per its correct posture. Information about the name of yoga pose gives one idea about its associated benefits. In this paper, the majority voting classifier is utilized for voting out the given yoga pose into five classes (goddess pose, downward dog pose, plank pose, tree pose, and warrior 2 pose). Voting classifier is explored to improve the accuracy of stacked individual ensemble classifiers (AdaBoost, bagging, and dagging classifier). Classification accuracy is evaluated with the help of standard machine learning evaluation metrics like precision, recall, F1-score, area under curve (AUC). Experimental results validate the improved performance of voting classifier as compared to individual classifiers. Higher average F1-score of 0.9755, as compared to scores of bagging classifier, classifier, and AdaBoost classifier, also confirms the better balance of precision and recall metrics and better tolerance to the imbalanced or small datasets.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Image Illumination Enhancement for Construction Worker Pose Estimation in Low-light Conditions\n",
            "Authors: Chen X.\n",
            "Abstract: Many construction scenes feature low-light work, such as nighttime construction and tunnel construction. Poor lighting and low visibility will increase the risk of site accidents. One of the leading causes of construction accidents is unsafe worker behavior, which can be predicted via worker posture estimation. Therefore, this study proposes an Unsupervised Illumination Reflectance Estimation (UIRE-Net) framework for estimating the dark worker pose. On the basis of lightness-color consistency, in spite of ungratified illumination conditions, the “true color” of objects depends on the illumination reflectance only. The illumination reflectance estimation is monotonous to neighboring pixel differences, making the extracted features robust for worker pose estimation. In addition, the proposed UIRE-Net restores image brightness without relying on image pairs. A testing experiment based on nighttime construction workers is conducted to validate the veracity.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An application of building information modelling-based approach and current developments towards ergonomic risk assessment in the construction sector - a systematic review\n",
            "Authors: Singh A.K.\n",
            "Abstract: For ages, construction has been obligatory in human life and more so in today's technologically advanced society. The construction sector includes several activities like brick masonry, plastering, carpentry and various other activities that involve complex and awkward working postures, which may lead to work in the long run related to musculoskeletal disorders. Therefore, ergonomics assessment of the construction sector is of utmost importance. Literature indicates that several tools and techniques for ergonomics risk assessment of construction sites are available, e.g., pre-job assessment check, smartphone-based sensor methods, workers posture assessment, maximum lifting strength test and building information modelling (BIM). The current review focuses on the ergonomic aspects of the construction industry, emphasising the optimisation of worksites and equipment with design modifications applying ergonomic interventions. The paper further demonstrates the application of the hybrid technique of simulating construction sites and ergonomics risk assessment of the same using BIM.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Intelligent Sitting Posture Classifier for Wheelchair Users\n",
            "Authors: Vermander P.\n",
            "Abstract: In recent years, there has been growing interest in postural monitoring while seated, thus preventing the appearance of ulcers and musculoskeletal problems in the long term. To date, postural control has been carried out by means of subjective questionnaires that do not provide continuous and quantitative information. For this reason, it is necessary to carry out a monitoring that allows to determine not only the postural status of wheelchair users, but also to infer the evolution or anomalies associated with a specific disease. Therefore, this paper proposes an intelligent classifier based on a multilayer neural network for the classification of sitting postures of wheelchair users. The posture database was generated based on data collected by a novel monitoring device composed of force resistive sensors. A training and hyperparameter selection methodology has been used based on the idea of using a stratified K-Fold in weight groups strategy. This allows the neural network to acquire a greater capacity for generalization, thus allowing, unlike other proposed models, to achieve higher success rates not only in familiar subjects but also in subjects with physical complexions outside the standard. In this way, the system can be used to support wheelchair users and healthcare professionals, helping them to automatically monitor their posture, regardless physical complexions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Musculoskeletal disorders risk assessment methods: a scoping review from a sex perspective\n",
            "Authors: Serna Arnau S.\n",
            "Abstract: The evidence points to differences in the impact of musculoskeletal disorders (MSD) in males and females due to different exposure to risk factors and inherent characteristics. To identify risks associated with MSDs, ergonomic assessment is carried out by applying various methods. The aim of this scoping review was to determine to what extent ergonomic assessment methods consider sex-related factors and if they were found to do so, to determine the extent of this consideration. A total of 31 papers on 32 ergonomic assessment methods were analysed in the review. Of these 32 methods, only 6 considered sex as an assessment parameter or when interpreting the results. The results revealed that the limited consideration given to the sex factor in ergonomic methods, together with the different impacts of MSDs and their consequences according to a person’s sex, supports the importance of including sex factors in ergonomic assessment methods. Practitioner summary: This scoping review determined to what extent ergonomic assessment methods consider sex-related factors and if they do so, to establish the extent of such consideration. Of the 32 methods analysed, only 6 considered a person’s sex. The results revealed that only a limited consideration is given to the sex factor in ergonomic methods.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: BiomacVR: A Virtual Reality-Based System for Precise Human Posture and Motion Analysis in Rehabilitation Exercises Using Depth Sensors\n",
            "Authors: Maskeliūnas R.\n",
            "Abstract: Remote patient monitoring is one of the most reliable choices for the availability of health care services for the elderly and/or chronically ill. Rehabilitation requires the exact and medically correct completion of physiotherapy activities. This paper presents BiomacVR, a virtual reality (VR)-based rehabilitation system that combines a VR physical training monitoring environment with upper limb rehabilitation technology for accurate interaction and increasing patients’ engagement in rehabilitation training. The system utilises a deep learning motion identification model called Convolutional Pose Machine (CPM) that uses a stacked hourglass network. The model is trained to precisely locate critical places in the human body using image sequences collected by depth sensors to identify correct and wrong human motions and to assess the effectiveness of physical training based on the scenarios presented. This paper presents the findings of the eight most-frequently used physical training exercise situations from post-stroke rehabilitation methodology. Depth sensors were able to accurately identify key parameters of the posture of a person performing different rehabilitation exercises. The average response time was 23 ms, which allows the system to be used in real-time applications. Furthermore, the skeleton features obtained by the system are useful for discriminating between healthy (normal) subjects and subjects suffering from lower back pain. Our results confirm that the proposed system with motion recognition methodology can be used to evaluate the quality of the physiotherapy exercises of the patient and monitor the progress of rehabilitation and assess its effectiveness.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Human Postures Recognition by Accelerometer Sensor and ML Architecture Integrated in Embedded Platforms: Benchmarking and Performance Evaluation\n",
            "Authors: Leone A.\n",
            "Abstract: Embedded hardware systems, such as wearable devices, are widely used for health status monitoring of ageing people to improve their well-being. In this context, it becomes increasingly important to develop portable, easy-to-use, compact, and energy-efficient hardware-software platforms, to enhance the level of usability and promote their deployment. With this purpose an automatic tri-axial accelerometer-based system for postural recognition has been developed, useful in detecting potential inappropriate behavioral habits for the elderly. Systems in the literature and on the market for this type of analysis mostly use personal computers with high computing resources, which are not easily portable and have high power consumption. To overcome these limitations, a real-time posture recognition Machine Learning algorithm was developed and optimized that could perform highly on platforms with low computational capacity and power consumption. The software was integrated and tested on two low-cost embedded platform (Raspberry Pi 4 and Odroid N2+). The experimentation stage was performed on various Machine Learning pre-trained classifiers using data of seven elderly users. The preliminary results showed an activity classification accuracy of about 98% for the four analyzed postures (Standing, Sitting, Bending, and Lying down), with similar accuracy and a computational load as the state-of-the-art classifiers running on personal computers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: CREBAS: Computer-Based REBA Evaluation System for Wood Manufacturers Using MediaPipe\n",
            "Authors: Jeong S.O.\n",
            "Abstract: Recently, musculoskeletal disorders (MSDs) caused by repetitive working postures in industrial sites have emerged as one of the biggest problems in the field of industrial health. The risk of MSDs caused by the repetitive working postures of workers is quantitatively evaluated by using NLE (NIOSH Lifting Equation), OWAS (Ovako Working-posture Analysis System), RULA (Rapid Upper Limb Assessment), REBA (Rapid Entire Body Assessment), etc. Methods used for the working posture analysis include vision-based analysis and motion capture analysis. Vision-based analysis is a method where an expert with ergonomics knowledge watches and manually analyzes recorded working images. Although the analysis is inexpensive, it takes a lot of time to analyze. In addition, the analyst’s subjective opinions or mistakes may be reflected in the results, so it may be somewhat unreliable. On the other hand, motion capture analysis can obtain more accurate and consistent results, but its measurement equipment is very expensive and it requires a large space for measurement. In this paper, we propose a computer-based automated REBA system that can evaluate, automatically and consistently, working postures in order to supplement the shortcomings of these existing methods. The CREBA system uses the body detection learning model of MediaPipe to detect the worker’s area in the recorded images and sets the body area based on the position of the face, detected using the face tracking learning model. In the set area, the positions of joints are tracked using the posture tracking learning model, and the angles of joints are calculated based on the joint positions using the inverse kinematics, and then by automatically calculating the degree of load of the working posture with the REBA evaluation method. In order to verify the accuracy of the evaluation results of the CREBA system, we compared them with the experts’ vision-based REBA evaluation results. The result of the experiment showed a slight difference of about 1.0 points between the evaluation results of the expert group and those of the CREBA system. It is expected that the ergonomic analysis method for the working posture used in this study will reduce workers’ labor intensity and improve their safety and efficiency.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Predicting Wrist Posture during Occupational Tasks Using Inertial Sensors and Convolutional Neural Networks\n",
            "Authors: Young C.\n",
            "Abstract: Current methods for ergonomic assessment often use video-analysis to estimate wrist postures during occupational tasks. Wearable sensing and machine learning have the potential to automate this tedious task, and in doing so greatly extend the amount of data available to clinicians and researchers. A method of predicting wrist posture from inertial measurement units placed on the wrist and hand via a deep convolutional neural network has been developed. This study has quantified the accuracy and reliability of the postures predicted by this system relative to the gold standard of optoelectronic motion capture. Ten participants performed 3 different simulated occupational tasks on 2 occasions while wearing inertial measurement units on the hand and wrist. Data from the occupational task recordings were used to train a convolutional neural network classifier to estimate wrist posture in flexion/extension, and radial/ulnar deviation. The model was trained and tested in a leave-one-out cross validation format. Agreement between the proposed system and optoelectronic motion capture was 65% with (Formula presented.) = 0.41 in flexion/extension and 60% with (Formula presented.) = 0.48 in radial/ulnar deviation. The proposed system can predict wrist posture in flexion/extension and radial/ulnar deviation with accuracy and reliability congruent with published values for human estimators. This system can estimate wrist posture during occupational tasks in a small fraction of the time it takes a human to perform the same task. This offers opportunity to expand the capabilities of practitioners by eliminating the tedium of manual postural assessment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Remote-Vision-Based Safety Helmet and Harness Monitoring System Based on Attribute Knowledge Modeling\n",
            "Authors: Wu X.\n",
            "Abstract: Remote-vision-based image processing plays a vital role in the safety helmet and harness monitoring of construction sites, in which computer-vision-based automatic safety helmet and harness monitoring systems have attracted significant attention for practical applications. However, many problems have not been well solved in existing computer-vision-based systems, such as the shortage of safety helmet and harness monitoring datasets and the low accuracy of the detection algorithms. To address these issues, an attribute-knowledge-modeling-based safety helmet and harness monitoring system is constructed in this paper, which elegantly transforms safety state recognition into images’ semantic attribute recognition. Specifically, a novel transformer-based end-to-end network with a self-attention mechanism is proposed to improve attribute recognition performance by making full use of the correlations between image features and semantic attributes, based on which a security recognition system is constructed by integrating detection, tracking, and attribute recognition. Experimental results for safety helmet and harness detection demonstrate that the accuracy and robustness of the proposed transformer-based attribute recognition algorithm obviously outperforms the state-of-the-art algorithms, and the presented system is robust to challenges such as pose variation, occlusion, and a cluttered background.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Is low-cost motion capture with artificial intelligence applicable for human working posture risk assessment during manual material handling? A pilot study\n",
            "Authors: Zhang R.\n",
            "Abstract: BACKGROUND: Assessing working posture risks is important for occupational safety and health. However, low-cost assessment techniques for human motion injuries in the logistics delivery industry have rarely been reported. OBJECTIVE: To propose a novel approach for posture risk assessment using low-cost motion capture with artificial intelligence. METHODS: A Kinect was adopted to obtain red-green-blue (RGB) and depth images of the subject with 24 postures, and the human joints were extracted using artificial intelligence. The images were registered to obtain the actual three-dimensional (3D) human joint angle. RESULTS: The root mean square error (RMSE) significantly decreased. Finally, two common methods for evaluating human working posture injuries - the Rapid Upper Limb Assessment and Ovako Working Posture Analysis System - were investigated. CONCLUSIONS: The outputs of the proposed method are consistent with those of the commercial ergonomic evaluation software.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomics Evaluation Using Motion Capture Technology—Literature Review\n",
            "Authors: Rybnikár F.\n",
            "Abstract: Due to the increasingly high proportion of manual activities in production processes, there is a constant risk of musculoskeletal disorders or work-related injuries. The risk of these problems is exacerbated by the trend towards an ageing working population. European legislation is pressing for improved working conditions to eliminate the risks associated with health problems for workers. For this reason, the application of ergonomics in this field is growing. Musculoskeletal disorders, which are most often caused by inappropriate working postures, are a major problem. There are many methods for evaluating working postures. However, there is a high degree of subjectivity in the risk assessment. Motion capture kinematic suits can ensure the objectivity of the assessment. This article discusses research on ergonomics assessment using motion capture technology. A systematic literature search method was used for the research, beginning with the determination of the research procedure, through the definition of the research queries, to the formulation of the research itself to identify relevant sources. The study presents the most widely used methods for assessing the ergonomics of work positions using motion capture technology, their advantages, and disadvantages. It also follows the trend in the number of publications between 2010 and 2022 in countries where the topic is most frequently addressed and in the industries where motion capture technology is used for ergonomics assessment in general. The research showed that this approach is most often used in industry and logistics, and less frequently in healthcare and sport. The authors agree that the most frequently used ergonomics assessment methods are not complex enough to be used in combination with motion capture and that a combination of the two is needed. At the same time, this technology has become very important in the field of ergonomic evaluation of work positions, offering a higher degree of objectivity, or can be combined with the use of virtual reality, but the evaluation systems are still not error-free and there is a need for continuous improvement.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An Effective Methodology for Movement Evaluation in Patients with Parkinson’s Disease\n",
            "Authors: Calì M.\n",
            "Abstract: Analyzing pathological movements can substantially help neurologists in the diagnosis and treatment improvement for patients with Parkinson’s disease (PD). A linkage between the intensity and characteristics of moving and walking disorders and the stage and types of PD can be actually established. The main aim of this study is to develop an effective methodology that allows to evaluate, in real time and / or in deferred time, movements and posture of PD patients in their usual living environments. For this purpose, a wearable suit with Inertial Measurement Unit (IMU) sensors was designed; it has made it possible to acquire linear and angular signals of displacement, velocity and acceleration of the most relevant body points of the patients. The filtered and integrated signals were then used to animate a human parametric multibody model that virtually reproduces in real time and / or in deferred patient’s movements and posture. Serving as the patient's “avatar”, the multibody model enables the neurologist to carry out an accurate assessment of the patient’s movements and posture (freezing, festination, postural balance) as well as to measure disease progression and response to interventions. If compared to traditional 3D video-based motion analysis systems, the proposed method has the advantage of providing a more accurately measurable patients movements analysis and comparison performed in their usual living environments in real-world conditions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic Characteristics of Expert Masons\n",
            "Authors: Ryu J.\n",
            "Abstract: Masons are aided by ergonomic inventions such as tools, processes, and equipment, yet they are still subjected to performing physically demanding and hazardous tasks at the worksite. Experienced masons have a high level of job satisfaction; however, they also experience a high rate of attrition during their training phase and do not, on average, experience as long of a working life as nonconstruction workers. By analyzing expert masons' performance, in terms of body kinematics and load levels, during various masonry activities, guidelines for the training of a safer and more productive generation of masons can be formulated. This study investigated expert masons' performance and ergonomic characteristics during seven common masonry activities. Specifically, eight expert masons with over 20 years of experience laid out 16.6 kg concrete masonry units (CMUs) to construct a standard wall, a reinforced wall, a wall in constraint space (under ceiling), and the first course. They also utilized individual and collaborative lifts to build a five-course wall using 23 kg CMUs and collaborative lifts to build the same configuration using 35.2 kg CMUs. Inertial motion capture systems captured their motion, and a biomechanical analysis determined the load experienced by major body joints in each activity. The present study contributes to the body of knowledge by providing insights into expert masons' distinctive ergonomic characteristics in seven common masonry activities. Our findings open the door to providing apprentices with improved training based on those characteristics. We quantified the impact of optimized work configurations (working height for picking up and laying down material at about waist level) on minimizing musculoskeletal risks. A more significant impact on masons' safety, health, and productivity is expected by applying expert masons' biomechanical strategies in designing and/or redesigning work systems for a safer generation of masons.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Human Intrusion Detection in Static Hazardous Areas at Construction Sites: Deep Learning-Based Method\n",
            "Authors: Mei X.\n",
            "Abstract: Construction sites have complex environments and high accident rates. Human intrusion into static hazardous areas is a significant cause of accidents. Traditional engineering safety management mainly relies on manual methods, such as patrol inspection by safety supervisors, which is time-consuming and labor-intensive, and it is difficult to achieve a complete safety supervision. In recent years, the emergence of artificial intelligence technology and computer vision has provided a new scheme for intrusion detection. However, existing studies have used a single method for human intrusion judgment in static dangerous areas, without in-depth consideration of the influence of human posture, intrusion direction, and other factors. In this study, a computer vision-based intrusion detection method was developed, mainly aimed at static hazardous areas. The object detection was based on the You Only Look Once (YOLO) V5 module to extract the image feature information. Subsequently, the basic rule of intrusion judgment based on the key points of bounding boxes was formulated, in which the workers' intrusion direction was recognized and postured using two auxiliary detection modules. Finally, the intrusion rule base was constructed as the basis for human intrusion detection, containing rules with different sensitivities for different intrusion states. The case study indicated that the precision and recall rate of the algorithm were 96.05% and 90.05%, respectively. Overall, this method can effectively address the defects of manual supervision in engineering safety management, reducing the probability of accident occurrence and enhancing safety at construction sites.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Posture Interactive Self Evaluation Algorithm Based on Computer Vision\n",
            "Authors: Barberi E.\n",
            "Abstract: Many workers and citizens have been forced to make a lifestyle change in the past two years due to the pandemic emergency. In order to keep a high level of personal health, the doctors suggest to do fitness exercises. Before the pandemic it was possible to do these exercises at the gym or during dedicated session in the office supervised by professional trainers. During the pandemic emergency the gyms were closed, the workers were forced to stay home and the people started to do gym exercises by themselves without the control of a professional figure. This situation could lead to several diseases associated to musculoskeletal disorders if the exercises are performed incorrectly. In this work, an approach based on the pose-estimator application OpenPose is developed. The reference exercise is an isometric squat performed by a professional trainer. During the exercise, thanks to a deep neural network, the pose-estimator gets a series of key-points and vectors which represent the user’s pose. A dataset of videos (for both the correct and incorrect postures) has been used to train several machine learning algorithms. The result is an automatic tool that recognizes incorrect poses during the exercise and helps the performer to correct it.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Markerless Motion Capture and Virtual Reality for Real-Time Ergonomic Analysis of Operators in Workstations with Collaborative Robots: a preliminary study\n",
            "Authors: Lanzoni D.\n",
            "Abstract: Collaborative robots (cobots) are designed to directly interact with human beings within a shared workspace. To minimize the risk of musculoskeletal disease for the workers, a physical ergonomic assessment of their interaction is needed. Virtual reality (VR) and motion capture (Mocap) systems can aid designers in building low-hazard collaborative environments. This work presents a framework based on VR and Mocap systems for the ergonomic evaluation of collaborative robotic workstations. Starting from the 3D models of the cobot and workstation components, a virtual environment is built in Unity and ROS is employed to manage the cobot behavior. The physical ergonomics is evaluated by means of RULA methodology, exploiting the body tracking capabilities of the device Kinect Azure, a low-cost markerless Mocap system. The framework has been tested by building a virtual environment for collaborative control of flanges with different diameters. The worker interacts with a six-axis Nyro One to move parts on the workstation. The ergonomic assessment is performed in real-time, and a report is generated for later uses and evaluations. The proposed framework fosters the design of collaborative robotics workstations based on an objective assessment of ergonomics. The results of this research work allow planning future development steps for the emulation of more complex workstations with cobots and the use of augmented reality to evaluate how to modify existing workstations to introduce a cobot.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Performance and Ergonomic Characteristics of Expert Masons\n",
            "Authors: Ryu J.\n",
            "Abstract: Masons are aided by ergonomic inventions like tools, processes, and equipment, yet they are still subjected to performing physically demanding and hazardous tasks at the worksite. With advances in materials, design, and automation, the masonry work system may be modified to minimize the bodily harm associated with the industry. Analysis of the extensive motion data collected on masonry work enables us to understand the ergonomic risks of masonry tasks. Previous studies found that expert masons adopted ergonomically safer and more productive work methods than less experienced masons, as from analyzing the experts’ body kinematics and biomechanical force levels during masonry activities, we can provide training for a safer and more productive generation of masons. To achieve these goals, we investigated the expert masons’ work methods during four masonry activities to determine the associated risk. Specifically, eight expert masons with over 20 years of experience, laid out 16.6 kg concrete masonry units (CMUs) to construct (1) a standard wall, (2) a reinforced wall, (3) a wall in constraint space (under ceiling), and (4) a lead (first) course. Motion capture suits captured their motions, and a biomechanical analysis determined the load experienced by major body joints in each activity. The study found that the most critical body joints were in the lower back and upper limbs, as strain to these joints may lead to days away from work or, in severe cases, retirement. Furthermore, the results provided insights into expert masons’ distinctive work techniques through ergonomic evaluation for various masonry tasks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Video-Based 3D pose estimation for residential roofing\n",
            "Authors: Wang R.\n",
            "Abstract: Residential roofers are often exposed to awkward postures and motions in a prolonged time, which may not only reduce their body stability and increase fall potential, but also increase the risk of musculoskeletal disorders (MSDs). To assess their risks of fatal and musculoskeletal injuries, it is crucial to capture 3D body poses of workers during roofing tasks. In this paper, we proposed a novel two-stage motion estimation approach based on a convolution neural network to estimate residential roofer’s body poses using three-view video data. Our approach includes two stages: (1) use of an offline multi-view model to estimate the 3D pose in a single frame; (2) use of a multi-frame model to apply temporal convolutions to refine the multi-view outputs. The performance of the approach was evaluated by comparing our estimation with the gold-standard marker-based 3D human pose during one of the common residential roofing tasks–shingle installation. The evaluation results show that the proposed multi-frame model can effectively improve the accuracy of the coordinate sequence. Moreover, these results prove that the proposed video-based motion estimation approach can efficiently and accurately locate 3D body joints and pave the way for future onsite motion analysis during roofing activities.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Localization and posture recognition via magneto-inductive and relay-aided sensor networks\n",
            "Authors: Schulten H.R.L.\n",
            "Abstract: Body-centric wireless sensor networks are expected to enable future technologies such as medical in-body micro robots or unobtrusive smart textiles. These technologies may advance personalized healthcare as they allow for tasks such as minimally invasive surgery, in-body diagnosis, and continuous activity recognition. However, the localization of individual sensor nodes within such networks or the determination of the entire network topology still pose challenges that need to be solved. This work provides both theoretic and simulative insights to enable the required sub-millimeter localization accuracy of such sensors using magneto-inductive networks. It identifies inherent localization issues such as the asymmetry of the position estimation in magneto-inductive networks and outlines how such issues may be addressed by using passive relays or cooperation. It further proposes a novel approach to recognize the entire structure of a magneto-inductive network using simple impedance measurements and clusters of passive tags. This approach is evaluated extensively by simulation and experiment to demonstrate the feasibility of low-cost human body posture recognition.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The two-stage therapeutic effect of posture biofeedback training on back pain and the associated mechanism: A retrospective cohort study\n",
            "Authors: Fundoiano-Hershcovitz Y.\n",
            "Abstract: Introduction: Back pain is an extremely common symptom experienced by people of all ages and the number one cause of disability worldwide.2 Poor posture has been identified as one of the factors leading to back pain. Digital biofeedback technology demonstrates the promising therapeutic ability in pain management through posture training. One common goal of such an approach is to increase users’ posture awareness with associated movement correction. However, we lack a deep understanding of the biofeedback therapeutic mechanisms and the temporal dynamics of efficacy. Objective: This study investigates the temporal dynamics of the biofeedback learning process and associated outcomes in daily life settings, testing the mechanism of the biofeedback-associated pain reduction. Methods: This retrospective real-world evidence study followed 981 users who used the UpRight posture biofeedback platform. Piecewise mixed models were used for modeling the two-stage trajectory of pain levels, perceived posture quality, and weekly training duration following an 8-week biofeedback training. Also, the mediation effect of perceived posture quality on the analgesic effect of training duration was tested using Monte Carlo simulations based on lagged effect mixed models. Results: The analysis revealed significant pain level reduction (p <.0001) and posture quality improvement (p <.0001) during the first 4 weeks of the training, maintaining similar pain levels and perceived posture quality during the next 4 weeks. In addition, weekly training duration demonstrated an increase during the first 3 weeks (p <.001) and decreased during the next 5 weeks (p <.001). Moreover, training duration predicted following-week perceived posture quality (p <.001) and in turn perceived posture quality predicted following-week pain (p <.001) (p = 0.30). Finally, perceived posture quality mediated the effect of weekly training duration on the pain levels in 2 weeks (p <.0001). Conclusion: Our findings provide a better understanding of the therapeutic dynamic during digital biofeedback intervention targeting pain, modeling the associated two-stage process. Moreover, the study sheds light on the biofeedback mechanism and may assist in developing a better therapeutic approach targeting perceived posture quality.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Musculoskeletal Health Problems and their Association with Risk Factors among Manual Dairy Farm Workers\n",
            "Authors: Gurnani U.\n",
            "Abstract: Work related musculoskeletal problems are very common in industries operating their routine activities manually. These problems are the outcome of various strenuous tasks in awkward postures. A study in similar contrast was carried out for manual Indian dairy farm workers to investigate the prevalence of musculoskeletal problems and associated postural risk in this occupation. For this purpose a modified Nordic questionnaire was administered among 125 manual dairy farm workers. Binary logistic regression was applied to determine the association of postural risk factors and prevalence of musculoskeletal problems. As per the results, lower back pain was found to be the most common health issue (50.52%) mostly affecting workers engaged in fodder cutting (64.29%) and working in cowshed (63.16%). The age was significantly associated with musculoskeletal disorders in shoulders (OR=1.122, p=0.038), lower back area (OR=1.145, p=0.027) and also knees (OR=1.457, p=0.001). The workers with a balanced BMI ratio (20.1-25) were associated with very less neck disorders (OR=0.01, p=0.035) as compared to those who are underweight or overweight. The most strenuous task in dairy work is miking of cattle which was significantly associated with neck disorders (OR=5.731, , p=0.045) compared to other tasks. The height of an individual is also associated with heavy disorders in neck area of workers. With a proper ergonomic intervention, quality training of workers, use of proper hand tools and aids as well as modification in workstation design are needed to provide the more comfortable work life to dairy farm workers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Wearable Sensors and Artificial Intelligence for Physical Ergonomics: A Systematic Review of Literature\n",
            "Authors: Donisi L.\n",
            "Abstract: Physical ergonomics has established itself as a valid strategy for monitoring potential disorders related, for example, to working activities. Recently, in the field of physical ergonomics, several studies have also shown potential for improvement in experimental methods of ergonomic analysis, through the combined use of artificial intelligence, and wearable sensors. In this regard, this review intends to provide a first account of the investigations carried out using these combined methods, considering the period up to 2021. The method that combines the information obtained on the worker through physical sensors (IMU, accelerometer, gyroscope, etc.) or biopotential sensors (EMG, EEG, EKG/ECG), with the analysis through artificial intelligence systems (machine learning or deep learning), offers interesting perspectives from both diagnostic, prognostic, and preventive points of view. In particular, the signals, obtained from wearable sensors for the recognition and categorization of the postural and biomechanical load of the worker, can be processed to formulate interesting algorithms for applications in the preventive field (especially with respect to musculoskeletal disorders), and with high statistical power. For Ergonomics, but also for Occupational Medicine, these applications improve the knowledge of the limits of the human organism, helping in the definition of sustainability thresholds, and in the ergonomic design of environments, tools, and work organization. The growth prospects for this research area are the refinement of the procedures for the detection and processing of signals; the expansion of the study to assisted working methods (assistive robots, exoskeletons), and to categories of workers suffering from pathologies or disabilities; as well as the development of risk assessment systems that exceed those currently used in ergonomics in precision and agility.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Narrative Review on Wearable Inertial Sensors for Human Motion Tracking in Industrial Scenarios\n",
            "Authors: Digo E.\n",
            "Abstract: Industry 4.0 has promoted the concept of automation, supporting workers with robots while maintaining their central role in the factory. To guarantee the safety of operators and improve the effectiveness of the human-robot interaction, it is important to detect the movements of the workers. Wearable inertial sensors represent a suitable technology to pursue this goal because of their portability, low cost, and minimal invasiveness. The aim of this narrative review was to analyze the state-of-the-art literature exploiting inertial sensors to track the human motion in different industrial scenarios. The Scopus database was queried, and 54 articles were selected. Some important aspects were identified: (i) number of publications per year; (ii) aim of the studies; (iii) body district involved in the motion tracking; (iv) number of adopted inertial sensors; (v) presence/absence of a technology combined to the inertial sensors; (vi) a real-time analysis; (vii) the inclusion/exclusion of the magnetometer in the sensor fusion process. Moreover, an analysis and a discussion of these aspects was also developed.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Comparative Analysis of Skeleton-Based Human Pose Estimation\n",
            "Authors: Chung J.L.\n",
            "Abstract: Human pose estimation (HPE) has become a prevalent research topic in computer vision. The technology can be applied in many areas, such as video surveillance, medical assistance, and sport motion analysis. Due to higher demand for HPE, many HPE libraries have been developed in the last 20 years. In the last 5 years, more and more skeleton-based HPE algorithms have been developed and packaged into libraries to provide ease of use for researchers. Hence, the performance of these libraries is important when researchers intend to integrate them into real-world applications for video surveillance, medical assistance, and sport motion analysis. However, a comprehensive performance comparison of these libraries has yet to be conducted. Therefore, this paper aims to investigate the strengths and weaknesses of four popular state-of-the-art skeleton-based HPE libraries for human pose detection, including OpenPose, PoseNet, MoveNet, and MediaPipe Pose. A comparative analysis of these libraries based on images and videos is presented in this paper. The percentage of detected joints (PDJ) was used as the evaluation metric in all comparative experiments to reveal the performance of the HPE libraries. MoveNet showed the best performance for detecting different human poses in static images and videos.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Posture Monitoring and Correction Exercises for Workers in Hostile Environments Utilizing Non-Invasive Sensors: Algorithm Development and Validation\n",
            "Authors: Khaksar S.\n",
            "Abstract: Personal protective equipment (PPE) is an essential key factor in standardizing safety within the workplace. Harsh working environments with long working hours can cause stress on the human body that may lead to musculoskeletal disorder (MSD). MSD refers to injuries that impact the muscles, nerves, joints, and many other human body areas. Most work-related MSD results from hazardous manual tasks involving repetitive, sustained force, or repetitive movements in awkward postures. This paper presents collaborative research from the School of Electrical Engineering and School of Allied Health at Curtin University. The main objective was to develop a framework for posture correction exercises for workers in hostile environments, utilizing inertial measurement units (IMU). The developed system uses IMUs to record the head, back, and pelvis movements of a healthy participant without MSD and determine the range of motion of each joint. A simulation was developed to analyze the participant’s posture to determine whether the posture present would pose an increased risk of MSD with limits to a range of movement set based on the literature. When compared to measurements made by a goniometer, the body movement recorded 94% accuracy and the wrist movement recorded 96% accuracy.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Emerging Trends of Ergonomic Risk Assessment in Construction Safety Management: A Scientometric Visualization Analysis\n",
            "Authors: Vijayakumar R.\n",
            "Abstract: Ergonomic risk assessment is critical for identifying working posture hazardous to the health of construction workers. Work-related musculoskeletal disorders (WMSDs) are predominant non-fatal injuries in the construction industry owing to manual handling activities and poor working conditions. However, there is a lack of scientific synopsis aiming to better understand the emerging research focus in this field. To fill the research gap, this study performed a scientometric evaluation of the bibliometric data on ergonomic risk assessment from the Web of Science database using VOSviewer software. The purpose of this study is to analyze the co-occurrence network of keywords, co-authorship network, most active countries, and the sources of publication. The results indicate that research related to risk assessment in construction has fluctuating growth, peaking in 2020 with significant advancements in the USA, China, and Canada. WMSDs, risk factors, construction workers, and ergonomics are hot research topics in this field. Furthermore, the research gaps of previous studies and suggestions for future research have been provided to bridge the knowledge gap. We believe that this scientometric review provides useful reference points for early-stage researchers as well as beneficial in-depth information to experienced practitioners and scholars in the construction industry.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Validity and feasibility of remote measurement systems for functional movement and posture assessments in people with axial spondylarthritis\n",
            "Authors: Hannink E.\n",
            "Abstract: Introduction: This study aimed to estimate the criterion validity of functional movement and posture measurement using remote technology systems in people with and without Axial spondylarthritis (axSpA). Methods: Validity and agreement of the remote-technology measurement of functional movement and posture were tested cross-sectionally and compared to a standard clinical measurement by a physiotherapist. The feasibility of remote implementation was tested in a home environment. There were two cohorts of participants: people with axSpA and people without longstanding back pain. In addition, a cost-consequence analysis was performed. Results: Sixty-two participants (31 with axSPA, 53% female, age = 45(SD14), BMI = 26.6(SD4.6) completed the study. In the axSpA group, cervical rotation, lumbar flexion, lumbar side flexion, shoulder flexion, hip abduction, tragus-to-wall and thoracic kyphosis showed a significant moderate to strong correlation; in the non-back pain group, the same measures showed significant correlation ranging from weak to strong. Conclusions: Although not valid for clinical use in its current form, the remote technologies demonstrated moderate to strong correlation and agreement in most functional and postural tests measured in people with AxSA. Testing the CV-aided system in a home environment suggests it is a safe and feasible method. Yet, validity testing in this environment still needs to be performed.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Construction motion data library: an integrated motion dataset for on-site activity recognition\n",
            "Authors: Tian Y.\n",
            "Abstract: Identifying workers’ activities is crucial for ensuring the safety and productivity of the human workforce on construction sites. Many studies implement vision-based or inertial-based sensors to construct 3D human skeletons for automated postures and activity recognition. Researchers have developed enormous and heterogeneous datasets for generic motion and artificially intelligent models based on these datasets. However, the construction-related motion dataset and labels should be specifically designed, as construction workers are often exposed to awkward postures and intensive physical tasks. This study developed a small construction-related activity dataset with an in-lab experiment and implemented the datasets to manually label a large-scale construction motion data library (CML) for activity recognition. The developed CML dataset contains 225 types of activities and 146,480 samples; among them, 60 types of activities and 61,275 samples are highly related to construction activities. To verify the dataset, five widely applied deep learning algorithms were adopted to examine the dataset, and the usability, quality, and sufficiency were reported. The average accuracy of models without tunning can reach 74.62% to 83.92%.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ten questions concerning human-building interaction research for improving the quality of life\n",
            "Authors: Becerik-Gerber B.\n",
            "Abstract: This paper seeks to address ten questions that explore the burgeoning field of Human-Building Interaction (HBI), an interdisciplinary field that represents the next frontier in convergent research and innovation to enable the dynamic interplay of human and building interactional intelligence. The field of HBI builds on several existing efforts in historically separate research fields/communities and aims to understand how buildings affect human outcomes and experiences, as well as how humans interact with, adapt to, and affect the built environment and its systems, to support buildings that can learn, enable adaptation, and evolve at different scales to improve the quality-of-life of its users while optimizing resource usage and service availability. Questions were developed by a diverse group of researchers with backgrounds in design, engineering, computer science, social science, and health science. Answers to these questions draw conclusions from what has been achieved to date as reported in the available literature and establish a foundation for future HBI research. This paper aims to encourage interdisciplinary collaborations in HBI research to change the way people interact with and perceive technology within the context of buildings and inform the design, construction, and operation of next-generation, intelligent built environments. In doing so, HBI research can realize a myriad of benefits for human users, including improved productivity, health, cognition, convenience, and comfort, all of which are essential to societal well-being.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Applications of wireless sensor networks to improve occupational safety and health in underground mines\n",
            "Authors: Sadeghi S.\n",
            "Abstract: Introduction: The very complex and hazardous environment of underground mines may significantly contribute to occupational fatalities and injuries. Deploying wireless sensor network (WSN) technology has the potential to improve safety and health monitoring of miners and operators. However, the application of WSN in the industry is not fully understood and current research themes in this area are fragmented. Thus, there is a need for a comprehensive review that directly explores the contribution of WSNs to occupational safety and health (OSH) in underground mines. Method: This study aims to conduct a systematic literature review on the existing applications of WSNs for improving OSH in the underground mining industry to pinpoint innovative research themes and their main achievements, reveal gaps and shortcomings in the literature, recommend avenues for future scholarly works, and propose potential safety interventions. The major contribution of this review is to provide researchers and practitioners with a holistic understanding of the integration of WSN applications into underground mine safety and health management. Results: The review results have been categorized and discussed under three predominant categories including location monitoring and tracking, physiological and body kinematics monitoring, and environmental monitoring. Finally, seven major directions for future research and practical interventions have been identified based on the existing research gaps including: (1) further applications of WSNs for underground mining OSH management; (2) application of WSNs from research to real-world practice; (3) big data analytics and management; (4) deploying multiple WSNs-based monitoring systems; (5) integration of WSNs with other communication systems; (6) adapting WSNs to the Internet of Things (IoT) infrastructure; and (7) autonomous WSNs.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Conformity assessment of a computer vision-based posture analysis system for the screening of postural deformation\n",
            "Authors: Kim K.H.\n",
            "Abstract: Background: This study evaluates the conformity of using a computer vision-based posture analysis system as a screening assessment for postural deformity detection in the spine that is easily applicable to clinical practice. Methods: One hundred forty participants were enrolled for screening of the postural deformation. Factors that determine the presence or absence of spinal deformation, such as shoulder height difference (SHD), pelvic height difference (PHD), and leg length mismatch (LLD), were used as parameters for the clinical decision support system (CDSS) using a commercial computer vision-based posture analysis system. For conformity analysis, the probability of postural deformation provided by CDSS, the Cobb angle, the PHD, and the SHD was compared and analyzed between the system and radiographic parameters. A principal component analysis (PCA) of the CDSS and correlation analysis were conducted. Results: The Cobb angles of the 140 participants ranged from 0° to 61°, with an average of 6.16° ± 8.50°. The postural deformation of CDSS showed 94% conformity correlated with radiographic assessment. The conformity assessment results were more accurate in the participants of postural deformation with normal (0–9°) and mild (10–25°) ranges of scoliosis. The referenced SHD and the SHD of the CDSS showed statistical significance (p < 0.001) on a paired t-test. SHD and PHD for PCA were the predominant factors (PC1 SHD for 79.97%, PC2 PHD for 19.86%). Conclusion: The CDSS showed 94% conformity for the screening of postural spinal deformity. The main factors determining diagnostic suitability were two main variables: SHD and PHD. In conclusion, a computer vision-based posture analysis system can be utilized as a safe, efficient, and convenient CDSS for early diagnosis of spinal posture deformation, including scoliosis.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automatic real-time occupational posture evaluation and select corresponding ergonomic assessments\n",
            "Authors: Lin P.C.\n",
            "Abstract: The objective is to develop a system to automatically select the corresponding assessment scales and calculate the score of the risk based on the joint angle information obtained from the imaged process (OpenPose) via image-based motion capture technology. Current occupational assessments, for example, REBA, RULA, and OWAS were used to evaluate the risk of musculoskeletal disorders. However, the assessment result would not be reported immediately. Introducing real-time occupational assessments in different working environments will be helpful for occupational injury prevention. In this study, the decision tree was developed to select the most appropriate assessment method according to the joint angles derived by OpenPose image process. Fifteen operation videos were tested and these videos can be classified into six types including maintenance, handling, assembly, cleaning, office work, and driving. The selected ergonomic assessment method by our developed decision tree in each condition are consistent with the recommendation of the Labour Research Institute. Moreover, the high-risk posture could be identified immediately and provide to the inspector for further evaluation on this posture rather than the whole operation period. This approach provides a quick inspection of the operation movements to prevent musculoskeletal injuries and enhances the application of the scale assessment method in different industrial environments.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Artificial intelligence in the construction industry: Theory and emerging applications for the future of work\n",
            "Authors: Behzadan A.H.\n",
            "Abstract: None\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: WEDAR: Webcam-based Attention Analysis via Attention Regulator Behavior Recognition with a Novel E-reading Dataset\n",
            "Authors: Lee Y.\n",
            "Abstract: Human attention is critical yet challenging cognitive process to measure due to its diverse definitions and non-standardized evaluation. In this work, we focus on the attention self-regulation of learners, which commonly occurs as an effort to regain focus, contrary to attention loss. We focus on easy-to-observe behavioral signs in the real-world setting to grasp learners' attention in e-reading. We collected a novel dataset of 30 learners, which provides clues of learners' attentional states through various metrics, such as learner behaviors, distraction self-reports, and questionnaires for knowledge gain. To achieve automatic attention regulator behavior recognition, we annotated 931,440 frames into six behavior categories every second in the short clip form, using attention self-regulation from the literature study as our labels. The preliminary Pearson correlation coefficient analysis indicates certain correlations between distraction self-reports and unimodal attention regulator behaviors. Baseline model training has been conducted to recognize the attention regulator behaviors by implementing classical neural networks to our WEDAR dataset, with the highest prediction result of 75.18% and 68.15% in subject-dependent and subject-independent settings, respectively. Furthermore, we present the baseline of using attention regulator behaviors to recognize the attentional states, showing a promising performance of 89.41% (leave-five-subject-out). Our work inspires the detection & feedback loop design for attentive e-reading, connecting multimodal interaction, learning analytics, and affective computing.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Comparison of Concordance between Chuna Manual Therapy Diagnostic Methods (Palpation, X-ray, Artificial Intelligence Program) in Lumbar Spine: An Exploratory, Cross-Sectional Clinical Study\n",
            "Authors: Lee J.H.\n",
            "Abstract: Before Chuna manual therapy (CMT), a manual therapy applied in Korean medicine, CMT spinal diagnosis using palpation or X-ray is performed. However, studies on the inter-rater concordance of CMT diagnostic methods, concordance among diagnostic methods, and standard CMT diagnostic methods are scarce. Moreover, no clinical studies have used artificial intelligence (AI) programs for X-ray image-based CMT diagnosis. Therefore, this study sought a feasible and standard CMT spinal diagnostic method and explored the clinical applicability of the CMT-AI program. One hundred participants were recruited, and the concordance within and among different diagnostic modalities was analyzed by dividing them into manual diagnosis (MD), X-ray image-based diagnosis (XRD) by experts and non-experts, and XRD using a CMT-AI program by non-experts. Regarding intra-group concordance, XRD by experts showed the highest concordance (used as a gold standard when comparing inter-group concordance), followed by XRD using the AI program, XRD by non-experts, and then MD. Comparing diagnostic results between the groups, concordance with the gold standard was the highest for XRD using the AI program, followed by XRD by non-experts, and MD. Therefore, XRD is a more reasonable CMT diagnostic method than MD. Furthermore, the clinical applicability of the CMT-AI program is high.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of a New Procedure for Evaluating Working Postures: An Application in a Manufacturing Company\n",
            "Authors: Gattamelata D.\n",
            "Abstract: Musculoskeletal diseases represent a constant phenomenon in occupational health and safety (OHS) despite the large effort at governmental and technical levels. In the industrial context, numerous studies have dealt with the evaluation of the physical demand of workers. Moreover, numerous studies have investigated the problem, providing tools for ergonomics analysis. However, practical approaches aimed at integrating ergonomics issues in risk assessment activities are still scarce. To reduce such a gap, the current study proposes a procedure for the evaluation of the static working postures of workers to be included in the risk assessment activities. Such an approach is based on the ISO 11226 standard, providing a practical checklist that can be used both at the workstation’s design stage and during risk assessment activities. Its effectiveness was verified through a case study at a manufacturing company. The results achieved showed that as well as the non-conformity of the workstations’ design, the lack of training of the operators on how to maintain a neutral posture while working can also lead to awkward postures of the trunk and head. Additionally, the proposed methodology allowed us to verify the correctness of each workstation based on the physical characteristics of the workers, providing a useful guideline for the company managers on how to properly assign working tasks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Sitting comfort analysis and prediction for high-speed rail passengers based on statistical analysis and machine learning\n",
            "Authors: Yuxue B.\n",
            "Abstract: Various comfort evaluation models have been extensively studied for improving driver seat and office seat designs for the purpose of improving seat comfort. High-speed rail (HSR) seat comfort is influenced by specific environments, activities, and postures, and targeted in-depth research on this topic is lacking. Existing evaluation cannot ensure the validity of data at the early stages of model training because of their direct reliance on subjective evaluation data, thereby limiting the improvement in the accuracy of prediction. In this study, we designed a sitting observation experiment and static sitting comfort experiment for the typical activities of HSR passengers. The sitting posture of HSR passengers under typical activities was classified for different comfort levels based on the factors influencing the sitting posture in terms of bone and muscle biomechanics. The correlations between the subjective discomfort in different sitting positions, objective change patterns, and body pressure distribution parameters were statistically analysed. The possibility of using sitting duration and sitting frequency as objective behavioural indicators of discomfort evaluation was indicated. Based on the verification of the reliability of the evaluation data, the classification performance of various machine learning algorithms was compared and analysed, and a sitting comfort prediction model was established based on the gradient boosting machine algorithm, with an accuracy of 89.5%. This study serves as an effective reference for improvement strategies for HSR passenger comfort and will inspire new ideas for exploring objective indicators for sitting comfort evaluation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An investigation of musculoskeletal discomforts among mining truck drivers with respect to human vibration and awkward body posture using random forest algorithm\n",
            "Authors: Aliabadi M.\n",
            "Abstract: Using Random Forest algorithms, this study aimed to investigate musculoskeletal discomforts among mining truck drivers considering human vibration and awkward body posture. The study was conducted on 65 professional male drivers of mining trucks. The Cornell questionnaire was used to determine musculoskeletal discomforts. Drivers' exposure to vibrations was measured using the Svanteck 106 A vibration meter. The body posture was analyzed using the quick exposure check (QEC). The main mechanical and individual risk factors were used as predictor variables of musculoskeletal discomforts model. The relative importance of each feature on the discomforts was determined based on Random Forest algorithm compared with multiple linear regression using R Statistics Packages. The equivalent acceleration of whole-body vibration (WBV) was higher than the exposure limit, however, the equivalent acceleration of hand-transmitted vibration (HTV) was lower than the exposure limit. The body posture of drivers was from moderate to high risk so that investigation and changes are required soon. The predictive error of Random Forest model for musculoskeletal discomfort scores was at an acceptable level with root mean square error (RMSE) = 5.29 for the blind case of drivers compared with regressions model with RMSE = 15.92. Random forest showed that the awkward body posture, vibration, and age, respectively, have the greatest relative importance on musculoskeletal discomforts. The findings provide empirical evidence on the relative importance of risk factors on musculoskeletal discomfort so that awkward body posture has a greater effect compared with whole-body vibration. Random forest provided better outputs and was more accurate compared with the regression method.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The pause that refreshes: Break-taking occurs when task demands are reduced allowing for replenishing of attentional resources\n",
            "Authors: Santos C.P.\n",
            "Abstract: There is a controversy over whether the difficulty (i.e. mental demands) of a task leads to more or less mind wandering, with studies showing apparently conflicting results. Guided by the established association between mind wandering and fidgeting, here we propose a new interpretative model for mind wandering based on Non-Instrumental Movement Inhibition (NIMI), an active effort to suppress embodied natural fluctuations, which would otherwise result in both mental and physical displacements. In a video game-based experiment, break-taking (during level changes) functioned as a trigger for people to suspend NIMI, detectable as fidgeting. They suspended NIMI to transiently replenish depleted mental resources, which allowed mental arousal, detectable as postural uplift. We conclude that task persistence (beside difficulty level) creates a substrate (a latent state with depleted mental resources) encouraging mind wandering to temporarily replenish mental resources to re-control attention.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Challenging Ergonomics Risks with Smart Wearable Extension Sensors\n",
            "Authors: Maksimović N.\n",
            "Abstract: Concerning occupational safety, the aim of ergonomics as a scientific discipline is to study and adjust working conditions, worker equipment, and work processes from a psychological, physiological, and anatomical aspect instead of adapting the worker to the needs of the job. This paper will discuss and analyze the potential of the garment-embedded body posture tracking sensor and its usage as standard working equipment, which is meant to help correct improper and high-risk upper body positions during prolonged and static work activities. The analysis evaluation cross-reference is based on the Rapid Upper Limb Assessment ergonomics risk assessment tool. Signals generated by the wearable are meant to help the wearer and observer promptly-continuously detect and correct bad posture. The results show a positive progression of workers’ body posture to reduce the ergonomic risks this research covers. It can be concluded that wearable technology and sensors would significantly contribute to the observer as the evaluation tool and the wearer to spot the risk factors promptly and self-correct them independently. This feature would help workers learn and improve the correct habits of correcting ergonomically incorrect body postures when performing work tasks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Simple Method to Optimally Select Upper-Limb Joint Angle Trajectories from Two Kinect Sensors during the Twisting Task for Posture Analysis\n",
            "Authors: Liu P.L.\n",
            "Abstract: A trunk-twisting posture is strongly associated with physical discomfort. Measurement of joint kinematics to assess physical exposure to injuries is important. However, using a single Kinect sensor to track the upper-limb joint angle trajectories during twisting tasks in the workplace is challenging due to sensor view occlusions. This study provides and validates a simple method to optimally select the upper-limb joint angle data from two Kinect sensors at different viewing angles during the twisting task, so the errors of trajectory estimation can be improved. Twelve healthy participants performed a rightward twisting task. The tracking errors of the upper-limb joint angle trajectories of two Kinect sensors during the twisting task were estimated based on concurrent data collected using a conventional motion tracking system. The error values were applied to generate the error trendlines of two Kinect sensors using third-order polynomial regressions. The intersections between two error trendlines were used to define the optimal data selection points for data integration. The finding indicates that integrating the outputs from two Kinect sensor datasets using the proposed method can be more robust than using a single sensor for upper-limb joint angle trajectory estimations during the twisting task.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Wearable devices: Cross benefits from healthcare to construction\n",
            "Authors: Abuwarda Z.\n",
            "Abstract: The use of smart wearables provides an opportunity to improve construction safety and productivity. Because the healthcare industry has been at the forefront of applying such technologies, this paper investigates available ubiquitous wearables, their metrics, and types of measurements; how existing healthcare systems detect hazards and unhealthy behaviors; and the potential for cross-fertilization between healthcare and construction domains. A comprehensive review of 173 papers is used to examine existing developments in the use of smart wearables in the construction and healthcare industries. The literature survey identified applicable healthcare metrics, measurements, and ranges that can be readily utilized in the construction industry. This information can facilitate further studies related to improving work ergonomics, health and safety, and worker stress analysis. Future research can also help develop efficient construction schedules that dynamically monitor workers' fatigue, and accordingly devise corrective actions that minimize the impact on workers' safety and work productivity.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Motion Tracking Smart Work Suit with a Modular Joint Angle Sensor Using Screw Routing\n",
            "Authors: Lee J.\n",
            "Abstract: Activity data of workers can be used to manage their safety and working processes. To date, the adoption of motion measuring systems in industrial sites has been limited, due to cost and noisy environments. In this study, a motion-tracking smart work suit is presented to monitor the movements of workers. This system comprises modular joint-angle sensors that utilize a BoASensor mechanism, a conventional work suit with added sensor sleeves, and a monitoring device. The modularized joint-angle sensor can be easily attached or detached onto or from the normal work suit, improving its usability and washability. This suit could experience relative motion and deformation between the body, degrading sensor robustness, unlike conventional motion sensing suits. The screw sensor routing method is proposed to minimize the coordination effect between the sensor and skeletal system during body movements. Various postures recorded with the suit exhibited root mean square errors lower than 7.75%$\\ $from the elbow range of motion (150°) compared with the inertial-measurement-unit-(IMU)-based motion tracker. It was determined that there exists statistical significance between the proposed screw-routing method and the IMU in precision, thereby demonstrating sensing robustness with various upper limb motions. Additionally, the linearity analysis revealed that screw-routing has the highest linear behavior. The proposed work suit is expected to be utilized in preventing industrial accidents at various sites, owing to its low production cost and high accessibility.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Human motion prediction for intelligent construction: A review\n",
            "Authors: Xia X.\n",
            "Abstract: Intelligent construction is an important construction trend. With the growing number of intelligent autonomous systems implemented in the construction area, understanding and predicting human motion becomes increasingly important. Based on such predictions, the autonomous systems can optimize their actions to improve the efficiency of human-robot interactions, and supervisors can make informed decisions about when and where to intervene in human motion to avoid collisions. This paper presents a comprehensive review of existing literature on human motion prediction (HMP). Relevant studies from a wide range of fields are reviewed, analyzed and synthesized, in terms of prediction indicators, methods and applications, based on a three-level taxonomy. The taxonomy is structured based on the levels of human information required by different prediction methods, and reflects different understandings of the underlying causality and mediators of human motions and intent. The paper also discusses the evolutions of the theoretical understanding and methodological development of HMP, its application scenarios in and beyond the construction domain, and possible directions for future research. This review is expected to increase the visibility of this rapidly expanding research area, and inspire future studies and advancements for human-robot interactions in construction.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A novel platform to enable the future human-centered factory\n",
            "Authors: Generosi A.\n",
            "Abstract: This paper introduces a web-platform system that performs semi-automatic compute of several risk indexes, based on the considered evaluation method (e.g., RULA—Rapid Upper Limb Assessment, REBA—Rapid Entire Body Assessment, OCRA—OCcupational Repetitive Action) to support ergonomics risk estimation, and provides augmented analytics to proactively improve ergonomic risk monitoring based on the characteristics of workers (e.g., age, gender), working tasks, and environment. It implements a body detection system, marker-less and low cost, based on the use of RGB cameras, which exploits the open-source deep learning model CMU (Carnegie Mellon University), from the tf-pose-estimation project, assuring worker privacy and data protection, which has been already successfully assessed in standard laboratory conditions. The paper provides a full description of the proposed platform and reports the results of validation in a real industrial case study regarding a washing machine assembly line composed by 5 workstations. A total of 15 workers have been involved. Results suggest how the proposed system is able to significantly speed up the ergonomic assessment and to predict angles and perform a RULA and OCRA analysis, with an accuracy comparable to that obtainable from a manual analysis, even under the unpredictable conditions that can be found in a real working environment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A review on tools and methods applied to enhance ergonomics in the construction industry\n",
            "Authors: Mukesh Kumar D.\n",
            "Abstract: This paper aims to review the tools and methods used to enhance ergonomics in the construction industry (CI) using bibliometric and systematic literature analysis. For this purpose, the bibliometric information from the research article published on ergonomics in the field of CI was extracted from the databases of Scopus. A total of 3,052 articles published between 1997 and 2021 were retrieved. Information collected was analyzed using bibliometric and systematic analysis of literature using open-source computer software. The main findings of the study show the publication trends related to ergonomics in CI since 1997 and identify the most productive authors and the most influential research work. Our findings show that Peter Hancock and Waldemar Karwowski are the leading authors in the field of ergonomics in CI, the most influential articles have been published in journals such as the State of Science: Mental Workload in Ergonomics, Human Factors, and Ergonomics in Production Planning, A Review of Enterprise Agility: Concepts, Frameworks and Attributes, and Human Factors and Ergonomics. Systematic literature analysis of these articles has shown the impact of this topic on the research society and among academics. The findings of our research have theoretical and practical implications for CI ergonomics. The scope for future work has been identified which will be of use to emerging researchers in the field of ergonomics.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Influence of task decision autonomy on physical ergonomics and robot performances in an industrial human–robot collaboration scenario\n",
            "Authors: Pantano M.\n",
            "Abstract: Adoption of human–robot collaboration is hindered by barriers in collaborative task design. A new approach for solving these problems is to empower operators in the design of their tasks. However, how this approach may affect user welfare or performance in industrial scenarios has not yet been studied. Therefore, in this research, the results of an experiment designed to identify the influences of the operator’s self-designed task on physical ergonomics and task performance are presented. At first, a collaborative framework able to accept operator task definition via parts’ locations and monitor the operator’s posture is presented. Second, the framework is used to tailor a collaborative experience favoring decision autonomy using the SHOP4CF architecture. Finally, the framework is used to investigate how this personalization influences collaboration through a user study with untrained personnel on physical ergonomics. The results from this study are twofold. On one hand, a high degree of decision autonomy was felt by the operators when they were allowed to allocate the parts. On the other hand, high decision autonomy was not found to vary task efficiency nor the MSD risk level. Therefore, this study emphasizes that allowing operators to choose the position of the parts may help task acceptance and does not vary operators’ physical ergonomics or task efficiency. Unfortunately, the test was limited to 16 participants and the measured risk level was medium. Therefore, this study also stresses that operators should be allowed to choose their own work parameters, but some guidelines should be followed to further reduce MSD risk levels.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automated Posture Analysis for the Assessment of Sports Exercises\n",
            "Authors: Pardos A.\n",
            "Abstract: Numerous studies in the medical field correlate the maintenance of human posture in static and dynamic situations with the muscle-skeletal health. One of the most widely used methods for assessing human posture is through visual inspection by professionals. However, this observational assessment process requires the presence of a field expert performing a time-consuming manual analysis. Hence, a reliable automatic posture evaluation system would be of great help for professionals to detect postural misalignments. In the recent years, significant progress has been achieved in pose estimation through state-of-the-art deep learning techniques, competent to estimate human body landmarks fast and accurately from RGB images. In this paper, we describe a methodology scheme to estimate human posture and detect postural misalignments in static and dynamic exercises in real-time. The MediaPipe Pose algorithm is employed to detect human pose and the vector geometry of the pose is evaluated to detect postural misalignments. Furthermore, in order to not limit the applications of this work by preselecting rule parameters for only a certain set of exercises, the rule parameters of any form of exercise are automatically extracted from an example of a single correct execution through machine learning. The datasets of the videos utilized in this work were provided and annotated by a clinical exercise physiologist.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Simple method integrating OpenPose and RGB-D camera for identifying 3D body landmark locations in various postures\n",
            "Authors: Liu P.L.\n",
            "Abstract: Ergonomic assessments of posture are indispensable for reducing the risk of physical discomfort in the workplace. However, it is challenging to measure postural data in field studies because of the high cost and complex setup required by conventional motion tracking systems. OpenPose is an advanced approach for real-time multi-person two-dimensional (2D) pose estimations in an image, whereas RGB-D cameras can simultaneously record image and depth data. Thus, the present study proposes integrating these two approaches to identify 3D body landmark locations. To quantify the accuracy of the proposed method, the anatomical body landmark locations identified by a marker-based reference system were used as a gold standard. The tracking errors of using two RGB-D cameras, which used different data acquisition techniques (stereoscopic and time-of-flight (ToF)), were examined and compared. Thirty participants were recruited to perform 15 static postures. The average tracking errors of the landmark locations were 7.96 ± 3.59 and 9.81 ± 5.57 cm (stereoscopic), and 6.38 ± 2.88 and 8.18 ± 5.56 cm (ToF) for the standing postures and sitting postures, respectively. Depending on the desired accuracy, the integration of the RGB-D cameras and OpenPose could provide an alternative motion tracking method to identify 3D body landmark locations in a simple manner when postural assessments are performed.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Using real-time feedback of L5/S1 compression force based on markerless optical motion capture to improve the lifting technique in manual materials handling\n",
            "Authors: Brandl C.\n",
            "Abstract: Challenges in manual materials handling (MMH) are posed in particular by the requirements for continuous repetition and individual feedback. Low effort in MMH instructions is accordingly a relevant factor. The combination of a markerless motion capture system with a biomechanical model providing visual MMH instructions by individual real-time feedback of the compression force of the intervertebral disc in L5/S1 (CF) could tackle these challenges. However, this raises the question of whether this approach provides appropriate MMH instructions to improve the lifting technique in MMH. Results of an experiment with 22 young male participants indicate that visual MMH instructions with such individual real-time feedback have significant advantages in improving the lifting technique by reducing those factors associated with lower back pain compared to instructions with a reference paper-based tutorial or a baseline without instructions. Thus, peak and mean CF and peak trunk flexion, for example, were significantly lower when lifting with individual real-time feedback of CF compared to other conditions tested. Hence, the results suggest that it may be sensible to improve the lifting technique by such an approach of MMH instructions and integrate it in MMH training programs or on-the-job training in order to reduce or prevent lower back pain. Relevance to industry: Using real-time feedback of the compression force of the intervertebral disc of L5/S1 based on markerless optical motion capture can improve the lifting technique in manual materials handling. This may be integrated into MMH training programs or on-the-job training to reduce or prevent low back pain.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Can We Quantify Aging-Associated Postural Changes Using Photogrammetry? A Systematic Review\n",
            "Authors: Dilian O.\n",
            "Abstract: Background: Aging is widely known to be associated with changes in standing posture. Recent advancements in the field of computerized image processing have allowed for improved analyses of several health conditions using photographs. However, photogrammetry’s potential for assessing aging-associated postural changes is yet unclear. Thus, the aim of this review is to evaluate the potential of photogrammetry in quantifying age-related postural changes. Materials and Methods: We searched the databases PubMed Central, Scopus, Embase, and SciELO from the beginning of records to March 2021. Inclusion criteria were: (a) participants were older adults aged ≥60; (b) standing posture was assessed by photogrammetric means. PRISMA guidelines were followed. We used the Newcastle–Ottawa Scale to assess methodological quality. Results: Of 946 articles reviewed, after screening and the removal of duplicates, 11 reports were found eligible for full-text assessment, of which 5 full studies met the inclusion criteria. Significant changes occurring with aging included deepening of thoracic kyphosis, flattening of lumbar lordosis, and increased sagittal inclination. Conclusions: These changes agree with commonly described aging-related postural changes. However, detailed quantification of these changes was not found; the photogrammetrical methods used were often unvalidated and did not adhere to known protocols. These methodological difficulties call for further studies using validated photogrammetrical methods and improved research methodologies.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Cluster analysis of kitchen cabinet operation posture based on OpenPose technology\n",
            "Authors: Zhou C.\n",
            "Abstract: With the help of OpenPose technology, the key data of the user's operating posture when using the kitchen cabinet during cooking are obtained. The second-order clustering method is used to cluster the obtained data, and the relationship between the characteristics of human operating behavior posture and height among different categories is analyzed, to provide a scientific basis for the design of high adaptability customization scheme of the kitchen cabinet table in the later stage. The clustering results show that the deviation angle of the parts beyond the health threshold is different under different task states. The average deviation angle of the neck was more than 45°. In Category 3, the average waist deviation angle was 3–9 times of the other categories, and 68.05% of the operation time exceeded the health threshold. Therefore, in the design of the kitchen cabinet, the sizes of the cleaning area and preparation area need to be adjusted according to the sight distance to ensure that users maintain a healthy operation behavior. In addition, it is found that the user sight distance range of 160–180 cm is [419,621] mm under the operation state, which can be used as a reference for design evaluation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Extended reality applications in industry 4.0. – A systematic literature review\n",
            "Authors: Adriana Cárdenas-Robledo L.\n",
            "Abstract: Extended reality technologies such as virtual reality, augmented reality, and mixed reality represents a paradigm that enhances and supports industry 4.0 in diverse settings. To spread such a revolutionary environment, this systematic review focuses on analyzing extendend reality essence and application and reporting the assessment of 287 approaches gathered from 2011 to 2022, classified and characterized in the proposed taxonomy. Based on the sample of analyzed works, the results indicate that industry 4.0 has embraced the use of these technologies. Heterogeneous solution proposals in various fields of application and activities were found. Notwithstanding, the research articles report similar advantages and benefits (e.g., high performance on human tasks or robot collaboration, high-quality rates for specific products, among others). In addition, we present the most widespread equipment and devices that are currently preferred to develop extended reality applications, which allows us to identify hardware patterns commonly shared in a variety of fields. Whilst, with the aid of association rules, we reveal further insights among the items of the proposed taxonomy. Furthermore, we also present a thorough analysis of trends and research directions in the extended reality field for industry 4.0. Finally, from our results, we show that the accessibility and accelerated progress in technological devices, incorporating advanced algorithms, ergonomic features, built-in cameras, and sensors, have encouraged a massive adoption and extensive application development in a wide spectrum of industry 4.0 domains.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Posture and Mechanical Load Assessment During Patient Transfers\n",
            "Authors: Hellmers S.\n",
            "Abstract: Caregivers experience high musculoskeletal loads during their daily work, which leads to back complaints and a high rate of absenteeism at work. This reinforces the already existing discrepancy between the supply and demand of caregivers. Ergonomically correct working can significantly reduce musculoskeletal load. Therefore, we developed a system that recognizes potentially harmful body postures. In a study with 13 caregiver students, we analyzed the body postures, as well as muscle activities, and loads during the transfer of a patient from bed to wheelchair. The body postures were measured by a full-body motion capture system and a Multi-Kinect System. Muscle activities and loads were recorded via surface electromyography and a force plate. The posture analysis system is based on the motion capture data and considers the recommendations for ergonomic working in the care sector. The system generates a result report visualizing the skeleton model as well as color-coded information about inclination and torsion angles. The motion capture data were also related to EMG and force data and analyzed according to biomechanical assumptions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Artificial intelligence technologies for more flexible recommendation in uniforms\n",
            "Authors: Wen C.H.\n",
            "Abstract: Purpose: This research aims to collect human body variables via 2D images captured by digital cameras. Based on those human variables, the forecast and recommendation of the Digital Camouflage Uniforms (DCU) for Taiwan's military personnel are made. Design/methodology/approach: A total of 375 subjects are recruited (male: 253; female: 122). In this study, OpenPose converts the photographed 2D images into four body variables, which are compared with those of a tape measure and 3D scanning simultaneously. Then, the recommendation model of the DCU is built by the decision tree. Meanwhile, the Euclidean distance of each size of the DCU in the manufacturing specification is calculated as the best three recommendations. Findings: The recommended size established by the decision tree is only 0.62 and 0.63. However, for the recommendation result of the best three options, the DCU Fitting Score can be as high as 0.8 or more. The results of OpenPose and 3D scanning have the highest correlation coefficient even though the method of measuring body size is different. This result confirms that OpenPose has significant measurement validity. That is, inexpensive equipment can be used to obtain reasonable results. Originality/value: In general, the method proposed in this study is suitable for applications in e-commerce and the apparel industry in a long-distance, non-contact and non-pre-labeled manner when the world is facing Covid-19. In particular, it can reduce the measurement troubles of ordinary users when purchasing clothing online.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The use of deep learning technology in dance movement generation\n",
            "Authors: Liu X.\n",
            "Abstract: The dance generated by the traditional music action matching and statistical mapping models is less consistent with the music itself. Moreover, new dance movements cannot be generated. A dance movement generation algorithm based on deep learning is designed to extract the mapping between sound and motion features to solve these problems. First, the sound and motion features are extracted from music and dance videos, and then, the model is built. In addition, a generator module, a discriminator module, and a self-encoder module are added to make the dance movement smoother and consistent with the music. The Pix2PixHD model is used to transform the dance pose sequence into a real version of the dance. Finally, the experiment takes the dance video on the network as the training data and trained 5,000 times. About 80% of the dance data are used as the training set and 20% as the test set. The experimental results show that Train, Valid, and Test values based on the Generator+Discriminator+Autoencoder model are 15.36, 17.19, and 19.12, respectively. The similarity between the generated dance sequence and the real dance sequence is 0.063, which shows that the proposed model can generate a dance more in line with the music. Moreover, the generated dance posture is closer to the real dance posture. The discussion has certain reference value for intelligent dance teaching, game field, cross-modal generation, and exploring the relationship between audio-visual information.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automatic Ergonomic Risk Assessment Using a Variational Deep Network Architecture\n",
            "Authors: Chatzis T.\n",
            "Abstract: Ergonomic risk assessment is vital for identifying work-related human postures that can be detrimental to the health of a worker. Traditionally, ergonomic risks are reported by human experts through time-consuming and error-prone procedures; however, automatic algorithmic methods have recently started to emerge. To further facilitate the automatic ergonomic risk assessment, this paper proposes a novel variational deep learning architecture to estimate the ergonomic risk of any work-related task by utilizing the Rapid Entire Body Assessment (REBA) framework. The proposed method relies on the processing of RGB images and the extraction of 3D skeletal information that is then fed to a novel deep network for accurate and robust estimation of REBA scores for both individual body parts and the entire body. Through a variational approach, the proposed method processes the skeletal information to construct a descriptive skeletal latent space that can accurately model human postures. Moreover, the proposed method distills knowledge from ground truth ergonomic risk scores and leverages it to further enhance the discrimination ability of the skeletal latent space, leading to improved accuracy. Experiments on two well-known datasets (i.e., University of Washington Indoor Object Manipulation (UW-IOM) and Technische Universität München (TUM) Kitchen) validate the ability of the proposed method to achieve accurate results, overcoming current state-of-the-art methods.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Visualizing Collaboration in Teamwork: A Multimodal Learning Analytics Platform for Non-Verbal Communication\n",
            "Authors: Noël R.\n",
            "Abstract: Developing communication skills in collaborative contexts is of special interest for educational institutions, since these skills are crucial to forming competent professionals for today’s world. New and accessible technologies open a way to analyze collaborative activities in face-to-face and non-face-to-face situations, where collaboration and student attitudes are difficult to measure using traditional methods. In this context, Multimodal Learning Analytics (MMLA) appear as an alternative to complement the evaluation and feedback of core skills. We present a MMLA platform to support collaboration assessment based on the capture and classification of non-verbal communication interactions. The developed platform integrates hardware and software, including machine learning techniques, to detect spoken interactions and body postures from video and audio recordings. The captured data is presented in a set of visualizations, designed to help teachers to obtain insights about the collaboration of a team. We performed a case study to explore if the visualizations were useful to represent different behavioral indicators of collaboration in different teamwork situations: a collaborative situation and a competitive situation. We discussed the results of the case study in a focus group with three teachers, to get insights in the usefulness of our proposal. The results show that the measurements and visualizations are helpful to understand differences in collaboration, confirming the feasibility the MMLA approach for assessing and providing collaboration insights based on non-verbal communication.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: SEE: A proactive strategy-centric and deep learning-based ergonomic risk assessment system for risky posture recognition\n",
            "Authors: Lee Y.C.\n",
            "Abstract: Work-related musculoskeletal disorders (WMSDs) are serious workplace injuries that put workers' safety at risk. However, traditional WMSD assessments are based on the human-evaluation strategy (HES), requiring human intervention. Proactive strategy (PAS)-oriented WMSDs assessments collect data using posture data tags and special semi-human–machine equipment to improve efficiency and reduce human efforts to capture specific postures in a real-world setting. Meanwhile, more research on applying artificial intelligence-based pose machines for musculoskeletal risk assessment in various workplaces is needed. Hence, this study proposed a holistic posture acquisition and ergonomic risk analysis model with the PAS-oriented philosophy for developing a smartphone-based and workplace-based risk assessment system for WMSDs. The Convolutional Pose Machines (CPM) method was combined with a rapid entire body assessment method for the system's design. Finally, the smart ergonomic explorer (SEE) system includes three subsystems: an automotive scene capturer, an ergonomic risk level calculator, and a risk assessment reporter. A musculoskeletal risk assessment experiment with 13 poses was also carried out to validate the SEE system and compare its accuracy with manual evaluation. The result shows good agreement with the REBA score, with an average proportion agreement index (P0) of 0.962 and kappa of 0.82. It indicates that the proposed system can not only accurately analyze the working posture, but also accurately evaluate the total REBA scores. This study is hoped to provide practical advice and implications for achieving a more effective empirical response for WMSD assessment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of a Robust Machine Learning Model to Monitor the Operational Performance of Fixed-Post Multi-Blade Vertical Sawing Machines\n",
            "Authors: Borz S.A.\n",
            "Abstract: Monitoring the operational performance of the sawmilling industry has become important for many applications including strategic and tactical planning. Small-scale sawmilling facilities do not hold automatic production management capabilities mainly due to using obsolete technology which is an effect of low financial capacity and focus their strategy on increasing value recovery and saving resources and energy. Based on triaxial acceleration data collected over five days at a sampling rate of 1 Hz, a robust machine learning model was developed with the purpose of using it to infer the operational events based on lower sampling rates adopted as a strategy to collect long-term data. Among its performance metrics, the model was characterized in its training phase by a very high overall classification accuracy (CA = 98.7%), F1 score (98.4%) and a very low error rate (LOG LOSS = 5.6%). For a three-class problem, it worked very well in classifying the main events related to the operation of the machine, with active work being characterized by an F1 score of 99.6% and an error of 3.6%. By accounting for the same metrics, the model was proven to be invariant to the sampling rates of up to 0.05 Hz (20 s) and produced even better results in the testing phase (CA = 98.9%, F1 = 98.6%, LOG LOSS = 5.5%, for a testing sample extracted at 0.05 Hz), while there were no differences in the share of class data irrespective of the sampling rate. The developed model not only preserves a high classification performance in the training and testing phases but it also seems to be invariant to lower sampling rates, making it useful for prediction over data collected at low sampling rates. In turn, this would enable the use of cheap data collectors to be operated for extended periods of time in various locations and will save human resources and money associated with data collection. Further tests would be required only for validation and they could be supported by collecting and feeding new data to the model to infer the long-term performance of similar sawmilling machines.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Intelligent Posture Training: Machine-Learning-Powered Human Sitting Posture Recognition Based on a Pressure-Sensing IoT Cushion\n",
            "Authors: Bourahmoune K.\n",
            "Abstract: We present a solution for intelligent posture training based on accurate, real-time sitting posture monitoring using the LifeChair IoT cushion and supervised machine learning from pressure sensing and user body data. We demonstrate our system’s performance in sitting posture and seated stretch recognition tasks with over 98.82% accuracy in recognizing 15 different sitting postures and 97.94% in recognizing six seated stretches. We also show that user BMI divergence significantly affects posture recognition accuracy using machine learning. We validate our method’s performance in five different real-world workplace environments and discuss training strategies for the machine learning models. Finally, we propose the first smart posture data-driven stretch recommendation system in alignment with physiotherapy standards.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Machine Learning Approaches for the Frailty Screening: A Narrative Review\n",
            "Authors: Oliosi E.\n",
            "Abstract: Frailty characterizes a state of impairments that increases the risk of adverse health outcomes such as physical limitation, lower quality of life, and premature death. Frailty prevention, early screening, and management of potential existing conditions are essential and impact the elderly population positively and on society. Advanced machine learning (ML) processing methods are one of healthcare’s fastest developing scientific and technical areas. Although research studies are being conducted in a controlled environment, their translation into the real world (clinical setting, which is often dynamic) is challenging. This paper presents a narrative review of the procedures for the frailty screening applied to the innovative tools, focusing on indicators and ML approaches. It results in six selected studies. Support vector machine was the most often used ML method. These methods apparently can identify several risk factors to predict pre-frail or frailty. Even so, there are some limitations (e.g., quality data), but they have enormous potential to detect frailty early.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Vision-Based Collision Monitoring System for Proximity of Construction Workers to Trucks Enhanced by Posture-Dependent Perception and Truck Bodies’ Occupied Space\n",
            "Authors: Shin Y.S.\n",
            "Abstract: In the study, an automated visualization of the proximity between workers and equipmeis developed to manage workers’ safety at construction sites using the convolutional-neural-networbased image processing of a closed-circuit television video. The images are analyzed to automaticaltransform a hazard index visualized in the form of a plane map. The graphical representation personalized proximity in the plane map is proposed and termed as safety ellipse in the study. Tsafety ellipse depending on the posture of workers and the area occupied by the hazardous objec(trucks) enable to represent precise proximity. Collision monitoring is automated with computvision techniques of artificial-intelligence-based object detection, occupied space calculation, poestimation, and homography.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Human Factor Index Measurement Using an ISM-SEM-Fuzzy Approach\n",
            "Authors: Vijayakumar K.\n",
            "Abstract: In recent years, there has been a trend toward automation and data exchange in manufacturing processes through industrial cognitive computing, the Internet of Things (IoT), and artificial intelligence. However, the human–machine interface plays a role in establishing a smart manufacturing system in any industry. It is necessary to develop a comprehensive model to identify the risk factors that contribute to the loss of human performance and productivity and evaluate the workplace for its compliance and agility toward safe human–machine systems. In this study, a model is proposed that can be used as a measurement tool to design ergonomic workplaces in the automotive industry. Several criteria have been classified under four enablers: physiological factors, psychological factors, environmental factors, and safety factors. These were identified through a literature review. The proposed model integrates the applications of structural equation modeling (SEM), interpretive structural modeling (ISM), and the multigrade fuzzy approach. ISM was employed to demonstrate the applicability of the model to depict various ergonomic enablers considered in the ergonomic measurement. SEM was used to validate the ergonomic measurement model statistically. Physiological factors were found to be highly correlated with ergonomic practices. Physiological and psychological factors were also highly correlated. The use of the multigrade fuzzy approach was demonstrated to determine the human factor index for an automotive component manufacturing industry. The proposed model can enable management to evaluate the various risk factors that hamper the ergonomic level of a company and thereby allow the company to harness the benefits of ergonomics to enhance safety and productivity.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Assessing exposure to slip, trip, and fall hazards based on abnormal gait patterns predicted from confidence interval estimation\n",
            "Authors: Lee H.\n",
            "Abstract: Monitoring workers' exposures to slip, trip, and fall (STF) hazards is critical to preventing STFs at construction sites. This study developed a model to assess workers' exposures to STF hazards by predicting abnormal gait patterns from a series of steps. The model was then evaluated and validated through a field experiment. Gait variability features were extracted from a waist-worn inertial measurement unit (IMU) and converted into Mahalanobis distance. Bidirectional long short-term memory models were used to predict abnormal gait patterns using confidence interval estimation. The model generated an Unweighted Average Recall (UAR) of 93.0% (normal walking: 93.0% and exposure to STF hazards: 93.0%), which demonstrates that workers' exposures to STF hazards can be continuously and remotely monitored, potentially helping to prevent STFs on construction worksites.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: K-score: A novel scoring system to quantify fatigue-related ergonomic risk based on joint angle measurements via wearable inertial measurement units\n",
            "Authors: Beltran Martinez K.\n",
            "Abstract: Work-related musculoskeletal disorders have been recognized as a global problem that affects millions of people annually. Fatigue is one of the main contributors to musculoskeletal disorders. Thus, this study investigated fatigue detection based on the measured body motion by wearable inertial measurement units. We quantified the body motion during manual handling tasks using a novel kinematic score (i.e., K-score), and the Rapid Entire Body Assessment (REBA). K-score and REBA were calculated using joint angles. Nevertheless, unlike REBA, K-score showed a significant correlation (Spearman's correlation coefficient of ρ(302) = 0.21, p < 0.05) with electromyography (EMG) signal amplitude, which was affected by muscle fatigue. Therefore, in-field measurement of K-score using inertial measurement units could detect the fatigue-induced change of body motion in long-duration manual handling tasks. Our proposed K-score can be used to assess fatigue-related ergonomic risk in long-term and real-world working conditions without the need for tedious EMG recording at workplaces.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Assessing Sensorimotor Synchronisation in Toddlers Using the Lookit Online Experiment Platform and Automated Movement Extraction\n",
            "Authors: Rocha S.\n",
            "Abstract: Adapting gross motor movement to match the tempo of auditory rhythmic stimulation (sensorimotor synchronisation; SMS) is a complex skill with a long developmental trajectory. Drumming tasks have previously been employed with infants and young children to measure the emergence of rhythmic entrainment, and may provide a tool for identification of those with atypical rhythm perception and production. Here we describe a new protocol for measuring infant rhythmic movement that can be employed at scale. In the current study, 50 two-year-olds drummed along with the audiovisual presentation of four steady rhythms, using videos of isochronous drumming at 400, 500, 600, and 700 ms IOI, and provided their spontaneous motor tempo (SMT) by drumming in silence. Toddlers’ drumming is observed from video recordings made in participants’ own homes, obtained via the Lookit platform for online infant studies. We use OpenPose deep-learning model to generate wireframe estimates of hand and body location for each video. The vertical displacement of the hand was extracted, and the power and frequency of infants’ rhythmic entrainment quantified using Fast Fourier Transforms. We find evidence for age-appropriate tempo-flexibility in our sample. Our results demonstrate the feasibility of a fully digital approach to measuring rhythmic entrainment from within the participant’s home, from early in development.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automated System to Measure Static Balancing in Children to Assess Executive Function\n",
            "Authors: Pavel H.R.\n",
            "Abstract: We present multiple methods based on computer vision and deep learning to automate the task of \"Balancing on one foot\". This is one of the Activate Test of Embodied Cognition (ATEC) tasks used to measure cognitive skills in children through physical activity. A dataset of 27 children performing the ATEC task is used to train and validate the deep learning models used to automate the task. As opposed to most balance identification systems that use sensors, our proposed approach relies only on computer vision which can be easily deployed at home or classroom environment, is portable, and cheap. Our proposed system automatically identifies the task and assigns an ATEC and an ergonomics score for the \"Balancing on one foot\"task. Our proposed system achieves an accuracy of 97% when calculating the raw score for the ATEC task and 86.5% for assigning the ergonomic score.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Review of IoT-Enabled Mobile Healthcare: Technologies, Challenges, and Future Trends\n",
            "Authors: Yang Y.\n",
            "Abstract: The Internet of Things (IoT) has grown over decades to encompass many forms of sensing modalities, and continues to improve in terms of sophistication and lower costs. The trend of hardware miniaturization and emphasis on user convenience has inspired numerous studies to integrate more varied devices within the IoT into modernizing healthcare systems, facilitating applications, such as activity recognition, fitness assistance, vital signs monitoring, daily dietary tracking, and sleep monitoring. These applications are vital for prevention, detection, and treatment of ailments and can be realized using both dedicated health sensors as well as general-purpose sensors not originally designed for health monitoring. This article surveys such studies, detailing smart health monitoring systems, and the types of sensor components utilized within the IoT. We categorize and analyze these works based on their leverage of device-based techniques (i.e., use of sensors worn or carried by the person) and device-free techniques (i.e., wireless sensing without need to carry hardware), as well as signal processing and classification techniques utilized. In particular, we discuss how different combinations of these techniques can be creatively applied to support professional and commercial health-monitoring IoT networks. We also identify limitations and potential directions that future research may explore.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automated Detection of Ear Tragus and C7 Spinous Process in a Single RGB Image—A Novel Effective Approach\n",
            "Authors: Kramer I.\n",
            "Abstract: Biophotogrammetric methods for postural analysis have shown effectiveness in the clinical practice because they do not expose individuals to radiation. Furthermore, valid statements can be made about postural weaknesses. Usually, such measurements are collected via markers attached to the subject’s body, which can provide conclusions about the current posture. The craniovertebral angle (CVA) is one of the recognized measurements used for the analysis of human head–neck postures. This study presents a novel method to automate the detection of the landmarks that are required to determine the CVA in RGBs. Different image processing methods are applied together with a neuronal network Openpose to find significant landmarks in a photograph. A prominent key body point is the spinous process of the cervical vertebra C7, which is often visible on the skin. Another visual landmark needed for the calculation of the CVA is the ear tragus. The methods proposed for the automated detection of the C7 spinous process and ear tragus are described and evaluated using a custom dataset. The results indicate the reliability of the proposed detection approach, particularly head postures.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automatic clustering of proper working postures for phases of movement\n",
            "Authors: Ryu J.H.\n",
            "Abstract: Expert workers are often unable to articulate or convey their ‘physical wisdom’ to apprentices, as they tend to underestimate how difficult a task can be for apprentices. This can make it difficult for apprentices to learn from experts. This study aims to identify the proper working postures that experts develop as they gain experience. The methods utilized whole-body motion data and a k-means clustering algorithm to identify the most frequent postures in an ensemble of concrete masonry unit (CMU) lifts. Then, it systematically classified the expert postures necessary to undertake the different phases of CMU lifts as opposed to inferior, apprentice-dominated, postures. The methods and findings may play an important role in: 1) providing insights for methods to objectively compare working postures of experts and apprentices, and 2) identifying and conveying those expert work methods to trainees and trainers in a highly detailed and visual form that can be used directly as training material in order to proactively minimize safety and health hazards and improve productivity.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomics Risk Assessment for Manual Material Handling of Warehouse Activities Involving High Shelf and Low Shelf Binning Processes: Application of Marker-Based Motion Capture\n",
            "Authors: Zhao Y.S.\n",
            "Abstract: Lower back pain is a musculoskeletal disorder that is commonly reported among warehouse workers due to the nature of the work environment and manual handling activities. The objective of this study was to assess the ergonomic risks among warehouse workers carrying out high shelf (HS) and low shelf (LS) binning processes. A questionnaire was used to determine the prevalence of musculoskeletal symptoms, while a marker-based motion capture (MoCap) system worksheet was used to record the participants’ motion and determine the action risk level. A total of 33% of the participants reported lower back pain in the past seven days, based on the Cornell Musculoskeletal Discomfort Questionnaire (CMDQ) results. Analysis of the body velocities showed that the HS binning process had four major velocity peaks, defined as the initial, lowering, lifting, and final phases.In comparison, the LS binning process had two major peaks defined, the crouching and rising phases. There were significant differences between the mean velocities of the workers for the HS binning process, indicating that the workers have different movement patterns with varying velocities.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Learning from Acceleration Data to Differentiate the Posture, Dynamic and Static Work of the Back: An Experimental Setup\n",
            "Authors: Muşat E.C.\n",
            "Abstract: Information on body posture, postural change, and dynamic and static work is essential in understanding biomechanical exposure and has many applications in ergonomics and healthcare. This study aimed at evaluating the possibility of using triaxial acceleration data to classify postures and to differentiate between dynamic and static work of the back in an experimental setup, based on a machine learning (ML) approach. A movement protocol was designed to cover the essential degrees of freedom of the back, and a subject wearing a triaxial accelerometer implemented this protocol. Impulses and oscillations from the signals were removed by median filtering, then the filtered dataset was fed into two ML algorithms, namely a multilayer perceptron with back propagation (MLPBNN) and a random forest (RF), with the aim of inferring the most suitable algorithm and architecture for detecting dynamic and static work, as well as for correctly classifying the postures of the back. Then, training and testing subsets were delimitated and used to evaluate the learning and generalization ability of the ML algorithms for the same classification problems. The results indicate that ML has a lot of potential in differentiating between dynamic and static work, depending on the type of algorithm and its architecture, and the data quantity and quality. In particular, MLPBNN can be used to better differentiate between dynamic and static work when tuned properly. In addition, static work and the associated postures were better learned and generalized by the MLPBNN, a fact that could provide the basis for cheap real-world offline applications with the aim of getting time-scaled postural profiling data by accounting for the static postures. Although it wasn’t the case in this study, on bigger datasets, the use of MLPBPNN may come at the expense of high computational costs in the training phase. The study also discusses the factors that may improve the classification performance in the testing phase and sets new directions of research.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Multi-Kinects fusion for full-body tracking in virtual reality-aided assembly simulation\n",
            "Authors: Wang Y.\n",
            "Abstract: Skeleton tracking based on multiple Kinects data fusion has been proved to have better accuracy and robustness than single Kinect. However, previous works did not consider the inconsistency of tracking accuracy in the tracking field of Kinect and the self-occlusion of human body in assembly operation, which are of vital importance to the fusion performance of the multiple Kinects data in assembly task simulation. In this work, we developed a multi-Kinect fusion algorithm to achieve robust full-body tracking in virtual reality (VR)-aided assembly simulation. Two reliability functions are first applied to evaluate the tracking confidences reflecting the impacts of the position-related error and the self-occlusion error on the tracked skeletons. Then, the tracking skeletons from multiple Kinects are fused based on weighted arithmetic average and generalized covariance intersection. To evaluate the tracking confidence, the ellipsoidal surface fitting was used to model the tracking accuracy distribution of Kinect, and the relations between the user-Kinect crossing angles and the influences of the self-occlusion on the tracking of different parts of body were studied. On the basis, the two reliability functions were developed. We implemented a prototype system leveraging six Kinects and applied the distributed computing in the system to improve the computing efficiency. Experiment results showed that the proposed algorithm has superior fusion performance compared to the peer works.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Wearables for Movement Analysis in Healthcare\n",
            "Authors: Capodaglio P.\n",
            "Abstract: None\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: SnS/Ti<inf>3</inf>C<inf>2</inf>T<inf>x</inf>(MXene) Nanohybrid-Based Wearable Electromechanical Sensors for Sign-to-Text Translation and Sitting Posture Analysis\n",
            "Authors: Adepu V.\n",
            "Abstract: The challenges involved in realizing next-generation applications, like robotics, artificial electronic skin, noninvasive healthcare monitoring, motion detection, and so forth, enabled with wireless human-machine interfaces, present a growing need for high-performance flexible and wearable multifunctional electromechanical sensors. In this regard, emerging classes of two-dimensional nanomaterials and their hybrids show excellent promise as active sensing materials, given their high flexibility and remarkable sensitivity to external pressure and strain. This report is the first demonstration of SnS/Ti3C2Txnanohybrid-based electromechanical sensors for use in applications like sign-to-text translation and sitting posture analysis. The as-fabricated piezoresistive sensor exhibits a high gauge factor and sensitivity value, that is, 7.41 and 7.49 kPa-1, respectively. Furthermore, the nanohybrid-based sensor displayed a negligible change in performance over ∼3500 and ∼2500 cycles for both pressure and strain characterizations, indicating high robustness and exceptional stability. The underlying intrinsic piezoresistive mechanism in layered nanomaterials and the Ohmic contact formed at the SnS/Ti3C2Txheterojunction are explained in detail with the help of energy band diagrams wherein the work function and the Ehomovalues are extracted experimentally by ultraviolet photoelectron spectroscopy for both SnS and Ti3C2Tx. The successful demonstration of sign-to-text translation and e-cushion applications using SnS/Ti3C2Txnanohybrid-based piezoresistive sensors will further expand the scope of flexible and wearable electronics research.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Detection of Physical Strain and Fatigue in Industrial Environments Using Visual and Non-Visual Low-Cost Sensors\n",
            "Authors: Papoutsakis K.\n",
            "Abstract: The detection and prevention of workers’ body straining postures and other stressing conditions within the work environment, supports establishing occupational safety and promoting well being and sustainability at work. Developed methods towards this aim typically rely on combining highly ergonomic workplaces and expensive monitoring mechanisms including wearable devices. In this work, we demonstrate how the input from low-cost sensors, specifically, passive camera sensors installed in a real manufacturing workplace, and smartwatches used by the workers can provide useful feedback on the workers’ conditions and can yield key indicators for the prevention of work-related musculo-skeletal disorders (WMSD) and physical fatigue. To this end, we study the ability to assess the risk for physical strain of workers online during work activities based on the classification of ergonomically sub-optimal working postures using visual information, the correlation and fusion of these estimations with synchronous worker heart rate data, as well as the prediction of near-future heart rate using deep learning-based techniques. Moreover, a new multi-modal dataset of video and heart rate data captured in a real manufacturing workplace during car door assembly activities is introduced. The experimental results show the efficiency of the proposed approach that exceeds 70% of classification rate based on the F1 score measure using a set of over 300 annotated video clips of real line workers during work activities. In addition a time lagging correlation between the estimated ergonomic risks for physical strain and high heart rate was assessed using a larger dataset of synchronous visual and heart rate data sequences. The statistical analysis revealed that imposing increased strain to body parts will results in an increase to the heart rate after 100–120 s. This finding is used to improve the short term forecasting of worker’s cardiovascular activity for the next 10 to 30 s by fusing the heart rate data with the estimated ergonomic risks for physical strain and ultimately to train better predictive models for worker fatigue.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic assessment of office worker postures using 3D automated joint angle assessment\n",
            "Authors: Rodrigues P.B.\n",
            "Abstract: Sedentary activity and static postures are associated with work-related musculoskeletal disorders (WMSDs) and worker discomfort. Ergonomic evaluation for office workers is commonly performed by experts using tools such as the Rapid Upper Limb Assessment (RULA), but there is limited evidence suggesting sustained compliance with expert's recommendations. Assessing postural shifts across a day and identifying poor postures would benefit from automation by means of real-time, continuous feedback. Automated postural assessment methods exist; however, they are usually based on ideal conditions that may restrict users’ postures, clothing, and hair styles, or may require unobstructed views of the participants. Using a Microsoft Kinect camera and open-source computer vision algorithms, we propose an automated ergonomic assessment algorithm to monitor office worker postures, the 3D Automated Joint Angle Assessment, 3D-AJA. The validity of the 3D-AJA was tested by comparing algorithm-calculated joint angles to the angles obtained from manual goniometry and the Kinect Software Development Kit (SDK) for 20 participants in an office space. The results of the assessment show that the 3D-AJA has mean absolute errors ranging from 5.6° ± 5.1° to 8.5° ± 8.1° for shoulder flexion, shoulder abduction, and elbow flexion relative to joint angle measurements from goniometry. Additionally, the 3D-AJA showed relatively good performance on the classification of RULA score A using a Random Forest model (micro averages F1-score = 0.759, G-mean = 0.811), even at high levels of occlusion on the subjects’ lower limbs. The results of the study provide a basis for the development of a full-body ergonomic assessment for office workers, which can support personalized behavior change and help office workers to adjust their postures, thus reducing their risks of WMSDs.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Inertial Motion Capture-Based Wearable Systems for Estimation of Joint Kinetics: A Systematic Review\n",
            "Authors: Lee C.J.\n",
            "Abstract: In biomechanics, joint kinetics has an important role in evaluating the mechanical load of the joint and understanding its motor function. Although an optical motion capture (OMC) system has mainly been used to evaluate joint kinetics in combination with force plates, inertial motion capture (IMC) systems have recently been emerging in joint kinetic analysis due to their wearability and ubiquitous measurement capability. In this regard, numerous studies have been conducted to estimate joint kinetics using IMC-based wearable systems. However, these have not been comprehensively addressed yet. Thus, the aim of this review is to explore the methodology of the current studies on estimating joint kinetic variables by means of an IMC system. From a systematic search of the literature, 48 studies were selected. This paper summarizes the content of the selected literature in terms of the (i) study characteristics, (ii) methodologies, and (iii) study results. The estimation methods of the selected studies are categorized into two types: the inverse dynamics-based method and the machine learning-based method. While these two methods presented different characteristics in estimating the kinetic variables, it was demonstrated in the literature that both methods could be applied with good performance for the kinetic analysis of joints in different daily activities.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Quantitative Physical Ergonomics Assessment of Teleoperation Interfaces\n",
            "Authors: Gholami S.\n",
            "Abstract: Human factors and ergonomics are the essential constituents of teleoperation interfaces, which can significantly affect the human operator's performance. Thus, a quantitative evaluation of these elements and the ability to establish reliable comparison bases for different teleoperation interfaces are the keys to select the most suitable one for a particular application. However, most of the works on teleoperation have so far focused on the stability analysis and the transparency improvement of these systems and do not cover the important usability aspects. In this article, we propose a foundation to build a general framework for the analysis of human factors and ergonomics in employing diverse teleoperation interfaces. The proposed framework will go beyond the traditional subjective analyses of usability by complementing it with online measurements of human body configurations. As a result, multiple quantitative metrics, such as joints' usage, range of motion comfort, center of mass divergence, and posture comfort, are introduced. To demonstrate the potential of the proposed framework, two different teleoperation interfaces are considered, and real-world experiments with 11 participants performing a simulated industrial remote pick-and-place task are conducted. The quantitative results of this analysis are provided, and compared with subjective questionnaires, illustrating the effectiveness of the proposed framework.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Deep learning-based networks for automated recognition and classification of awkward working postures in construction using wearable insole sensor data\n",
            "Authors: Antwi-Afari M.F.\n",
            "Abstract: Among the numerous work-related risk factors, construction workers are often exposed to awkward working postures that may lead them to develop work-related musculoskeletal disorders (WMSDs). To mitigate WMSDs among construction workers, awkward working posture recognition is the first step in proactive WMSD prevention. Several researchers have proposed wearable sensor-based systems and machine learning classifiers for awkward posture recognition. However, these wearable sensor-based systems (e.g., surface electromyography) are either intrusive or require attaching multiple sensors on workers' bodies, which may lead to workers' discomfort and systemic instability, thus, limiting their application on construction sites. In addition, machine learning classifiers are limited to human-specific shallow features which influence model performance. To address these limitations, this study proposes a novel approach by using wearable insole pressure system and recurrent neural network (RNN) models, which automate feature extraction and are widely used for sequential data classification. Therefore, the research objective is to automatically recognize and classify different types of awkward working postures in construction by using deep learning-based networks and wearable insole sensor data. The classification performance of three RNN-based deep learning models, namely: (1) long-short term memory (LSTM), (2) bidirectional LSTM (Bi-LSTM), and (3) gated recurrent units (GRU), was evaluated using plantar pressure data captured by a wearable insole system from workers on construction sites. The experimental results show that GRU model outperforms the other RNN-based deep learning models with a high accuracy of 99.01% and F1-score between 93.19% and 99.39%. These results demonstrate that GRU models can be employed to learn sequential plantar pressure patterns captured by a wearable insole system to recognize and classify different types of awkward working postures. The findings of this study contribute to wearable sensor-based posture-related recognition and classification, thus, enhancing construction workers' health and safety.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Using existing site surveillance cameras to automatically measure the installation speed in prefabricated timber construction\n",
            "Authors: Ahmadian Fard Fini A.\n",
            "Abstract: Purpose: Measuring onsite productivity has been a substance of debate in the construction industry, mainly due to concerns about accuracy, repeatability and unbiasedness. Such characteristics are central to demonstrate construction speed that can be achieved through adopting new prefabricated systems. Existing productivity measurement methods, however, cannot cost-effectively provide solid and replicable evidence of prefabrication benefits. This research proposes a low-cost automated method for measuring onsite installation productivity of prefabricated systems. Design/methodology/approach: Firstly, the captured ultra-wide footages are undistorted by extracting the curvature contours and performing a developed meta-heuristic algorithm to straighten these contours. Then a preprocessing algorithm is developed that could automatically detect and remove the noises caused by vibrations and movements. Because this study aims to accurately measure the productivity the noise free images are double checked in a specific time window to make sure that even a tiny error, which have not been detected in the previous steps, will not been amplified through the process. In the next step, the existing side view provided by the camera is converted to a top view by using a spatial transformation method. Finally, the processed images are compared with the site drawings in order to detect the construction process over time and report the measured productivity. Findings: The developed algorithms perform nearly real-time productivity computations through exact matching of actual installation process and digital design layout. The accuracy and noninterpretive use of the proposed method is demonstrated in construction of a multistorey cross-laminated timber building. Originality/value: This study uses footages of an already installed surveillance camera where the camera's features are unknown and then image processing algorithms are deployed to retrieve accurate installation quantities and cycle times. The algorithms are almost generalized and versatile to be adjusted to measure installation productivity of other prefabricated building systems.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A vision for the future of wearable sensors in spine care and its challenges: narrative review\n",
            "Authors: Hodges P.W.\n",
            "Abstract: Objective: This review aimed to: (I) provide a brief overview of some topical areas of current literature regarding applications of wearable sensors in the management of low back pain (LBP); (II) present a vision for a future comprehensive system that integrates wearable sensors to measure multiple parameters in the real world that contributes data to guide treatment selection (aided by artificial intelligence), uses wearables to aid treatment support, adherence and outcome monitoring, and interrogates the response of the individual patient to the prescribed treatment to guide future decision support for other individuals who present with LBP; and (III) consider the challenges that will need to be overcome to make such a system a reality. Background: Advances in wearable sensor technologies are opening new opportunities for the assessment and management of spinal conditions. Although evidence of improvements in outcomes for individuals with LBP from the use of sensors is limited, there is enormous future potential. Methods: Narrative review and literature synthesis. Conclusions: Substantial research is underway by groups internationally to develop and test elements of this system, to design innovative new sensors that enable recording of new data in new ways, and to fuse data from multiple sources to provide rich information about an individual’s experience of LBP. Together this system, incorporating data from wearable sensors has potential to personalise care in ways that were hitherto thought impossible. The potential is high but will require concerted effort to develop and ultimately will need to be feasible and more effective than existing management.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Design and architecture of smart belt for real time posture monitoring\n",
            "Authors: Tlili F.\n",
            "Abstract: The bad back flexions are the main cause of the back disorders and pains. Many working conditions require that the worker remain sitting and slouching for long time. Having a correct sitting posture over time is the greatest way to protect workers from the back pains according to the latest medical researchers. In this paper, we present the architecture and design details of the proposed posture monitoring system. The aim of this study is to propose a tracking posture system include complete information about the back posture. The existing posture monitoring systems in literature were limited to trunk flexion monitoring. In this proposal we introduce the shoulder bent monitoring in addition to the trunk flexion monitoring in order to provide complete information about the back posture. The proposed posture monitoring system is a smart belt equipped by inertial sensors to detect the trunk flexion and a shoulder bent to monitor the posture over time. A smartphone application was developed to notify the person in case of bad posture detection. The proposed system demonstrates encouraging results to monitor the posture over time of seating persons and improves their seating behavior by receiving a real time notification in case of bad posture detection.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Walking-in-place for omnidirectional VR locomotion using a single RGB camera\n",
            "Authors: Kim W.\n",
            "Abstract: Locomotion is a fundamental interaction element allowing navigation inside the virtual environment, and the walking-in-place (WIP) techniques have been actively developed as a balanced compromise between naturalness and efficiency. One popular method to implement the WIP technique was to use a low-cost, easy to set up, and markerless Kinect, but required integration of multiple sensors or covered limited directions due to the poor tracking capability when facing non-frontal sides of the user. This study aimed to propose a WIP technique for omnidirectional VR locomotion based on a single RGB camera, utilizing an open-source 2D human pose estimation system called OpenPose. Three WIP techniques (existing Kinect-based technique, proposed Kinect-based technique, and proposed OpenPose-based technique) were compared in terms of variation of virtual walking speed and subjective evaluation through a user study with walking tasks in different directions. Experimental results showed that the proposed OpenPose-based technique performed comparably when the user faced the front of the camera, but it induced lower variation of virtual walking speed and higher subjective evaluation ratings at non-forward directions compared to other techniques. The proposed OpenPose-based WIP technique can be used in VR applications to provide a fully unobstructed VR locomotion experience. It can achieve stable WIP-based omnidirectional VR locomotion through a single low-cost easily accessible RGB camera, without the need for additional sensors, and at the same time, both hands are free for other interactions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Correlation analysis of poor body posture and living habits of preschool children in Beijing\n",
            "Authors: Zhao X.F.\n",
            "Abstract: Objective To explore the effects of children's living habits on body posture health among preschool children, and to provide reference for prevention of bad body posture. Methods A total of 406 preschoolers from four kindergartens in Beijing were randomly selected to conduct body posture assessment and lifestyle survey using body -style body posture assessment tester (Model.S-8.0) and the questionnaire for preschoolers' living habits. Results The body posture score was (21.98+3.01) points, and the detection rate of bad body posture was 75.86%. The high detection rate of forward pelvis, high and low Shoulders and O/X legs were 39.41%, 46.80% and 58.37%, respectively. The detection rate of poor body posture was associated with gender (x2=10.28), age (x2=16.57), and BMI (%2=7.46) with statistically significant difference (P<0.05), with a higher rate in girls (79.24%) than in boys (72.16%), and an increasing rate with age in the 3-4 years group (73.02%), 4-5 years group (75.00%), and 5-6 years group (79.86%). The detection rate of bad posture in obese children (86.36%) was relatively high. Body shape development was correlated with life habits. \"Daily physical exercise\" (Off=2.014, 95%C/:1.712-2.426), \"Video time less than 2 hours\" (Off=1.632, 95%67: 1.266-1.527), \"sleep time more than 6 hours\" (0fl=1.425, 95%67: 1.266-1.624) and \"basically eating dairy products every day\" (OR =1.067, 95% 67: 0.906-1.146) had positive effects on children's physical development. Conclusion The lifestyle of preschoolers has a significant impact on the physical health, and the physical health development of preschoolers can be promoted by improving physical activity, eating habits and sleep time.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Assessing Workplace Stress Among Nurses Using Heart Rate Variability Analysis With Wearable ECG Device–A Pilot Study\n",
            "Authors: Li X.\n",
            "Abstract: This study aims to measure workplace stress of nurses using heart rate variability (HRV) analysis based on data derived from wearable ECG heart rate monitors. The study population consists of 17 nurses at a major public hospital in China. Data was collected from 7 DON nurses (department of neurosurgery; all females; mean age: 31.43 ± 4.50), and 9 ICU nurses (intensive care unit; 8 females and 1 male; mean age: 31.33 ± 5.43). Each participant was asked to wear a wireless ECG heart rate monitor to measure stress level during work, and to complete the Chinese Nurses Stress Response Scale (CNSRS) after work as subjective response criteria. Demographic information, body posture, heart rate, R-R intervals (RRI), low frequency components (LF) and high frequency components (HF) were collected. LF%, LnHF and the squared root of the mean squared differences of successive NN intervals (RMSSD) based on HRV analysis were used to estimate the stress level of nurses. DON nurses reported a higher LF%, lower LnHF and lower RMSSD than ICU nurses. Work shifts were shown to have significant effects on LF%, LnHF and RMSSD respectively, with nurses in long shifts and night shifts reported high stress levels. Higher LF%, lower LnHF and lower RMSSD were found during work shift. Posture analysis revealed negative correlations with LnHF and RMSSD in walking and standing/sitting positions, and a significant negative correlation with LF% in lying-down position. Nurses with higher LF% reported higher CNSRS scores in all subscales, whereas nurses with lower LnHF or RMSSD reported higher CNSRS scores in social phobia and fatigue subscales. The results of this study support the idea that HRV can be used to investigate workplace stress among nurses under real work condition, and can serve as a preventive measure for identifying stress-related illnesses among nurses.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic Design of a Workplace Using Virtual Reality and a Motion Capture Suit\n",
            "Authors: Kačerová I.\n",
            "Abstract: Musculoskeletal disorders are some of the most frequent manual work disorders. Employers worldwide pay high costs for their treatment and prevention. We present an innovative method for designing an ergonomic workplace. This method uses new technologies and supports not only ergonomics, but also a general improvement in the designing of the manufacturing process. Although many researchers claim that there is a huge potential for using new disruptive technologies like virtual reality and motion capture in ergonomics, there is still a lack of a comprehensive methodological basis for implementing these technologies. Our approach was designed using the expert group method. We can validate the manufacturing process and the ergonomics using a motion capture (MoCap) suit and a head‐mounted display (HMD). There are no legislative restrictions for the tools which are used for ergonomic analyses, so we can use our outputs for workplace scoring. Firstly, we measure the anthropometrics of the proband. Then the proband is immersed in virtual reality and they go through a manufacturing process during which ergonomics data are collected. The design of a particular workplace or multiple workplaces can be validated based on the reactions, measurements, and input in real‐time. After processing the data, the workplace can be adjusted accordingly. The proposed method has a time and economic benefit for workplace design, optimisation of workplace ergonomics, and shortens the time required for designing the production line layout. It also includes optional steps for validation using conventional methods. These steps were used for method validation on a representative workplace using on‐site experiments. We validated it on a group of 20 healthy operators working in automotive production (age 22 to 35). A comparison study describes the classic methods of workplace ergonomics evaluation, compares the classic evaluation using biomechanical analysis, modern evaluation using a MoCap suit, and connection with virtual reality. We have proved the validity of the method using the comparison study. The results also showed other potential issues which can be further examined: like the role of peripheral vision or haptic feedback.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The Case for Negotiation Robots in simulated workplace negotiations: A Theoretical Approach\n",
            "Authors: Rosero A.\n",
            "Abstract: Job negotiations are an anxiety-inducing and highly important form of social interaction. Most people are not sufficiently trained in negotiation strategies and often do not receive job offers that are conducive to financial stability. With the rise of virtual agents and robotics that are capable of modeling social interactions, a significant research effort has been established to create realistic simulations of negotiations. While the bulk of this research has focused on virtual agents as a medium for simulated negotiations, we propose that embodied agents can be utilized to model the inherent nuances in human interaction. In this paper, we propose a study that aims to evaluate the effectiveness of embodied agents compared to virtual agents in simulated negotiations with human participants.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Mitigating the risk of musculoskeletal disorders during human robot collaboration: a reinforcement learning approach\n",
            "Authors: Xie Z.\n",
            "Abstract: Work-related musculoskeletal disorders (MSDs) are often observed in human-robot collaboration (HRC), a common work configuration in modern factories. In this study, we aim to reduce the risk of MSDs in HRC scenarios by developing a novel model-free reinforcement learning (RL) method to improve workers’ postures. Our approach follows two steps: first, we adopt a 3D human skeleton reconstruction method to calculate workers’ Rapid Upper Limb Assessment (RULA) scores; next, we devise an online gradient-based RL algorithm to dynamically improve the RULA score. Compared with previous model-based studies, the key appeals of the proposed RL algorithm are two-fold: (i) the model-free structure allows it to “learn” the optimal worker postures without need any specific biomechanical models of tasks or workers, and (ii) the data-driven nature makes it accustomed to arbitrary users by providing personalized work configurations. Results of our experiments confirm that the proposed method can significantly improve the workers’ postures.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Advanced visualization of ergonomic assessment data through industrial Augmented Reality\n",
            "Authors: Evangelista A.\n",
            "Abstract: The industrial transition to the 4.0 paradigm defines new scenarios in which the operator plays a central role within the industrial ecosystem. Thanks to the enabling technologies of Industry 4.0, it is possible to effectively improve operators' working conditions by applying the Human-Centered approach. Nowadays, one of the main challenges is to reduce work-related musculoskeletal disorders resulting from ergonomically incorrect working conditions in order to prevent the occurrence of occupational diseases. To this end, we developed a software tool that leverages a low-cost D-RGB camera (Kinect v2) to track the human body and an Augmented Reality (AR) visualization system based on Microsoft HoloLens 2. The tool assesses postural ergonomic risk in real-time according to the Rapid Upper Limb Assessment (RULA) metric. The proposed AR application allows a three-dimensional visualization of postures, which can be observed directly superimposed on the operator's body in the real scene. This approach aims to optimize the understanding of postures by creating a link between real information (operator's body) and virtual information (virtual skeleton, RULA score, and angles) by providing a simple and immediate user interface for ergonomists.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Review of Ergonomics Application on HSE Management Research for Construction Workers\n",
            "Authors: Liao K.\n",
            "Abstract: The construction industry has become one of the industries with the worst safety record. Ergonomics has been increasingly applied in the health, safety, and environment (HSE) management field for construction workers. However, a thorough review of ergonomics application in HSE management research is unavailable. To examine the state of the art of this research area, this study uses CiteSpace to visually analyze 204 peer-reviewed ergonomics journal papers published from 2000 to 2021. By analyzing contributing journals, the most cited documents, keyword co-occurrence network, and keyword burst detection results, four stages of the literature indicating the research trends were identified and discussed in chronological order: (1) taking safety intervention measures from psychophysical methods; (2) using ergonomics method to consider and address the risk factors leading to safety accidents; (3) preventing musculoskeletal disorders by improved postures of construction workers from the perspective of human factors; and (4) combining mature and advanced technologies in ergonomics with HSE management. This study serves as a reference for the HSE management research of construction workers and recommends potential interdisciplinary areas for future research.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Farmer Workplace Discomfort Levels Leading to Adverse Mental Health\n",
            "Authors: Chauhan H.\n",
            "Abstract: Musculoskeletal discomforts and disorders cause serious health-related problems that affect the mental well-being of farmers, reducing their work efficiency. The objective of this study was to evaluate the discomfort levels of farmers in Indian agriculture leading to mental stresses, and for this, the discomfort questionnaire has been applied after carrying out a detailed literature review. With the help of discomfort questionnaire and Depression, Anxiety, and Stress Scale (DASS-21), the farmer discomfort levels and their mental stress levels were evaluated. Further, by the application of ANFIS, an effort has been made to predict the mental stress of farmers during their work activities in hot climatic conditions based on the associated parameters like kcal burnt, pulse rate, high BP, low BP, and temperature, respectively.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Biomechanics beyond the lab: Remote technology for osteoarthritis patient data—A scoping review\n",
            "Authors: Hamilton R.I.\n",
            "Abstract: The objective of this project is to produce a review of available and validated technologies suitable for gathering biomechanical and functional research data in patients with osteoarthritis (OA), outside of a traditionally fixed laboratory setting. A scoping review was conducted using defined search terms across three databases (Scopus, Ovid MEDLINE, and PEDro), and additional sources of information from grey literature were added. One author carried out an initial title and abstract review, and two authors independently completed full-text screenings. Out of the total 5,164 articles screened, 75 were included based on inclusion criteria covering a range of technologies in articles published from 2015. These were subsequently categorised by technology type, parameters measured, level of remoteness, and a separate table of commercially available systems. The results concluded that from the growing number of available and emerging technologies, there is a well-established range in use and further in development. Of particular note are the wide-ranging available inertial measurement unit systems and the breadth of technology available to record basic gait spatiotemporal measures with highly beneficial and informative functional outputs. With the majority of technologies categorised as suitable for part-remote use, the number of technologies that are usable and fully remote is rare and they usually employ smartphone software to enable this. With many systems being developed for camera-based technology, such technology is likely to increase in usability and availability as computational models are being developed with increased sensitivities to recognise patterns of movement, enabling data collection in the wider environment and reducing costs and creating a better understanding of OA patient biomechanical and functional movement data.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: MANUAL TASKS REAL-TIME ERGONOMIC EVALUATION FOR COLLABORATIVE ROBOTICS\n",
            "Authors: Lanzoni D.\n",
            "Abstract: In manufacturing, ergonomic and productivity benefits may result from combining the sensing and dexterity of the human workers with the strength of collaborative robots (cobots). Anyway, manual tasks requiring repetitive motion or working with robots can cause musculoskeletal disorders especially of the hands. In such a context, this paper proposes a novel solution that includes both a full body inertial system and a dedicated solution for hand tracking. This allows implementing the standard methods for assessing ergonomic indexes and to introduce new advanced task analyses based on gesture evaluation. The benefits reached by the integrated system for body and hand tracking can be exploited in the virtual prototyping of collaborative workstation in the manufacturing domain. Different software packages have been considered to model and simulate the collaboration between the operator and the cobot. In particular, Unity and ROS are used to develop the virtual scene and control the cobot behavior and the HTC Vive Head Mounted Display (HMD) to interact with the virtual environment. Physical ergonomics is evaluated by using both a full body suit (XSENS) and sensorized gloves (MANUS). The solution has been applied to the simulation of a virtual production line where the operator collaborates with a six-axis cobot (NIRYO ONE). Test tasks require the operator to move and manage different objects and tools by simulating different types of grasping. Real-time feedback about ergonomics, in terms of posture evaluation and alerts in case of critical condition, is shown to the operator as well as the automatic generation of reports for the post-process evaluation of the entire process. The results show how the use of these tools can be effective in the ergonomic evaluation of a collaborative robotic workstation which requires manual tasks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: DULA and DEBA: Differentiable Ergonomic Risk Models for Postural Assessment and Optimization in Ergonomically Intelligent pHRI\n",
            "Authors: Yazdani A.\n",
            "Abstract: Ergonomics and human comfort are essential concerns in physical human-robot interaction applications. Defining an accurate and easy-to-use ergonomic assessment model stands as an important step in providing feedback for postural correction to improve operator health and comfort. Common practical methods in the area suffer from inaccurate ergonomics models in performing postural optimization. In order to retain assessment quality, while improving computational considerations, we propose a novel framework for postural assessment and optimization for ergonomically intelligent physical human-robot interaction. We introduce DULA and DEBA, differentiable and continuous ergonomics models learned to replicate the popular and scientifically validated RULA and REBA assessments with more than 99% accuracy. We show that DULA and DEBA provide assessment comparable to RULA and REBA while providing computational benefits when being used in postural optimization. We evaluate our framework through human and simulation experiments. We highlight DULA and DEBA's strength in a demonstration of postural optimization for a simulated pHRI task.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: ErgoMaps: Towards Interpretable and Accessible Automated Ergonomic Analysis\n",
            "Authors: Kostolani D.\n",
            "Abstract: Work-related musculoskeletal disorders account for high levels of absence and deplete the workforce through permanent incapacities. Degenerative health conditions can be prevented, if ergonomic risks are discovered and eliminated before the consequences can settle in. To prevent ergonomic risks in the early stage, ergonomic analysis is necessary. However, analysis conducted manually can lead to subjective results and is demanding in terms of time and effort, while current automated techniques are not easily accessible and lack interpretability. We propose ErgoMaps, a new method for automated ergonomic risk identification that results in interpretable heatmaps. Our tool is based on human pose estimation and RULA assessment method. It takes an RGB video as input and is open-sourced to increase accessibility. Our qualitative study with eight experts shows that visualisations in the form of heatmaps can be easily adopted by users and are well suited for first level risk assessment. Furthermore, study participants believe that ErgoMaps can reduce the time needed to conduct analysis and improve the awareness of ergonomic risk evaluation among non-experts.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Real-time postural training effects on single and multi-person ergonomic risk scores\n",
            "Authors: Berti N.\n",
            "Abstract: This article proposes and comments on the results achieved in recent laboratory testing activities to develop single and multi-person postural assessment and training in real-time. Research is carried out using the WEM-platform and is promising both in post-processing and in real-time analysis in manufacturing and logistics settings. Laboratory tests are conducted to quantify the impact of visual feedback intervention on workers' behavior based on individual experience and to determine the effect that different anthropometric characteristics can have on ergonomic risk score. Two inertial Motion Capture systems are jointly adopted and coupled with the WEM-platform to quantify the ergonomic risk of two operators employed in a multi-manned assembly station. The results are promising both in single and multi-manned configuration: the system is able to correct the postural behavior of workers when performing the tasks. Furthermore, the flexibility of the proposed platform permits a real-time ergonomic risk assessment for both the workers involved in the study and allow to investigate their mutual movements and collaborative tasks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Human-centred assembly and disassembly systems: a survey on technologies, ergonomic, productivity and optimisation\n",
            "Authors: Slama R.\n",
            "Abstract: Despite the increasing use of automation in the current industry 4.0 context, manual assembly and disassembly tasks are still common and in some situations even unavoidable. The interaction between humans and other elements of the Assembly and Disassembly Systems (ADS) has been discussed in the scientific literature with the dual objective of optimising human well-being and system performance. Human Factor (HF) related studies focused on new technologies such as motion tracking systems. These technologies enable the collection of data to improve understanding the work environment and its impact on employee well-being and productivity. In the literature, different metrics were suggested to measure the ergonomic and productivity scores. These measurements influence the global system performance and may allow its optimisation. In this paper, we provide a review of the literature on human-centred ADS. We mainly focus on technologies (used to capture human motion), metrics (used to assess human ergonomic risks and productivity), and operational research models (used to optimise the performance system considering economic and cycle time objectives). Future directions are discussed in the perspectives of this paper.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Constructing a Violence Recognition Technique for Elderly Patients with Lower Limb Disability\n",
            "Authors: Hung L.P.\n",
            "Abstract: Elder abuse has been recognized as an important public health problem, and will become increasingly serious as the world's population ages. Therefore, the first problem that needs to be solved is the detection of the incident by the outside world. This study proposes a real-time abuse detection method based on OpenPose, an open source human posture tracking technology. By extracting the posture information of people in the care field, we can further analyze the posture status and mutual position, as well as the changes of current and previous movements, and determine whether there are abuse events in the field. This design allows the family to be notified in case of suspected abuse to protect the rights of the elderly from being violated.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Improving posture recognition among construction workers through data augmentation with generative adversarial network\n",
            "Authors: Zhao J.\n",
            "Abstract: Deep Neural Networks (DNN) models have shown high potential in recognizing workers' risky postures using data from wearable Inertial Measurement Units (IMUs). However, there is a data paucity challenge - DNN models require a large dataset with annotation for desirable performance. The research discussed in this paper proposes to address this problem through a data generation framework that leverages Generative Adversarial Network (GAN) to i) synthesize motion data, ii) augment training data, then iii) improve the recognition performance. Its potential was validated using naturalistic posture data of workers. Three GAN models were developed for data generation. A Train on Real and Test on Hybrid approach was used to quantitatively assess synthesized data and select sufficiently-trained GAN models. The performance of three commonly-used DNN models was compared after data augmentation. Results showed that the augmentation with GAN-synthesized data improved recognition accuracy by 1.2%-3% for varying postures. These findings suggest the feasibility of applying motion data augmentation with GAN models to advance automated construction safety monitoring.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automatic Gait Analysis and Classification in Video Sequences\n",
            "Authors: Bejinariu S.I.\n",
            "Abstract: Gait abnormalities can be related to locomotion injuries or to various musculoskeletal and neurological pathologies. In this paper an automatic method for gait analysis and evaluation is proposed. It can be used for rehabilitation assessment but also to detect the gait abnormalities. The proposed system is noninvasive and it is based on the analysis of the video sequences captured in the sagittal plane. The MoveNet pose estimation model is used to detect the joints positions of the body segments. Then the knee and thigh-trunk angles on both left and right side are computed in each frame of the video sequence to study their variation. The video sequences can have different lengths and frame rates, therefore the analysis will be done at stride level by using statistical parameters. Experiments were made on a reduced number of video sequences that contain pathological gait and normal gait. Data augmentation was applied to increase the volume of data which is then used for gait classification.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Work postural ergonomic assessment using two-dimensional joint coordinates\n",
            "Authors: Hida T.\n",
            "Abstract: Work-related musculoskeletal disorders are the most frequent health issues, with awkward posture being one of the risk factors. Observational methods are often used in the manufacturing industry to analyze work postures in production fields. In this study, we present a straightforward technique for evaluating work postures utilizing the Ovako working posture analysis system (OWAS). The proposed technique calculates OWAS-based posture codes by manually acquiring employees’ two-dimensional (2D) joint coordinates on the work image and inputting these coordinates into advanced machine learning models. Experiments were conducted to extract three-dimensional (3D) joint coordinates in the global coordinate system in the OWAS-based postures to develop machine learning models. Furthermore, the resulting 3D coordinates were converted to 2D joint coordinates in the camera image coordinate system using the direct linear transformation (DLT) method. The 2D joint coordinates and accompanying OWAS posture codes were utilized as training data to build machine learning models using the support vector machine algorithm. Cross validation confirmed the agreement rate of the OWAS action category (AC) by more than 80%, according to the experimental results.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: EPAS: An Ergonomic Posture Analysis System\n",
            "Authors: Vaishale S.M.\n",
            "Abstract: Ergonomics aims at creating a safe, productive and comfortable workspace by incorporating human abilities and limitations into the design of a workspace. A workplace ergonomics improvement process removes potential factors of risk that can lead to musculoskeletal injuries and enables enhanced human performance and productivity. Regular computer usage can lead to neck strain, typically due to improper posture. Periodic alerts and suggestions provided to users to correct their postures will result in better health and work experience for them. This paper proposes a system that analyzes the actual ergonomic rules with respect to the individual as well as their working environment and provides suggestions to improve their workplace posture.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Assistance system to improve ergonomics – Preventing musculoskeletal disorders in manufacturing with artificial intelligence\n",
            "Authors: Eversberg L.\n",
            "Abstract: To prevent musculoskeletal disorders at work, e.g., during manual assembly or repair, automated ergonomic postural assessment methods can be applied based on camera and artificial intelligence. Based on this, an assistance system can warn the specialists during work in the case of unergonomic postures. To avoid erroneous warnings, the confidence score of the body tracking should be included in the evaluation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Human deep squat detection method based on MediaPipe combined with Yolov5 network\n",
            "Authors: Zhang S.\n",
            "Abstract: Deep squat training plays a crucial role in the treatment of elderly patients. In this paper, we introduce the target detection algorithm YOLOv5 into MediaPipe, a human pose estimation framework, based on machine vision detection, and propose a method for detecting deep squatting movements. By modifying the YOLOv5 feature extraction network, the human target position is accurately detected, and MediaPipe obtains human skeletal information to mathematically model the deep squat pose and find out the trunk angle, hip angle, and knee angle. The experimental results show that the method can effectively detect deep squatting movements, eliminate false detection rates and improve the robustness of the algorithm in complex environments with an accuracy rate of over 96%.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Fibre-based wearable electronic technology for personal protective clothing\n",
            "Authors: Hassan E.A.M.\n",
            "Abstract: The traditional inorganic rigid electronic materials for personal protective purposes such as metals, semiconductors and synthetic polymers still dominate wearable electronics, making them unsuitable for general wear and healthcare applications, due to some limitations such as their high expense, and low comfort, biocompatibility and biodegradability, which can potentially lead to environmental pollution. Fibre-based structures and large-area fabric energy harvesters from natural resources are highly desirable for the wearable electronics that are expected to play an important role for the future generation of wearable healthcare electronics due to their conformable, long-lasting, flexible, light-weight, biodegradable and biocompatible properties. This chapter highlights the applicability of natural polymer composites (cellulose paper, cotton fabric, silk fabric, biodegradable synthetic polymers, etc.) in various kinds of flexible protective electronics including pressure/strain sensors, biochemical sensors, physiological health, information fitness monitoring, environmental thermal control, ultraviolet and protective clothing for firefighters, and antimicrobial and military applications. In addition, the main structural design and fabrication techniques of wearable devices are briefly summarized.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: AI in human behavior analysis\n",
            "Authors: Yun M.H.\n",
            "Abstract: Various types of biosignals can be measured and utilized to monitor and predict user behavior. In particular, by using wearable sensors and imaging techniques, it has become possible to obtain related information while minimizing user behavior disruption. However, existing analytic models for user behavior prediction do not accurately grasp the feature of data and have a problem in that the accuracy of behavior prediction is poor when applied in the real world. Researchers have utilized artificial intelligence (AI) technology based on machine/deep learning to solve these problems. In this chapter, the authors reviewed how AI and deep learning techniques have contributed to analyzing human behavior. The authors proposed implications and future tasks for human behavior analysis using AI based on the review.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Feasibility of Tree-based Machine Learning algorithms fed with surface electromyographic features to discriminate risk classes according to NIOSH\n",
            "Authors: Donisi L.\n",
            "Abstract: Many work activities can imply a biomechanical overload. Among these activities, lifting loads may determine work-related musculoskeletal disorders. In order to limit injuries, the National Institute for Occupational Safety and Health (NIOSH) proposed a methodology for assessing biomechanical risk in lifting tasks by means of a math formula based on intensity, duration, frequency and other geometrical characteristic of the lifting. In this work, we explored the feasibility of tree-based machine learning algorithms to classify biomechanical risk according to the Revised NIOSH lifting equation. Electromyography signals acquired from the biceps during lifting loads were collected using a wearable sensors for surface electromyography on a study population composed of 5 healthy young subjects. The EMG signals were segmented in order to extract the region of interest related to the lifting actions and for each region of interest several features in time and frequency domains were extracted. High results - greater than 95% - were obtained in terms of evaluation metrics for a binary risk/no-risk classification. In conclusion, this work indicates the proposed combination of features and machine learning algorithms represents a valid approach to automatically classify risk activities according to the Revised NISOH lifting equation. Future investigation on enriched study population could confirm the potentiality of this methodology to automatically classify potential risky activities.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: NeuroErgo: A Deep Neural Network Method to Improve Postural Optimization for Ergonomic Human-Robot Collaboration\n",
            "Authors: Nejadasl A.M.\n",
            "Abstract: Collaborative robots can help industry workers to improve their ergonomics. They can propose a safe and ergonomic posture to the workers to reduce the risk of musculoskeletal disorders. Proposing an ergonomic stance needs postural evaluation and optimization. To optimize the workers' posture, we need to run the optimization on a cost function representing the ergonomic status. The tabular ergonomic assessment methods are the most common methods used by ergonomists, but they are linear stepwise functions that are not differentiable and not suitable for optimization purposes. We propose NeuroErgo, a deep neural network model that can approximate the tabular ergonomic assessment methods more precisely than existing methods. By solving the task constraints optimization problem for any task in industry and NeuroErgo as posture cost function, a safe and ergonomic posture can be derived and recommended to the workers while accomplishing their job.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Vision-based Ergonomic and Fatigue Analyses for Advanced Manufacturing\n",
            "Authors: Kunz M.\n",
            "Abstract: In advanced manufacturing, ergonomic risk assess-ment and fatigue analysis ensure not only the health of human operators, but also the productivity and quality of the manu-facturing process. In this paper we investigate a vision-based method for automatic ergonomic and fatigue risk monitoring, based on a cost-efficient 3D camera system and AI-driven video-based approaches for 3D body posture analysis and repetition counting. Our laboratory trials showed that this method was able to track joint motions with an average accuracy of 3.5°, performed comparable to a human operator when assessing the ergonomic risk, and was able to track and focus on repetitive motions of the human operator. The proposed method supports data visualization, real-time ergonomic and fatigue analyses, and report generation, and has the potential to support the development of better manufacturing environments.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Sitting Posture Detection System Based on Keras Framework\n",
            "Authors: Yang P.\n",
            "Abstract: Aiming at a low-power embedded real-time sitting posture detection system, a real-time sitting posture detection system based on deep learning is designed. The system obtains the pressure of the sitting posture of the human body through a thin-film pressure sensor and the human body pressure in different sitting postures is collected and analyzed, and an analysis model is established under the Keras framework. Burn the model into STM32 through cubemax to realize real-time collection, analysis and detection of human sitting posture. Finally, the communication between the STM32 and the Android application is realized through the MQTT protocol, which realizes the real-time detection and discrimination of the sitting posture and gives the relevant sitting posture correction prompts.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Review Study of Smart Vehicle Seat Sensor for Real-Time Postural Analysis\n",
            "Authors: Dendi P.K.R.\n",
            "Abstract: The era of autonomous driving is gradually transitioning from humans as drivers to humans as passengers. With the advancement of artificial intelligence (AI), humans are switching roles from driver to passenger. Most of the early researches are driver central. But now, it is essential to also study passenger data to understand human states in an autonomous vehicle as a passenger. Smart sensor monitoring systems can play a major role in assessing human and AI dynamics in an autonomous vehicle. Several research studies have utilized electroencephalography, electrocardiography, or electromyography technologies to study human states. But there is a huge gap in the practical applicability of such a sensor in everyday life. Hence, this paper conducts an extensive review of smart seat sensors for easy implementation in a car.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Research on Underground Personnel Behavior Detection Algorithm Based on Lightweight OpenPose\n",
            "Authors: Lv Y.\n",
            "Abstract: To effectively identify the unsafe behaviour of underground workers in coal mines, this paper designs an intelligent detection system of underground workers' behaviour based on a lightweight OpenPose algorithm. Firstly, the system obtains the coordinates of key points of human bones, detects the posture of falling, climbing and pushing by constructing different detection algorithms, and deploys the posture detection model to the industrial computer; Secondly, the industrial computer reads the video of the infrared camera and transmits the information of the detected unsafe behaviour to the alarm. The experimental results show that the detection speed can reach the actual application effect of single-channel 30fps or dual-channel 20fps.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Research on Human Pose Capture Based on the Deep Learning Algorithm\n",
            "Authors: Xie W.\n",
            "Abstract: A method based on the deep learning algorithm is proposed to accurately capture the posture of the human body. It is one of the important means to improve athletes' competitive level in modern sports to accurately analyze the posture of sports training by technical means. Aiming at the application demand of using artificial intelligence technology to accurately analyze and predict the motion training posture, a motion posture analysis and prediction system based on deep learning is designed in this paper. Based on the Arduino embedded development board and equipped with multiple IMU sensors, the scheme established a system to collect accurate human movement data such as speed and acceleration by using stepper motors and obtained accurate human movement data. The experimental results show that these models have been trained with H3.6 m data sets. The sampling frequency was reduced to 25 Hz, and the joint angles were converted into exponential graphs. When the time window covers approximately 1 660 ms, the loop network will be initialized to 40 frames, equivalent to 1 600 ms. For each action, a separate pretrained recursive model is used. It is proved that the method based on deep learning can reduce the prediction error of fine-tuning specific movements and effectively classify and predict the movements not included in the original training data.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of Risk Assessment System for Sewing Machine Operators\n",
            "Authors: Arora A.\n",
            "Abstract: The prevalence of Work-related Musculoskeletal Disorder in the Ready-Made Garment (RMG) industry is quite common. Due to repetitive actions and subsequent awkward postures, the sewing machine operators are prone to the risk of Work-related Musculoskeletal Disorders—WMSDs, which results in temporary or permanent disability among the operators. The study aimed to develop a Risk Assessment System that identifies the level of risk factors involved and eventually computing the Rapid Upper Limb Assessment (RULA) score of each operator. The discrete posture evaluation of the sewing operators was done by tracking the body joints of the operators using their videos while per-forming the tasks. Several socio-demographic, psychological, and work-related details were also factored in through a structured questionnaire for testing and validation. In total 72 videos recorded from either side of different sewing operators, were analyzed at the speed of 30 frames per second. A system was successfully developed by applying various machine learning algorithms to compute the RULA score by extracting the different joint angles of the operators like Neck, Upper and Lower Arm & Trunk directly from the video captured. Such a Risk Assessment System developed shall help in understanding the work conditions operators work in and eventually guide in reducing the risk of WMSDs through precautionary measures against the risk. Other benefits may include productivity enhancement, improving overall health, and reducing the rate of absenteeism, which continues to be a major concern among the factory owners and the Ready-made garment industry, in general.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Pedestrian Physical Education Training over Visualization Tool\n",
            "Authors: Shloul T.a.\n",
            "Abstract: E-learning approaches are one of the most important learning platforms for the learner through electronic equipment. Such study techniques are useful for other groups of learners such as the crowd, pedestrian, sports, transports, communication, emergency services, management systems and education sectors. E-learning is still a challenging domain for researchers and developers to find new trends and advanced tools and methods. Many of them are currently working on this domain to fulfill the requirements of industry and the environment. In this paper, we proposed a method for pedestrian behavior mining of aerial data, using deep flow feature, graph mining technique, and convocational neural network. For input data, the state-of-the-art crowd activity University of Minnesota (UMN) dataset is adopted, which contains the aerial indoor and outdoor view of the pedestrian, for simplification of extra information and computational cost reduction the pre-processing is applied. Deep flow features are extracted to find more accurate information. Furthermore, to deal with repetition in features data and features mining the graph mining algorithm is applied, while Convolution Neural Network (CNN) is applied for pedestrian behavior mining. The proposed method shows 84.50% of mean accuracy and a 15.50% of error rate. Therefore, the achieved results show more accuracy as compared to state-of-the-art classification algorithms such as decision tree, artificial neural network (ANN).\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Design and evaluation of the electronic sensing system of Rehapiano\n",
            "Authors: Husar S.\n",
            "Abstract: This paper describes the development of a data acquisition system for the Rehapiano device, that is designed for diagnosis and rehabilitation of the fine motor skills impairments of upper extremities. Rehapiano measures the forces exerted by the fingers and enables to apply the principles of intelligent and adaptive rehabilitation. We introduce the reader to the benefits of intelligent rehabilitation and describe the similar state-of-the-art devices based on various sensors, namely active stereo-vision camera, force transducer, and inertial measurement unit. We describe the development of a data acquisition system for load cells, the mechanical, hardware, firmware, and software parts of the device. We have performed verification experiments to determine the ability of Rehapiano to detect finger tremors with various frequencies. Finger tremors are indicative, for example, in diagnosing Parkinson's disease. We performed frequency domain analysis on acquired data to detect dominant frequency and concluded that the device is capable to detect frequencies of Parkinson's tremor.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Comparative Studies of Ten Ergonomics Risk Assessment Methods\n",
            "Authors: Rawan M.R.M.\n",
            "Abstract: Work-related musculoskeletal disorders or WMSDs are most often cited in various studies related to the risk factors of repetition, application of excessive force, vibration, contact stress, and awkward postures. Lower back, neck, forearms, wrists, hands, shoulders, and elbow are the most often body areas that are affected from these WMSDs. The scientific literature shows that the best preventions from WMSDs are to reduce the exposure to the risk factors. In other words, risk factors of WMSDs should be assessed especially in the work area to ensure the workers have less interaction with the risk factors of WMSDs. The assessment of WMSDs risk factors can be placed in three categories, subjective judgment, direct measurement, and systematic observation. Based on the review, measurement is the most accurate and reliable methods to identify risk factors of WMSDs, but it required significant investment of resources whereas observation methods are the most commonly method used by the ergonomist. The observation method is easier and less costly compared to the other method in identifying the risk factors. It is also the most flexible method when it comes to collecting data in the actual site. The purpose of the study is to obtain the comparison results between the methods to identify the most effective ergonomics risk assessment in preventing WMSDs. While ergonomics practitioners, occupational therapists, employers, union workers, and health and safety authorities need information on the most effective assessment methods available for preventing WMSDs, the literature still offers little applied research that has tested these methods for comparison and lacks information on which methods are the best at preventing WMSDs. There is also no argument between the ergonomics practitioners as the best method to choose is to develop an experiment related to the task and compare the respective result.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of a sitting posture monitoring system for children using pressure sensors: An application of convolutional neural network\n",
            "Authors: Lee Y.\n",
            "Abstract: BACKGROUND: Today, sedentary lifestyles are very common for children. Therefore, maintaining a good posture while sitting is very important to prevent musculoskeletal disorders. To maintain a good posture, the formation of good postural habit must be encouraged through posture correction. However, long-term observation is required for effective posture correction. Additionally, posture correction is more effective when it is performed in real time. OBJECTIVE: The goal of this study is to classify nine representative sitting postures of children by applying a machine learning technique using pressure distribution data according to the sitting postures. METHODS: In this study, a customized film-type pressure sensor was developed and pressure distribution data from nine sitting postures was collected from seven to twelve year-old children. A convolutional neural network (CNN) was applied to classify the sitting postures and three experiments were conducted to evaluate the performance of the model in three applicable usage scenarios: usage by familiar identifiable users, usage by familiar, but unidentifiable users, and usage by unfamiliar users. RESULTS: The results of our experiments revealed model accuracies of 99.66%, 99.40%, and 77.35%, respectively. When comparing the recall values for each posture, leaning left and leaning right postures had high recall values, but good posture, leaning forward, and crossed-legs postures had low recall values. CONCLUSION: The results of experiments indicated that CNN is an excellent classification method to classify the posture when the pressure distribution data is used as input data. This study is expected to contribute a development of system to aid in observing the natural sitting behavior of children and correcting poor posture in real time.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Prevalence and Risk Factors of Work-Related Upper Extremity Disorders among University Teaching Staff in Ethiopia, 2021: An Institution-Based Cross-Sectional Study\n",
            "Authors: Tesfaye A.H.\n",
            "Abstract: Background. Work-related upper extremity disorders (WRUEDs) are aches, pains, tension, and discomfort in the neck, shoulders, arms, wrists, hands, and fingers. The situation is escalating in educational sectors due to a lousy working environment intertwined with extracurricular deeds. However, empirical evidence focusing on academicians in higher education society is negligible. The purpose of this study is to examine the prevalence and risk factors of WRUEDs among university teaching staff in Ethiopia. Materials and Methods. We conducted a cross-sectional study design from March to April 2021. A sample of 607 academicians were recruited using a stratified sampling technique, and a self-administered structured Nordic Musculoskeletal questionnaire was used to assess upper extremity disorders during the past 12 months. The collected data were entered into EpiData version 4.6 and analyzed using STATA version 14 software. The association between dependent and independent variables was computed with a binary logistic regression. The association was ascertained using an adjusted odds ratio (AOR) with a 95% confidence interval (CI) at a p value of <0.05. Results. A total of 607 participants correctly completed the questionnaire (response rate of 95.44%). Age ranges from 21 to 70 with a mean of 32.39 (SD ± 6.80)) years, and the majority (76.28%) of them were males. The prevalence of WRUED during the last 12 months was 59.14% [95% CI (55.1, 63.1)]. There is no significant difference in prevalence between males and females (45.14% versus 14%), respectively; χ2 = 0.001; p=0.974. Working more than 8 hours per day [AOR: 2.37; 95% CI (1.40, 4.00)], not performing physical exercise [AOR: 2.34; 95% CI (1.6, 3.45)], and job dissatisfaction [AOR: 2.50; 95% CI (1.69, 3.68)] were factors significantly increased the risk of experiencing WRUEDs. Conclusion. This study divulged upper extremity disorder among university teaching staff is pervasive, with more than three-fifth of the academicians were suffering from the condition, and it also indicates that males experienced higher proportions of pain than females. The manifestation of upper extremity disorder was affected by working hours per day, physical activity, and job satisfaction. Optimizing working hours, having a group regular exercise, and proper management of workplace conditions related to job satisfaction are recommended to lessen the condition.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Research on Methods of Physical Aided Education Based on Deep Learning\n",
            "Authors: Su W.\n",
            "Abstract: In order to better meet the training needs of sports and improve the standardization of sports training, an openpose-based sports posture estimation method and assisted training system are proposed, combining the basic structure and principle of openpose network. Firstly, the human posture estimation algorithm is constructed by combining with the openpose network; secondly, the overall framework, specific operation process, image acquisition, posture estimation, and other modules of the sports assistance system are designed in detail; finally, the openpose posture estimation method constructed above is validated. The results show that the value of the loss function obtained by the algorithm gradually stabilizes after 250 iterations. By using the COCO dataset as the training base and comparing it with the standard posture, it is found that the algorithm can correctly identify different badminton action postures, and the recognition rate can reach up to 94%. This shows that the algorithm is feasible and can be used for posture estimation and training of badminton sports movements.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Assessing Lower Extremity Kinematics of Roofing Tasks\n",
            "Authors: Jahani Jirsaraei M.\n",
            "Abstract: Roofers spend considerable time in awkward postures due to steep-slope rooftops. The combination of these postures, the forces acting on them, and the time spent in such postures increases the chance of roofers developing musculoskeletal disorders (MSDs). Several studies have connected these awkward postures to potential risk factors for injuries and disorders; however, existing models are not appropriate in roof workplaces because they are designed to assess work-related risk factors for general tasks. This study examines the impacts of work-related factors, namely working posture and roof slope, on kinematics measurements of body segments in a laboratory setting. To achieve this objective, time-stamped motion data from inertial measurement unit (IMU) devices (i.e., accelerometer, gyroscope, and quaternion signals) were collected from a sample of six undergraduate students at George Mason University. Participants performed two common roofing activities, namely walking along the roof and squatting in different roof slopes (0°, 30°). Comparing IMU signals using statistical analysis demonstrated significant differences in body kinematics between roofing activities on the slope and level ground. Overall, sloped-surface activities on a 30° roof resulted in changes in about 26% of walking and 12% of squatting variables. Such information is useful for a logical understanding of roofing MSD development and may lead to better interventions and guidelines for reducing roofing injuries.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Construction Worker Ergonomic Assessment via LSTM-Based Multi-Task Learning Framework\n",
            "Authors: Cai J.\n",
            "Abstract: Work-related musculoskeletal disorder (WMSD) is a critical occupational hazard and among the leading causes of nonfatal injuries in construction. Rapid ergonomic assessment is important to proactively detect and prevent WMSD-related hazards. This study proposes a novel deep learning framework for ergonomic assessment from construction videos. First, continuous skeleton postures of workers are extracted using a deep-learning-based pose tracking algorithm. Second, a long short-term memory (LSTM) based multi-task learning (MTL) model is created to simultaneously classify various ergonomic poses in different body parts using time-series skeleton postures. Finally, Ovako working posture analysis system (OWAS) is applied to assess the ergonomic risk from the identified poses in different body parts. Real-world construction videos are used to demonstrate the efficacy of the proposed method. Compared with existing vision-based ergonomic assessment methods, the novelty and contribution of this study is: (1) this study leverages LSTM network to exploit the temporal dependency among time-series skeleton postures, which effectively mitigates the errors associated with a single-frame posture and improves the accuracy, and (2) MTL is adopted to learn a unified classifier for multiple body parts leveraging the commonality in human pose, leading to improved performance and computational efficiency.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Research on Multiplayer Posture Estimation Technology of Sports Competition Video Based on Graph Neural Network Algorithm\n",
            "Authors: Guo X.\n",
            "Abstract: With the explosive growth of the number of sports videos, the traditional sports video analysis method based on manual annotation has been difficult to meet the growing demand because of its high cost and many limitations. The traditional model is usually based on the target detection algorithm of manual features, and the detection of human posture features is not accurate. Compared with global image features such as line features, texture features and structure features, local image features have the characteristics of rich quantity in the image, low correlation between features, and will not affect the detection and matching of other features due to the disappearance of some features in the case of occlusion. Referring to the practice of Deep-ID network considering both local and global features, this paper adjusts the traditional neural network, and combines the improved neural network with the human joint model to form a human pose detection method based on graph neural network, and then applies the algorithm to multiperson human pose estimation. The results of several groups of comparative experiments show that the algorithm can better estimate the human posture in sports competition video, and has a good performance in solving multiperson pose estimation in sports game video.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Predict joint angle of body parts based on sequence pattern recognition\n",
            "Authors: Kasani A.A.\n",
            "Abstract: The way organs are positioned and moved in the workplace can cause pain and physical harm. Therefore, ergonomists use ergonomic risk assessments based on visual observation of the workplace, or review pictures and videos taken in the workplace. Sometimes the workers in the photos are not in perfect condition. Some parts of the workers' bodies may not be in the camera's field of view, could be obscured by objects, or by self-occlusion, this is the main problem in 2D human posture recognition. It is difficult to predict the position of body parts when they are not visible in the image, and geometric mathematical methods are not entirely suitable for this purpose. Therefore, we created a dataset with artificial images of a 3D human model, specifically for painful postures, and real human photos from different viewpoints. Each image we captured was based on a predefined joint angle for each 3D model or human model. We created various images, including images where some body parts are not visible. Nevertheless, the joint angle is estimated beforehand, so we could study the case by converting the input images into the sequence of joint connections between predefined body parts and extracting the desired joint angle with a convolutional neural network. In the end, we obtained root mean square error (RMSE) of 12.89 and mean absolute error (MAE) of 4.7 on the test dataset.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Dynamic System to Predict an Assembly Line Worker's Comfortable Work-Duration Time by Using the Machine Learning Technique\n",
            "Authors: Rao Pabolu V.K.\n",
            "Abstract: Worker' work-rotation between the workstations of an assembly line is a common task to an assembly line manager, to manage the workload between the assembly line workers. Usually, worker work rotation makes an interruption to a continuous production system. It is a desire of an assembly line manager to avoid the worker's work-rotation, at least between the work breaks. This work aims to protect the manager's interest by predicting the comfortable work-duration time of an assembly line worker for a given work, based on the working condition and the instantaneous physical & mental status of the worker. The comfortable work-duration time can be used during the worker's work assignment to reduce interruptions. Factors, which influence the longevity of workers' comfortable work duration time are identified. IIoT based sensors are proposed here to monitor the relevant factors for diagnostics. Machine Learning techniques are used as a part of prognostics to predict the comfortable work-duration time of a worker, based on his/her physical & mental status. Implementation methodology is explained along with a simulated experiment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Design of Intelligent Perception Module Based on Wireless Sensor Network and Basketball Sports Attitude\n",
            "Authors: Jin W.\n",
            "Abstract: In recent years, along with microelectromechanical (MEMS) technique and wireless body area network (WBAN), wearable health monitoring systems have emerged. With sustainability posture detection technique, people pay more and more attention to mankind posture detection. Human posture detection technique has been widely used in medical, film and television, industry, sports, and other fields. Motion capture is a technique for measuring the motion of moving objects in three-dimensional space with great accuracy. It is the most efficient method for producing computer 3D animation and collecting human motion data. The use of motion capture systems in animation is becoming increasingly common. The problem of a single sensor having a large error in monitoring human motion and attitude is addressed. The use of multisensor data fusion technology is used to propose a human motion pattern recognition method based on data fusion of accelerometer and gyroscope. The system must effectively integrate the information of various sensors in order to achieve the goal of accuracy, timeliness, and reliability processing, and multisensor information fusion systems for various complex application objects are constantly emerging.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Classification of kneeling and squatting in workers wearing protective equipment: development and validation of a rule-based model using wireless triaxial accelerometers\n",
            "Authors: Tjosvoll S.O.\n",
            "Abstract: Several professions in industries, such as petroleum, manufacturing, construction, mining, and forestry require prolonged work tasks in awkward postures, increasing workers’ risks for musculoskeletal pain and injury. Therefore, we developed and validated a rule-based model for classifying unilateral and bilateral kneeling and squatting based on 15 individuals wearing personal protective equipment and using three wireless triaxial accelerometers. The model provided both high sensitivity and specificity for classifying kneeling (0.98; 0.98) and squatting (0.96; 0.91). Hence, this model has the potential to contribute to increased knowledge of physical work demands and exposure thresholds in working populations with strict occupational safety regulations. Practitioner summary: Our results indicate that this rule-based model can be applied in a human-factors perspective enabling high-quality quantitative information in the classification of occupational kneeling and squatting, known risk factors for musculoskeletal pain, and sick leave. This study is adapted for working populations wearing personal protective equipment and aimed for long-term measurements in the workplace.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Vision-based Skeleton Motion Phase to Evaluate Working Behavior: Case Study of Ladder Climbing Safety\n",
            "Authors: Chen Z.\n",
            "Abstract: Since workers’ unsafe behavior is one of the major risks related to construction accidents and injuries, behavior management plays an important role in enhancing construction safety. The rapidly developed computer vision approaches have been utilized to determine unsafe behaviors in construction. Nevertheless, the evaluation of actions from a perspective of construction regulations poses a significant research challenge due to the complexity of spatio-temporal features of movement. In an effort to provide an automated and robust methodology to analyze the working behavior, this paper proposes a framework of vision-based skeleton motion phase feature for evaluating the normalization of behavior. The framework developed is used to: efficiently obtain the human skeletons from imagery data based on convolutional neural network (CNN) models; automatically extract the motion phase feature of each 2D skeleton data; and evaluate the behavior by the sequence characteristics of a synthesis of bone movement (e.g., limbs movement). To validate our approach, a case study of ladder climbing is undertaken to distinguish between three typical climbing postures based on collected climbing video data in the laboratory. The results reveal that the proposed framework can potentially achieve promising performance at detecting safe/unsafe actions by evaluating regular/irregular movements of workers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Video image-based posture assessment: an approach for dynamic working posture assessment\n",
            "Authors: Mohan K.\n",
            "Abstract: Traditional observational posture evaluation methods stress on sampling approach for continuous evaluation of dynamic postures in any activity. Hence, the quality of results from such evaluations is under debate. This article proposes a Video Image-based Posture Assessment (VIPA) method as a highly capable one for assessing an activity requiring dynamic postures of workers. This article explains the various steps of VIPA and its application for (i) the extraction and classification of postures into different categories based on the instructed posture classes from 10 videos of soil loosening activity having 48,715 postures and (ii) the use of OWAS to evaluate the postures. VIPA relies on traditional posture evaluation methods. The results indicate that VIPA could identify precarious postures 30% of the activity duration; these results were found to be accurate and reliable because there is no sampling method involved. The capability of VIPA method is proven through the activity studied.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Method for Sleep Position Identification Based on Back Propagation Neural Network\n",
            "Authors: Liu Z.\n",
            "Abstract: Sleep occupies roughly one-third of our lifetime and strongly impacts our work, physical well-being and daily activities. The identification of different sleep positions is critical to sleep health analysis and improvement as well as sleep quality intervention and improvement. The six common sleep positions consist of sleeping on the back (Supine, S), sleeping on the stomach (Prone, P), left lateral sleep in the foetal position (LF), left-sided log sleep (LL), right lateral sleep in the foetal position (RF) and right-sided log sleep (RL). In this study, a piezoresistive transducer was employed to collect pressure distribution images of the human body during sleep. Afterwards, feature extraction was conducted through kernel principal component analysis, and then six sleep positions were classified according to support vector machine and back-propagation neural networks. The precision rates of identification and classification were satisfactory. For example, the precision rate reached its peak (i.e. 96.8%) when back-propagation was performed. Moreover, the proposed sleep position identification methods can also be applied to the analysis and prevention of pressure sores as well as to the intervention and improvement of sleep quality. In other words, our established methods are beneficial to promoting both sleep quality and health.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Recognition method of submarine operation posture based on convolutional pose machine\n",
            "Authors: Wang J.L.\n",
            "Abstract: A new posture recognition and analysis method based on convolutional pose machines was proposed aiming at the problems of complicated recognition process and low recognition accuracy in the existing submariner's operation posture recognition and analysis methods. The human body posture features were structured and coded, and the spatial and projected coordinate system were constructed to explain the human body posture. The calculation formulae of limb angle and the judging processes of special limb state were defined. The spatial and texture features of the RGB operation posture image can be extracted by building the submariner's operation posture recognition algorithm. The joint points, limb angles and state data of the submariner's operation posture can be output. The application of the proposed method was verified by the submariner's operation posture sample data set constructed by collecting submarine operation posture image. The percentage of correct keypoints index value of the recognition algorithm reached 81.2% in the algorithm test. The average accuracy rate of the algorithm in identifying the joint points reached 87.7% in the application verification experiment. The experimental results show that the method is reliable in the recognition and analysis of the submariner's operation posture, and can effectively identify and analyze the negative factors of the submariner's operation posture.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Physiotherapeutic methods of treatment of mandibular distal occlusion and the progress of therapy: A case report\n",
            "Authors: Ciuraj M.\n",
            "Abstract: Background: Studies have demonstrated a relationship between dental malocclusion and posture defects. The aims of the study were to present (1) the effect of a physiotherapeutic approach to a patient with a distal occlusion defect with the use of a set of exercises to strengthen the muscles responsible for mandibular protrusion, and (2) a non-invasive and easy-to-use method to monitor the effects of therapy. Methods: Five year old girl with a distal occlusion and with a low basic postural tone was referred to physiotherapy. A therapeutic program i.a. concerning a strengthening of the temporomandibular joint muscles with the use of a flexible tape was proposed. To assess the functional changes of the masticatory apparatus a photoanthropometric method was used. In side-face photos, proportions of 2 linear measurements and values of two angles on the first day of therapy, after 2 and after 4 months of exercises, with the mandible located freely and in the maximum protrusion were compared. Results: A comparison of indices and angles showed a marked improvement in mandibular mobility already after two and four months of the exercises. Using the elastic resistance tape in addition to general developmental exercises allowed for increasing the mobility in the temporomandibular joint. Conclusion: Malocclusion should not be considered separately, without taking into account the body posture. The work of the physiotherapist can benefit the orthodontist, correcting postural defects and consequently affecting malocclusion. A comparison of linear measurements and angles can be used to assess the progress of the therapy.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Posture Prediction for Healthy Sitting Using a Smart Chair\n",
            "Authors: Gelaw T.A.\n",
            "Abstract: Poor sitting habits have been identified as a risk factor to musculoskeletal disorders and lower back pain especially on the elderly, disabled people, and office workers. In the current computerized world, even while involved in leisure or work activity, people tend to spend most of their days sitting at computer desks. This can result in spinal pain and related problems. Therefore, a means to remind people about their sitting habits and provide recommendations to counterbalance, such as physical exercise, is important. Posture recognition for seated postures have not received enough attention as most works focus on standing postures. Wearable sensors, pressure or force sensors, videos and images were used for posture recognition in the literature. The aim of this study is to build Machine Learning models for classifying sitting posture of a person by analyzing data collected from a chair platted with two 32 by 32 pressure sensors at its seat and backrest. Models were built using five algorithms: Random Forest (RF), Gaussian Naïve Bayes, Logistic Regression, Support Vector Machine and Deep Neural Network (DNN). All the models are evaluated using KFold cross validation technique. This paper presents experiments conducted using the two separate datasets, controlled and realistic, and discusses results achieved at classifying six sitting postures. Average classification accuracies of 98% and 97% were achieved on the controlled and realistic datasets, respectively.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Features of ‘Internet of Things’ to Resolve Agricultural Problems\n",
            "Authors: Satapathy S.\n",
            "Abstract: This chapter deals with the problems associated with ergonomic risks as well as musculoskeletal disorders (MSDs) among the farmers along with possible measures through the application of “Internet of Things (IoT)” in agricultural machinery. With an in-depth review of literature with regard to the existing cultivation practices and the benefits of IoT utilization in agricultural sectors in the developing as well as under-developed countries, the “strength, weaknesses, opportunities as well as threats (SWOT)” analysis was used for evaluating the benefits of utilizing IoT in agriculture by considering two cases such as the “conventional agriculture-based machinery” and the “IoT-based agricultural machinery”. Further, in view of the requirements of small-scale farmers, an IoT-based agricultural machinery was proposed and its performance was evaluated with respect to field applications.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Validation of an Embedded Motion-Capture and EMG Setup for the Analysis of Musculoskeletal Disorder Risks during Manhole Cover Handling\n",
            "Authors: Hubaut R.\n",
            "Abstract: Musculoskeletal disorders in the workplace are a growing problem in Europe. The measurement of these disorders in a working environment presents multiple limitations concerning equipment and measurement reliability. The aim of this study was to evaluate the use of inertial measurement units against a reference system for their use in the workplace. Ten healthy volunteers conducted three lifting methods (snatching, pushing, and pulling) for manhole cover using a custom-made tool weighting 20 and 30 kg. Participants’ back and dominant arm were equipped with IMU, EMG, and reflective markers for VICON analysis and perception of effort was estimated at each trial using a Visual Analog Scale (VAS). The Bland–Altman method was used and results showed good agreement between IMU and VICON systems for Yaw, Pitch and Roll angles (bias values < 1, −4.4 < LOA < 3.6°). EMG results were compared to VAS results and results showed that both are a valuable means to assess efforts during tasks. This study therefore validates the use of inertial measurement units (IMU) for motion capture and its combination with electromyography (EMG) and a Visual Analogic Scale (VAS) to assess effort for use in real work situations.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A governance framework to assist with the adoption of sensing technologies in construction\n",
            "Authors: Arabshahi M.\n",
            "Abstract: Sensing technologies present great improvements in construction performance including the safety, productivity, and quality. However, the corresponding applications in real projects are far behind compared with the academically research. This research aims to discover dominate influence factors in the sensing technologies adoption and ultimately develop a governance framework facilitating adoption processes. The framework is dedicated on general sensing technologies rather than single sensor in previous framework studies. To begin with, the influence factors of sensing technologies and other similar emerging technologies are summarised through a review. Then, a mixed methods design was employed to collect quantitative data through an online survey, and qualitative data through semi‐structured interviews. Findings of the quantitative method reveal that the most widely implemented sensing technologies are GPS and visual sensing technology, but they’re still not adopted by all construction companies. Partial Least Squares Structural Equation Modelling reveals that supplier characteristics have the highest effect in all influence factors. Qualitative method was adopted to investigate perceptions of construction stakeholders on the major decision‐making considerations in the adoption process. Ultimately, a triangulation analysis of findings from the literature review, online survey and interviews resulted in the governance framework development. The overarching contribution of this research focus on the general adoption of sensing technologies rather than the adoption of a specific sensor. Therefore, the governance framework can assist with the decision‐making process of any sensing technology adoption in construction.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Human work sustainability tool\n",
            "Authors: Ciccarelli M.\n",
            "Abstract: The work environment influences workers’ well-being and contributes to the growth of personal experiences. In fact, working in an unhealthy workplace can cause stress, frustration, and anxiety. Therefore, companies have to deal with the workers’ well-being in the work environment, making the management of human factors a crucial aspect. In this context, the introduction of Industry 4.0 technologies can support workplace monitoring and improvement. Some researchers propose structured methods that consider several ergonomic domains together; however, it is necessary to create platforms that support data collection, elaboration, and correlation in an integrated way. Accordingly, this paper presents a tool that supports the monitoring of operators’ activities, the data analysis, and the implementation of corrective actions to make the workplace socially sustainable. Preliminary tests were conducted to assess the functionality of the tool architecture and two use cases are presented. They focus on posture analysis and stress detection by inertial sensors and unsupervised machine learning algorithms, respectively.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Investigation of office workers’ sitting behaviors in an ergonomically adjusted workstation\n",
            "Authors: Tahernejad S.\n",
            "Abstract: Objectives. Common ergonomic office workstations are designed for a few optimum postures. Nonetheless, sitting is a dynamic activity and the ideal sitting posture is rarely maintained in practice. Therefore, the present study aimed to investigate the sitting behavior of office workers in an actual working environment using ergonomically adjusted workstations to examine whether they promote maintaining appropriate sitting postures. Methods. Sitting behaviors (frequency of postures and position changes in different body parts) were explored among 26 office workers during a 60-min sitting duration, using the posture recording and classification method developed by Graf et al. The rapid upper limb assessment (RULA) method was also used to assess postural load. Then, the results of the RULA method were compared with the results from investigating the sitting behavior of office workers. Results. Common ergonomic workstations were effective in eliminating some awkward postures. However, some important risk factors such as holding postures with an inappropriate lumbar spine curve (86% of the observations) and maintaining a posture for a long time (for 7–12 min) were observed in the participants’ sitting behaviors, while they were neglected in the RULA method. Conclusions. The common ergonomic workstations could not guarantee the users’ appropriate sitting behaviors.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Framework for Intelligent Fitness Guiding System\n",
            "Authors: Yang H.\n",
            "Abstract: Using fitness equipment for workout is becoming increasingly popular. High expertise and skills were required for the user to manipulate the equipment for exercising. Injuries were commonly generated by applying an awkward posture to exertion due to lack of professional guidance. This study therefore proposed an intelligent guiding system for instructing users for fitness. The system used 3D computer vision technology to identify the body contour of the user and established a video-base of virtual fitness posture model. This model digitized the user’s actions to accurately obtain fitness posture data in real time, and comparison with the standard motion model through the in-depth algorithm calculation to identify whether the fitness posture is standard. Providing feedbacks to the bodybuilder in time, correct the bodybuilder's motions, and effectively ensure that people are efficient and safe in weight training.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The role of machine learning in the primary prevention of work-related musculoskeletal disorders: A scoping review\n",
            "Authors: Chan V.C.H.\n",
            "Abstract: To determine the applications of machine learning (ML) techniques used for the primary prevention of work-related musculoskeletal disorders (WMSDs), a scoping review was conducted using seven literature databases. Of the 4,639 initial results, 130 primary research studies were deemed relevant for inclusion. Studies were reviewed and classified as a contribution to one of six steps within the primary WMSD prevention research framework by van der Beek et al. (2017). ML techniques provided the greatest contributions to the development of interventions (48 studies), followed by risk factor identification (33 studies), underlying mechanisms (29 studies), incidence of WMSDs (14 studies), evaluation of interventions (6 studies), and implementation of effective interventions (0 studies). Nearly a quarter (23.8%) of all included studies were published in 2020. These findings provide insight into the breadth of ML techniques used for primary WMSD prevention and can help identify areas for future research and development.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A hierarchical model for learning to understand head gesture videos\n",
            "Authors: Li J.\n",
            "Abstract: Head gesture videos recorded of a person bear rich information about the individual. Automatically understanding these videos can empower many useful human-centered applications in areas such as smart health, education, work safety and security. To understand a video's content, low-level head gesture signals carried in the video that capture characteristics of both human postures and motions need to be translated into high-level semantic labels. To meet this aim, we propose a hierarchical model for learning to understand head gesture videos. Given a head gesture video of an arbitrary length, the model first segments the full-length video into multiple short clips for clip-based feature extraction. Multiple base feature extraction procedures are then independently tuned via a set of peripheral learning tasks without consuming any labels of the goal task. These independently derived base features are subsequently aggregated through a multi-task learning framework, coupled with a feature dimensionality reduction module, to optimally learn to accomplish the end video understanding task in an weakly supervised manner, utilizing the limited amount of video labels available of the goal task. Experimental results show that the hierarchical model is superior to multiple state-of-the-art peer methods in tackling versatile video understanding tasks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Prediction of slaughterhouse workers’ RULA scores and knife edge using low-cost inertial measurement sensor units and machine learning algorithms\n",
            "Authors: Villalobos A.\n",
            "Abstract: The high prevalence of work-related musculoskeletal disorders (WRMSDs) has been a concern in the meat-processing industry, owing to the manual nature of the work and the high upper-limb and neck exposure to movements that can lead to WRMSD. The ability to perform an accurate and fast assessment of WRMSDs remains a challenge in industrial environments. Most assessment methodologies rely on standard survey-based methods, which are time- and labor-intensive. In this paper, we present an application of inertial measurement units (IMUs) to measure human activity, and the use of artificial intelligence and machine learning techniques to perform task classification and ergonomic assessments in workplace settings. We present the results obtained by using simple low-cost IMUs worn on slaughterhouse worker wrists to capture information on their movements. We describe the use of this information to detect the risk factors of the wrists/hands that can lead to WRMSDs. The results indicate that by using low-cost IMU-based sensors on the wrists of slaughterhouse workers, we can accurately classify the sharpness of the knife and predict the worker RULA score.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A novel cost-effective postural tracking algorithm using marker-based video processing\n",
            "Authors: Nazerian R.\n",
            "Abstract: Recently, many postural analysis techniques have been developed in order to reduce the risk of musculoskeletal problems. Methods such as rapid entire body assessment are capable of analyzing the most constant or awkward positions, but the selection of these postures is subjective. To make an objective postural analysis, devices such as electromagnetic trackers can be used continuously during the job task, but utilizing such devices is costly. Therefore, in this study a cost-effective marker-based video processing algorithm is developed for measuring three-dimensional (3D) information regarding both the location and the orientation of human posture. To investigate the precision of the measurements, an experiment was designed. With the average of 2.88 mm and 1.34° for location and orientation, respectively, the algorithm was able to measure six degrees of freedom information regarding 3D space. Furthermore, the precision of the algorithm is found to be significantly affected by the marker pattern.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A mini-survey and feasibility study of deep-learning-based human activity recognition from slight feature signals obtained using privacy-aware environmental sensors\n",
            "Authors: Madokoro H.\n",
            "Abstract: Numerous methods and applications have been proposed in human activity recognition (HAR). This paper presents a mini-survey of recent HAR studies and our originally developed benchmark datasets of two types using environmental sensors. For the first dataset, we specifically examine human pose estimation and slight motion recognition related to activities of daily living (ADL). Our proposed method employs OpenPose. It describes feature vectors without effects of objects or scene features, but with a convolutional neural network (CNN) with the VGG-16 backbone, which recognizes behavior patterns after classifying the obtained images into learning and verification subsets. The first dataset comprises time-series panoramic images obtained using a fisheye lens monocular camera with a wide field of view. We attempted to recognize five behavior patterns: eating, reading, operating a smartphone, operating a laptop computer, and sitting. Even when using panoramic images including distortions, results demonstrate the capability of recognizing properties and characteristics of slight motions and pose-based behavioral patterns. The second dataset was obtained using five environmental sensors: a thermopile sensor, a CO2 sensor, and air pressure, humidity, and temperature sensors. Our proposed sensor system obviates the need for constraint; it also preserves each subject’s privacy. Using a long short-term memory (LSTM) network combined with CNN, which is a deep-learning model dealing with time-series features, we recognized eight behavior patterns: eating, operating a laptop computer, operating a smartphone, playing a game, reading, exiting, taking a nap, and sitting. The recognition accuracy for the second dataset was lower than for the first dataset consisting of images, but we demonstrated recognition of behavior patterns from time-series of weak sensor signals. The recognition results for the first dataset, after accuracy evaluation, can be reused for automatically annotated labels applied to the second dataset. Our proposed method actualizes semi-automatic annotation, false recognized category detection, and sensor calibration. Feasibility study results show the new possibility of HAR used for ADL based on unique sensors of two types.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Review on sensing technology adoption in the construction industry\n",
            "Authors: Arabshahi M.\n",
            "Abstract: Sensing technologies demonstrate promising potential in providing the construction industry with a safe, productive, and high-quality process. The majority of sensing technologies in the construction research area have been focused on construction automation research in prefabrication, on-site operation, and logistics. However, most of these technologies are either not implemented in real construction projects or are at the very early stages in practice. The corresponding applications are far behind, even in extensively researched aspects such as Radio Frequency Identification, ultrawideband technology, and Fiber Optic Sensing technology. This review systematically investigates the current status of sensing technologies in construction from 187 articles and explores the reasons responsible for their slow adoption from 69 articles. First, this paper identifies common sensing technologies and investigates their implementation extent. Second, contributions and limitations of sensing technologies are elaborated to understand the current status. Third, key factors influencing the adoption of sensing technologies are extracted from construction stakeholders’ experience. Demand towards sensing technologies, benefits and suitability of them, and barriers to their adoption are reviewed. Lastly, the governance framework is determined as the research tendency facilitating sensing technologies adoption. This paper provides a theoretical basis for the governance framework development. It will promote the sensing technologies adoption and improve construction performance including safety, productivity, and quality.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Systematic review of Kinect-based solutions for physical risk assessment in manual materials handling in industrial and laboratory environments\n",
            "Authors: Lunin A.\n",
            "Abstract: Due to demographic changes, the number of older workers employed in production and logistics environments increases continuously. During the execution of manual materials handling tasks that are still very common in these industries, especially older workers face an increased risk of developing musculoskeletal disorders (MSDs). The substantial MSD rates we can observe in many countries could be decreased through an improvement in working conditions. Ergonomic observational methods play an important role in this context: they facilitate an ergonomic risk assessment of workplaces and work processes and, by comparing system alternatives, help to lower MSD risks. Despite their advantages, these methods have also been criticized in the past, especially because they are time-consuming and often provide subjective results. Markerless motion capturing technology could be used to overcome some of the limitations of ergonomic observational methods, as they could quickly provide objective posture data of the worker. The aim of this paper is to provide a comprehensive review of works that develop solutions for evaluating manual materials handling activities at industrial workplaces using the Microsoft Kinect. Microsoft Kinect is an inexpensive markerless motion capturing system originally developed for Microsoft's Xbox gaming console that has recently been used in industry-type settings as well. Information collected in a systematic search of the literature is used to develop a conceptual framework that is then employed to discuss and synthesize the sampled literature. The results of this review support researchers and practitioners in developing and evaluating Kinect-based systems that support the ergonomic evaluation of workplaces and the consequent improvement of working conditions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Computer vision applications in construction: Current state, opportunities &amp; challenges\n",
            "Authors: Paneru S.\n",
            "Abstract: Thousands of images and videos are collected from construction projects during construction. These contain valuable data that, if harnessed efficiently, can help automate or at least reduce human effort in diverse construction management activities such as progress monitoring, safety management, quality control and productivity tracking. Extracting meaningful information from images requires the development of technology and algorithms that enable computers to understand digital images or videos, replicating the functionality of human visual systems. This is the goal of computer vision. This review aims at providing an updated and categorized overview of computer vision applications in construction by examining the recent developments in the field and identifying the opportunities and challenges that future research needs to address to fully leverage the potential benefits of Computer Vision. We restrict the focus to four areas that can benefit the most from computer vision - Safety Management, Progress Monitoring, Productivity Tracking and Quality Control.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Assessment of the handcart pushing and pulling safety by using deep learning 3D pose estimation and IoT force sensors\n",
            "Authors: Vukicevic A.M.\n",
            "Abstract: Pushing and pulling (P&P) are common and repetitive tasks in industry, which non-ergonomic execution is among major causes of musculoskeletal disorders (MSD). The current safety management of P&P assumes restrictions of maximal weight, distance, height – while variable individual parameters (such as the P&P pose ergonomic) remain difficult to account for with the standardized guides. Since manual detection of unsafe P&P acts is subjective and inefficient, the aim of this study was to utilize IoT force sensors and IP cameras to detect unsafe P&P acts timely and objectively. Briefly, after the IoT module detects moments with increased P&P forces, the assessment of pose ergonomics was performed from the employee pose reconstructed with the VIBE algorithm. The experiments showed that turn-points correspond to the high torsion of torso, and that in such moments poses are commonly non ergonomic (although P&P forces are below values defined as critical in previous studies – their momentum cause serious load on the human body). Moreover, the analysis revealed that the loading/unloading of a cargo are also moments of frequent unsafe P&P acts – although they are commonly neglected when studying P&P. The experimental validation of the solution showed good agreement with motion sensors and high potential for monitoring and improving P&P workplace safety. Accordingly, future research will be directed towards: 1) acquisition of P&P data sets for direct recognition and classification of unsafe P&P acts; 2) incorporation of wearable sensors (EMG and EEG) for detecting fatigue and decrease of physical abilities.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Touch-dynamics based Behavioural Biometrics on Mobile Devices -A Review from a Usability and Performance Perspective\n",
            "Authors: Ellavarason E.\n",
            "Abstract: Over the past few years, there has been an exponential increase in the percentage of people owning and using a smart phone. These devices have sensor-rich touchscreens that can capture sensitive biometric features such as keystroke typing and finger-swiping patterns. Touch-dynamics based behavioural biometrics is a time-based assessment of how a user performs a particular touch task on a mobile device. Several performance-focused surveys already exist. In this article, building upon the existing reviews, we have examined studies on touch-dynamics based behavioural biometrics based on usability and its impact on authentication performance. We also emphasize the need for shifting the focus on usability during performance evaluations by presenting a consolidated list of usability and ergonomic-based factors that influence user interaction and cause performance variations. In this article, we report and review the usability evaluations: user acceptance studies and performance-based studies influencing the user interaction process on three specific touch-dynamics based modalities - signature, keystroke, and swipe. With regards to performance, we present a comparative analysis of error rates and accuracy of various research works undertaken. Additionally, we present a consolidated list of public datasets and discuss evolving vulnerabilities of touch-dynamics based behavioural biometrics, their adopted attack models, and their feasibility. Finally, we present our assessment of this domain's existing unresolved problems that could pave the way for future research.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Wearable sensing technologies for improving workers' safety in the construction industry: A review\n",
            "Authors: Antwi-Afari M.F.\n",
            "Abstract: Occupational injuries are prevalent in the construction industry. These fatal and non-fatal occupational injuries could result in loss of productivity, absenteeism, and project delays. One way to reduce the manifestation of injuries is the use of wearable sensing technologies. This chapter summarizes the different types of wearable sensing technologies for improving workers' safety. In this chapter, published articles that met the inclusion criteria through a three-step method were compiled for the results and findings. The results revealed that the types of wearable sensing technologies include direct measurement sensors, real-time location system (RTLS)-based on radio frequency identification, remote-sensing techniques, RTLS-based on ultrawideband, fiber optic sensors, wireless sensor networks/wireless local area network/internet of things, global positioning systems/geographical information systems, behavior-based safety with proactive construction management systems, and RTLS based on Bluetooth sensing technology. The findings advocate the use of wearable sensing technologies for continuous monitoring of workers' movements to provide proactive preventive measures for safety in construction.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Design and Analytics of Smart Posture Monitoring System\n",
            "Authors: Chaitanya Kumar A.\n",
            "Abstract: Instances of low-back pain in people of all ages is one of the most common issues in the world. Over 50% of the world population report of being affected by low-back pain at least once a year. It is therefore of paramount importance for individuals to realize the necessity and importance of a proper sitting posture, to interact and work in an ergonomically supportive environment. With the advent of the Internet of Things, it is now evident that communication technology coupled with the mechanics of the seating device can help produce meaningful insights, and help in undertaking data-driven decisions. There have been various attempts at designing “smart chairs”. These smart chairs in addition to the above mentioned functionalities, can also be deployed as robust health-monitoring systems. Using embedded sensors within, these chairs can function as an alert mechanism to the user, when he/she is sitting with an incorrect posture, that could be detrimental to the physical health of the individual. In this paper, the researchers conduct a comprehensive analysis of the existing products, by a customer survey and propose a solution that could potentially serve the people with back pain to use the proposed chair: embedded with sensors, and supplemented by data analytics. The system designed is a cost-effective low-power consuming posture monitoring system, that simultaneously works as an accurate health monitoring system as well.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automated activity and progress analysis based on non-monotonic reasoning of construction operations\n",
            "Authors: Johansen K.W.\n",
            "Abstract: Purpose: Real-time location sensing (RTLS) systems offer a significant potential to advance the management of construction processes by potentially providing real-time access to the locations of workers and equipment. Many location-sensing technologies tend to perform poorly for indoor work environments and generate large data sets that are somewhat difficult to process in a meaningful way. Unfortunately, little is still known regarding the practical benefits of converting raw worker tracking data into meaningful information about construction project progress, effectively impeding widespread adoption in construction. Design/methodology/approach: The presented framework is designed to automate as many steps as possible, aiming to avoid manual procedures that significantly increase the time between progress estimation updates. The authors apply simple location tracking sensor data that does not require personal handling, to ensure continuous data acquisition. They use a generic and non-site-specific knowledge base (KB) created through domain expert interviews. The sensor data and KB are analyzed in an abductive reasoning framework implemented in Answer Set Programming (extended to support spatial and temporal reasoning), a logic programming paradigm developed within the artificial intelligence domain. Findings: This work demonstrates how abductive reasoning can be applied to automatically generate rich and qualitative information about activities that have been carried out on a construction site. These activities are subsequently used for reasoning about the progress of the construction project. Our framework delivers an upper bound on project progress (“optimistic estimates”) within a practical amount of time, in the order of seconds. The target user group is construction management by providing project planning decision support. Research limitations/implications: The KB developed for this early-stage research does not encapsulate an exhaustive body of domain expert knowledge. Instead, it consists of excerpts of activities in the analyzed construction site. The KB is developed to be non-site-specific, but it is not validated as the performed experiments were carried out on one single construction site. Practical implications: The presented work enables automated processing of simple location tracking sensor data, which provides construction management with detailed insight into construction site progress without performing labor-intensive procedures common nowadays. Originality/value: While automated progress estimation and activity recognition in construction have been studied for some time, the authors approach it differently. Instead of expensive equipment, manually acquired, information-rich sensor data, the authors apply simple data, domain knowledge and a logical reasoning system for which the results are promising.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Application Scenarios for Artificial Intelligence in Nursing Care: Rapid Review\n",
            "Authors: Seibert K.\n",
            "Abstract: Background: Artificial intelligence (AI) holds the promise of supporting nurses’ clinical decision-making in complex care situations or conducting tasks that are remote from direct patient interaction, such as documentation processes. There has been an increase in the research and development of AI applications for nursing care, but there is a persistent lack of an extensive overview covering the evidence base for promising application scenarios. Objective: This study synthesizes literature on application scenarios for AI in nursing care settings as well as highlights adjacent aspects in the ethical, legal, and social discourse surrounding the application of AI in nursing care. Methods: Following a rapid review design, PubMed, CINAHL, Association for Computing Machinery Digital Library, Institute of Electrical and Electronics Engineers Xplore, Digital Bibliography & Library Project, and Association for Information Systems Library, as well as the libraries of leading AI conferences, were searched in June 2020. Publications of original quantitative and qualitative research, systematic reviews, discussion papers, and essays on the ethical, legal, and social implications published in English were included. Eligible studies were analyzed on the basis of predetermined selection criteria. Results: The titles and abstracts of 7016 publications and 704 full texts were screened, and 292 publications were included. Hospitals were the most prominent study setting, followed by independent living at home; fewer application scenarios were identified for nursing homes or home care. Most studies used machine learning algorithms, whereas expert or hybrid systems were entailed in less than every 10th publication. The application context of focusing on image and signal processing with tracking, monitoring, or the classification of activity and health followed by care coordination and communication, as well as fall detection, was the main purpose of AI applications. Few studies have reported the effects of AI applications on clinical or organizational outcomes, lacking particularly in data gathered outside laboratory conditions. In addition to technological requirements, the reporting and inclusion of certain requirements capture more overarching topics, such as data privacy, safety, and technology acceptance. Ethical, legal, and social implications reflect the discourse on technology use in health care but have mostly not been discussed in meaningful and potentially encompassing detail. Conclusions: The results highlight the potential for the application of AI systems in different nursing care settings. Considering the lack of findings on the effectiveness and application of AI systems in real-world scenarios, future research should reflect on a more nursing care–specific perspective toward objectives, outcomes, and benefits. We identify that, crucially, an advancement in technological-societal discourse that surrounds the ethical and legal implications of AI applications in nursing care is a necessary next step. Further, we outline the need for greater participation among all of the stakeholders involved.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Recognition of manual welding positions from depth hole image remotely sensed by rgb-d camera\n",
            "Authors: Kim J.H.\n",
            "Abstract: The proportion of welding work in total man-hours required for shipbuilding processes has been perceived to be significant, and welding man-hours are greatly affected by working posture. Continuous research has been conducted to identify the posture in welding by utilizing the relationship between man-hours and working posture. However, the results that reflect the effect of the welding posture on man-hours are not available. Although studies on posture recognition based on depth image analysis are being positively reviewed, welding operation has difficulties in image interpretation because an external obstacle caused by arcs exists. Therefore, any obstacle element must be removed in advance. This study proposes a method to acquire work postures using a low-cost RGB-D camera and recognize the welding position through image analysis. It removes obstacles that appear as depth holes in the depth image and restores the removed part to the desired state. The welder’s body joints are extracted, and a convolution neural network is used to determine the corresponding welding position. The restored image showed significantly improved recognition accuracy. The proposed method acquires, analyzes, and automates the recognition of welding positions in real-time. It can be applied to all areas where image interpretation is difficult due to obstacles.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Posture assessment in dentistry for different visual aids using 2d markers\n",
            "Authors: Pispero A.\n",
            "Abstract: Attention and awareness towards musculoskeletal disorders (MSDs) in the dental profession has increased considerably in the last few years. From recent literature reviews, it appears that the prevalence of MSDs in dentists concerns between 64 and 93%. In our clinical trial, we have assessed the dentist posture during the extraction of 90 third lower molars depending on whether the operator performs the intervention by the use of the operating microscope, surgical loupes, or with the naked eye. In particular, we analyzed the evolution of the body posture during different interventions evaluating the impact of visual aids with respect to naked eye interventions. The presented posture assessment approach is based on 3D acquisitions of the upper body, based on planar markers, which allows us to discriminate spatial displacements up to 2 mm in translation and 1 degree in rotation. We found a significant reduction of neck bending in interventions using visual aids, in particular for those performed with the microscope. We further investigated the impact of different postures on MSD risk using a widely adopted evaluation tool for ergonomic investigations of work-places, named (RULA) Rapid Upper Limb Assessment. The analysis performed in this clinical trial is based on a 3D marker tracker that is able to follow a surgeon’s upper limbs during interventions. The method highlighted pros and cons of different approaches.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Applications of pose estimation in human health and performance across the lifespan\n",
            "Authors: Stenum J.\n",
            "Abstract: The emergence of pose estimation algorithms represents a potential paradigm shift in the study and assessment of human movement. Human pose estimation algorithms leverage advances in computer vision to track human movement automatically from simple videos recorded using common household devices with relatively low-cost cameras (e.g., smartphones, tablets, laptop computers). In our view, these technologies offer clear and exciting potential to make measurement of human movement substantially more accessible; for example, a clinician could perform a quantitative motor assessment directly in a patient’s home, a researcher without access to expensive motion capture equipment could analyze movement kinematics using a smartphone video, and a coach could evaluate player performance with video recordings directly from the field. In this review, we combine expertise and perspectives from physical therapy, speech-language pathology, movement science, and engineering to provide insight into applications of pose estimation in human health and performance. We focus specifically on applications in areas of human development, performance optimization, injury prevention, and motor assessment of persons with neurologic damage or disease. We review relevant literature, share interdisciplinary viewpoints on future applications of these technologies to improve human health and performance, and discuss perceived limitations.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Wearable sensor for assessing gait and postural alterations in patients with diabetes: A scoping review\n",
            "Authors: Brognara L.\n",
            "Abstract: Background and Objectives: Diabetes mellitus is considered a serious public health problem due to its high prevalence and related complications, including gait and posture impairments due to neuropathy and vascular alterations and the subsequent increased risk of falls. The gait of patients with diabetes is characterized by alterations of the main spatiotemporal gait parameters such as gait velocity, cadence, stride time and length, which are also known to worsen with disease course. Wearable sensor systems can be used for gait analysis by providing spatiotemporal parameters and postural control (evaluated from the perspective of body sway), useful for investigating the disease progression. Thanks to their small size and low cost of their components, inertial measurement units (IMUs) are easy to wear and are cheap tools for movement analysis. Materials and Methods: The aim of this study is to review articles published in the last 21 years (from 2000 to 2021) concerning the application of wearable sensors to assess spatiotemporal parameters of gait and body postural alterations in patients with diabetes mellitus. Relevant articles were searched in the Medline database using PubMed, Ovid and Cochrane libraries. Results: One hundred and four articles were initially identified while searching the scientific literature on this topic. Thirteen were selected and analysed in this review. Wearable motion sensors are useful, noninvasive, low-cost, and objective tools for performing gait and posture analysis in diabetic patients. The IMUs can be worn at the lumber levels, tibias or feet, and different spatiotemporal parameters of movement and static posture can be assessed. Conclusions: Future research should focus on standardizing the measurement setup and selecting the most informative spatiotemporal parameters for gait and posture analysis.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of a fully automated RULA assessment system based on computer vision\n",
            "Authors: Nayak G.K.\n",
            "Abstract: The purpose of this study was to develop an automated, RULA-based posture assessment system using a deep learning algorithm to estimate RULA scores, including scores for wrist posture, based on images of workplace postures. The proposed posture estimation system reported a mean absolute error (MAE) of 2.86 on the validation dataset obtained by randomly splitting 20% of the original training dataset before data augmentation. The results of the proposed system were compared with those of two experts’ manual evaluation by computing the intraclass correlation coefficient (ICC), which yielded index values greater than 0.75, thereby confirming good agreement between manual raters and the proposed system. This system will reduce the time required for postural evaluation while producing highly reliable RULA scores that are consistent with those generated by manual approach. Thus, we expect that this study will aid ergonomic experts in conducting RULA-based surveys of occupational postures in workplace conditions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Sensor-based computational approach to preventing back injuries in construction workers\n",
            "Authors: Subedi S.\n",
            "Abstract: Repetitive labor-intensive tasks are common in civil construction projects. Construction workers are prone to getting into musculoskeletal disorders-related injuries while performing such activities. The paper proposes a novel approach to identify the theoretical maximum attainable level of safety, safety frontier, for a given construction task that can be achieved in perfect conditions under good management. The paper outlines the method and the framework components and demonstrates them through an actual construction-lab-based case study. The case study includes computation of safety frontier for lifting and setting down tasks. For this, the paper proposes to use a depth sensor camera (Kinect) for workers' postural data collection while performing the task. With the postural data as an input feature, all the unique actions are identified using a random forest classifier model for each movement frame. Also, the paper proposes to develop a moment prediction model to predict the lower back moment exerted in each movement frame. The lower back moment is computed using inverse kinematics and inverse dynamic in OpenSim for the training data set. Then, the paper implements a random forest regression algorithm to create a moment prediction model with postural data and velocity as input features. Finally, the safe work posture, safety frontier is computed, combining the unique actions exerting minimum lower back moment. The computed safety frontier can potentially help the safety managers to improve their safety strategies by providing a higher safety benchmark for monitoring their construction site.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Machine Learning-Based Risk Analysis for Construction Worker Safety from Ubiquitous Site Photos and Videos\n",
            "Authors: Tang S.\n",
            "Abstract: This paper proposes a new method for single-worker severity level prediction from already collected site images and video clips. Onsite safety observers often assess workers' severity levels during construction activities. While risk analysis is key to improving long-term construction site safety, omnipresent monitoring is still time-consuming and costly to implement. The recent growth of visual data captured actively on construction sites has opened a new opportunity to increase the frequency of worker safety monitoring. This paper shows that a comprehensive vision-based assessment is the most informative to automatically infer worker severity level from images. Efficient computer vision models are presented to conduct this risk analysis. The method is validated on a challenging image dataset first of its kind. Specifically, the proposed method detects and evaluates the worker state from visual data, defined by (1) worker body posture, (2) the usage of personal protective equipment, (3) worker interactions with tools and materials, (4) the construction activity being performed, and (5) the presence of surrounding workplace hazards. To estimate the worker state, a multitasked recognition model is introduced that recognizes objects, activity, and keypoints from visual data simultaneously, taking 36.6% less time and 40.1% less memory while keeping comparably performances compared to a system running individual models for each subtask. Worker activity recognition is further improved with a spatio-temporal graph neural network model using recognized per-frame worker activity, detected bounding boxes of tools and materials, and estimated worker poses. Finally, severity levels are predicted by a trained classifier on a dataset of images of construction workers accompanied with ground truth severity level annotations. In the test dataset assembled from real-world projects, the severity level prediction model achieves 85.7% cross-validation accuracy in a bricklaying task and 86.6% cross-validation accuracy for a plastering task, demonstrating the potential for near real-time worker safety detection and severity assessment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Risk assessment for musculoskeletal disorders based on the characteristics of work posture\n",
            "Authors: Wang J.\n",
            "Abstract: Construction workers are at high risk of work-related musculoskeletal disorders (WMSDs). Although the existing observational assessment methods are easy to use, when it comes to a more in-depth statistical analysis of the dynamic characteristics of the worker's operation, the sample data to be processed turn out to be large, the labor cost high, and the analysis easily affected by the prejudice of the evaluator. This study examines a novel WMSD prediction method based on the dynamic characteristics of the working posture, which comprises three artificial intelligence algorithms in series. In this method, the posture detector identifies the limb angles and state in the working video, the posture risk evaluator evaluates the risk level of the working posture frame by frame, and the task risk predictor predicts the risk level of the current work process. The collected video data of common tasks of construction workers and the MPII Human Pose dataset were used for training and evaluation of the algorithms. The method achieved 87.0% accuracy of the joint point recognition. The micro-averaged accuracy, recall, and F1-score (harmonic average of accuracy and recall) reached 96.7%, 96.0%, and 96.6%, respectively. The results showed that the proposed method has great potential for real-time risk assessment. It can output all of the changes of the limb angles of workers in the work process frame by frame and predict the risk level of the whole work process.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A portable sitting posture monitoring system based on a pressure sensor array and machine learning\n",
            "Authors: Ran X.\n",
            "Abstract: Poor sitting posture is one of the main inducements that lead to a series of skeletal muscle diseases. Sitting posture monitoring system can remind the user to maintain the correct sitting posture to prevent the harm of poor sitting posture to the body. In this paper, we proposed a portable sitting posture monitoring system to recognize the user's sitting posture and feedback the results in real time. A pressure sensor array is used to collect sitting postures related information, while the collected data can be displayed on a computer. The proposed system was designed to recognize seven types of sitting postures, including sitting upright, leaning forward, leaning backward, leaning left, leaning right, cross left leg, and cross right leg. Seven machine learning algorithms were implemented for comparation. The results showed that a five-layer Artificial Neural Network could achieve the highest accuracy of 97.07 %. To enhance system performance and reduce hardware cost, we further optimized the size of the sensor array. An 11 × 13 sensor array combined with Random Forest algorithm realized the optimal balance between classification accuracy (96.26 %) and hardware resource consumption. The final system prediction time is 19 us on the Raspberry Pi, which could satisfy the practical application requirement on the embedded platform.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Smartphone-based human sitting behaviors recognition using inertial sensor\n",
            "Authors: Sinha V.K.\n",
            "Abstract: At present, people spend most of their time in passive rather than active mode. Sitting with computers for a long time may lead to unhealthy conditions like shoulder pain, numbness, headache, etc. To overcome this problem, human posture should be changed for particular intervals of time. This paper deals with using an inertial sensor built in the smartphone and can be used to overcome the unhealthy human sitting behaviors (HSBs) of the office worker. To monitor, six volunteers are considered within the age band of 26 ± 3 years, out of which four were male and two were female. Here, the inertial sensor is attached to the rear upper trunk of the body, and a dataset is generated for five different activities performed by the subjects while sitting in the chair in the office. Correlation-based feature selection (CFS) technique and particle swarm optimization (PSO) methods are jointly used to select feature vectors. The optimized features are fed to machine learning supervised classifiers such as naive Bayes, SVM, and KNN for recognition. Finally, the SVM classifier achieved 99.90% overall accuracy for different human sitting behaviors using an accel-erometer, gyroscope, and magnetometer sensors.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Validation and assessment of a posture measurement system with magneto-inertial measurement units\n",
            "Authors: Paloschi D.\n",
            "Abstract: Inappropriate posture and the presence of spinal disorders require specific monitoring systems. In clinical settings, posture evaluation is commonly performed with visual observation, electrogoniometers or motion capture systems (MoCaps). Developing a measurement system that can be easily used also in non-structured environments would be highly beneficial for accurate posture monitoring. This work proposes a system based on three magneto-inertial measurement units (MIMU), placed on the backs of seventeen volunteers on the T3, T12 and S1 vertebrae. The reference system used for validation is a stereophotogrammetric motion capture system. The volunteers performed forward bending and sit-to-stand tests. The measured variables for identifying the posture were the kyphosis and the lordosis angles, as well as the range of movement (ROM) of the body segments. The comparison between MIMU and MoCap provided a maximum RMSE of 5.6° for the kyphosis and the lordosis angles. The average lumbo-pelvic contribution during forward bending (41.8 ± 8.6%) and the average lumbar ROM during sit-to-stand (31.8 ± 9.8° for sitting down, 29.6 ± 7.6° for standing up) obtained with the MIMU system agree with the literature. In conclusion, the MIMU system, which is wearable, inexpensive and easy to set up in non-structured environments, has been demonstrated to be effective in posture evaluation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Evidence for the effectiveness of feedback from wearable inertial sensors during work-related activities: A scoping review\n",
            "Authors: Lee R.\n",
            "Abstract: Background: Wearable inertial sensor technology (WIST) systems provide feedback, aim-ing to modify aberrant postures and movements. The literature on the effects of feedback from WIST during work or work-related activities has not been previously summarised. This review examines the effectiveness of feedback on upper body kinematics during work or work-related activities, along with the wearability and a quantification of the kinematics of the related device. Methods: The Cinahl, Cochrane, Embase, Medline, Scopus, Sportdiscus and Google Scholar databases were searched, including reportsfrom January 2005 to July 2021. The included studies were summarised descriptively and the evidence was assessed. Results: Fourteen included studies demonstrated a ‘limited’ level of evidence supporting posture and/or movement behaviour improvements using WIST feedback, with no improvements in pain. One study assessed wearability and another two investigated comfort. Studies used tri-axial accelerometers or IMU integration (n = 5 studies). Visual and/or vibrotactile feedback was mostly used. Most studies had a risk of bias, lacked detail for methodological reproducibility and displayed inconsistent reporting of sensor technology, with validation provided only in one study. Thus, we have proposed a minimum ‘Technology and Design Checklist’ for reporting. Conclusions: Our findings suggest that WIST may improve posture, though not pain; however, the quality of the studies limits the strength of this conclusion. Weara-bility evaluations are needed for the translation of WIST outcomes. Minimum reporting standards for WIST should be followed to ensure methodological reproducibility. Précis: This review summa-rises studies reporting on feedback from wearable inertial sensor technology (WIST) devices that aim to improve posture and/or movement behaviour during workplace-related tasks. The included studies lacked methodological reproducibility; therefore, a ‘Technology and Design Checklist’ was proposed. A ‘limited’ level of evidence supported changes in posture/movement behaviour using WIST, with no improvements in pain, though the study quality limits the strength of these findings.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Applying incremental Deep Neural Networks-based posture recognition model for ergonomics risk assessment in construction\n",
            "Authors: Zhao J.\n",
            "Abstract: Monitoring and assessing awkward postures is a proactive approach for Musculoskeletal Disorders (MSDs) prevention in construction. Machine Learning models have shown promising results when used in recognition of workers’ posture from Wearable Sensors. However, there is a need to further investigate: i) how to enable Incremental Learning, where trained recognition models continuously learn new postures from incoming subjects while controlling the forgetting of learned postures; ii) the validity of ergonomics risk assessment with recognized postures. The research discussed in this paper seeks to address this need through an adaptive posture recognition model– the incremental Convolutional Long Short-Term Memory (CLN) model. The paper discusses the methodology used to develop and validate this model's use as an effective Incremental Learning strategy. The evaluation was based on real construction workers’ natural postures during their daily tasks. The CLN model with “shallow” (up to two) convolutional layers achieved high recognition performance (Macro F1 Score) under personalized (0.87) and generalized (0.84) modeling. Generalized CLN model, with one convolutional layer, using the “Many-to-One” Incremental Learning scheme can potentially balance the performance of adaptation and controlling forgetting. Applying the ergonomics rules on recognized and ground truth postures yielded comparable risk assessment results. These findings support that the proposed incremental Deep Neural Networks model has a high potential for adaptive posture recognition. They can be deployed alongside ergonomics rules for effective MSDs risk assessment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Lifting posture prediction with generative models for improving occupational safety\n",
            "Authors: Li L.\n",
            "Abstract: Lifting tasks have been identified to be highly associated with work-related low back pain. Posture prediction can be used for simulating workers' posture of lifting tasks and thus facilitate the prevention of low back pain (LBP). This study adopts two generative models, conditional variational encoder and conditional generative adversarial network, to predict lifting postures. A regular feed-forward neural network (FNN) developed upon previous studies is also investigated for comparison purposes. Ground-truth lifting posture data collected by a motion capture system is used for training and testing the models. The models are trained with datasets of different size and loss functions, and the results are compared. The conditional variational autoencoder and the regular FNN achieved comparable top performance in lifting posture prediction in terms of accuracy and posture validity. Both generative models are able to partially capture the variability of constrained postures. Overall, the results prove that using a generative model is able to predict postures with reasonable accuracy and validity (RMSE of coordinates = 0.049 m; RMSE of joint angles = 19.58°). The predicted postures can support biomechanical analysis and ergonomics assessment of a lifting task to reduce the risk of low back injuries.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Pose guided anchoring for detecting proper use of personal protective equipment\n",
            "Authors: Xiong R.\n",
            "Abstract: Ensuring proper use of personal protective equipment (PPE) is essential for improving workplace safety management. The authors present an extensible pose-guided anchoring framework aimed at multi-class PPE compliance detection. The overall approach harnesses a pose estimator to detect worker body parts as spatial anchors and guide the localization of part attention regions using body-knowledge-based rules considering workers' orientations and object scales. Specifically, “part attention regions” are local image patches expecting PPEs based on their inherent relationships with body parts, e.g., (head, hardhat) and (upper-body, vest). Finally, the shallow CNN-based classifiers can reliably recognize both PPE and non-PPE classes within their corresponding part attention regions. Quantitative evaluations tested on the developed construction personal protective equipment dataset (CPPE) show an overall 0.97 and 0.95 F1-score for hardhat and safety vest detection, respectively. Comparative studies with existing methods also demonstrate the higher detection accuracy and advantageous extensibility of the proposed strategy.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Assessment of construction workers’ perceived risk using physiological data from wearable sensors: A machine learning approach\n",
            "Authors: Lee B.G.\n",
            "Abstract: Considering that workers' safe or unsafe behaviors are responses to their perceived risk when working, understanding workers' perceived risk is vital for safety management in the construction industry. Existing tools for measuring workers' perceived levels of risk mainly rely on post-hoc survey-based assessments, which are limited by their lack of continuous monitoring ability, lack of objectivity, and high cost. To address these limitations, this study develops an automatic method to recognize construction workers’ perceived levels of risk by using physiological signals acquired from wristband-type wearable biosensors in conjunction with a supervised-learning algorithm. The performance of the model was examined with physiological signals acquired from eight construction workers performing their daily work. The model achieved a validation accuracy of 81.2% for distinguishing between low and high levels of perceived risk. This study provides a new means of continuous, objective, and non-invasive method for monitoring construction workers' perceived levels of risk.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Improved self‐organizing map‐based unsupervised learning algorithm for sitting posture recognition system\n",
            "Authors: Cai W.\n",
            "Abstract: As the intensity of work increases, many of us sit for long hours while working in the office. It is not easy to sit properly at work all the time and sitting for a long time with wrong postures may cause a series of health problems as time goes by. In addition, monitoring the sitting posture of patients with spinal disease would be beneficial for their recovery. Accordingly, this paper designs and implements a sitting posture recognition system from a flexible array pressure sensor, which is used to acquire pressure distribution map of sitting hips in a real‐time manner. Moreover, an improved self‐organizing map‐based classification algorithm for six kinds of sitting posture recognition is proposed to identify whether the current sitting posture is appropriate. The extensive experimental results verify that the performance of ISOM‐based sitting posture recognition algorithm (ISOM‐SPR) in short outperforms that of four kinds of traditional algorithms including decision tree‐based(DT), K‐means‐based(KM), back propagation neural network‐based(BP), self‐organizing map‐based(SOM) sitting posture recognition algorithms. Finally, it is proven that the proposed system based on ISOM‐SPR algorithm has good robustness and high accuracy.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A mechatronics data collection, image processing, and deep learning platform for clinical posture analysis: a technical note\n",
            "Authors: Salahzadeh Z.\n",
            "Abstract: Static and dynamic posture analysis was a critical clinical examination in physiotherapy and rehabilitation. It was a time-consuming task for clinicians, so a semi-automatic method can facilitate this process as well as provide well-documented medical records and strong infrastructure for deep learning scenarios. The current research presents a mechatronics platform for static and real-time dynamic posture analysis, which consisted of hybrid computational modules. Our study was a developmental and applied research according to a system development life cycle. The designed modules are as follows: (1) a mechanical structure includes patient place, 360-degree engine, mirror, laser, distance meter, and cams; (2) a software module includes data collection, electronic medical record, semi-automatic image analysis, annotation, and reporting, and (3) a network to exchange raw data with deep learning server. Patients were informed about the research by their healthcare provider and all data were transformed into a Fourier format, in which the patients remained autonomous without a bit of information. The results show acceptable reliability and validity of the instruments. Also, a telerehabilitation application was designed to cover the patients after diagnosis. We suggest a longer time for data acquisition. It will lead to a more accurate and fully automated dynamic posture analysis. The result of this study suggest that the designed mechatronics device used in conjunction with smartphone application is a valid tool that can be used to obtain reliable measurements.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Analysis of college martial arts teaching posture based on 3D image reconstruction and wavelet transform\n",
            "Authors: Deng L.\n",
            "Abstract: Martial arts is a traditional sports event of the Chinese nation, which carries history and culture. With the development of “Martial Arts on Campus Activities” in recent years, more and more schools have opened general martial arts courses. However, due to the more complex technical movements of martial arts, there are often varying degrees of gaps between the movements and standard movements. Based on this, this research introduces three-dimensional imaging technology on the basis of traditional physical education teaching methods, aiming to explore new martial arts teaching models through image reconstruction and posture analysis. First of all, in order to obtain a three-dimensional point cloud and three-dimensional line, this paper extracts and matches feature points and feature lines on the input image. Secondly, on the basis of obtaining dense matching and straight-line matching, this paper selects the image with the most feature line matching for reprojection. Wavelet transform is used in the process of image compression and coding, including signal decomposition and reconstruction steps. Finally, through the experimental test of martial arts teaching posture images in colleges and universities, it shows that the method of combining three-dimensional image reconstruction and wavelet transform proposed in this paper has good applicability and efficiency, and can provide a scientific reference for college martial arts teaching.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Real-time Posture Monitoring System Towards Bad Posture Detection\n",
            "Authors: Tlili F.\n",
            "Abstract: The neck and back pains are the most spread health problems of the century caused by remaining slouching for long hours on the smart phones, the tablets and the computers. Many medical researches prove that the monitoring and the improving of the seating posture can prevent the spinal pains. In this paper we propose a Real-time seating posture monitoring system. The system is composed of a smart belt equipped with inertial sensors. The sensors collect the posture information and send them to a cloud server via Wi-Fi connection. The cloud server processes the collected data, then, sends the result to mobile applications via Wi-Fi connection. The mobile applications allow the user to monitor his posture over time and receive in Real-time a sound and a visual notification in case of a bad posture detection. Two mobile applications Android and iOS are implemented that can be used for different mobile phone OS. In this work we will detail the design and the architecture of the proposed posture monitoring system and the implemented mobile applications. We will present the posture measurements of good and bad posture using the proposed posture monitoring system.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Basic Biomechanics and Workplace Design\n",
            "Authors: Marras W.S.\n",
            "Abstract: Occupational biomechanics is an interdisciplinary field in which information from both the biological sciences and engineering mechanics is used to quantify the forces present on the body during work. Biomechanics assumes that the body behaves according to the laws of Newtonian mechanics. The approach to a biomechanical assessment is to characterize the human-work system situation through a mathematical representation or model. This chapter focuses on the information required to develop proper biomechanical reasoning when assessing the physical demands of a workplace. It presents a series of key biomechanical concepts that constitute the underpinning of biomechanical reasoning. The National Research Council reviewed the scientific literature in epidemiology, biomechanics, tissue mechanobiology, and workplace intervention strategies and concluded that there is a significant relationship between workplace design and the occurrence of musculoskeletal disorders of the low back and upper extremities. Shoulder pain is believed to be one of the most underrecognized occupationally related musculoskeletal disorders.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Sitting posture detection and recognition of aircraft passengers using machine learning\n",
            "Authors: Cun W.\n",
            "Abstract: Prolonged sitting in a fixed or constrained position exposes aircraft passengers to long-term static loading of their bodies, which has deleterious effects on passengers' comfort throughout the duration of the flight. The previous studies focused primarily on office and driving sitting postures and few studies, however, focused on the sitting postures of passengers in aircraft. Consequently, the aim of the present study is to detect and recognize the sitting postures of aircraft passengers in relation to sitting discomfort. A total of 24 subjects were recruited for the experiment, which lasted for 2 h. Furthermore, a total of 489 sitting postures were extracted and the pressure data between subjects and seat was collected from the experiment. After the detection of sitting postures, eight types of sitting postures were classified based on key parts (trunk, back, and legs) of the human bodies. Thereafter, the eight types of sitting postures were recognized with the aid of pressure data of seat pan and backrest employing several machine learning methods. The best classification rate of 89.26% was obtained from the support vector machine (SVM) with radial basis function (RBF) kernel. The detection and recognition of the eight types of sitting postures of aircraft passengers in this study provided an insight into aircraft passengers' discomfort and seat design.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Technology and management for sustainable buildings and infrastructures\n",
            "Authors: Kim S.\n",
            "Abstract: None\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Implementation of kinetic and kinematic variables in ergonomic risk assessment using motion capture simulation: A review\n",
            "Authors: Yunus M.N.H.\n",
            "Abstract: Work‐related musculoskeletal disorders (WMSDs) are among the most common disorders in any work sector and industry. Ergonomic risk assessment can reduce the risk of WMSDs. Motion capture that can provide accurate and real‐time quantitative data has been widely used as a tool for ergonomic risk assessment. However, most ergonomic risk assessments that use motion capture still depend on the traditional ergonomic risk assessment method, focusing on qualitative data. There-fore, this article aims to provide a view on the ergonomic risk assessment and apply current motion capture technology to understand classical mechanics of physics that include velocity, acceleration, force, and momentum in ergonomic risk assessment. This review suggests that using motion capture technologies with kinetic and kinematic variables, such as velocity, acceleration, and force, can help avoid inconsistency and develop more reliable results in ergonomic risk assessment. Most studies related to the physical measurement conducted with motion capture prefer to use non‐op-tical motion capture because it is a low‐cost system and simple experimental setup. However, the present review reveals that optical motion capture can provide more accurate data.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automated postural ergonomic risk assessment using vision-based posture classification\n",
            "Authors: Seo J.O.\n",
            "Abstract: Construction workers are at high risk of work-related musculoskeletal disorders (WMSDs) due to physically demanding manual-handling tasks in awkward postures. Although existing observational methods to identify ergonomic risks are inexpensive and easy to use, they are seldom used in construction sites because they are time-consuming, subject to observer bias, and require well-trained analysts. To address these drawbacks, this paper proposes a vision-based method to automatically classify workers' postures for ergonomic assessment. Specifically, it proposes a vision-based method that eliminates the need to collect extensive training-image datasets by employing classification algorithms to learn diverse postures from virtual images, and then identifies those postures in real-world images. The experimental tests showed about 89% classification accuracy in automatically classifying diverse postures on images, confirming the usefulness of virtual training images for posture classification. The proposed method has potential for automated ergonomic risk analysis, and could help to prevent WMSDs during diverse occupational tasks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Application of Data Fusion via Canonical Polyadic Decomposition in Risk Assessment of Musculoskeletal Disorders in Construction: Procedure and Stability Evaluation\n",
            "Authors: Dutta A.\n",
            "Abstract: Missing data is a common problem in data collection for work-related musculoskeletal disorder (WMSD) risk-assessment studies. It can cause incompleteness of risk indicators, leading to erroneous conclusion on potential risk factors. Previous studies suggested that data fusion is a potential way to solve this issue. This research evaluated the numerical stability of a data fusion technique that applies canonical polyadic decomposition (CPD) for WMSD risk assessment in construction. Two knee WMSD risk-related data sets - three-dimensional (3D) knee rotation (kinematics) and electromyography (EMG) of five knee postural muscles - collected from previous studies were fused for the evaluation. By comparing the consistency performance with and without data fusion, it revealed that for all low to high proportion of missing data (10%-70%) from both kinematics and EMG data sets, the WMSD risk assessment using fused data sets outperformed using unfused kinematics data sets. For large proportions of missing data (>50%) from both kinematics and EMG data sets, better performance was observed by using fused data sets in comparison with unfused EMG data sets. These findings suggest that data fusion using CPD generates a more reliable risk assessment compared with data sets with missing values and therefore is an effective approach for remedying missing data in WMSD risk evaluation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Survey on Wearable Technology: History, State-of-the-Art and Current Challenges\n",
            "Authors: Ometov A.\n",
            "Abstract: Technology is continually undergoing a constituent development caused by the appearance of billions new interconnected “things” and their entrenchment in our daily lives. One of the underlying versatile technologies, namely wearables, is able to capture rich contextual information produced by such devices and use it to deliver a legitimately personalized experience. The main aim of this paper is to shed light on the history of wearable devices and provide a state-of-the-art review on the wearable market. Moreover, the paper provides an extensive and diverse classification of wearables, based on various factors, a discussion on wireless communication technologies, architectures, data processing aspects, and market status, as well as a variety of other actual information on wearable technology. Finally, the survey highlights the critical challenges and existing/future solutions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic study of construction workers in Odisha (India): A case study in construction sites\n",
            "Authors: Mishra D.\n",
            "Abstract: Work-related productivity falls for the most part on account of labor, which is the most significant factor. Since labor has to know how the work is to be done and issues can be decreased by taking usual breaks, avoiding multitasks, minimizing intrusions during work. Moreover, improper design of workplaces causes most of the occupational accidents as well as injuries in production sites that are labor-intensives. A number of factors adversely affect the workers reducing their productivity such as compelling efforts, repetitive-tasks, static and awkward postures, tools, and materials. Thus, adequate safety management is required to be undertaken and proper postures need to be followed by the workers. Therefore, an attempt was carried out in the present study to identify the potential risk factors for the construction site workers through ergonomic interventions, such that through proper education, training, and ergonomic design, the hazards and dis-comfortableness can be reduced to a minimum level.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic postural assessment using a new open-source human pose estimation technology (OpenPose)\n",
            "Authors: Kim W.\n",
            "Abstract: Observational ergonomic postural assessment methods have been commonly used to evaluate the risks of musculoskeletal disorders. Researchers have proposed semi-automatic methods using Kinect, known for limitations with body occlusions and non-frontal tracking. Meanwhile, new human pose estimation methods have been actively developed, and a popular open-source technology is OpenPose. This study aims to propose the OpenPose-based system for computing joint angles and RULA/REBA scores and validate against the reference motion capture system, and compare its performance to the Kinect-based system. Recordings of 10 participants performing 12 experimental tasks under different conditions: with/without body occlusions and tracked from frontal/non-frontal views were analyzed. OpenPose showed good performance under all task conditions, whereas Kinect performed significantly worse than OpenPose especially at cases with body occlusions or non-frontal tracking. The findings suggested that OpenPose could be a promising technology to measure joint angles and conduct semi-automatic ergonomic postural assessments in the real workspace where the conditions are often non-ideal.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Towards Real-time Generalized Ergonomic Risk Assessment for the Prevention of Musculoskeletal Disorders\n",
            "Authors: Konstantinidis D.\n",
            "Abstract: Providing real-time ergonomic feedback to workers is essential towards preventing extreme postures that can cause work-related musculoskeletal disorders (WMSDs). In this work, we propose a novel methodology to assess in real-time the ergonomic risk of any work-related task using the REBA framework. The proposed methodology gets as input video sequences, extracts 3D skeletal features and processes these features to compute REBA scores. At the core of the methodology lies a novel multi-stream deep network that can process 3D skeletal joints regardless of the method used to acquire them and provides not only a total REBA score, but also partial REBA scores that correspond to individual body parts, thus assisting workers towards a better understanding of which body parts face the biggest strain during a task. Experimental results on two publicly available datasets demonstrate the generalization ability and accuracy of the proposed ergonomic risk assessment methodology.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Detection of physical strain and fatigue in industrial environments using visual and non-visual sensors\n",
            "Authors: Papoutsakis K.\n",
            "Abstract: sustAGE is an ongoing project, developing an Internet of Things ecosystem, including smartphones, smartwatches, localization and environmental sensors and cameras to support ageing workers in industrial environments while performing assembly tasks, such a car manufacturing factory. In this context, we briefly describe a non-obtrusive method for assessing the physical strain of workers using visual data and a method for detecting worker fatigue using heart rate data acquired by smartwatches. The results of both methods are utilized by the recommendation system developed in sustAGE to support preventive actions towards work-related musculo-skeletal disorders and fatigue and to promote occupational safety.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Reliability of kinematic parameters related to the timed up and Go test in patients with gait impairments\n",
            "Authors: Pagano G.\n",
            "Abstract: Pathologies which imply motor impairment are most common and very studied. The aim of the study is to explore the repeatability of kinematic parameters related to the Timed Up and Go test in different pathologies: hemiparesis, femur fracture, hip replacement and knee replacement. We performed the study instrumenting the patients with a commercial wearable inertial system for gait analysis: G-WALK System by BTS Bioengineering Inc. A cohort of 40 patients with neurological and orthopedic pathologies was enrolled in the study. Repeatability was assessed through the calculation of the Intraclass Correlation Coefficient. Study results showed that the motion parameters exhibited different repeatability. Moreover their repeatability changed on the basis of the kind of pathology under examination. The study demonstrated the importance of a repeatability study to be a valuable approach to select the kinematic parameters which are be able to better characterize a specific pathology and consequently the rehabilitation outcome of patients. The future investigations on enriched datasets will further confirm these preliminary results.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Systematic Review on Lumbar Alignment Device's Mechanism Using Sensor Fusion Technology\n",
            "Authors: Jerome Christhudass A.\n",
            "Abstract: Good posture reflects a proper state of mind which let anyone get away with anything but people nowadays, is experiencing loads of work burden that are resulting in a bad posture. In this work the role of sensors in posture corrector devices are reviewed. Multiple techniques with different applications are used to detect, identify, and classify the lower lumbar spine movement. In the review multiple sensors employed in posture correctors are reviewed. Each sensor has a different working principle, its own advantages and disadvantages in this review, each paper had different methods and sensors. They are used in the devices according to their functions to get the exact expected output.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Deep learning in spine surgery\n",
            "Authors: Ghaednia H.\n",
            "Abstract: Deep learning is increasingly impactful for healthcare research and delivery. In orthopaedics, there has been a significant increase in the number of publications using deep learning for interpreting radiographs; however, there are only a few applications of deep learning specific to spine surgery. In this review, we discuss the potential of deep learning within spine surgery in four contexts: diagnosis (1), prognosis (2), patient management (3) and integration with virtual/augmented reality, robotic surgery and biomedical wearables (4). Additionally, we discuss current literature, future potentials and provide takeaways for clinicians who wish to apply deep learning in their research and practice.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: ANN-based automated scaffold builder activity recognition through wearable EMG and IMU sensors\n",
            "Authors: Bangaru S.S.\n",
            "Abstract: Construction worker activity recognition is essential for worker performance and safety assessment. With the development of wearable sensing technologies, many researchers developed kinematic sensor-based worker activity recognition methods with considerable accuracy. However, the limitations of the previous studies remain at the challenge of using smartphones for practical implementation, fewer classified activities, and limited recognized motions and body parts. This study proposes an ANN-based automated construction worker activity recognition method that can recognize complex construction activities. The proposed methodology discusses data acquisition, data fusion, and artificial neural network (ANN) model development. A case study of scaffold builder activities was investigated to validate the proposed methodology's feasibility and evaluate its performance compared to other existing methods. The results show that the proposed model can recognize fifteen scaffold builder activities with an accuracy of 94% with 0.94 weighted precision, recall, and F1 Score.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Artificial Neural Network Analyzing Wearable Device Gait Data for Identifying Patients With Stroke Unable to Return to Work\n",
            "Authors: Iosa M.\n",
            "Abstract: A potential dramatic effect of long-term disability due to stroke is the inability to return to work. An accurate prognosis and the identification of the parameters inflating the possibility of return to work after neurorehabilitation are crucial. Many factors may influence it, such as mobility and, in particular, walking ability. In this pilot study, two emerging technologies have been combined with the aim of developing a prognostic tool for identifying patients able to return to work: a wearable inertial measurement unit for gait analysis and an artificial neural network (ANN). Compared with more conventional statistics, the ANN showed a higher accuracy in identifying patients with respect to healthy subjects (90.9 vs. 75.8%) and also in identifying the subjects unable to return to work (93.9 vs. 81.8%). In this last analysis, the duration of double support phase resulted the most important input of the ANN. The potentiality of the ANN, developed also in other fields such as marketing on social networks, could allow a powerful support for clinicians that today should manage a large amount of instrumentally recorded parameters in patients with stroke.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Wearable Devices for Gait Analysis in Intelligent Healthcare\n",
            "Authors: Liu X.\n",
            "Abstract: In this study, we review the role of wearable devices in tracking our daily locomotion. We discuss types of wearable devices that can be used, methods for gait analyses, and multiple healthcare-related applications aided by artificial intelligence. Impaired walking and locomotion are common resulting from injuries, degenerative pathologies, musculoskeletal disorders, and various neurological damages. Daily tracking and gait analysis are convenient and efficient approaches for monitoring human walking, where concreate and rich data can be obtained for examining our posture control mechanism during body movement and providing enhanced clinical pieces of evidence for diagnoses and treatments. Many sensors in wearable devices can help to record data of walking and running; spatiotemporal and kinematic variables can be further calculated in gait analysis. We report our previous works in gait analysis, discussing applications of wearable devices for detecting foot and ankle lesions, supporting surgeons in early diagnosis, and helping physicians with rehabilitation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Image processing and qr code application method for construction safety management\n",
            "Authors: Kim J.S.\n",
            "Abstract: Construction safety accidents occur due to a combination of factors. Even a minor accident that could have been treated as a simple injury can lead to a serious accident or death, depending on when and where it occurred. Currently, methods for tracking worker behavior to manage such construction safety accidents are being studied. However, applying the methods to the construction site, various additional elements (e.g., sensors, transmitters, wearing equipment, and control systems) that must be additionally installed and managed are required. The cost of installation and management of these factors increases in proportion to the size of the site and the number of targets to be managed. In addition, the application of new equipment and new rules lowers the work efficiency of workers. In this paper, the following contents are described: (1) system overview, (2) image processing-QR code-based safety management target recognition methodology, and (3) object location discrimination technique applying the geometric transformation. Finally, the proposed methodology was tested to confirm the operation in the field, and the experimental results and conclusions were described in the paper.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automatic scaffolding workface assessment for activity analysis through machine learning\n",
            "Authors: Ying W.\n",
            "Abstract: Scaffolding serves as one construction trade with high importance. However, scaffolding suffers from low productivity and high cost in Australia. Activity Analysis is a continuous procedure of assessing and improving the amount of time that craft workers spend on one single construction trade, which is a functional method for monitoring onsite operation and analyzing conditions causing delays or productivity decline. Workface assessment is an initial step for activity analysis to manually record the time that workers spend on each activity category. This paper proposes a method of automatic scaffolding workface assessment using a 2D video camera to capture scaffolding activities and the model of key joints and skeleton extraction, as well as machine learning classifiers, were used for activity classification. Additionally, a case study was conducted and showed that the proposed method is a feasible and practical way for automatic scaffolding workface assessment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Classifying diverse manual material handling tasks using a single wearable sensor\n",
            "Authors: Porta M.\n",
            "Abstract: The use of inertial measurement units (IMUs) for monitoring and classifying physical activities has received substantial attention in recent years, both in occupational and non-occupational contexts. However, a “user-friendly” approach is needed to promote this approach to quantify physical demands in actual workplaces. We explored the use of a single IMU for extracting information about different manual material handling (MMH) tasks (i.e., specific type of task performed, and associated duration and frequency), using a bidirectional long short-term memory network for classification. Classification performance using single IMUs placed on several body parts was compared with performance using multiple IMU configurations (2, 3, and 17 IMUs). Overall, the use of a single sensor led to satisfactory results (e.g., median accuracy >97%) in classifying MMH tasks and estimating task duration and frequency. Limited benefits were obtained using additional sensors, and several sensor locations yielded similar outcomes. Classification performance, though, was relatively inferior for push/pull vs. other tasks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Mapping Datafication in Construction-Worker Safety Research to Minimize Injury-Related Disputes\n",
            "Authors: Subedi S.\n",
            "Abstract: Construction workers are susceptible to work-related injury, which increases the probability of a workers' compensation claim. But the workers' compensation claim can cause dispute for several reasons such as whether the injury occurred on the job, suspicion of fraud, and lack of evidence. This highlights the necessity of improvement in workers' safety and the recording of evidence to reduce dispute occurrence. The rapid datafication of construction processes implementing available technologies can be a potential solution. This paper aims to trace the trends of such datafication by investigating the available scientific literature to create a novel tabular index of what data are (or can be) generated and leveraged, for what purpose, following what methodologies, and when. This paper identifies different technologies that can be used to monitor workers' safety and provide data for dispute resolution, if any. The authors propose the use of a systematic literature review (SLR) for this study to provide reliable data-based mapping. The methodology includes identification of safety factors and technology implemented from published scholarly articles and their applicability in dispute resolution. A tabular index was created containing information such as factors tracked, technology used, type of data, and accuracy. Similarly, multiple visual maps were generated aiding in the identification of important safety factors and most reliable technologies fit to be implemented for data collection, which can help to reduce the chance of injury and identify the reason behind the injury, if any. This paper will serve as an index for researchers and practitioners working on construction safety or wanting to learn about real-time construction safety research. The visual maps reported in this paper contribute as a guide to understand what data type is required for a specific safety issue, how to collect them, and how the data can be analyzed. The maps will also reveal trends in the rise and fall of distinct types of analysis methods and technologies in construction safety research. Finally, construction practitioners can use the map to identify the technology that can be used to collect different data that could help to reduce the chance of injury as well as identify the reason behind the injuries if occurred, reducing the probability of disputes.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A worker posture coding scheme to link automatic and manual coding\n",
            "Authors: Chen H.\n",
            "Abstract: Real-time and automatic monitoring of worker behaviors and activities have great potential to improve construction job site operation. Traditional behavior monitoring of construction workers relies on human interpretation to determine workers' semantic conditions (e.g., tasks performing, safety status). Although advanced sensing technologies provide more accurate quantitative data on worker behavior, how to effectively link the data to a worker's semantic condition in a form that is understandable for humans remains a challenge. This paper proposed a novel posture coding scheme based on the worker's body part relative position (BPRP) information. The proposed coding scheme compresses the quantitative 3D skeleton data into qualitative posture descriptions but keeps the body part relative space information. Afterward, an indoor motion test is conducted to validate the reliability of the proposed BPBR coding scheme. The test results showed that by employing the BPRP coding scheme, the manual and automatic posture coding could achieve consistent results. Therefore, the manual posture coding results can be transformed into human skeleton figures and then further processed by the quantitative algorithms. Correspondingly, the computer-captured human skeleton data can be easily connected to the manual observation results by interpreting the BPRB codes\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Fully automated generation of parametric BIM for MEP scenes based on terrestrial laser scanning data\n",
            "Authors: Wang B.\n",
            "Abstract: As-built building information modeling (BIM) has gained much attention in mechanical, electrical and plumbing (MEP) systems for better facility management. To create as-built BIMs, laser scanning technology is widely used to collect raw data due to its high measurement speed and accuracy. Currently, as-built models are mostly drawn by experienced personnel in BIM modeling software with point cloud data as reference, which is labor intensive and time consuming. This study presents a fully automated approach to converting terrestrial laser scanning data to well-connected as-built BIMs for MEP scenes. According to the geometry complexity, MEP components are divided into regular shaped components and irregular shaped components. A 2D to 3D analysis framework is developed to detect objects and extract accurate geometry information for the two categories of MEP components. Firstly, the MEP scene is divided into slices on which rough geometry information of components' cross sections is extracted. Then, the extracted information on different slices is integrated and analyzed in 3D space to verify the existence of MEP components and obtain refined geometry information used for modeling. Following the detection stage, an MEP network construction approach is developed for MEP components connection and position fine-tuning. Finally, the extracted geometry information and connection relationships are imported into Dynamo to automatically generate the parametric BIM model. To validate the feasibility of the proposed technique, experiments were conducted with point clouds acquired from three scenes in Hong Kong. A comprehensive assessment is presented to evaluate the as-built model quality with three indices: retrieval rate, geometry parameter accuracy and deviation from point clouds to as-built model. The experiment results show that the proposed technique could successfully transform laser scanning data of MEP scenes to as-built BIMs with sufficient accuracy for facility management purpose.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Developing and Evaluating a Mixed Sensor Smart Chair System for Real-Time Posture Classification: Combining Pressure and Distance Sensors\n",
            "Authors: Jeong H.\n",
            "Abstract: A novel sensor-embedded smart chair system was developed to monitor and classify a worker's sitting postures in real time. The smart chair system was a mixed sensor system utilizing six pressure sensors and six infrared reflective distance sensors in combination. The pressure sensors were embedded in the seat cushion to gather seat cushion pressure distribution data. The distance sensors were placed in the seatback to measure seatback-trunk distances at different locations in the frontal plane. The use of the seatback distance sensors represented a unique design feature, which distinguished the mixed sensor system from the previous posture monitoring systems. Employing a k-Nearest Neighbor algorithm, the mixed sensor system classified an instantaneous posture as one of posture categories determined based on an analysis of the ergonomics literature on sitting postures and sitting-related musculoskeletal problems. The mixed sensor system was evaluated in posture classification performance in comparison with two benchmark systems that utilized only a single type of sensors. The purpose of the comparisons was to determine the utility of the design combining seat cushion pressure sensors and seatback distance sensors. The mixed sensor system yielded significantly superior classification performance than the two benchmark systems. The mixed sensor system is low-cost utilizing only a small number of sensors; yet, it accomplishes accurate classification of postures relevant to the ergonomic analyses of seated work tasks. The mixed sensor system could be utilized for various applications including the development of a real-time posture feedback system for preventing sitting-related musculoskeletal disorders.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The analysis of employees’ work posture by using Rapid Entire Body Assessment (REBA) and Rapid Upper Limb Assessment (RULA)\n",
            "Authors: Wibowo A.H.\n",
            "Abstract: This study aims to analyze the work posture of employees by using Rapid Entire Body Assessment (REBA) and Rapid Upper Limb Assessment (RULA) methods. In this study, the angle of the employee was calculated, and the results showed that on the body part B, the angle of the back movement is 77ºflexion, the neck is 18ºextension, and the leg is 39º, while the leg is not uniformly supported. One of the body parts, such as the upper arm is formed an angle of 65 ° flexion, the forearm is 13 ° flexion, the wrist is 0 ° flexion, and the wrist is in the intermediate range of rotation. Based on the results of RULA, a grand score is 7, categorized as Action level 4. Meanwhile, based on the results of REBA, the grand score obtained is 11, and also categorized as Action level 4. Based on the calculation of work posture using RULA and REBA methods, it revealed that the operator’s work posture has a high-level and dangerous risk. Therefore, the operator needs to immediately improve his work posture. In addition, due to the lifting position that was started with no squatting position, it causes waist injures, since it becomes the lift's pedestal.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Work-related risk assessment according to the revised niosh lifting equation: A preliminary study using a wearable inertial sensor and machine learning\n",
            "Authors: Donisi L.\n",
            "Abstract: Many activities may elicit a biomechanical overload. Among these, lifting loads can cause work-related musculoskeletal disorders. Aspiring to improve risk prevention, the National Institute for Occupational Safety and Health (NIOSH) established a methodology for assessing lifting actions by means of a quantitative method based on intensity, duration, frequency and other geometrical characteristics of lifting. In this paper, we explored the machine learning (ML) feasibility to classify biomechanical risk according to the revised NIOSH lifting equation. Acceleration and angular velocity signals were collected using a wearable sensor during lifting tasks performed by seven subjects and further segmented to extract time-domain features: root mean square, minimum, maximum and standard deviation. The features were fed to several ML algorithms. Interesting results were obtained in terms of evaluation metrics for a binary risk/no-risk classification; specifically, the treebased algorithms reached accuracies greater than 90% and Area under the Receiver operating curve characteristics curves greater than 0.9. In conclusion, this study indicates the proposed combination of features and algorithms represents a valuable approach to automatically classify work activities in two NIOSH risk groups. These data confirm the potential of this methodology to assess the biomechanical risk to which subjects are exposed during their work activity.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of a modality-invariant multi-layer perceptron to predict operational events in motor-manual willow felling operations\n",
            "Authors: Borz S.A.\n",
            "Abstract: Motor-manual operations are commonly implemented in the traditional and short rotation forestry. Deep knowledge of their performance is needed for various strategic, tactical and operational decisions that rely on large amounts of data. To overcome the limitations of traditional analytical methods, Artificial Intelligence (AI) has been lately used to deal with various types of signals and problems to be solved. However, the reliability of AI models depends largely on the quality of the signals and on the sensing modalities used. Multimodal sensing was found to be suitable in developing AI models able to learn time and location-related data dependencies. For many reasons, such as the uncertainty of preserving the sensing location and the inter-and intra-variability of operational conditions and work behavior, the approach is particularly useful for monitoring motor-manual operations. The main aim of this study was to check if the use of acceleration data sensed at two locations on a brush cutter could provide a robust AI model characterized by invariance to data sensing location. As such, a Multi-Layer Perceptron (MLP) with backpropagation was developed and used to learn and classify operational events from bimodally-collected acceleration data. The data needed for training and testing was collected in the central part of Romania. Data collection modalities were treated by fusion in the training dataset, then four single-modality testing datasets were used to check the performance of the model on a binary classification problem. Fine tuning of the regularization parameters (α term) has led to acceptable testing and generalization errors of the model measured as the binary cross-entropy (log loss). Irrespective of the hyperparameters’ tunning strategy, the classification accuracy (CA) was found to be very high, in many cases approaching 100%. However, the best models were those characterized by α set at 0.0001 and 0.1, for which the CA in the test datasets ranged from 99.1% to 99.9% and from 99.5% to 99.9%, respectively. Hence, data fusion in the training set was found to be a good strategy to build a robust model, able to deal with data collected by single modalities. As such, the developed MLP model not only removes the problem of sensor placement in such applications, but also automatically classifies the events in the time domain, enabling the integration of data collection, handling and analysis in a simple less resource-demanding workflow, and making it a feasible alternative to the traditional approach to the problem.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Posture-related data collection methods for construction workers: A review\n",
            "Authors: Yu Y.\n",
            "Abstract: Construction workers' posture-related data is closely connected with their safety, health, and productivity performance. The importance of posture-related data has drawn the attention of researchers in construction management and other fields. Accordingly, many data collection methods have been developed and applied to collect posture-related data. Despite the importance of workers' posture-related data, there lacks a review of previous data collection methods in the construction industry. This paper fills the research gap by reviewing previous methods to collect posture-related data for construction workers via 1) summarizing working principles and applications of posture-related data collection in construction management, which demonstrates the extensive use of motion sensors and Red-Green-Blue (RGB) cameras in posture-related data collection, 2) comparing the above methods based on data quality and feasibility on construction sites, which reveals the reason why motion sensors and RGB cameras have been prevalent in previous studies, 3) revealing research gaps of posture-related data collection tools and applications, and providing possible future research directions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Multimodal Fusion for Objective Assessment of Cognitive Workload: A Review\n",
            "Authors: Debie E.\n",
            "Abstract: Considerable progress has been made in improving the estimation accuracy of cognitive workload using various sensor technologies. However, the overall performance of different algorithms and methods remain suboptimal in real-world applications. Some studies in the literature demonstrate that a single modality is sufficient to estimate cognitive workload. These studies are limited to controlled settings, a scenario that is significantly different from the real world where data gets corrupted, interrupted, and delayed. In such situations, the use of multiple modalities is needed. Multimodal fusion approaches have been successful in other domains, such as wireless-sensor networks, in addressing single-sensor weaknesses and improving information quality/accuracy. These approaches are inherently more reliable when a data source is lost. In the cognitive workload literature, sensors, such as electroencephalography (EEG), electrocardiography (ECG), and eye tracking, have shown success in estimating the aspects of cognitive workload. Multimodal approaches that combine data from several sensors together can be more robust for real-time measurement of cognitive workload. In this article, we review the published studies related to multimodal data fusion to estimate the cognitive workload and synthesize their main findings. We identify the opportunities for designing better multimodal fusion systems for cognitive workload modeling.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Computer vision technologies for safety science and management in construction: A critical review and future research directions\n",
            "Authors: Guo B.H.W.\n",
            "Abstract: Recent years have seen growing interests in developing and applying computer vision technologies to solve safety problems in the construction industry. Despite the technological advancements, there is no research that exams the theoretical links between computer vision technology and safety science and management. Thus, the objectives of this paper are to: (1) investigate the current status of applying computer vision technology to construction safety, (2) examine the links between computer vision applications and key research themes of construction safety, (3) discuss the theoretical challenges of applying computer vision to construction safety, and (4) recommend future research directions. A five-step review approach was adopted to search and analyze peer-reviewed academic journal articles. A three-level computer vision development framework was proposed to categorized computer vision applications in the construction industry. The links between computer vision and three main safety research traditions: safety management system, behavior-based safety program, and safety culture, were discussed. The results suggest that the majority of past efforts were focused on object recognition, object tracking, and action recognition, with limited research focused on recognizing unsafe behavior. There are even fewer studies aimed at developing vision-based safety assessment and prediction systems. Based on the review findings, four future research directions are suggested: (1) develop and test a behavioral-cues-based safety climate measure, (2) develop safety behavior datasets, (3) develop a formal hazard identification and assessment model, and (4) develop criteria to evaluate the real impacts of vision-based technologies on safety performance.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automatic Recognition of Workers' Motions in Highway Construction by Using Motion Sensors and Long Short-Term Memory Networks\n",
            "Authors: Kim K.\n",
            "Abstract: Monitoring and understanding construction workers' behavior and working conditions are essential to achieve success in construction projects. The dynamic nature of construction sites has heightened the awareness of the need for improved monitoring of individual workers on sites. Although several studies indicated promising results in automated motion and activity recognition using wearable motion sensors, their technical and practical feasibility was not properly validated at actual job sites. Motion recognition models have to be evaluated in actual conditions because the motion sensor data collected in controlled conditions, and actual conditions can have different characteristics. This study proposes Long Short-Term Memory (LSTM) networks for recognizing construction workers' motions. The LSTM networks were validated through case studies in one bridge construction site and two road pavement sites. The LSTM networks indicated classification accuracies of 97.6%, 95.93%, and 97.36% from three different field test sites, respectively. Through the case studies, the technical and practical feasibility of the LSTM networks was properly investigated. With LSTM networks, individual workers' behavior and working conditions are expected to be automatically monitored and managed without excessive manual observation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Intelligence-Based Spine Care Model: A New Era of Research and Clinical Decision-Making\n",
            "Authors: Mallow G.M.\n",
            "Abstract: None\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Activity classification using accelerometers and machine learning for complex construction worker activities\n",
            "Authors: Sanhudo L.\n",
            "Abstract: Automated Construction worker activity classification has the potential to not only benefit the worker performance in terms of productivity and safety, but also the overall project management and control. The activity-level knowledge and indicators that can be extracted from this process may support project decision making, aiding in project schedule adjustment, resource management, construction site control, among others. Previous works on this topic focused on the collection and classification of worker acceleration data using wearable accelerometers and supervised machine learning algorithms, respectively. However, most of these studies tend to consider small sets of activities performed in an instructed manner, which can lead to higher accuracy results than those expected in a real construction scenario. To this end, this paper builds on the results of these past studies, committing to expand this discussion by covering a larger set of complex Construction activities than the current state-of-the-art, while avoiding the need to instruct test subjects on how and when to perform each activity. As such, a Machine Learning methodology was developed to train and evaluate 13 classifiers using artificial features extracted from raw accelerometer data segments. An experimental study was carried out under the form of a realistic activity-circuit to recognise ten different activities: gearing up; hammering; masonry; painting; roughcasting; sawing; screwing; sitting; standing still; and walking; with most activities being a cluster of simpler tasks (i.e. masonry includes fetching, transporting, and laying bricks). Activities were initially separated and tested in three different activity groups, before assessing all activities together. It was found that a segment length of 6 s, with a 75% overlap, enhanced the classifier performance. Feature selection was carried out to speed the algorithm running time. A nested cross-validation approach was performed for hyperparameter tuning and classifier training and testing. User-dependent and -independent approaches (differing in whether the system must undergo an additional training phase for each new user) were evaluated. Results indicate that accelerometers can be used to create a robust system to recognise large sets of Construction worker activities automatically. The K-Nearest Neighbours and Gradient Boosting algorithms were selected according to their performances, respectively, for the user-dependent and -independent scenarios. In both cases, the classifiers showed balanced accuracies above 84% for their respective approaches and test groups. Results also indicate that a user-dependent approach using task groups provides the highest accuracy.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Remote indoor construction progress monitoring using extended reality\n",
            "Authors: Ali A.K.\n",
            "Abstract: Construction Progress monitoring noticed recent expansions by adopting vision and laser technologies. However, inspectors need to personally visit the job-site or wait for a time gap to process data captured from the construction site to use for inspection. Recent inspection methods lacks automation and real-time data exchange, therefore, it needs inspection manpower for each job-site, the health risk of physical interaction between workers and inspector, loss of energy, data loss, and time consumption. To address this issue, a near real-time construction work inspection system called iVR is proposed; this system integrates 3D scanning, extended reality, and visual programming to visualize interactive onsite inspection for indoor activities and provide numeric data. The iVR comprises five modules: iVR-location finder (finding laser scanner located in the construction site) iVR-scan (capture point cloud data of job-site indoor activity), iVR-prepare (processes and convert 3D scan data into a 3D model), iVR-inspect (conduct immersive visual reality inspection in construction office), and iVR-feedback (visualize inspection feedback from job-site using augmented reality). An experimental lab test is conducted to verify the applicability of iVR process; it successfully exchanges required information between construction job-site and office in a specific time. This system is expected to assist Engineers and workers in quality assessment, progress assessments, and decisionmaking which can realize a productive and practical communication platform, unlike conventional monitoring or data capturing, processing, and storage methods, which involve storage, compatibility and time-consumption issues.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Wearable inertial measurement unit sensing system for musculoskeletal disorders prevention in construction\n",
            "Authors: Zhao J.\n",
            "Abstract: Construction workers executing manual-intensive tasks are susceptible to musculoskeletal disorders (MSDs) due to overexposure to awkward postures. Automated posture recognition and assessment based on wearable sensor output can help reduce MSDs risks through early risk-factor detection. However, extant studies mainly focus on optimizing recognition models. There is a lack of studies exploring the design of a wearable sensing system that assesses the MSDs risks based on detected postures and then provides feedback for injury prevention. This study aims at investigating the design of an effective wearable MSDs prevention system. This study first proposes the design of a wearable inertial measurement unit (IMU) sensing system, then develops the prototype for end-user evaluation. Construction workers and managers evaluated a proposed system by interacting with wearable sensors and user interfaces (UIs), followed by an evaluation survey. The results suggest that wearable sensing is a promising approach for collecting motion data with low discomfort; posture-based MSDs risk assessment has a high potential in improving workers’ safety awareness; and mobile-and cloud-based UIs can deliver the risk assessment information to end-users with ease. This research contributes to the design, development, and validation of wearable sensing-based injury prevention systems, which may be adapted to other labor-intensive occupations.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of a safety management system tracking the weight of heavy objects carried by construction workers using fsr sensors\n",
            "Authors: Lee S.H.\n",
            "Abstract: It has been pointed out that the act of carrying a heavy object that exceeds a certain weight by a worker at a construction site is a major factor that puts physical burden on the worker’s musculoskeletal system. However, due to the nature of the construction site, where there are a large number of workers simultaneously working in an irregular space, it is difficult to figure out the weight of the object carried by the worker in real time or keep track of the worker who carries the excess weight. This paper proposes a prototype system to track the weight of heavy objects carried by construction workers by developing smart safety shoes with FSR (Force Sensitive Resistor) sensors. The system consists of smart safety shoes with sensors attached, a mobile device for collecting initial sensing data, and a web-based server computer for storing, preprocessing and analyzing such data. The effectiveness and accuracy of the weight tracking system was verified through the experiments where a weight was lifted by each experimenter from +0 kg to +20 kg in 5 kg increments. The results of the experiment were analyzed by a newly developed machine learning based model, which adopts effective classification algorithms such as decision tree, random forest, gradient boosting algorithm (GBM), and light GBM. The average accuracy classifying the weight by each classification algorithm showed similar, but high accuracy in the following order: random forest (90.9%), light GBM (90.5%), decision tree (90.3%), and GBM (89%). Overall, the proposed weight tracking system has a significant 90.2% average accuracy in classifying how much weight each experimenter carries.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Smart Device Monitoring System Based on Multi-type Inertial Sensor Machine Learning\n",
            "Authors: Zeng Y.\n",
            "Abstract: Construction activity recognition can be improved using data fusion from multiple inertial sensors such as accelerometers and gyroscopes, yet the number of accelerometers and gyroscopes and their optimal placement for combination need empirical determination. We considered the optimal combination of these two types of sensors placed on different parts of a construction worker for identifying construction activities through machine learning. The waist, arm, and wrist were equipped with data acquisition units to simultaneously acquire acceleration and angular velocity data for multiple sensor locations. A system for recognizing complex construction activities was developed on the basis of an accelerometer and gyroscope (A+G) synergy at multiple sensor locations. Results show that the A+G combination dataset at the wrist had the best activity recognition among the sensor configurations when the raw data came from a single sensor location. The results of comparing a single sensor location, two sensor locations, and three sensor locations indicate that combination with three sensor locations produced the best accuracy.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Wearable devices for ergonomics: A systematic literature review\n",
            "Authors: Stefana E.\n",
            "Abstract: Wearable devices are pervasive solutions for increasing work efficiency, improving workers’ well-being, and creating interactions between users and the environment anytime and anywhere. Although several studies on their use in various fields have been performed, there are no systematic reviews on their utilisation in ergonomics. Therefore, we conducted a systematic review to identify wearable devices proposed in the scientific literature for ergonomic purposes and analyse how they can support the improvement of ergonomic conditions. Twenty-eight papers were retrieved and analysed thanks to eleven comparison dimensions related to ergonomic factors, purposes, and criteria, populations, application and validation. The majority of the available devices are sensor systems composed of different types and numbers of sensors located in diverse body parts. These solutions also represent the technology most frequently employed for monitoring and reducing the risk of awkward postures. In addition, smartwatches, body-mounted smartphones, insole pressure systems, and vibrotactile feedback interfaces have been developed for evaluating and/or controlling physical loads or postures. The main results and the defined framework of analysis provide an overview of the state of the art of smart wearables in ergonomics, support the selection of the most suitable ones in industrial and non-industrial settings, and suggest future research directions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Three-Dimensional Working Pose Estimation in Industrial Scenarios with Monocular Camera\n",
            "Authors: Yu Y.\n",
            "Abstract: Three-dimensional (3-D) pose data has drawn great attention owing to its wide range of applications. Internet of Things (IoT)-based techniques have been introduced to collect 3-D pose data. Though previous studies have yielded significant results, researchers have yet to use 3-D pose estimation in real-life applications. Since wearable sensors might be intrusive and infrared depth cameras are sensitive to sunlight, monocular-camera-based computer vision algorithms provide a possible solution. Previous algorithms are trained and tested with simple daily postures. There are industrial scenarios where the poses are more complex and irregular. An example is the poses of workers on construction sites, such as lifting, climbing, and rebar tying. These postures differ drastically from daily postures and vary from person to person. For instance, some workers prefer bending rebar tying, while others prefer squatting rebar tying. As a result, the previous monocular-camera-based-3-D poses estimation methods have proved to be inapplicable to industrial scenarios. Thus, this article developed a monocular-camera-based 3-D estimation method which is suitable for industry working poses. A residual artificial neural network (RANN) with flexible complexity and weighted training loss was designed. A 3-D pose data set, which consists of diversified working poses in worksites, was built to test the performance of the network in complex scenarios. Compared with previous 3-D pose capture methods, the mean per joint position error was reduced by 31.42%. The latency was 0.24 s. Thus, we conclude that the proposed monocular-camera-based method has great potential in industrial application scenarios.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Analysis of the Limits of Automated Rule-Based Ergonomic Assessment in Bricklaying\n",
            "Authors: Ryu J.\n",
            "Abstract: Physically demanding and repetitive tasks expose workers to work-related musculoskeletal disorders (WMSDs). Over the last few decades, various rule-based postural assessment systems have been developed and widely used to facilitate the measurement and evaluation of risks related to WMSDs in many industries. However, the applicability of rule-based assessment to tasks involving heavy material handling has not yet been examined. This study investigated the applicability of three rule-based assessment systems (RULA, REBA, and OWAS) to a bricklaying task. To achieve this goal, an automated assessment tool was developed to implement those systems on whole-body data sets consisting of static postures captured by wearable inertial measurement unit suits. The study demonstrates the use of this tool in assessing risk levels (grand scores) encountered by 43 masons during the laying of 16.6-kg concrete masonry units (CMUs) in a standard wall. Furthermore, the biomechanical analysis of the same data set was carried out and utilized as ground truth to evaluate those results. It was found that rule-based assessment may lead to erroneously inflated risk evaluation in heavy manual handling tasks. In contrast, biomechanical analysis provided sensitive risk evaluations that distinguish the different degrees of risk arising from different motion patterns while participants performed the same tasks. These findings suggest using biomechanical analysis as an objective and robust method to evaluate risks encountered in tasks involving heavy material handling.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Artificial intelligence based on fuzzy logic for the analysis of human movement in healthy people: a systematic review\n",
            "Authors: Lima B.N.\n",
            "Abstract: Technological advances that involve computing and artificial intelligence (AI) have led to advances in analysis methods. Fuzzy logic (FL) serves as a qualitative interpretation tool for AI. The objective of this systematic review is to investigate the methods of human movement (HM) analysis using AI through FL to understand the characteristics of the movement of healthy people. To identify relevant studies published up to April 19, 2019, we conducted a study of the PubMed, Scopus, ScienceDirect, and IEEE Xplore databases. We included studies that evaluated HM through AI using FL in healthy people. A total of 951 articles were examined, of which six were selected because they met the criteria presented in the methods. The protocols had high heterogeneity, yet all articles selected presented statistically satisfactory results, in addition to low errors or a false positive index. Only one selected article presented protocol applicability within the free-living model. Generally, AI using FL is a good tool to help assess HM in healthy people, but the model still needs new data acquisition entries to make it applicability within the free-living model.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Sitting Posture Recognition Using a Spiking Neural Network\n",
            "Authors: Wang J.\n",
            "Abstract: To increase the quality of citizens' lives, we designed a personalized smart chair system to recognize sitting behaviors. The system can receive surface pressure data from the designed sensor and provide feedback for guiding the user towards proper sitting postures. We used a liquid state machine and a logistic regression classifier to construct a spiking neural network for classifying 15 sitting postures. To allow this system to read our pressure data into the spiking neurons, we designed an algorithm to encode map-like data into cosine-rank sparsity data. The experimental results consisting of 15 sitting postures from 19 participants show that the prediction precision of our SNN is 88.52%.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Collection and Classification of Human Posture Data using Wearable Sensors\n",
            "Authors: Gupta J.\n",
            "Abstract: Analysis of human posture has many applications in the field of sports and medical science including patient monitoring, lifestyle analysis, elderly care etc. It is important to understand if a person is healthy (in terms of his everyday posture) or is suffering from a joint/bone disease as reflected by his incorrect posture. Many of the works in this area have been based on computer vision techniques. These are limited in providing real-time solution. The aim of the proposed work is to classify the human posture during three different activities (standing, sitting and sleeping/lying) as a healthy or an unhealthy one. This is done by applying machine learning techniques on a large posture dataset which is collected with the help of MPU-6050 sensors mounted on multiple positions on the body. The performance evaluation of the proposed work reveals that the proposed work is efficient enough to classify the postures accurately.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Mechanical digital twinning of the human body in the workplace for reduced injury risk and improved health\n",
            "Authors: Harrison S.M.\n",
            "Abstract: A digital twin (DT) is a virtual model that acts as a mirror of its physical counterpart that may be solely a replication of certain features of the physical twin, or it may also include the ability to simulate potential future states. The fusion of data from the real world with the virtual model requires the use of sensors and processing of sensor data for inclusion in the digital representation. Simulation capabilities of the DT must be of sufficient detail to accurately forecast the effect of proposed system changes. Usability of the DT for operational tasks depends on the quality of the aforementioned requirements plus the clarity in which the state of the DT is presented to the user. Here we describe development of a human digital twin (HDT) pipeline for predicting injury risk during workplace activities. The system comprises a set of cameras (typically cheap webcams), a GPU enabled computer, and an in-house developed software package called “Ergomechanic”. Figure 1 shows an example visualisation of the HDT for a participant performing a manual handling task. The software combines markerless motion capture (MMC) with biomechanical modelling to calculate the pose of each worker's body and the loading upon major body components. Extremes in movement speeds and loading can be predicted and related to injury risk. Metrics defining injury risk can be improved and refined by wider spread use of the technology and correlation with recorded injuries. Example uses of the system to measure workplace activities and body loading are described. Future extensions of the system are discussed, such as viewing outputs in Augmented Reality (AR).\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The reliability and validity of body vision system for assessing posture\n",
            "Authors: Salekzamani Y.\n",
            "Abstract: Introduction: Body vision is a novel method which examines postural indices through photogrammetric essentials. Nevertheless, its reliability and validity has not been appraised till now. We aimed to evaluate the reliability and validity of body vision system for posture assessment. Methods: This was a cross-sectional study in which two examiners evaluated photographs of 71 subjects using body vision system twice with a two-week interval. The body vision system involves a grid wall and a camera fixed in front of the grid wall at about 390 cm distances. Three standing photographs (anterior, right lateral, and posterior view) were captured for participants. Results: The results for inter-rater reliability analysis showed that most of the parameters (74%) had excellent 95% confidence interval (CI), 10 % had good to excellent 95% CI, 13% had moderate to good 95% CI, and 1% had poor to moderate 95% CI. The results for intra-rater reliability analysis showed that 70%-72% of the parameters had excellent 95% CI, 6%-9% had good to excellent 95% CI, 12%-13% had moderate to good 95% CI, and 9% had poor to moderate 95% CI. The comparison between known distances and angles on grid wall and those obtained from photogrammetric measurements showed that there was no statistically significant difference (P > 0.05). Also, the regression analysis showed that there was a significant and positive relationship between them (R2 = 1, P< 0.05). Conclusion: The results of this study showed that body vision system is a valid and reliable tool for measuring postural parameters.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: 3D Viewing System in Vitreoretinal Surgery\n",
            "Authors: Eckert T.P.\n",
            "Abstract: Current three-dimensional (3D) viewing systems transmit the image recorded by a stereoscopic high dynamic range (HDR) digital camera with a very short latency to a 3D screen. The surgeon uses polarizing glasses and looks on the screen instead of using the oculars of the microscope. The application of such systems in vitreoretinal surgery has several advantages: better ergonomics due to a heads-up position, a good depth of field, the ease of using higher magnifications, reduced illumination levels, potentially reduced phototoxicity, improved teaching capabilities, and digital processing for enhanced visualization of delicate intraocular structures like vitreous, epiretinal membranes, or internal limiting membrane. As soon as high-definition sensors will be replaced by ultrahigh-definition (4K) sensors, the resolution of 3D viewing systems will surpass current analog microscopes. Soon digital operating microscopes will be available. One can assume that future 3D digital visualization systems will supersede traditional operating microscopes.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Real-time LiDAR for Monitoring Construction Worker Presence Near Hazards and in Work Areas in a Virtual Reality Environment\n",
            "Authors: Jacobsen E.L.\n",
            "Abstract: In this paper, a novel sensor system is used to detect worker presence near hazards and in key locations tied to productivity through geo-fencing. The systems' main component is real-time monitoring via LiDAR, which allows for more precise detection of the workers' position relative to the locations. The method involves LiDAR change and use-time event detections. The system is tested in a virtual environment resembling a real construction site, allowing for a safe evaluation while initial results are produced. Preliminary findings demonstrate the usability and the potential of this type of monitoring system, because of the precise detection of workers in geo-fenced locations in general. It could potentially be incorporated into live construction work environments.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: SeatPlus: A Smart Health Chair Supporting Active Sitting Posture Correction\n",
            "Authors: Shen Z.\n",
            "Abstract: Nowadays, sedentary and poor sitting postures mainly cause lumbar spine-related diseases for office workers. According to the related medical theory of sitting posture correction, this paper presents a smart chair SeatPlus that actively corrects the poor sitting posture. To identify and address the issues in sitting posture correction, we iterated our prototype three times following Lean UX design method. We evaluated SeatPlus in terms of system performance and system usability. The accuracy of the sitting posture recognition is higher than 90%, and the effectiveness of correction exceeds 70%. The overall usability of SeatPlus is good especially in two usability dimensions, impact and perceived Ease of Use. Furthermore, we find that the effectiveness of correction positively influences some usability dimensions, while the frequency of correction negatively influences the perceived ease of use.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Prediction of Kinematic and Kinetic Behavior of a Human Body While Performing Labor-Intensive Repetitive Task Using Machine Learning\n",
            "Authors: Subedi S.\n",
            "Abstract: Civil construction projects have numerous labor-intensive repetitive activities such as manual material handling, tile laying, concreting, among others. A handful of safety personnel cannot monitor the dispersed workers performing these tasks on the construction site. Besides, manual monitoring can be tedious, error-prone, and challenging to analyze postural safety. For computing the \"safe work posture\" of a task, unique actions and the moment exerted on major joints for each movement frame needs to be identified. For this, the paper proposes to use the Kinect to get the skeletal postural data while performing lifting and setting down task. Also, the research implements different machine learning algorithms to predict the unique actions and the moment exerted on the lower back for each movement frame. The training data was collected using Kinect in a controlled lab setup. The unique actions were manually identified for each movement frame. Then the kinetic analysis was performed in OpenSim using a human musculoskeletal model to compute the moment exerted on the lower back. The identified unique actions were used to train the action classification model using a random forest classifier, and the moment data was used to train the moment prediction model using a random forest regressor. Additional postural data were collected to validate the applicability of the developed model. The proposed research can play a pivotal role in assisting safety personnel in real-time safety monitoring of such repetitive tasks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Detecting Hook Attachments of a Safety Harness Using Inertial Measurement Unit Sensors\n",
            "Authors: Lee H.\n",
            "Abstract: Construction workers are required to wear a safety harness while working at height, and safety managers need to ensure that a safety hook is attached to proper anchorage points to prevent falls from height. However, it is difficult for the managers to monitor all the worker’s hook attachments continuously and remotely in dynamic workplace environments. This study developed an approach to detect an individual worker’s hook attachments by assessing the relative movements between the hook and the worker’s body. An Inertial Measurement Unit sensor was attached to the hook and the body strap to monitor the relative movements. The collected IMU data was transformed into image data by Markov Transition Field. The detection algorithm was developed based on the convolution neural networks that classify the worker’s postures, activities, and hook attachments simultaneously, and the developed detection system provided classification accuracies of 86.40%, 86.97%, and 96.58, respectively. The results validated that the relative movement between the hook and the worker’s body is a key feature for hook attachment detection.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Human Motion Posture Detection Algorithm Using Deep Reinforcement Learning\n",
            "Authors: Qi L.\n",
            "Abstract: To address problems of serious loss of details and low detection definition in the traditional human motion posture detection algorithm, a human motion posture detection algorithm using deep reinforcement learning is proposed. Firstly, the perception ability of deep learning is used to match human motion feature points to obtain human motion posture features. Secondly, normalize the human motion image, take the color histogram distribution of human motion posture as the antigen, search the region close to the motion posture in the image, and take its candidate region as the antibody. By calculating the affinity between the antigen and the antibody, the feature extraction of human motion posture is realized. Finally, using the training characteristics of deep learning network and reinforcement learning network, the change information of human motion posture is obtained, and the design of human motion posture detection algorithm is realized. The results show that when the image resolution is 384 × 256 px, the motion pose contour detection accuracy of this algorithm is 87%. When the image size is 30 MB, the recognition time of this method is only 0.8 s. When the number of iterations is 500, the capture rate of human motion posture details can reach 98.5%. This shows that the proposed algorithm can improve the definition of human motion posture contour, improve the posture detailed capture rate, reduce the loss of detail, and have better effect and performance.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Comparison of Multiple Machine Learning Algorithms to Predict Whole-Body Vibration Exposure of Dumper Operators in Iron Ore Mines in India\n",
            "Authors: Upadhyay R.\n",
            "Abstract: Background: This study deals with some factors that influence the exposure of whole-body vibration (WBV) of dumper operators in surface mines. The study also highlights the approach to improve the multivariate linear analysis outcomes when collinearity exists between certain factor pairs. Material and Methods: A total number of 130 vibration readings was taken from two adjacent surface iron ore mines. The frequency-weighted RMS acceleration was used for the WBV exposure assessment of the dumper operators. The factors considered in this study are age, weight, seat backrest height, awkward posture, the machine age, load tonnage, dumper speed and haul road condition. Four machine learning models were explored through the empirical trainingtesting approach. Results: The bootstrap linear regression model was found to be the best model based on performance and predictability when compared to multiple linear regression, LASSO regression, and decision tree. Results revealed that multiple factors influence WBV exposure. The significant factors are: weight of operators (regression coefficient β =-0.005, p<0.001), awkward posture (β=0.033, p<0.001), load tonnage (β=-0.026, p<0.05), dumper speed (β=0.008, p<0.001) and poor haul road condition (β=0.015, p<0.001). Conclusion: The bootstrap linear regression model produced efficient results for the dataset which was characterized by collinearity. WBV exposure is multifactorial. Regular monitoring of WBV exposure and corrective actions through appropriate prevention programs including the ergonomic design of the seat would increase the health and safety of operators.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Prediction and comparison of postural discomfort based on MLP and quadratic regression\n",
            "Authors: Lee J.\n",
            "Abstract: Objective: The objective of this study was to predict postural discomfort based on the deep learning-based regression (multilayer perceptron [MLP] model). Methods: A total of 95 participants performed 45 different static postures as a combination of 3 neck angles, 5 trunk angles, and 3 knee angles and rated the whole-body discomfort. Two different combinations of variables including model 1 (all variables: gender, height, weight, exercise, body segment angles) and model 2 (gender, body segment angles) were tested. The MLP regression and a conventional regression (quadratic regression) were both conducted, and the performance was compared. Results: In the overall regression analysis, the quadratic regression showed better performance than the MLP regression. For the postural discomfort group-specific analysis, MLP regression showed greater performance than the quadratic regression especially in the high postural discomfort group. The MLP regression also showed better performance in predicting postural discomfort among individuals who had a variability of subjective rating among different postures compared to the quadratic regression. The deep learning for postural discomfort prediction would be useful for the efficient job risk assessment for various industries that involve prolonged static postures. Conclusions: The deep learning for postural discomfort prediction would be useful for the efficient job risk assessment for various industries that involve prolonged static postures. This information would be meaningful as basic research data to study in predicting psychophysical data in ergonomics.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Review on the Use of Microsoft Kinect for Gait Abnormality and Postural Disorder Assessment\n",
            "Authors: Bawa A.\n",
            "Abstract: Gait and posture studies have gained much prominence among researchers and have attracted the interest of clinicians. The ability to detect gait abnormality and posture disorder plays a crucial role in the diagnosis and treatment of some diseases. Microsoft Kinect is presented as a noninvasive sensor essential for medical diagnostic and therapeutic purposes. There are currently no relevant studies that attempt to summarise the existing literature on gait and posture abnormalities using Kinect technology. The purpose of this study is to critically evaluate the existing research on gait and posture abnormalities using the Kinect sensor as the main diagnostic tool. Our studies search identified 458 for gait abnormality, 283 for posture disorder of which 26 studies were included for gait abnormality, and 13 for posture. The results indicate that Kinect sensor is a useful tool for the assessment of kinematic features. In conclusion, Microsoft Kinect sensor is presented as a useful tool for gait abnormality, postural disorder analysis, and physiotherapy. It can also help track the progress of patients who are undergoing rehabilitation.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of Eye Blink Rate Level Classification System Utilizing Sitting Postural Behavior Data\n",
            "Authors: Lee H.\n",
            "Abstract: The prevalence of dry eye syndrome (DES) has rapidly increased in recent years, negatively affecting the eye health of many office workers worldwide. Although low eye blink rate (EBR) has been pointed out as one of the main risk factors for DES, it is difficult for office workers to continuously monitor and increase their own involuntary blinking, especially when they are focused on the primary work task. Thus, as an effort to help office workers correct their low EBR, the current study developed a real-time EBR level classification system utilizing sitting postural behavior data. A total of twenty participants performed typical computer tasks on a sensor-embedded chair. The participants' eye blinking and postural behavior data were collected to develop the EBR level classification system with a random forest algorithm. After evaluating the system performance, the relationships between EBR and postural behaviors were empirically examined to help understand how the system worked for EBR level classification. As a result, the developed system showed high classification performance overall; and compared with high EBR condition, low EBR condition was related to less overall postural variability and greater extent of forward bending posture. The real-time EBR level classification system is expected to contribute to preventing/relieving DES and thereby enhancing the eye health of office workers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Assistive devices to help correct sitting-posture based on posture analysis results\n",
            "Authors: Lee S.M.\n",
            "Abstract: —As many people spend a lot of time sitting on a chair, diseases such as turtle neck, straight neck, caused by incorrect posture have been increasing. Preventing these diseases and treating initial symptoms is helpful just by sitting properly. However, when people sit, their postures become disturbed without their knowledge. In this paper, we propose an assistive device in the form of a chair that helps people to sit properly and helps correct their sitting posture. The assistive device is equipped with pressure sensors capable of measuring the distribution of pressure applied to the floor of the chair, and an ultrasonic sensor capable of measuring the distance between the user's back and the chair back. First, an ultrasonic sensor and pressure sensors are used to determine the user's posture, and if the user's posture is not correct, an alarm is sent to the user to help the user to correct the posture by himself. Second, stretching information is provided according to the degree of distribution of pressure measured by the pressure sensors, and pressures are applied to the user's back with press-type cushions to help the user sit in a correct posture. In addition, even when sitting in a chair for a long time, an alarm is triggered to induce a person to rise from the chair. After implementing the system based on Raspberry Pi, each operation was checked. Furthermore, it was confirmed through the experiment participants that the proposed assistive device can help people correct their sitting posture.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Exercise Abnormality Detection Using BlazePose Skeleton Reconstruction\n",
            "Authors: Kulikajevas A.\n",
            "Abstract: There still exists a knowledge gap in the field of computer vision in respect of posture prediction and deviation evaluation is an important metric for various medical applications, that require posture abnormality quantization. Our paper proposes a deep heuristic neural network architecture, using BlazePose as a backbone, that is capable of reconstructing users skeleton from a real-time monocular video feed, using which we are able to evaluate the subjects performed exercise and measure the deviation from expected values. The proposed heuristics are able to identify and evaluate most of the abnormalities, with the highest indicator of postural issues being the spinal deviation accounting for 95%. Additional evaluation of real-time performance has shown that our method is capable of maintaining 23-ms response times, making it applicable to real-time applications.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Review on the Malaysian and Indonesian Batik Production, Challenges, and Innovations in the 21st Century\n",
            "Authors: Syed Shaharuddin S.I.\n",
            "Abstract: Malaysia and Indonesia are well known as prolific producers of batik in Southeast Asia. The history of batik in both countries is deeply intertwined for more than a century. Most available published works related to batik production, challenges, and innovations were discussed within the local batik context of each country. This study aims to identify collectively how far batik, as a creative industry in these countries has progressed since its establishment until the present 21st century. It was notable that batik craftsmanships have been mostly maintained as similar tools and techniques are persistently being used until today in both countries. Significant progress was observed in the design and stylization of the batik design with the use of digital approaches such as fractal geometry. Similar challenging problems faced by both nations were highlighted and clustered into internal and external issues. It was concluded that assimilations of Third Industrial Revolution technology (IR3.0) primarily centered on the use of computer-aided design and computer-aided manufacturing to improve existing batik production. Emerging studies have shown the positive impact of integrating Fourth Industrial Revolution (IR4.0) technology such as augmented reality (AR) in promoting batik knowledge and transmitting batik as an intangible cultural heritage. The transmission of batik skills to the young generation has been a persistent problem. Thus, a brief framework was proposed to exemplify how IR4.0 technology can innovatively be used to transmit the batik skills via education platform.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Technological advancements in the analysis of human motion and posture management through digital devices\n",
            "Authors: Roggio F.\n",
            "Abstract: Technological development of motion and posture analyses is rapidly progressing, especially in rehabilitation settings and sport biomechanics. Consequently, clear discrimination among different measurement systems is required to diversify their use as needed. This review aims to resume the currently used motion and posture analysis systems, clarify and suggest the appropriate approaches suitable for specific cases or contexts. The currently gold standard systems of motion analysis, widely used in clinical settings, present several limitations related to marker placement or long procedure time. Fully automated and markerless systems are overcoming these drawbacks for conducting biomechanical studies, especially outside laboratories. Similarly, new posture analysis techniques are emerging, often driven by the need for fast and non-invasive methods to obtain high-precision results. These new technologies have also become effective for children or adolescents with non-specific back pain and postural insufficiencies. The evolutions of these methods aim to standardize measurements and provide manageable tools in clinical practice for the early diagnosis of musculoskeletal pathologies and to monitor daily improvements of each patient. Herein, these devices and their uses are described, providing researchers, clinicians, orthopedics, physical therapists, and sports coaches an effective guide to use new technologies in their practice as instruments of diagnosis, therapy, and prevention.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Fuzzy Logic Approach to Evaluate Discomfort of Body Parts Among Female Sal Leaf Plate Makers in India\n",
            "Authors: Ghosh B.\n",
            "Abstract: The commonly used ergonomic posture analysis tools are unable to measure exact level of risk associated with human body parts, since these tools exclude several factors, such as uncertainties in the border regions between adjacent ranges of inputs, design of work places, characteristic of works, etc. To capture those uncertainties, a computational methodology is developed for evaluating discomfort level of body parts among the female Sal leaf plate makers using the Mamdani fuzzy inference system. The modified Nordic questionnaire is used, subsequently, to measure consistency in collecting responses from the workers. The body part discomfort (BPD) scale is considered for subjective validation. The scores achieved from BPD scale and rapid entire body assessment worksheet are used to act as the input values of the proposed system. Due to some unavoidable imprecisions associated with the collected data, the membership functions of the input and output variables of the developed fuzzy system are represented by linear type fuzzy numbers. To show feasibility and reliability of the proposed methodology, a comparison is made between the achieved results and the scores obtained through fuzzy decision support system using rapid upper limb assessment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Detection of anomalies in working posture during obstacle avoidance tasks using one-class support vector machine\n",
            "Authors: Hiranai K.\n",
            "Abstract: This study was conducted to evaluate working posture during obstacle avoidance tasks using a one-class support vector machine (SVM), and to compare the efficacy of this method in relation to traditional ergonomic evaluation methods. Eleven right-handed male participants performed reaching tasks in which they were required to move their right arm toward a predefined target position while avoiding obstacles. Working position, obstacle height/width, and obstacle presence varied among the experimental conditions. Working posture and subjective difficulty were assessed for each condition. The one-class SVM was applied to the quaternion of each body segment, which was determined based on measurements of working posture. Rates of postural anomalies were calculated for each experimental condition. The rates of postural anomalies for the right upper limb and head/neck increased as the width of the obstacle increased. Similarly, the subjective difficulty of work increased as obstacle width increased. Observational methods are unable to identify postural anomalies with regard to the right shoulder abduction angle and right lateral bending angle of the neck. However, our findings indicate that the proposed one-class SVM can detect postural anomalies in the right upper limb and head/neck for different obstacle widths.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A multi-task learning approach for human activity segmentation and ergonomics risk assessment\n",
            "Authors: Parsa B.\n",
            "Abstract: We propose a new approach to Human Activity Evaluation (HAE) in long videos using graph-based multi-task modeling. Previous works in activity evaluation either directly compute a metric using a detected skeleton or use the scene information to regress the activity score. These approaches are insufficient for accurate activity assessment since they only compute an average score over a clip, and do not consider the correlation between the joints and body dynamics. Moreover, they are highly scene-dependent which makes the generalizability of these methods questionable. We propose a novel multi-task framework for HAE that utilizes a Graph Convolutional Network backbone to embed the interconnections between human joints in the features. In this framework, we solve the Human Activity Segmentation (HAS) problem as an auxiliary task to improve activity assessment. The HAS head is powered by an Encoder-Decoder Temporal Convolutional Network to semantically segment long videos into distinct activity classes, whereas, HAE uses a Long-Short-Term-Memory-based architecture. We evaluate our method on the UW-IOM and TUM Kitchen datasets and discuss the success and failure cases in these two datasets.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Feasibility of using floor vibration to detect human falls\n",
            "Authors: Shao Y.\n",
            "Abstract: With the increasing aging population in modern society, falls as well as fall-induced injuries in elderly people become one of the major public health problems. This study proposes a classification framework that uses floor vibrations to detect fall events as well as distinguish different fall postures. A scaled 3D-printed model with twelve fully adjustable joints that can simulate human body movement was built to generate human fall data. The mass proportion of a human body takes was carefully studied and was reflected in the model. Object drops, human falling tests were carried out and the vibration signature generated in the floor was recorded for analyses. Machine learning algorithms including K-means algorithm and K nearest neighbor algorithm were introduced in the classification process. Three classifiers (human walking versus human fall, human fall versus object drop, human falls from different postures) were developed in this study. Results showed that the three proposed classifiers can achieve the accuracy of 100, 85, and 91%. This paper developed a framework of using floor vibration to build the pattern recognition system in detecting human falls based on a machine learning approach.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Practice on human posture based on opencv\n",
            "Authors: Li Z.\n",
            "Abstract: With the popularity of monitoring devices and the completion of monitoring systems, computer vision has been widely used. The analysis and research of human posture is an important part of computer vision and a hot research direction. This paper chooses human motion posture analysis in computer vision as the research direction. By inputting video information, the foreground image is extracted, and the outline of the human body in the foreground image is normalized to get the standard human posture image. Finally, the projection histogram of the human posture image is compared with that of the image in the template library to find the image with the highest similarity, and then the human posture can be determined. This paper realizes the determination of three postures: standing, sitting and lying. An experimental verification is carried out using OpenCV on VS2017 platform. The experimental results show that the proposed method is feasible.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: EMG characterization and processing in production engineering\n",
            "Authors: del Olmo M.\n",
            "Abstract: Electromyography (EMG) signals are biomedical signals that measure electrical currents generated during muscle contraction. These signals are strongly influenced by physiological and anatomical characteristics of the muscles and represent the neuromuscular activities of the human body. The evolution of EMG analysis and acquisition techniques makes this technology more reliable for production engineering applications, overcoming some of its inherent issues. Taking as an example, the fatigue monitoring of workers as well as enriched human–machine interaction (HMI) systems used in collaborative tasks are now possible with this technology. The main objective of this research is to evaluate the current implementation of EMG technology within production engineering, its weaknesses, opportunities, and synergies with other technologies, with the aim of developing more natural and efficient HMI systems that could improve the safety and productivity within production environments.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Bibliometric review of visual computing in the construction industry\n",
            "Authors: Wang H.W.\n",
            "Abstract: In the construction area, visuals such as drawings, photos, videos, and 3D models, play a significant role in the design, build and maintenance of a facility, bringing efficiency to generate, transfer, and store information. Advanced visual computing techniques facilitate the understanding of design contents, work plans, and other types of information shared in the construction industry. Automatic visual data collection and analysis provide many possibilities to the construction industry and a large number of works have investigated how visual computing can improve construction management processes and other problems in the construction area. However, a comprehensive literature review is needed. This study uses bibliometric approaches to review the works published to date, and analyses the development of knowledge, significant research results, and trends. The purpose of this study is to help newcomers to this research field understand knowledge structure and formulate research directions, thereby enhancing knowledge development. From this study, it can be concluded that computer vision is a key axis of improvement. Moreover, building information modeling, laser scanning, and other visualization-related techniques are also important in advancing the construction area.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Health and productivity impact of semi-automated work systems in construction\n",
            "Authors: Ryu J.H.\n",
            "Abstract: Variability of construction sites and tasks make their automation prohibitively complex. Workers continue to carry out physically demanding tasks which adversely affect their health, safety, and productivity. The flexibility of semi-automated work systems, where operators work in conjunction with machines and robots, is an attractive alternative. It is critical to estimate the anticipated effectiveness of these interventions before integrating them into the current work processes. This study proposes a systematic and objective methodology to assess the value of a semi-automated work system in a construction context, as it pertains to reduced exposure to musculoskeletal disorder risks and productivity improvements. Additional assessments are also suggested for a complete analysis of efficacy. The proposed methodology was validated through an experimental evaluation of a force-assist self-leveling pallet in a masonry task. It provides an objective evaluation of impact on the task showing 40% reduction in joint loads and 10% increase in productivity.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Detecting excessive load-carrying tasks using a deep learning network with a Gramian Angular Field\n",
            "Authors: Lee H.\n",
            "Abstract: Manual load carrying without sufficient rest may cause work-related musculoskeletal disorders (WMSDs) and needs to be monitored at construction sites. While previous studies have been able to predict load-carrying modes using multiple wearable inertial measurement unit (IMU) sensors, wearing multiple sensors obtrudes on workers during various construction tasks. In this context, by using a single IMU sensor, this research proposes an automatic detecting technique for excessive carrying-load (DeTECLoad) to predict load-carrying weights and postures simultaneously. DeTECLoad converts the IMU data into image data using a Gramian Angular Field, and then uses a hybrid Convolutional Neural Network-Long Short-Term Memory to classify load-carrying modes from the image data. DeTECLoad provides 92.46% and 96.33% accuracies for the load-carrying weight and posture classifications, respectively. By exploiting DeTECLoad, a construction worker's excessive load-carrying tasks could be managed in situ, helping to prevent construction site WMSDs.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Human-object interaction recognition for automatic construction site safety inspection\n",
            "Authors: Tang S.\n",
            "Abstract: Today, computer vision object detection methods are used for safety inspections from site videos and images. These methods detect bounding boxes and use hand-made rules to enable personal protective equipment compliance checks. This paper presents a new method to improve the breadth and depth of vision-based safety compliance checking by explicitly classifying worker-tool interactions. A detection model is trained on a newly constructed image dataset for construction sites, achieving 52.9% average mean precision for 10 object categories and 89.4% average precision for detecting workers. Using this detector and new dataset, the proposed human-object interaction recognition model achieved 79.78% precision and 77.64% recall for hard hat checking; 79.11% precision and 75.29% recall for safety coloring checking. The new model also verifies hand protection for workers when tools are being used with 66.2% precision and 64.86% recall. The proposed model is superior in these checking tasks when compared with post-processing detected objects with hand-made rules, or applying detected objects only.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Repairability assessment of vehicle new model line-up using modeling and virtual reality\n",
            "Authors: Makarova I.\n",
            "Abstract: The increasingly sophisticated design of modern vehicles affects the technological processes of assembly, repair and maintenance. When assessing the vehicle maintainability, nuances may arise at the operation stage that were not taken into account in the design, especially for new and modernized models. So, problems may arise associated with the non-optimal organization of the repair technological processes or with their injury hazard. Therefore, there is a need for feedback from the manufacturer, who has effective tools for checking and adjusting processes. An algorithm for the technological process of assessing maintainability has been developed, which includes a sequence of actions by designers and technologists and then checking the corrected process in the service center. The use of simulation and virtual reality tools allows to achieve one of the main tasks of any enterprise-ensuring the safe labor of workers, preventing injuries at the workplace. On the other hand, the correct organization of labor increases the productivity of workers and saves time significantly. Simulation of the technological process of removing the crankcase protection has been carried out. We took into account the anthropological parameters of real workers. As a result of optimization experiments, the parameters of the lift were selected, they will reduce the load on all muscle groups, thereby preventing the occurrence of occupational diseases.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Review of measuring microenvironmental changes at the body–seat interface and the relationship between object measurement and subjective evaluation\n",
            "Authors: Liu Z.\n",
            "Abstract: Being seated has increasingly pervaded both working and leisure lifestyles, with development of more comfortable seating surfaces dependent on feedback from subjective questionnaires and design aesthetics. As a consequence, research has become focused on how to objectively resolve factors that might underpin comfort and discomfort. This review summarizes objective methods of measuring the microenvironmental changes at the body–seat interface and examines the relationship between objective measurement and subjective sensation. From the perspective of physical parameters, pressure detection accounted for nearly two thirds (37/54) of the publications, followed by microclimatic information (temperature and relative humidity: 18/54): it is to be noted that one article included both microclimate and pressure measurements and was placed into both categories. In fact, accumulated temperature and relative humidity at the body–seat interface have similarly negative effects on prolonged sitting to that of unrelieved pressure. Another interesting finding was the correlation between objective measurement and subjective evaluation; however, the validity of this may be called into question because of the differences in experiment design between studies.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Position Matters: Sensor Placement for Sitting Posture Classification\n",
            "Authors: Kappattanavar A.M.\n",
            "Abstract: Prolonged sitting behavior and postures that cause strain on the spine and muscles have been reported to increase the probability of low back pain. To address this issue, many commercially available sensors already provide feedback about whether a person is 'slouching' or 'not slouching'. However, they do not provide information on a person's posture, which would give insights into the strain caused by a specific posture. Hence, in this pilot study, we attempt to find the optimum number of inertial measurement unit sensors required and the best locations to place them using six mock postures. Data is collected from these sensors and features are extracted. The number of features are reduced and the best features are selected using the Recursive Feature Elimination method with Cross-Validation. The reduced number of features is then trained and tested on Logistic Regression, Support Vector Machine and Hierarchical Model. Among the three models, the Support Vector Machine algorithm had the highest accuracy of 93.68%, obtained for the thoracic, hip and sacral region sensor combinations. While these findings will be validated in a larger study in an uncontrolled environment, this pilot study quantitatively highlights the importance of sensor placement in shaping discriminative performance in sitting posture classification tasks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Posture related musculoskeletal disorders (MSDs) among computer users in higher education sectors of Malaysia\n",
            "Authors: Khan S.H.\n",
            "Abstract: Introduction: Computer usage has become an indispensable tool in the official set up of all the workplaces in the current era. Predominance of musculoskeletal disorders (MSDs) in relation to habitual posture during work is the utmost problem of modern society. Teaching staff stand out amongst a group of workers exposed to occupational MSDs. The objective of this study was to identify the prevalence and risk factors of musculoskeletal disorders in relation to posture and computer ergonomics at workplace among the college and university staff in Petaling Jaya, Malaysia. Methods: This cross-sectional quantitative study was conducted from August 2019-October 2019, among 419 volunteers by using a self-administered survey questionnaire. Descriptive and bivariate statistics were used for the analyses of multiple variables. The association between demographic characteristics, computer ergonomics and prevalence of musculoskeletal pains were analyzed through Chi-square test. Results: 55.8 % respondents (n=234) reported neck pain (NP), (n=196) 46.8% shoulder pain (SP) and (n=308) 73.5% low back pain (LBP) respectively. A significant relationship between desktop computer usage and musculoskeletal pains in LBP (P=0.036) and SP (P=0.023) was observed. Significant association of head posture was found with NP (P=0.002), SP (P=0.042) and LBP (P=0.001), correspondingly. Discussion: Habitual postures were significantly associated with musculoskeletal pains while using computer. Conclusion: This study proved with precession that higher prevalence rate of musculoskeletal disorders was undoubtedly influenced by prolonged sitting, awkward postures at workstation, and repetitive movements of shoulders and hands. Further synchronous studies are vital to limit the modern era of musculoskeletal disorders.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Monitoring of occupant states in autonomous vehicles using capacitance-sensing imaging\n",
            "Authors: Kumar R.P.\n",
            "Abstract: The increasing popularity of autonomous vehicles has heightened the need to deploy robust systems that guarantee the safety and comfort of vehicle occupants. Such systems are required to monitor the presence and posture of occupants in real-time. This paper proposes a novel system that combines capacitive sensing with machine learning to achieve real-time occupant detection and posture recognition. The main constituent of the system is a capacitance-sensing mat that spans both the seat base (SB) and the backrest (BR) of a typical vehicle seat. The mat is connected to a sensing circuitry that continuously monitors variations in capacitance inside the mat to generate grayscale capacitance-sensing images (CSIs). The CSIs are real-time pictorial representations of the variations in capacitance caused within the mat due to changes in the position and the posture of occupants. The real-time CSIs then serve as inputs to a k-nearest-neighbors-based (k-NN) classifier that is capable of identifying different posture classes. The classifier is pre-trained using a previously acquired database consisting of a collection of CSIs belonging to known posture classes. Subsequently, the performance of the classifier is validated, and the system is deployed for real-time occupant detection and posture recognition.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Deep learning in the construction industry: A review of present status and future innovations\n",
            "Authors: Akinosho T.D.\n",
            "Abstract: The construction industry is known to be overwhelmed with resource planning, risk management and logistic challenges which often result in design defects, project delivery delays, cost overruns and contractual disputes. These challenges have instigated research in the application of advanced machine learning algorithms such as deep learning to help with diagnostic and prescriptive analysis of causes and preventive measures. However, the publicity created by tech firms like Google, Facebook and Amazon about Artificial Intelligence and applications to unstructured data is not the end of the field. There abound many applications of deep learning, particularly within the construction sector in areas such as site planning and management, health and safety and construction cost prediction, which are yet to be explored. The overall aim of this article was to review existing studies that have applied deep learning to prevalent construction challenges like structural health monitoring, construction site safety, building occupancy modelling and energy demand prediction. To the best of our knowledge, there is currently no extensive survey of the applications of deep learning techniques within the construction industry. This review would inspire future research into how best to apply image processing, computer vision, natural language processing techniques of deep learning to numerous challenges in the industry. Limitations of deep learning such as the black box challenge, ethics and GDPR, cybersecurity and cost, that can be expected by construction researchers and practitioners when adopting some of these techniques were also discussed.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic risk assessment based on computer vision and machine learning\n",
            "Authors: MassirisFernández M.\n",
            "Abstract: We develop a novel method that performs accurate ergonomic risk assessment, automatically computing Rapid Upper Limb Assessment (RULA) scores from snapshots or digital video using computer vision and machine learning techniques. Our method overcomes the limitations in recent developments based on computer vision or in wearable measurement sensors, being able to perform unsupervised assessment handling multiple workers simultaneously, even under sub-optimal viewing conditions (e.g., poor illumination, occlusions, and unstable camera views). The processing workflow uses open-source neural networks to detect the workers’ skeletons, after which their body-joint positions and angles are inferred, with which RULA scores are computed. The method was tested with computer-generated, controlled real-world image datasets, and with freely available videos taken in outdoor working scenarios. The computed RULA scores were in close agreement with the assessments of seven specialists in the field, achieving a Cohen's κ over 0.6 in most real-world experiments.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Fusing imperfect experimental data for risk assessment of musculoskeletal disorders in construction using canonical polyadic decomposition\n",
            "Authors: Dutta A.\n",
            "Abstract: Field or laboratory data collected for work-related musculoskeletal disorder (WMSD) risk assessment in construction often becomes unreliable as a large amount of data go missing due to technology-induced errors, instrument failures or sometimes at random. Missing data can adversely affect the assessment conclusions. This study proposes a method that applies Canonical Polyadic Decomposition (CPD) tensor decomposition to fuse multiple sparse risk-related datasets and fill in missing data by leveraging the correlation among multiple risk indicators within those datasets. Two knee WMSD risk-related datasets—3D knee rotation (kinematics) and electromyography (EMG) of five knee postural muscles—collected from previous studies were used for the validation and demonstration of the proposed method. The analysis results revealed that for a large portion of missing values (40%), the proposed method can generate a fused dataset that provides reliable risk assessment results highly consistent (70%–87%) with those obtained from the original experimental datasets. This signified the usefulness of the proposed method for use in WMSD risk assessment studies when data collection is affected by a significant amount of missing data, which will facilitate reliable assessment of WMSD risks among construction workers. In the future, findings of this study will be implemented to explore whether, and to what extent, the fused dataset outperforms the datasets with missing values by comparing consistencies of the risk assessment results obtained from these datasets for further investigation of the fusion performance.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: PoseScape: Pose-based Analysis System for Long-term Observation Studies\n",
            "Authors: Sung J.\n",
            "Abstract: Designers employ various design methods to observe people in their daily lives, to uncover rich information about their behaviors. However, manually analyzing and annotating long-term data such as data from video can be time-consuming. In this paper, we propose PoseScape, an automated long-term posture analysis system which uses markerless motion capturing, to help designers understand the patterns of the poses in use and to conduct ergonomic assessments. The system clusters postures using K-means clustering to reveal their varieties and visualizes the frequency, the duration, and the transitions of postures to help designers better understand human behaviors. For an early evaluation, we applied our tool to analyze sitting patterns from an in-the-wild perspective. We collected 3D postures of people working with a tablet PC on a sofa for two hours and compared analysis results from both PoseScape and design researchers. We identified a near resemblance between those two results, though with a subtle difference. We discuss the results and the future implications of pose recognition systems on the design of everyday things.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Computer Vision for Structural Dynamics and Health Monitoring\n",
            "Authors: Feng D.\n",
            "Abstract: Provides comprehensive coverage of theory and hands-on implementation of computer vision-based sensors for structural health monitoring This book is the first to fill the gap between scientific research of computer vision and its practical applications for structural health monitoring (SHM). It provides a complete, state-of-the-art review of the collective experience that the SHM community has gained in recent years. It also extensively explores the potentials of the vision sensor as a fast and cost-effective tool for solving SHM problems based on both time and frequency domain analytics, broadening the application of emerging computer vision sensor technology in not only scientific research but also engineering practice. Computer Vision for Structural Dynamics and Health Monitoring presents fundamental knowledge, important issues, and practical techniques critical to successful development of vision-based sensors in detail, including robustness of template matching techniques for tracking targets; coordinate conversion methods for determining calibration factors to convert image pixel displacements to physical displacements; sensing by tracking artificial targets vs. natural targets; measurements in real time vs. by post-processing; and field measurement error sources and mitigation methods. The book also features a wide range of tests conducted in both controlled laboratory and complex field environments in order to evaluate the sensor accuracy and demonstrate the unique features and merits of computer vision-based structural displacement measurement. Offers comprehensive understanding of the principles and applications of computer vision for structural dynamics and health monitoring Helps broaden the application of the emerging computer vision sensor technology from scientific research to engineering practice such as field condition assessment of civil engineering structures and infrastructure systems Includes a wide range of laboratory and field testing examples, as well as practical techniques for field application Provides MATLAB code for most of the issues discussed including that of image processing, structural dynamics, and SHM applications Computer Vision for Structural Dynamics and Health Monitoring is ideal for graduate students, researchers, and practicing engineers who are interested in learning about this emerging sensor technology and advancing their applications in SHM and other engineering problems. It will also benefit those in civil and aerospace engineering, energy, and computer science.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Worker 4.0: The future of sensored construction sites\n",
            "Authors: Calvetti D.\n",
            "Abstract: The digitalization of the construction industry (CI) has the aim-among others-to raise the bar of overall productivity. The craft workforce is very relevant on the overall value-chain. Therefore, a boost in this dimension impacts the entire sector. There is a gap in proper methodologies to measure and model productivity. Construction 4.0 novelties provide new approaches for its evaluation and progress. This communication presents a review of workforce productivity assessment and delivers methods focusing primarily on craft workers motion monitoring. Products and services opportunities from Construction 4.0 in the spectrum of craft workforce management include support by embedded sensors for data collection that allow near real-time monitoring. The work developed led to the systematization of a framework to standardize craft workers' motion productivity. The craft workforce motion productivity framework, Worker 4.0, tenders nine processes integrated on a flowchart to streamline task processes assessment and mechanization level. It also sets up a two-handed/two-legged chart system to model craft workers' activities and operations. The contributions to the body of knowledge are substantiated on the framework creation with the ability to model and assess craft workforce performance. This approach is meant to serve as base point for different stakeholders focusing on skills, efficiency, mechanization and productivity improvements.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of an IoT‐based construction worker physiological data monitoring platform at high temperatures\n",
            "Authors: Kim J.H.\n",
            "Abstract: This study presents an IoT‐based construction worker physiological data monitoring platform using an off‐the‐shelf wearable smart band. The developed platform is designed for construction workers performing under high temperatures, and the platform is composed of two parts: an overall heat assessment (OHS) and a personal management system (PMS). OHS manages the breaktimes for groups of workers based using a thermal comfort index (TCI), as provided by the Korea Meteorological Administration (KMA), while PMS assesses the individual health risk level based on fuzzy theory using data acquired from a commercially available smart band. The device contains three sensors (PPG, Acc, and skin temperature), two modules (LoRa and GPS), and a power supply, which are embedded into a microcontroller (MCU). Thus, approved personnel can monitor the status as well as the current position of a construction worker via a PC or smartphone, and can make necessary decisions remotely. The platform was tested in both indoor and outdoor environment for reliability, achieved less than 1% of error, and received satisfactory feedback from on‐site users.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Convolutional long short-term memory model for recognizing construction workers’ postures from wearable inertial measurement units\n",
            "Authors: Zhao J.\n",
            "Abstract: This paper proposes using Deep Neural Networks (DNN) models for recognizing construction workers’ postures from motion data captured by wearable Inertial Measurement Units (IMUs) sensors. The recognized awkward postures can be linked to known risks of Musculoskeletal Disorders among workers. Applying conventional Machine Learning (ML)-based models has shown promising results in recognizing workers’ postures. ML models are limited – they reply on heuristic feature engineering when constructing discriminative features for characterizing postures. This makes further improving the model performance regarding recognition accuracy challenging. In this paper, the authors investigate the feasibility of addressing this problem using a DNN model that, through integrating Convolutional Neural Networks (CNN) with Long Short-Term Memory (LSTM) layers, automates feature engineering and sequential pattern detection. The model's recognition performance was evaluated using datasets collected from four workers on construction sites. The DNN model integrating one convolutional and two LSTM layers resulted in the best performance (measured by F1 Score). The proposed model outperformed baseline CNN and LSTM models suggesting that it leveraged the advantages of the two baseline models for effective feature learning. It improved benchmark ML models’ recognition performance by an average of 11% under personalized modelling. The recognition performance was also improved by 3% when the proposed model was applied to 8 types of postures across three subjects. These results support that the proposed DNN model has a high potential in addressing challenges for improving the recognition performance that was observed when using ML models.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Detection of Personal Protective Equipment (PPE) Compliance on Construction Site Using Computer Vision Based Deep Learning Techniques\n",
            "Authors: Delhi V.S.K.\n",
            "Abstract: Construction safety is a matter of great concern for practitioners and researchers worldwide. Even after risk assessments have been conducted and adequate controls have been implemented, workers are still subject to safety hazards in construction work environments. The need for personal protective equipment (PPE) is important in this context. Automatic and real-time detection of the non-compliance of workers in using PPE is an important concern. Developments in the field of computer vision and data analytics, especially using deep learning algorithms have the potential to address this challenge in construction. This study developed a framework to sense in real-time, the safety compliance of construction workers with respect to PPE, which is intended to be integrated into the safety workflow of an organization. The study makes use of the Convolutional Neural Networks model, which was developed by applying transfer learning to a base version of the YOLOv3 deep learning network. Taking into account the presence of hardhat and safety jackets, the model predicts compliance in four categories such as NOT SAFE, SAFE, NoHardHat, and NoJacket. A data set of 2,509 images was collected from video recordings from several construction sites and this web-based collection was used to train the model. The model reported an F1 score of 0.96 with an average precision and recall rate at 96% on the test data set. Once a non “SAFE” category is detected by the model, an alarm and a time-stamped report are also incorporated to enable a real-time integration and adoption on the construction sites. Overall, the study provides evidence on the feasibility and utility of computer vision-based techniques in automating the safety-related compliance processes at construction sites.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Hand Motion Recognition of Shipyard Welder Using 9-DOF Inertial Measurement Unit and Multi Layer Perceptron Approach\n",
            "Authors: Pribadi T.W.\n",
            "Abstract: A viable system that can monitor the effective working time of welder in real-time is required to overcome the low use of effective welder time in the Shipbuilding Project in the Indonesian Shipyard. It is made possible by using a wearable sensor tri-axial accelerometer, gyroscope, and magnetometer. In this research, sensors are used to recognize typically hand motion of welder during welding activities: preparation, welding and cleaning slags, respectively in three welding positions 1G, 2G, and 3G. Initially, observations were made to recognize the relationship between welder activities and hand motion. Second, raw data containing hand movements from the welder is captured in the form of time-series signals using inertia sensors for various different activities. Third, the raw data of measurements for those activities is extracted and analyzed to identify significant features such as mean, root-mean-square, power spectral density using the welch method (autocorrelation, spectral peak, and spectral power). Finally, typical activities of welder are classified using the resulting feature data with Multi Layer Perceptron. The validation of results shows that the algorithm is capable to recognize the hand motion activities of the welder.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Validation of inertial-magnetic wearable sensors for full-body motion tracking of automotive manufacturing operations\n",
            "Authors: Ji X.\n",
            "Abstract: The objective of this study is to determine if wearable inertial-magnetic tracking systems can be suitably used to conduct full-body motion analysis when performing common tasks in the automotive manufacturing industry. Twenty unimpaired participants were recruited for this study. Seventeen Xsens inertial-magnetic sensors and fifty-two Cortex reflective markers were secured onto each of the participants to record their operations at six workstations. We compared the root mean square error produced by the two measuring systems in 13 human joints. We also evaluated the linear positional error of the left foot placement. Due to the complexity of the shoulder girdle motion, we compared the outputs from the Cortex and Xsens systems in two additional postural tests with a 3rd camera system. Our results indicate that the Xsens platform is affected by positional drifts; however, such drifts are contained in an acceptable range. Due to the use of magnetometers to measure tilt, data from these complementary inertial sensors can be used to reduce drift by continuously correcting the orientation obtained by integrating sensor data. The Xsens system maintains acceptable accuracy (r.m.s.e. < 10° for most of the joints), even in the presence of large metal parts that could cause systematic errors in the transducer output, which is based on the sensor fusion of an inertial-magnetic sensor. We believe that the Xsens, a wearable inertial-magnetic tracking system, could be a viable alternative to camera-based systems for full-body biomechanical model analysis. Relevance to industry: An accurate wearable inertial-magnetic tracking system can be used to conduct multi-segment full-body motion analysis when performing common tasks in the manufacturing industry. The easy integration of such sensors with dynamic simulation software can help creating a virtual full-body ergonomic assessment for occupational activities to prevent work-related musculoskeletal injury among workers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A quantitative analysis model of thoracic flexibility for wearable personal protection equipment\n",
            "Authors: Eldar R.\n",
            "Abstract: Human body models of pose and motion are widely used in the interactive design process. Existing models, however, have examined movements of the thoracic spine independent of the ribcage, without specifically examining the influence of motion on specific thoracic areas. Additionally, current models are not widely used by designers or the industry for a variety of reasons. Consequently, the application of postural assessments in the design process may lack crucial data regarding complex yet contextually relevant body motions. To address this, we evaluated the optimal levels of thoracic flexibility for wearable personal protection equipment (WPPE). The ranges of four separate thoracic motions were measured in fifteen healthy males and females subjects using a motion capture system necessitating clusters of 92 reflective markers. A kinematic model for calculating 3D transformation and thoracic displacement over time was developed. A 60 segment thoracic map demonstrated that while ± 20° was sufficient for most frontal and lateral motions, distal to the xiphoid, 45° of flexion was required. For most rearward thoracic motions, ± 15° degrees was sufficient, but for movements involving the thorax distal to the T10 vertebra, 30° of flexion was required. The causal hypothesis for this numerical data was based on existing biomechanical literature. The quantitative analysis is a useful tool for assessing the biomechanics of body motion and supporting the industrial design process of well-fitted WPPE. We anticipate that our quantitative analysis model will be an integral aspect of any future ergonomic design interactive processes.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Cyber-physical postural training system for construction workers\n",
            "Authors: Akanmu A.A.\n",
            "Abstract: Risks of work-related musculoskeletal injuries can be reduced by adequately training construction workers on performing work in safe postures. Traditional training approaches provide limited support for performing work tasks and receiving real-time feedback. This paper describes a cyber-physical postural training environment where workers can practice to perform work with reduced ergonomic risks. The proposed system uses wearable sensors, Vive trackers, machine learning and virtual reality to track body kinematics, and engagement with physical construction resources, and provides feedback via an interactive user interface. The postural training system was developed for training workers engaged in wood frame construction. User study of the effectiveness of the feedback and user interface was conducted. Findings showed that the user interface was perceived as convenient with limited interference with the workspace. The feedback was understandable in learning risks associated with participant's postures. Further research will involve conducting formative workload evaluation of the user interface and developing a reinforcement learning model for adapting the feedback based on the state of learning.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Can human posture and range of motion be measured automatically by smart mobile applications?\n",
            "Authors: Moreira R.\n",
            "Abstract: Human posture and Range of Motion (ROM) are important components of a physical assessment and, from the collected data, it is possible to identify postural deviations such as scoliosis or joint and muscle limitations, hence identifying risks of more serious injuries. Posture assessment and ROM measures are also necessary metrics to monitor the effect of treatments used in the motor rehabilitation of patients, as well as to monitor their clinical progress. These evaluation processes are more frequently performed through visual inspection and manual palpation, which are simple and low cost methods. These methods, however, can be optimized with the use of tools such as photogrammetry and goniometry. Mobile solutions have also been developed to help health professionals to capture more objective data and with less risk of bias. Although there are already several systems proposed for assessing human posture and ROM in the literature, they have not been able to automatically identify and mark Anatomical and Segment Points (ASPs). The hypothesis presented here considers the development of a mobile application for automatic identification of ASPs by using machine learning algorithms and computer vision models associated with technologies embedded in smartphones. From ASPs identification, it will be possible to identify changes in postural alignment and ROM. In this context, our view is that an application derived from the hypothesis will serve as an additional tool to assist in the physical assessment process and, consequently, in the diagnosis of disorders related to postural and movement changes.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Computer vision-based recognition of 3D relationship between construction entities for monitoring struck-by accidents\n",
            "Authors: Yan X.\n",
            "Abstract: Struck-by accidents often cause serious injuries in construction. Monitoring of the struck-by hazards in terms of spatial relationship between a worker and a heavy vehicle is crucial to prevent such accidents. The computer vision-based technique has been put forward for monitoring the struck-by hazards but there exists shortages such as spatial relationship distortion due to two-dimensional (2D) image pixels-based estimation and self-occlusion of heavy vehicles. This study is aimed to address these problems, including the detection of workers and heavy vehicles, three-dimensional (3D) bounding box reconstruction for the detected objects, depth and range estimation in the monocular 2D vision, and 3D spatial relationship recognition. A series of experiments were conducted to evaluate the proposed method. The proposed method is expected to estimate 3D spatial relationship between construction worker and heavy vehicle in a real-time and view-invariant manner, thus enhancing struck-by hazards monitoring at the construction site.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An evaluation of posture recognition based on intelligent rapid entire body assessment system for determining musculoskeletal disorders\n",
            "Authors: Li Z.\n",
            "Abstract: Determining the potential risks of musculoskeletal disorders through working postures in a workplace is expensive and time‐consuming. A novel intelligent rapid entire body assessment (REBA) system based on convolutional pose machines (CPM), entitled the Quick Capture system, was applied to determine the risk levels. The aim of the study was to validate the feasibility and reliability of the CPM‐based REBA system through a simulation experiment. The reliability was calculated from the differences of motion angles between the CPM‐based REBA and a motion capture system. Results show the data collected by the Quick Capture system were consistent with those of the motion capture system; the average of root mean squared error (RMSE) was 4.77 and the average of Spearman’s rho (ρ) correlation coefficient in the different 12 postures was 0.915. For feasibility evaluation, the linear weighted Cohen’s kappa between the REBA score obtained by the Quick Capture system and those from the three experts were used. The result shows good agreement, with an average proportion agreement index (P0) of 0.952 and kappa of 0.738. The Quick Capture system does not only accurately analyze working posture, but also accurately determines risk level of musculoskeletal disorders. This study suggested that the Quick Capture system could be applied for a rapid and real‐time on‐site assessment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A computer vision approach for classifying isometric grip force exertion levels\n",
            "Authors: Asadi H.\n",
            "Abstract: Exposure to high and/or repetitive force exertions can lead to musculoskeletal injuries. However, measuring worker force exertion levels is challenging, and existing techniques can be intrusive, interfere with human–machine interface, and/or limited by subjectivity. In this work, computer vision techniques are developed to detect isometric grip exertions using facial videos and wearable photoplethysmogram. Eighteen participants (19–24 years) performed isometric grip exertions at varying levels of maximum voluntary contraction. Novel features that predict forces were identified and extracted from video and photoplethysmogram data. Two experiments with two (High/Low) and three (0%MVC/50%MVC/100%MVC) labels were performed to classify exertions. The Deep Neural Network classifier performed the best with 96% and 87% accuracy for two- and three-level classifications, respectively. This approach was robust to leave subjects out during cross-validation (86% accuracy when 3-subjects were left out) and robust to noise (i.e. 89% accuracy for correctly classifying talking activities as low force exertions). Practitioner summary: Forceful exertions are contributing factors to musculoskeletal injuries, yet it remains difficult to measure in work environments. This paper presents an approach to estimate force exertion levels, which is less distracting to workers, easier to implement by practitioners, and could potentially be used in a wide variety of workplaces. Abbreviations: MSD: musculoskeletal disorders; ACGIH: American Conference of Governmental Industrial Hygienists; HAL: hand activity level; MVC: maximum voluntary contraction; PPG: photoplethysmogram; DNN: deep neural networks; LOSO: leave-one-subject-out; ROC: receiver operating characteristic; AUC: area under curve.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Mobile applications for assessing human posture: A systematic literature review\n",
            "Authors: Moreira R.\n",
            "Abstract: Smartphones are increasingly incorporated with features such as sensors and high resolution cameras that empower their capabilities, enabling their use for varied activities including human posture assessments. Previous reviews have discussed methods used in postural assessment but none of them focused exclusively on mobile applications. This paper systematically reviews mobile applications proposed for analyzing human posture based on alignment of the body in the sagittal and coronal plane. The main digital libraries were searched, 26 articles published between 2010 and 2020 were selected, and 13 mobile applications were identified, classified and discussed. Results showed that the use of mobile applications to assist with posture assessment have been demonstrated to be reliable, and this can contribute to clinical practice of health professionals, especially the assessment and reassessment phases of treatments, despite some variations when compared to traditional methods. Moreover, in the case of image-based applications, we highlight the advantage that measurements can be taken with the assessor at a certain distance with respect to the patient’s position, which is an important function for assessments performed in pandemic times such as the outbreak of COVID-19.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Analysis of Relationships between Body Load and Training, Work Methods, and Work Rate: Overcoming the Novice Mason's Risk Hump\n",
            "Authors: Ryu J.\n",
            "Abstract: Masons regularly perform physically strenuous and demanding duties that may exceed a safe limit. Such activities can contribute to an early retirement for masons, resulting in a shortage of skilled craft workers. Previous ergonomic studies have observed that workers develop safer and more productive work techniques as they gain experience. This study aims to analyze relationships between body loads, experience, and work methods. Specifically, we expanded a previous pilot study by increasing the number of participants from 21 masons to 66 masons. Participants completed a prebuilt standard concrete masonry unit (CMU) lead wall using 45 CMUs. Motion capture suits were used to capture masons' motions, and a combined biomechanical-productivity analysis was carried out to determine the loads experienced by major body joints. Exploiting the larger dataset, this study assessed how different experience groups load their joints and adjust their work techniques as the work height changes. The results suggested that experienced journeymen adopt similar work techniques distinct from those of less experienced workers. Further, training apprentices to adopt these work methods can help reduce occupational injuries and improve productivity. The results show that the journeymen with more than 20 years of experience adopt safer and more productive work techniques distinct from those of less experienced workers. The present study contributes to the body of knowledge on masons' safety and productivity by providing an in-depth understanding of the linkage between body loads, work experience, techniques, and productivity. Additionally, the findings in this study are expected to have a greater impact when they are adopted to apprentice-training methods and applied to other high musculoskeletal-disorders-risk trades.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic evaluation on the manufacturing shop floor: A review of hardware and software technologies\n",
            "Authors: Mgbemena C.E.\n",
            "Abstract: The high rate of work-related musculoskeletal disorders (WMSDs) among workers on the shop floor has led to the development of various ergonomic evaluation and risk assessment tools by researchers. This paper presents a summary of existing literature reviews of hardware and software technologies developed for effective ergonomic evaluation and correct risk assessment on manufacturing shop floors. Criteria was set for the review and after comprehensive search on 14 databases, 24 studies met the criteria. Old and modern ergonomic evaluation hardware and software technologies for effective evaluation on shop floors are identified. Most literatures cited the digital human models (DHMs), which can be created on many ergonomic evaluation software tools, to be an effective ergonomic evaluation tool. Gaps are identified with the use of DHMs for ergonomic evaluations. Ultimately, this study is a contribution towards identifying adequate ergonomic evaluation and correct risk assessment tools which when implemented on the Shop floor, can lead to improved productivity, enhanced efficiency and reduced cost.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Deep learning-based classification of work-related physical load levels in construction\n",
            "Authors: Yang K.\n",
            "Abstract: Work-related musculoskeletal disorders (WMSDs) are the leading cause of the nonfatal injuries for construction workers, and a worker's overexertion is a major source of such WMSDs. Pushing, pulling, and carrying movements—which are all activities largely associated with physical loads—account for 35% of WMSDs. However, most previous studies have focused on the identification of non-ergonomic postures, and there has been limited effort expended on measuring a worker's exposures to the physical loads caused by materials or tools during construction tasks. With the advantage of using a wearable inertial measurement sensor to monitor a worker's bodily movements, this study investigates the feasibility of identifying various physical loading conditions by analyzing a worker's lower body movements. In the experiment with laboratory settings, workers performed a load carrying task by moving concrete bricks. A bidirectional long short-term memory algorithm is employed to classify physical load levels; this approach achieved 74.6 to 98.6% accuracy and 0.59 to 0.99 F-score in classification. The results demonstrate the feasibility of the proposed approach in identifying the states of physical loads. The findings of this study contribute to the literature on classifying ergonomically at-risk workers and on preventing WMSDs in high physical demand occupations, thereby helping enhance the health and safety of the construction workplace.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Testing the capability of low-cost tools and artificial intelligence techniques to automatically detect operations done by a small-sized manually driven bandsaw\n",
            "Authors: Cheţa M.\n",
            "Abstract: Research Highlights: A low-cost experimental system was developed to enable the production monitoring of small-scale wood processing facilities by the means of sensor-collected data and the implementation of artificial intelligence (AI) techniques, which provided accurate results for the most important work operations. Background and Objectives: The manufacturing of wood-based products by small-scale family-held business is commonly affected by a lack ofmonitoring data that, on the one hand, may prevent the decision-making process and, on the other hand, may lead to less technical efficiency that could result in business failure. Long-term performance of such manufacturing facilities is limited because data collection and analysis require significant resources, thus preventing the approaches that could be pursued for competitivity improvement. Materials and Methods: An external sensor system composed of two dataloggers-a triaxial accelerometer and a sound pressure level meter-was used in combination with a video camera to provide the input signals and meta-documentation for the training and testing of an artificial neural network (ANN) to check the accuracy of automatic classification of the time spent in operations. The study was based on a sample of ca. 90 k observations collected at a frequency of 1 Hz. Results: The approach provided promising results in both the training (ca. 20 k) and testing (ca. 60 k) datasets, with global classification accuracies of ca. 85%. However, the events characterizing the effective sawing, which requires electrical power, were even better recognized, reaching a classification accuracy of 98%. Conclusions: The system requires low-cost devices and freely available software that could enable data feeding on local computers by their direct connection to the devices. As such, it could collect, analyze and plot production data that could be used for maintaining the competitiveness of traditional technologies.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Monocular Vision-Based Framework for Biomechanical Analysis or Ergonomic Posture Assessment in Modular Construction\n",
            "Authors: Chu W.\n",
            "Abstract: Awkward and improper postures and motions reduce productivity and increase project costs in the modular construction industry. Ergonomic assessment is essential to identify, mitigate, and prevent these postures for safety and productivity improvement. Advanced computer vision technologies have made vision-based ergonomic assessment cost-effective in real workplaces. However, their accuracy and robustness still need to be improved. This paper proposes a monocular vision-based framework for conducting a biomechanical analysis or ergonomic posture assessment. The framework consists of four components: Worker visual tracking, two-dimensional (2D) joint and body part detection, 2D joints refinement, and three-dimensional (3D) body model generation and joint angle calculation. The framework has been tested with videos recorded in real construction workshops. The results show that the framework could use the videos from a single camera to estimate a total of 14 joint angles with the average error of 11 and identify workers' awkward postures and motions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Vision-Based Construction Worker Activity Analysis Informed by Body Posture\n",
            "Authors: Roberts D.\n",
            "Abstract: Activity analysis of construction resources is generally performed by manually observing construction operations either in person or through recorded videos. It is thus prone to observer fatigue and bias and is of limited scalability and cost-effectiveness. Automating this procedure obviates these issues and can allow project teams to focus on performance improvement. This paper introduces a novel deep learning- and vision-based activity analysis framework that estimates and tracks two-dimensional (2D) worker pose and outputs per-frame worker activity labels given input red-green-blue (RGB) video footage of a construction worker operation. We used 317 annotated videos of bricklaying and plastering operations to train and validate the proposed method. This method obtained 82.6% mean average precision (mAP) for pose estimation and 72.6% multiple-object tracking accuracy (MOTA), and 81.3% multiple-object tracking precision (MOTP) for pose tracking. Cross-validation activity analysis accuracy of 78.5% was also obtained. We show that worker pose contributes to activity analysis results. This highlights the potential for using vision-based ergonomics assessment methods that rely on pose in conjunction with the proposed method for assessing the ergonomic viability of individual activities.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Validation of a novel wearable solution for measuring L5/S1 load during manual material handling tasks\n",
            "Authors: Conforti I.\n",
            "Abstract: Excessive values of force on L5/S1 joint can cause work-related musculoskeletal disorders, such as low back pain. Currently, the reference solution for estimating such variables is the combination of optoelectronic system and force platform, used for calculating the bottom up inverse dynamics in laboratory settings. Here we propose and validate a novel, completely wearable solution, composed by twelve inertial measurement units and pressure insole sensors. We validate the wearable solution with respect to the output of the reference solution, with data collected simultaneously on a subject performing lifting and releasing tasks with two different loads. The results are encouraging towards the use of the wearable methodology, considering the great impact of such a solution in a real manufacturing scenario.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Extraction of parameters for lane change intention based on driver's gaze transfer characteristics\n",
            "Authors: Peng J.S.\n",
            "Abstract: In naturalistic driving environment, lane change is a necessary, frequent operation, and causes traffic accidents and fatalities. Current lane-change driver assistance system uses turn signals as start time; however, drivers show lane-change intention before turning on the signals. To identify lane-change intention, a driving experiment was designed and conducted, during which eye movement characteristics were recorded from 16 drivers. Time period data from 5 s before changing lanes and 5 s in lane-keeping period were analysed. Saccade speed, eye–head coordination mode, and other parameters were confirmed to be significantly different between two periods. Based on area division and Markov theory, attributes related to gaze transition were obtained, including one- and two-step gaze transition probabilities, main gaze transition paths, and regional gaze probabilities. In summary, all features extracted from eye movement characteristics, gaze transition paths, and gaze areas demonstrate that visual attention is more dispersed during the lane-change intention period. These parameters also lay the foundation for lane-change intention recognition systems and make lane change safer.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A critical review of vision-based occupational health and safety monitoring of construction site workers\n",
            "Authors: Zhang M.\n",
            "Abstract: Globally, the occupational health and safety (OHS) of construction workers has long been a serious concern. To address this issue, there is an urgent need for an efficient means to continuously monitor the construction site to eliminate potential hazards in a timely manner. As robust and automated video and image information extraction and processing tools for construction sites, computer vision techniques have been considered to be effective solutions and been applied for the occupational health and safety monitoring of construction site workers. This paper aims to use bibliometric and content-based analysis methods to review the previous attempts in related fields and present the current research status in this field. The results clarify the major limitations and challenges of the current research from both technical and practical perspectives, in turn suggesting the direction of future research.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Prediction model of the effect of postural interactions on muscular activity and perceived exertion\n",
            "Authors: Hellig T.\n",
            "Abstract: Musculoskeletal disorders are a prevalent disease in many Western countries. While a large number of ergonomic analyses and assessment methods are nowadays available, most current methods that assess exposure calculate overall risk scores of individual body segments without considering interaction effects of exposure variables. Therefore, a study was conducted that aimed at investigating and quantifying interaction effects of trunk inclination and arm lifting on ratings of perceived exertion (RPE) and muscle activity. A multiple regression model to predict musculoskeletal load under consideration of interaction effects was derived. The study revealed that there is a significant interaction effect of trunk inclination and arm lifting. Furthermore, final regression models explained variance in exposure variables in a range of R2 = 0.68 to R2 = 0.147 with a subset of two to three inputs. The predicative equations support the computer-based post-processing of sensor data. Practitioner summary: This article elaborates on the importance of interaction effects of working postures on assessment results of load. In practise, easy to-use-methods for an assessment of working postures are needed. Therefore, a regression model is derived, which facilitates the quantification of work load under consideration of interaction effects. The use of this regression model for the assessment of posture data gathered by range sensors is recommended. Abbreviations: RPE: rating of perceived exertion; MSD: musculoskeletal disorder; OWAS: ovako working posture analysing system; RULA: rapid upper limb assessment; LUBA: postural loading on the upper body assessment; REBA: rapid entire body assessment; OCRA: occupational repetitive action;S D: standard deviation; EMG: surface electromyography; LUT: left upper trapezius pars descendens; RUT: right upper trapezius pars descendens; LLT: left trapezius pars ascendens; RLT: right trapezius pars ascendens; LAD: left anterior deltoideus; RAD: right anterior deltoideus; LES: left erector spinae longissimus; RES: right erector spinae longissimus; SENIAM: surface electroMyoGraphy for the non-invasive assessment of muscles; MVC: maximum voluntary contraction; MANOVA: multivariate analysis of variance; ANOVA: analysis of variance; OLS: ordinary least squares; MANCOVA: multivariate analysis of covariance.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Stressfoot: Uncovering the potential of the foot for acute stress sensing in sitting posture\n",
            "Authors: Elvitigala D.S.\n",
            "Abstract: Stress is a naturally occurring psychological response and identifiable by several body signs. We propose a novel way to discriminate acute stress and relaxation, using movement and posture characteristics of the foot. Based on data collected from 23 participants performing tasks that induced stress and relaxation, we developed several machine learning models to construct the validity of our method. We tested our models in another study with 11 additional participants. The results demonstrated replicability with an overall accuracy of 87%. To also demonstrate external validity, we conducted a field study with 10 participants, performing their usual everyday office tasks over a working day. The results showed substantial robustness. We describe ten significant features in detail to enable an easy replication of our models.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of a Twisted String Actuator-based Exoskeleton for Hip Joint Assistance in Lifting Tasks\n",
            "Authors: Seong H.S.\n",
            "Abstract: This paper presents a study on a compliant cable-driven exoskeleton for hip assistance in lifting tasks that is aimed at preventing low-back pain and injuries in the vocational setting. In the proposed concept, we used twisted string actuator (TSA) to design a light-weight and powerful exoskeleton that benefits from inherent TSA advantages. We have noted that nonlinear nature of twisted strings' transmission ratio (decreasing with twisting) closely matched typical torque-speed requirements for hip assistance during lifting tasks and tried to use this fact in the exoskeleton design and motor selection. Hip-joint torque and speed required to lift a 10-kg load from stoop to stand were calculated, which gave us a baseline that we used to design and manufacture a practical exoskeleton prototype. Preliminary experimental trials demonstrated that the proposed device was capable of generating required torque and speed at the hip joint while weighing under 6 kg, including battery.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Effective inertial sensor quantity and locations on a body for deep learning-based worker's motion recognition\n",
            "Authors: Kim K.\n",
            "Abstract: Construction tasks involve various activities composed of one or more body motions. As construction projects are labor-intensive and heavily rely on manual tasks, understanding the ever-changing behavior and activities is essential to manage construction workers effectively regarding their safety and productivity. While several research efforts have shown promising results in automated motion and activity recognition of the workers using motion sensors, there is still a lack of understanding about how motion sensors' numbers and their locations affect the performance of the recognition, which can contribute to improving the recognition performance and reducing the implementation cost. Moreover, further research is necessary to seek the motion recognition model that accurately identifies various motions using motion sensors attached to the workers' bodies. This study proposes a construction worker's motion recognition model using the Long Short-Term Memory (LSTM) network based on an evaluation of the effectiveness of motion sensors' numbers and locations to maximize motion recognition performance. The evaluation is conducted by generating different datasets containing motion sensor data collected from the sensors located on different body parts. Comparing the performance of five machine learning models trained using the datasets, the desired numbers and locations of motion sensors are identified. The quasi-experimental test with multiple subjects is conducted to validate the findings of the evaluation. Based on the findings, the LSTM network for recognizing construction workers' motions is developed. The LSTM network classifies various motions of the workers that can be utilized as primitive elements for monitoring the workers regarding their safety and productivity.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Sensor-based safety management\n",
            "Authors: Asadzadeh A.\n",
            "Abstract: The construction industry has one of the most hazardous working environments worldwide, which accounts for about 1 in every 5 occupational fatalities. The high rates of workplace injuries, illnesses and fatalities cause irreversible harm to workers and are often the source of delays and additional project costs. Improvements in sensor technologies, wireless communication, the processing power of computers, and advancements in machine learning and computer vision are now enabling the development of sensor-based safety management systems. The rapid growth of Building Information Modelling (BIM) has also created opportunities for improving safety management. While considerable progress has been made to improve construction safety, few studies have focused on the integration of sensor-based systems and BIM. This research, which is motivated by the development of such integrated methods, carries out a systematic review of the relevant literature, summarising recent developments of sensor-based safety management systems and advancements in safety management through BIM. The research gaps are identified and an outline for potential future research is provided. The results of the review reveal the potential of combining sensor-driven systems with BIM for improving safety management in construction.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An overview of reba method applications in the world\n",
            "Authors: Hita-Gutiérrez M.\n",
            "Abstract: The objective of this work is to review literature, worldwide, in which the Rapid Entire Body Assessment (REBA) ergonomic assessment method was applied and count the number of times that REBA was applied together with other methods and subsequent incidence. The database used was the “Web of Science—Core Collection”. Only scientific articles and bibliographic reviews were included, analysing a total of 314 documents and selecting only 91. The use of the REBA method is indicated in terms of knowledge, country, year and journal sectors. It was most used in the knowledge areas of “Manufacturing” (24.18%), “Agriculture, forestry and fishing” (21.98%) and in “Other activities” (19.78%). One of the benefits of REBA is that it evaluates different body parts: upper limbs (arm, forearm and wrist), lower extremities, trunk and neck. It is a useful method to identify the forced postures adopted by workers to thus develop improvement measures if necessary. It is concluded that REBA method use has increased over the last decade, probably due to the digitization of knowledge. It is almost always applied in combination with other methods, and its use can be a positive indicator of company sustainability.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A model for predicting the risk of musculoskeletal disorders among computer professionals\n",
            "Authors: Sasikumar V.\n",
            "Abstract: Objective. This study aimed to develop a model for predicting the risk of musculoskeletal disorders among computer professionals. Materials and methods. A preliminary study with a modified Nordic musculoskeletal questionnaire was conducted to identify the risk in different body parts of the professionals during their work. A discrete postural evaluation of the dynamic postures involved in the work was assessed using rapid upper limb assessment. Postural, physiological and work-related factors were considered as attributes of the model. The model was developed using various machine learning algorithms, and was then tested and validated. Results. The postural factor of the computer professionals was found to be significantly (p < 0.01) correlated with the musculoskeletal disorders. Results of the logistic regression analysis showed that physiological and work-related factors were also significantly (p < 0.05) associated with musculoskeletal disorders. The Random Forest algorithm and Naïve Bayes Classifier predicted the risk of musculoskeletal disorders with the highest accuracy (81.25%). Conclusion. Postural, physiological and work-related factors contribute to the development of musculoskeletal disorders. The Random Forest algorithm or Naïve Bayes Classifier model developed based on these factors could be used to accurately predict the risk of musculoskeletal disorders among computer professionals at any instance of time, during their work.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An inertial data-based upper body posture recognition tool: A machine learning study approach\n",
            "Authors: Cerqueira S.M.\n",
            "Abstract: This study presents the development of an automatic and user-independent human motion recognition tool, using kinematic data from inertial measurement units. Data from 50 heterogeneous individuals were collected, and a benchmark of 4 normalization techniques, 4 dimensionality reduction algorithms and 10 machine-learning classifiers was conducted. The tool with the best performance was achieved using the z-score normalization, the mMRM as dimensionality reduction technique, and a Quadratic SVM classifier. This tool presented an overall accuracy of 94,76% in the recognition of 6 static and 10 transitional postures. This work is relevant for awkward postures identification and can be integrated with established frameworks such as RULA and LUBA for ergonomic risk assessment and workspace redesign.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic adaptation of robotic movements in human-robot collaboration\n",
            "Authors: Van Den Broek M.K.\n",
            "Abstract: Musculoskeletal Disorders (MSDs) are common occupational diseases. An interesting research question is whether collaborative robots actively can minimise the risk of MSDs during collaboration. In this work ergonomic adaptation of robotic movements during human-robot collaboration is explored in a first test case, namely, adjustment of work sureface height. Vision based markerless posture estimation is used as input in combination with ergonomic assessment methods to adapt robotic movements in order to facilitate better ergonomic conditions for the human worker.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Multi-attention deep recurrent neural network for nursing action evaluation using wearable sensor\n",
            "Authors: Zhong Z.\n",
            "Abstract: A nursing action evaluation system that can assess the performance of students practicing patient handling related nursing skills becomes an urgent need for solving the nursing educator shortage problem. Such an evaluation system should be designed with less hand-crafted procedures for its scalability. Additionally, realizing high accuracy of nursing action recognition, especially fine-grained action recognition remains a problem. This reflects in the recognition of the correct and incorrect methods when students perform a nursing action, and low accuracy of that would mislead the nursing students. We propose a multi-attention deep recurrent neural network (MA-DRNN) model for nursing action recognition by directly processing the raw acceleration and rotational speed signals from wearable sensors. Data samples of target nursing actions in a nursing skill called patient transfer were collected to train and compare the models. The experiment results show that the proposed model can reach approximately 96% recognition accuracy for four target fine-grained nursing action classes helped by the attention mechanism on time and layer domains, which outperforms the state-of-the-art models of wearable sensor-based HAR.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: On the OCRA measurement: Automatic computation of the dynamic technical action frequency factor\n",
            "Authors: Taborri J.\n",
            "Abstract: OCRA (OCcupational Repetitive Action) is currently one of the most widespread procedures for assessing biomechanical risks related to upper limb repetitive movements. Frequency factor of the technical actions represents one of the OCRA elements. Actually, the frequency factor computation is based on workcycle video analysis, which is time-consuming and may lead to up to 30% of intra-operator variability. This paper aims at proposing an innovative procedure for the automatic counting of dynamic technical actions on the basis of inertial data. More specifically, a threshold-based algorithm was tested in four industrial case studies, involving a cohort of 20 workers. Nine combinations of the algorithm were tested by varying threshold values related to time and amplitude. The computation of frequency factor showed an average relative error lower than 5.7% in all industrial-based case studies after the appropriate selection of the time and amplitude threshold values. These findings open the possibility to use the threshold-based algorithm proposed here for the automatic computation of OCRA frequency factor, avoiding the time efforts in video analysis.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Measuring biomechanical risk in lifting load tasks through wearable system and machine-learning approach\n",
            "Authors: Conforti I.\n",
            "Abstract: Ergonomics evaluation through measurements of biomechanical parameters in real time has a great potential in reducing non-fatal occupational injuries, such as work-related musculoskeletal disorders. Assuming a correct posture guarantees the avoidance of high stress on the back and on the lower extremities, while an incorrect posture increases spinal stress. Here, we propose a solution for the recognition of postural patterns through wearable sensors and machine-learning algorithms fed with kinematic data. Twenty-six healthy subjects equipped with eight wireless inertial measurement units (IMUs) performed manual material handling tasks, such as lifting and releasing small loads, with two postural patterns: correctly and incorrectly. Measurements of kinematic parameters, such as the range of motion of lower limb and lumbosacral joints, along with the displacement of the trunk with respect to the pelvis, were estimated from IMU measurements through a biomechanical model. Statistical differences were found for all kinematic parameters between the correct and the incorrect postures (p < 0.01). Moreover, with the weight increase of load in the lifting task, changes in hip and trunk kinematics were observed (p < 0.01). To automatically identify the two postures, a supervised machine-learning algorithm, a support vector machine, was trained, and an accuracy of 99.4% (specificity of 100%) was reached by using the measurements of all kinematic parameters as features. Meanwhile, an accuracy of 76.9% (specificity of 76.9%) was reached by using the measurements of kinematic parameters related to the trunk body segment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Motion-Sensing Identification System for Construction Operation\n",
            "Authors: Yang T.Y.\n",
            "Abstract: Productivity assessment helps contractors estimate labor cost and activity duration. Some methods such as work sampling or Data Envelope Analysis can be used to assess productivity. However, they are post-analyzed based on recorded video of construction activities instead of real-time assessment. Their base upon human judgment also limits the feasible sampling rate of the video. This research uses depth cameras to capture joints of human skeleton and builds a system to automatically determine whether a subject's posture is a productive or nonproductive in a real time fashion. When the target activity (e.g., formwork) is known, the system may further categorize the subject's posture into the associated sub-activities (e.g., formwork assembly, formwork nailing). Experiments, which targeted on common construction activities including rebar assembly, formwork assembly, moving materials, reading blueprints, laying bricks, and tiling, were conducted to evaluate the identification accuracy. The results show that accuracies are 92.23%, 80.19%, 90.82%, 90.65%, 62.24%, and 94.40%, respectively.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Spatio-temporal pyramid graph convolutions for human action recognition and postural assessment\n",
            "Authors: Parsa B.\n",
            "Abstract: Recognition of human actions and associated interactions with objects and the environment is an important problem in computer vision due to its potential applications in a variety of domains. Recently, graph convolutional networks that extract features from the skeleton have demonstrated promising performance. In this paper, we propose a novel Spatio-Temporal Pyramid Graph Convolutional Network (ST-PGN) for online action recognition for ergonomics risk assessment that enables the use of features from all levels of the skeleton feature hierarchy. The proposed algorithm outperforms state-of-art action recognition algorithms tested on two public benchmark datasets typically used for postural assessment (TUM and UW-IOM). We also introduce a pipeline to enhance postural assessment methods with online action recognition techniques. Finally, the proposed algorithm is integrated with a traditional ergonomics risk index (REBA) to demonstrate the potential value for assessment of musculoskeletal disorders in occupational safety.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A smart system for preventing people with dementia from falling from the chair\n",
            "Authors: Moshnyaga V.G.\n",
            "Abstract: This paper presents a smart system that automatically analyzes postures of a person in the chair, estimates the risk of falling and warns both the person and his caregiver when the risk of falling is high. Unlike related designs, the system is inexpensive, robust and operates in real-time.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A narrative review on contemporary and emerging uses of inertial sensing in occupational ergonomics\n",
            "Authors: Lim S.\n",
            "Abstract: Accurate, reliable, and cost-effective quantification of real-time biomechanical exposures in occupational settings remains an enduring pursuit in ergonomics. Miniaturized, wireless, body-worn inertial sensors offer opportunities to directly measure vast and personalized kinematics data in both laboratory and applied settings. This review investigated the contemporary and emerging uses of wearable inertial sensing technology in occupational ergonomics research related to biomechanical exposure assessment in physical work. A review and narrative synthesis of 78 peer-reviewed studies was conducted. A conceptual framework was used for scoping and synthesizing the reviewed scientific literature. Review findings help to contextualize contributions of this emerging technology to the broader goals of reducing work-relevant musculoskeletal trauma disorders. The review made evident that despite the growing interest in wearable inertial sensing technologies for ergonomics research, its use in applied settings still lags. The review also identified differences in sensor attachment locations and methods and measures for calibration and validation, and inconsistent criteria for reporting and assessing biomechanical exposures even across studies with similar objectives. Emerging applications include combining inertial sensing with predictive modeling for obtaining cumulative exposure data, and providing real-time feedback about biomechanical work demands. The manuscript concludes with research directions for enabling inertial sensing technologies as a tool for online biomechanical exposure assessment and feedback, which has particular appeal in non-repetitive work settings. Relevance to industry: Despite the growing interest in wearable inertial sensing technologies for ergonomics research, its use in applied settings still lags. This manuscript explores contemporary and emerging uses of body-worn inertial sensing for assessing biomechanical exposures and reducing the risk of work-relevant musculoskeletal disorders.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A comparison of the conventional pig marker method versus a cluster‐based model when recording gait kinematics in trans‐tibial prosthesis users and the implications for future imu gait analysis\n",
            "Authors: Samala M.\n",
            "Abstract: Validation testing is a necessary step for inertial measurement unit (IMU) motion analysis for research and clinical use. Optical tracking systems utilize marker models which must be precise in measurement and mitigate skin artifacts. Prosthesis wearers present challenges to optical tracking marker model choice. Seven participants were recruited and underwent simultaneous motion capture from two marker sets; Plug in Gait (PiG) and the Strathclyde Cluster Model (SCM). Variability of joint kinematics within and between subjects was evaluated. Variability was higher for PiG than SCM for all parameters. The within‐subjects variability as reported by the average standard deviation (SD), was below 5.6° for all rotations of the hip on the prosthesis side for all participants for both methods, with an average of 2.1° for PiG and 2.5° for SCM. Statistically significant differences in joint parameters caused by a change in the protocol were evident in the sagittal plane (p < 0.05) on the amputated side. Trans‐tibial gait analysis was best achieved by use of the SCM. The SCM protocol appeared to provide kinematic measurements with a smaller variability than that of the PiG. Validation studies for prosthesis wearer populations must reconsider the marker protocol for gold standard comparisons with IMUs.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Data-driven Online Learning Engagement Detection via Facial Expression and Mouse Behavior Recognition Technology\n",
            "Authors: Zhang Z.\n",
            "Abstract: Online learning engagement detection is a fundamental problem in educational information technology. Efficient detection of students’ learning situations can provide information to teachers to help them identify students having trouble in real time. To improve the accuracy of learning engagement detection, we have collected two aspects of students’ behavior data: face data (using adaptive weighted Local Gray Code Patterns for facial expression recognition) and mouse interaction. In this article, we propose a novel learning engagement detection algorithm based on the collected data (students’ behavior), which come from the cameras and the mouse in the online learning environment. The cameras were utilized to capture students’ face images, while the mouse movement data were captured simultaneously. In the process of image data labeling, we built two datasets for classifier training and testing. One took the mouse movement data as a reference, while the other did not. We performed experiments on two datasets using several methods and found that the classifier trained by the former dataset had a better performance, and its recognition rate is higher than that of the latter one (94.60% vs. 91.51%).\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Electroencephalographic Workload Indicators During Teleoperation of an Unmanned Aerial Vehicle Shepherding a Swarm of Unmanned Ground Vehicles in Contested Environments\n",
            "Authors: Fernandez Rojas R.\n",
            "Abstract: Background: Although many electroencephalographic (EEG) indicators have been proposed in the literature, it is unclear which of the power bands and various indices are best as indicators of mental workload. Spectral powers (Theta, Alpha, and Beta) and ratios (Beta/(Alpha + Theta), Theta/Alpha, Theta/Beta) were identified in the literature as prominent indicators of cognitive workload. Objective: The aim of the present study is to identify a set of EEG indicators that can be used for the objective assessment of cognitive workload in a multitasking setting and as a foundational step toward a human-autonomy augmented cognition system. Methods: The participants' perceived workload was modulated during a teleoperation task involving an unmanned aerial vehicle (UAV) shepherding a swarm of unmanned ground vehicles (UGVs). Three sources of data were recorded from sixteen participants (n = 16): heart rate (HR), EEG, and subjective indicators of the perceived workload using the Air Traffic Workload Input Technique (ATWIT). Results: The HR data predicted the scores from ATWIT. Nineteen common EEG features offered a discriminatory power of the four workload setups with high classification accuracy (82.23%), exhibiting a higher sensitivity than ATWIT and HR. Conclusion: The identified set of features represents EEG indicators for the objective assessment of cognitive workload across subjects. These common indicators could be used for augmented intelligence in human-autonomy teaming scenarios, and form the basis for our work on designing a closed-loop augmented cognition system for human-swarm teaming.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Adaptability of study desks and chairs based on analysis of sitting posture using OpenPose\n",
            "Authors: Guo Y.\n",
            "Abstract: Using the non⁃contact Kinect motion capture system and two⁃dimensional posture detection open source real⁃ time system (OpenPose), this study collected the data of key body indicators in sitting postures of primary school students, analyzed the specific changes of key indicators in different tasks and periods, and then summarized the in⁃ herent regulations of ergonomics adaptation, so as to provide reliable bases for the later adaptive adjustment of desks and chairs. The results showed that the neck flexion and visual distance were significantly affected by the tasks of writ⁃ ing, reading and using tablet PC (P < 0.05). In the writing task, the mean value of neck flexion became larger and the visual distance was shorter than the other two tasks, and the amplitude probability distribution function (APDF) was significant, which indicated that the neck was the most changeable body part in the writing task. In addition, the neck flexion tended to be increased as time went on in the writing and tablet PC tasks. In the reading and writing tasks, the time percentage of neck flexion exceeded 20° and visual distance were approximate, while in tablet PC task, the value of neck flexion was smaller than the former tasks, and the visual distance was relatively larger. How⁃ ever, the trunk flexion exceeded 20° and with the time increased, the amplitude probability distribution function (AP⁃ DF) was significant, which indicated that the trunk was the most changeable body part in the tablet PC task. The mean value of trunk⁃thigh angle was the largest in reading task, which indicated that the body was relatively relaxed, but the value of neck flexion and visual distance was similar to the task of writing. It was suggested that the study desks should adapt to students to read by erecting books with the angles of 45°-60°, so that it would reduce neck flex⁃ ion and lengthen visual distance. In addition, with the help of intelligent detection technology, according to the sitting posture data real⁃time acquired, the desk system adjusted height of desk in due course to meet the requirements from the writing task to the tablet PC task, which reduced trunk flexion and amplitude variation. For the unhealthy sitting posture, the desk system gave an audio reminder or other ways to help primary school students to maintain a healthy posture via the adaption of a dynamic balance.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of a fuzzy decision support system to deal with uncertainties in working posture analysis using rapid upper limb assessment\n",
            "Authors: Ghosh B.\n",
            "Abstract: In most working sites, a large number of workers suffer from musculoskeletal disorders due to working in several hazardous postures. To reduce this problem and to maintain a rejuvenating environment at the worksite, this study focuses on developing a decision support system (DSS) to resolve uncertainties associated with posture analysis process through rapid upper limb assessment (RULA) by generating a fuzzy expert system. At first, all kinds of uncertainties associated with the input parameters of the RULA method, viz., body joint angles, force/load, etc., are identified and, subsequently, a fuzzy DSS is developed using a fuzzy inference system (FIS) to enrich the analysis process of working postures. In developing a FIS, a multigranular linguistic term set is used to represent the membership functions (MFs) of the input parameters of the proposed system. To develop a rule base of the FIS, Pearson's correlation coefficient is taken into account to find the most suitable operations to aggregate antecedents and consequents. To establish the application potentiality, validity, and reliability of the proposed system, a case study is carried out among the female Sal leaf plate makers, and the scores from the body part discomfort (BPD) scale were used to make a comparison between the proposed system and the existing one.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of a workers' behavior estimation system using sensing data and machine learning\n",
            "Authors: Tanaka R.\n",
            "Abstract: Accurate information on workers' behavior is important for safety and productivity management on construction sites. In recent years, some methods for estimating construction workers' behavior using sensing data have been proposed to collect the data based on scientific evidence. Due to the limitations of previously proposed methods that usually relied on expensive devices such as motion capture systems, the huge amount of investment on the system installation and human resource costs are required. This paper proposes a method for estimating workers' posture with Long Short-Term Memory (LSTM) by using terminals that have already been introduced to construction sites, taking into consideration the operational cost and issues in the previous studies. Moreover, we also propose and evaluate a data augmentation method for utilizing limited training data sets. The experiment results for a reinforcing bar worker indicated that the proposed method could estimate not only the forward-leaning and squatting postures with 79% or more F-measure but also the number of rebar binding points by the acceleration data. Besides, we confirmed that the data augmentation method improved the accuracy of posture estimation by 5%.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The spinalmeter biometrical assessment to improve posture diagnosis in school-age girls: A validation study\n",
            "Authors: Kamelska-Sadowska A.M.\n",
            "Abstract: Introduction: Assessing spinal deformities using an X-ray radiation is the method of choice for posture diagnosis. It is also used for the evaluation of the degree of correction, brace fit, and spinal balance as well as for further management decisions. However, multiple X-ray exposures during control visits could be too burdensome for children. Aim: The aim of this study was to investigate the precision and repeatability of measurement of the variables obtained by a fast, simple postural evaluation in children by the SpinalMeter. Material and methods: The measurements of the angle of trunk rotation (ATR) and SpinalMeter posture assessments were performed 8 to 10 times in a short period of time (6 s). The overall of 300 photos (SpinalMeter) and 1020 measurements (asymmetry, distance between anthropometric points as well as ATR) were obtained from 6 girls (8–15 years old). The validation study comprised of the repeatability, interclass correlation coefficient (Qw) and relative standard deviation (rSD) measurements. Results and discussion: The measurements of the distance between acro-mion–popliteal fossa, acromion–iliac crest, and acromion–posterior superior iliac spine obtained by SpinalMeter were clearly repeatable (Qw > 0.9). The scapular and pelvic asymmetry in standing and sitting positions were highly repeatable and had low rSD (e.g. for scapular asymmetry 5.6%–80.3%; Qw > 0.8). Conclusions: The precise and reliable postural biometrical measurements were performed by SpinalMeter in the case of the distance between anthropo-metric points and asymmetry of pelvis and scapula. These measurements could be useful in the assessment of girl’s posture when visiting the pediatrician.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Change in the coordinates of the center of pressure depending on sitting postures\n",
            "Authors: Epishev V.V.\n",
            "Abstract: Aim. The authors aim to determine the coordinates of the center of pressure in various sitting postures. Materials and methods. The study involved 22 persons (11 males and 11 females) ages from 20 to 50 years. The MBN Stabilo force platform was installed on a chair with a rigid metal frame. Eight tests were conducted in various sitting postures 30 seconds each. The averaged data on three indicators were analyzed: X – center of pressure in the frontal plane; Y – center of pressure in the sagittal plane; Z – body weight. Results. The analysis of the averaged coordinates of the center of pressure in the frontal plane (X axis) when sitting straight indicates its displacement to the right. The center of pressure in the sagittal plane (Y axis) depends on a sitting posture: in 5 sitting postures, the center of pressure was characterized by forward displacement, in 3 sitting postures, the center of pressure was characterized by backward displacement (compared to when sitting straight). When sitting legs under the chairthe maximum values of body weight were recorded (increase by 16.2% compared to when sitting straight), when the body was tilted forward body weight decreased by from 57.8% to 74.8% (compared to when sitting straight). Conclusion. The study showed significant differences in the location of the center of pressure in various sitting postures. The center of pressure in the frontal plane (X axis) when sitting straight could be considered as a criterion for early diagnostics of pelvic and spinal displacement. The center of pressure in the sagittal plane (Y axis) combined with body weight (Z axis) could be used as an indicator of sitting posture.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Classification of Human Posture with RGBD Camera: Is Deep Learning Necessary?\n",
            "Authors: Zhang H.\n",
            "Abstract: We describe an approach to human posture classification using RGBD camera (Kinect V2 sensor) data. We compared deep learning methods for human posture classification versus classical data classification methods. We conducted a user study where participants assumed various postures, including whole body, upper and lower body, as well as body transition motion. Several classical data classification methods, such as support vector machine, random forest, neural network, and Adaboost, were used for posture classification. Results show that the posture classification accuracy for the classical data classification methods is between 75% an 99%. The accuracy of the classical data classification methods is comparable to the accuracy of the long-short-term-memory (LSTM) deep learning method which is between 86% and 99%. Our findings suggest that the use of the classical data classification methods on the RGBD camera data is likely sufficient for posture classification, at least for certain task scenarios without incurring the overhead of deep learning.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Posture recognition method for caregivers during postural change of a patient on a bed using wearable sensors\n",
            "Authors: Kitagawa K.\n",
            "Abstract: Caregivers experience lower back pain due to their awkward postures while handling patients. Therefore, a monitoring system to supervise caregivers’ postures using wearable sensors is being developed. This study proposed a postural recognition method for caregivers during postural change while handling a patient on a bed. The proposed method recognizes foot positions and arm movements by a machine learning algorithm using inertial data on the trunk and foot pressure data obtained from wearable sensors. An experiment was conducted to evaluate whether the proposed method could recognize three foot positions and three arm movements. Participants provided postural change for a simulated patient on a bed (patient: supine to lateral recumbent) under nine conditions, including different combinations of the three foot positions and three arm movements; the experiment was repeated ten times for each condition. Experimental results showed that the proposed method using an artificial neural network with all features obtained from an inertial measurement unit and insole pressure sensors could recognize arm movements and foot positions with an accuracy of approximately 0.75 and 0.97, respectively. These results suggest that the proposed method can be used in a monitoring system tracking a caregiver’s posture.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A low cost motion analysis system based on RGB cameras to support ergonomic risk assessment in real workplaces\n",
            "Authors: Altieri A.\n",
            "Abstract: This paper introduces a motion analysis system based on a network of common RGB cameras, which provides the measurement of various angles considered for postural assessment, in order to facilitate the evaluation of the ergonomic indices commonly used for the determination of risk of musculoskeletal disorders of operators in manufacturing workplaces. To enable the tracking of operator postures during the performed tasks, the system exploits the multi person keypoints detection library “OpenPose”. The proposed system has been validated with a real industrial case study regarding a washing machine assembly line. Results suggest how the proposed system supports ergonomists in risk assessment of musculoskeletal disorders through the OCRA index.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automatic clustering of proper working posture\n",
            "Authors: Ryu J.H.\n",
            "Abstract: Construction workers regularly perform physically strenuous and demanding tasks involving heavy lifting, awkward postures, and forceful exertion. These activities can diminish productivity and threaten worker safety by increasing the risk of work-related musculoskeletal disorders (WMSDs). With advanced sensing technologies and analytical tools, significant efforts have attempted to address WMSDs by identifying and monitoring risk factors in construction. However, an objective definition of proper work techniques has yet to be determined. Previous studies found that more experienced workers adopt safer and more productive work techniques. This study aims to identify the proper working postures that experienced workers develop to increase their safety as well as productivity. Specifically, this study reports on an automated posture clustering technique based on applying a learning algorithm to whole-body kinematic data.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Applying deep incremental learning-based posture recognition model for injury prevention in construction\n",
            "Authors: Zhao J.\n",
            "Abstract: This research investigated the feasibility of applying a Deep Incremental Learning model to achieve a high posture recognition performance with Wearable Sensors (WS). The authors use the recognition of Musculoskeletal Disorder (MSDs) related postures among construction workers as the testbed. This research proposed the Convolutional Long Short-Term Memory (CLN) model under Incremental Learning (IL), where a trained model adapts to new subject' postures to maintain high recognition performance. The model was evaluated on datasets from nine construction workers. Results show: i) CLN model with shallow convolutional layers achieved high recognition accuracy (Macro F1 score) under personalized (0.87) and generalized (0.84) modelling; ii) Generalized CLN model under “Many-to-One” IL strategy can adapt to a new subject and balance the forgetting of learnt subjects; iii) incremental CLN model gave close detection of posture proportion and holding time to ground-truth, which facilitates reliable MSDs risk assessment and further prevention through monitoring injury-related postures.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Work Related Musculoskeletal Disorders in Electrical, Telecommunication and Instrument Mechanics of Armed forces\n",
            "Authors: Roli D.\n",
            "Abstract: Introduction: Modern defence system has a significant role of electrical, electronic and instrument technicians in armed forces. Despite their intensive role, little is known about work-related musculoskeletal disorder in these technicians. Objectives: To investigate the prevalence of the work-related musculoskeletal disorder in defence personnel involved in electrical and electronic maintenance and repairs. Methods: A cross-sectional study was carried out for 3 years, in electrical, telecom and instrument defence technicians (N = 164). Prevalence of work-related musculoskeletal disorder was assessed using the Nordic Musculoskeletal Questionnaire. Effect of age, working hours, work experience, Basal metabolic index and type of job on the prevalence of work-related musculoskeletal disorder was investigated using logistic regression analysis. Results: A total of 119 (72.56%) respondents reported work-related musculoskeletal disorder with 53.04% multiples & 19.51% single work-related musculoskeletal disorder. Simultaneous presence of neck, shoulder and upper back work-related musculoskeletal disorder were observed. Highest rate of work-related musculoskeletal disorder was in neck (44.44%), followed by shoulder (27.16%), ankle/ foot (14.81%), elbow/ forearm (12.96%), low back (11.72%) and wrist/ finger (9.87%). Neck (44%) related work-related musculoskeletal disorder were highest across all job crafts. Work experience (p = 0.012; OR = 0.87; 95% CI - 0.78- 0.97), working hours (p = 0.031; OR= 1.73, 95% CI - 0.58-5.12) smoking (p = 0.00 ; OR = 5.3, 95 % CI = 4.3 - 8.48) and job crafts like electrician (p = 0.434; OR = 1.89, 95% CI = 1.08-3.31) and telecom mechanics (p = 0.026; OR = 1.26, 95% CI =0.74 - 2.15) were significantly associated as risk factors of work-related musculoskeletal disorder. Conclusion: High prevalence of work-related musculoskeletal disorder was observed in electrical, telecommunication & instrument mechanics, with higher multiple work-related musculoskeletal disorder. Working hours, work experience, job craft and smoking were highly associated with a work-related musculoskeletal disorder. We suggest suitable ergonomic intervention and awareness program along with smoking control drive to reduce the risk of work-related musculoskeletal disorder.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Computer-aided teaching software of three-dimensional model of sports movement based on kinect depth data\n",
            "Authors: Li F.\n",
            "Abstract: This paper is based on Kinect's three-dimensional model of sports movement computer-aided teaching software. The framework of this system mainly includes three parts: input, auxiliary sports training system and output. Through input, calculation, comparison and other methods, it provides users with the functions of motion posture analysis, so as to realize the human motion analysis based on computer vision. In the input part of the system, the image sequences of athletes and coaches are input into the auxiliary sports training system through Kinect image acquisition. The auxiliary sports training system first detects the input image sequence and constructs the contour map of human body, then calculates the joint angle track of athletes and coaches when they move their limbs according to the corresponding algorithm, and finally compares the calculated results and calculates the similarity.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Deep-Learning Based Worker’s Pose Estimation\n",
            "Authors: Paudel P.\n",
            "Abstract: Work in a factory is physically demanding. It requires workers to perform tasks in different awkward positions. Thus, long work shifts might have prolonged effects on workers’ physical health. To minimize the risks, we introduce an automatic workers’ pose estimation system, which will calculate a worker’s body angle and indicate which angles are safe or not safe for performing tasks in various work places. By combining CMU OpenPose with body assessment tools, such as Rapid Entire Body Assessment (REBA) and Rapid Upper Limb Assessment (RULA), the proposed system automatically determines a worker’s risk pose. This method, intended to replace a manual analysis of work posture, will help build safer environments for workers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: High Fidelity and Objectivity in Balance Assessment—A Comparative Study of the 6-Degree Motion Tracking for Body Balance Assessment to the Conventional Paper Test\n",
            "Authors: Louw A.\n",
            "Abstract: Body balance is an essential capability for an individual to perform functional activities. There are various performance-based balance measures available to occupational therapists. However, conventional balance measures are limited due to subjectivity. There is a prominent need for a more objective and accurate assessment. NIMBLE, using motion sensing and tracking system was developed for a more objective and accurate measure of body movement with high-resolution recording. A pilot study was conducted in 20 participants for functional sitting balance measures by using both paper-based assessment and the NIMBLE. Results showed substantial discrepancies when the NIMBLE was able to detect balance deficits when the paper-based measures failed. The NIMBLE system can accurately capture the extraction of joint centers and segment orientation, providing the ability to calculate joint kinematics and spatiotemporal aspects of the movement. With this low cost and friendly interface, it has great potential to be widely used in healthcare practices.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: New design and optimization procedure of a 2-dof articulating mechanism for a laparoscopic surgical instrument\n",
            "Authors: Sancibrian R.\n",
            "Abstract: In Minimally Invasive Surgery (MIS) surgeons operate through small incisions in the body of the patient and due to the lack of the degrees of freedom their capability to manipulate the organs is limited. Thus, surgeons are forced to adopt awkward postures and this may lead to musculoskeletal injuries. This paper presents a new articulated mechanism designed for application in MIS providing an additional degree of freedom in the instrument. The new degree of freedom makes possible the rotation of the end-effector from 0° to 90° and enhances the dexterity of the tool. In this way, the capability to reach the organs is improved and the surgeon reduces the forced motion of hand, wrist and arm. The paper also presents the design process including the synthesis procedure with 2-dof linkage, which is an original contribution of this work. A prototype of the tool is shown at the end of the paper.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Working tool redesign to reduce ergonomic risk of salt evaporation field workers based on RULA and REBA assessments using esMOCA Instrument\n",
            "Authors: Arendra A.\n",
            "Abstract: What are the ergonomic risks of Indonesian salt evaporation field workers especially in Madura? This problem has not been much noticed, though salt production from Madura is the largest contributor to national salt production. This study aims to assess the level of ergonomic risk of salt evaporation field workers in Madura. Conduct ergonomic risk analysis and reduce the level of ergonomic risk through redesigning work tools with the REBA and RULA approaches. REBA and RULA assessments are conducted with esMOCA instrument application. This research shows that five activities of salt evaporation field workers pose a high ergonomic risk with a REBA and RULA score above 6. These five activities are, chopping salt deposits on salt field, scraping salt deposits on salt field, collecting and pile up salt deposits, picking up salt to the carrying basket, and packing salt into sack. One of these five activities, picking up salt activity poses the highest ergonomic risk with REBA score 11. Efforts undertaken to reduce risk were made by replacing shovel tool with pan hoe tool, REBA score dropped to 5.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Real-time sitting behavior tracking and analysis for rectification of sitting habits by strain sensor-based flexible data bands\n",
            "Authors: Zhang Y.\n",
            "Abstract: From human-machine interfaces to human-computer/robot interaction, the prevailing pattern has gradually become one of people remaining in a sitting posture while working. However, unhealthy sitting behavior seriously affects human health. This paper presents a novel tracking and analysis method of real-time sitting behavior. It is designed using a series of flexible wearable data bands, based on flexible stretchable sensors and pressure sensors (PSNRs). A flexible PSNR is fabricated using composites of carbon black, carbon nanotubes and silicon rubber, by a mixed solution method; it possesses a good property of pressure perception, for tracking sitting behavior. The sensors are accurately attached to human joints for accurate measurement of joint movement at the shoulders, elbows, wrists, knees, and waist. In this work, a new idea of real-time sitting behavior recognition is introduced and developed, based on a radial basis function neural network. Dynamic time warping is used to select candidates for dynamic sitting behavior and also to recognize postures by comparing the observed records with a series of pre-recorded reference data patterns. The solution deals simultaneously with real-time sitting behaviors as well as with multiple joints within the area of interest, to monitor the health level of the sitting behavior and to remind humans of sitting habits. The experimental results of the real-time sitting behavior tracking and analysis verify the effectiveness of the proposed methods. Additionally, undesirable sitting behaviors were gradually rectified and the sitting habit health levels of the participants were gradually increased.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A reach motion generation algorithm based on posture memories\n",
            "Authors: Yoo T.\n",
            "Abstract: BACKGROUND: Most existing models/algorithms for simulating goal-directed human motions were designed to generate a single 'realistic' motion for a given input scenario. OBJECTIVE: This study presents a novel reach motion generation algorithm utilizing multiple posture memories. The algorithm aims to compute and visualize a set of human reach motions that approximates the full range of physically and physiologically feasible human motions for a given input scenario. METHODS: The algorithm utilizes posture memories constructed specifically for an individual worker using a probabilistic posture generation and registration process. The posture memories relate a hand position to the set of postures that place the individual's hand in its vicinity. When given an input scenario, the algorithm first generates different hand paths connecting the starting and ending hand positions specified in the scenario. Then, for each hand path, the algorithm produces different 'feasible' motions by selecting and connecting multiple postures stored in the posture memories; the postures corresponding to the hand positions along the hand path are utilized. CONCLUSIONS: The proposed algorithm helps understand the impacts of workplace design on the range of feasible human motion behaviors, and, thereby, contributes to the computer-aided ergonomics design of work tasks and workplaces.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Wearables for integrative performance and tactic analyses: Opportunities, challenges, and future directions\n",
            "Authors: Lutz J.\n",
            "Abstract: Micro-electromechanical systems (MEMS) have reduced drastically in size, cost, and power consumption, while improving accuracy. The combination of different sensor technologies is considered a promising step in the monitoring of athletes. Those “wearables” enable the capturing of relevant physiological and tactical information in individual and team sports and thus replacing subjective, time-consuming and qualitative methods with objective, quantitative ones. Prior studies mainly comprised sports categories such as: targeting sports, batting and fielding games as well as net and wall games, focusing on the detection of individual, non-locomotive movements. The increasing capabilities of wearables allow for more complex and integrative analysis expanding research into the last category: invasion sports. Such holistic approaches allow the derivation of metrics, estimation of physical conditions and the analysis of team strategic behavior, accompanied by integrative knowledge gains in technical, tactical, physical, and mental aspects of a sport. However, prior and current researchers find the precise measurement of the actual movement within highly dynamic and non-linear movement difficult. Thus, the present article showcases an overview of the environments in which the wearables are employed. It elaborates their use in individual as well as team-related performance analyses with a special focus on reliability and validity, challenges, and future directions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Internet of things, digital biomarker, and artificial intelligence in spine: Current and future perspectives\n",
            "Authors: Nam K.H.\n",
            "Abstract: Recent interest in medical artificial intelligence (AI) has increased with onset of the fourth industrial revolution. Real-time monitoring of patients is an important research area of medical AI. The medical AI is very closely related to the Internet of Things (IoT), a core element of the fourth industrial revolution. Attempts to diagnose and treat patients using IoT have been already applied to patients with chronic disease such as hypertension and arrhythmia. However, in the spine, research on IoT and digital biomarkers are still in the early stages. The digital biomarker obtained by IoT devices is objective and could represent real-time, real-world, and abundant data. Based on its characteristics, IoT and digital biomarkers can also be useful in the spine. Currently, research on real-time monitoring of physical activity or spinal posture is ongoing. Therefore, the authors introduce the basic concepts of IoT and digital biomarkers, their relationship to AI, and recent trends. Current and future perspectives of IoT and digital biomarker in spine are also discussed. In the future, it is expected that IoT, digital biomarkers, and AI will lead to a paradigm shift in the diagnosis and treatment of spinal diseases.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Learning-Based Hand Motion Capture and Understanding in Assembly Process\n",
            "Authors: Liu L.\n",
            "Abstract: Manual assembly is still an essential part in modern manufacturing. Understanding the actual state of the assembly process can not only improve quality control of products, but also collect comprehensive data for production planning and proficiency assessments. Addressing the rising complexity led by the uncertainty in manual assembly, this paper presents an efficient approach to automatically capture and analyze hand operations in the assembly process. In this paper, a detection-based tracking method is introduced to capture trajectories of hand movement from the camera installed in each workstation. Then, the actions in hand trajectories are identified with a novel temporal action localization model. The experimental results have proved that our method reached the application level with high accuracy and a low computational cost. The proposed system is lightweight enough to be quickly set up on an embedded computing device for real-time online inference and on a cloud server for offline analysis as well.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic design visualization mapping- developing an assistive model for design activities\n",
            "Authors: Eldar R.\n",
            "Abstract: Ergonomic models and techniques are a fundamental issue in the design of comfortable and safe products and spaces. User studies, related to visualization tools are current issues in the ergonomics and design visualization literature. But researchers have begun to discover that user study is rarely straightforward, especially when drawing visualization data from interdisciplinary sources. The availability of a plethora of visualization techniques can make it difficult to determine the most appropriate technique to convey maximum possible understanding. The RT-MHV (“Real-time”– “Motion history volumes”) 3D computerized assessment model, developed by the authors, demonstrates a local risk evaluation of work-related musculoskeletal disorders (WMSDs), based on real-time and on motion history volumes. With the model, the visual display of the WMSD risk level for each body segment is defined by color-coding at points surrounding an avatar's segment, representing an actual user. The values associated with areas with an increased risk of WMSDs can be identified and iterated quickly, so as to determine the “optimal posture”. Designers can share this knowledge by recording the user's postural interactions, defined through the mapping of geometric comfort data and WMSD risk level categories. The challenge in the development process was to overcome existing “gaps” between ergonomics data and designer requirements. Further research on the RT-MHV model is recommended, principally for developing stand-alone CAD software. An aggregated statistical information database and complete body joints visualizations will be computerized in due course. 2D tabulation and statistical information relating to body joints will be made available on demand.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A scientometric analysis and critical review of computer vision applications for construction\n",
            "Authors: Martinez P.\n",
            "Abstract: Practical interest in ‘computer vision’ has risen remarkably over the last 20 years, transforming the current state of construction-related research and attracting the worldwide attention of scholars and practitioners. This study conducts a scientometric review of the global research published between 1999 and 2019 on computer vision applications for construction, through co-author, co-citation, keyword and clustering analysis. A total of 1158 journals and conference proceedings from Scopus database were analyzed. Trends within the field are identified, as are the dominant sub-fields and their interconnections, as well as citation patterns, key publications, key research institutions, key researchers, and key journals, along with the extent to which these interact with each other in research networks. The provided results were analyzed to identify the deficiencies in current research and propose future trends. Among these is a bias in the research literature towards traditional on-site construction and a concerning gap of off-site construction research, as well as a lack of inter-relationships and collaboration between researched areas, the researchers themselves, and/or the research institutions. In the near future, computer vision will play a key role in the future development of smart construction and improvement of quality in construction projects. This study hopes to bring awareness to the industry, the journal editors, and the researchers of the need for a deeper exchange of ideas in any future research efforts.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Wearable Sensing Technology Applications in Construction Safety and Health\n",
            "Authors: Ahn C.R.\n",
            "Abstract: The advent of wearable sensing technologies has produced unprecedented opportunities for the near real-time collection and analysis of workers' safety and health data. To encourage the proactive safety management these opportunities present, extensive research efforts have explored using various wearable sensing technologies - including motion sensors (e.g., inertial measurement units) and physiological sensors (e.g., heart-rate sensors, electrodermal-activity sensors, skin-temperature sensors, eye trackers, and brainwave monitors) - to detect potential safety hazards and to continuously monitor a worker's health on a construction jobsite. However, these efforts tend to be piecemeal or fragmented, which presents a challenge for both the practitioners and the researchers who wish to fully understand the current developments in this area. In this context, this paper provides a critical review of the state of the art of wearable applications in construction safety and health. The review first identifies five general applications within the literature: preventing musculoskeletal disorders, preventing falls, assessing physical workload and fatigue, evaluating hazard-recognition abilities, and monitoring workers' mental status. Second, this study identifies the challenges impeding further development and deployment of wearable applications, specifically, signal artifacts and noise in wearable-sensors' field measurements, variable standards for personal safety and health risks in construction, users' resistance to technology adoption, and uncertainty regarding the return on investment. Lastly, this paper recommends future research opportunities for advancing the field, especially in terms of conducting sensor fusion for wearable applications, developing a business case, and engaging wearables in risk assessment and post-injury compensability assessment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Low back pain and its relationship with sitting behaviour among sedentary office workers\n",
            "Authors: Bontrup C.\n",
            "Abstract: The relationships between sedentary lifestyle, sitting behaviour, and low back pain (LBP) remain controversial. In this study, we investigated the relationship between back pain and occupational sitting habits in 64 call-centre employees. A textile pressure mat was used to evaluate and parameterise sitting behaviour over a total of 400 h, while pain questionnaires evaluated acute and chronic LBP. Seventy-five percent of the participants reported some level of either chronic or acute back pain. Individuals with chronic LBP demonstrated a possible trend (t-test not significant) towards more static sitting behaviour compared to their pain-free counterparts. Furthermore, a greater association was found between sitting behaviour and chronic LBP than for acute pain/disability, which is plausibly due to a greater awareness of pain-free sitting positions in individuals with chronic pain compared to those affected by acute pain.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An ergonomic evaluation method using a mobile depth sensor and pose estimation\n",
            "Authors: De Freitas P.V.A.\n",
            "Abstract: An ergonomic evaluation is an observation of a person in order to identify musculoskeletal disorders (WMSDs) caused by prolonged or repeated harmful poses that a person adopts during work tasks. Nowadays, an ergonomist or other health professional perform such evaluations based on a set of posture rules and checklists, which can be subjective and thus lead to erroneous risk classifications. Moreover, this professional usually perform such evaluation in the patient work environment. In order to make those evaluations more objective and concise we propose a evaluation method using a mobile depth sensor. Different from other methods based in fixed depth sensors (e.g. Kinect), our method enable professionals easily perform it in the patient work environment. More precisely, we present an experiment that uses a smartphone from Google’s Tango project and the Ovako Working Posture Analysing System (OWAS) method. To evaluate our approach, we also perform the ergonomic assessment using the Kinect sensor, a device that has a good reliability in the automated ergonomic evaluation. Both evaluations involved a set of 34 poses performed by 3 volunteers and annotated by an ergonomist. The Kinect has achieved accuracy of 57,08% on torso classification, 58,33% for arms and 25,00% for legs positions. While the approach using the mobile depth sensor has achieved 35,41% on torso classification, 93,05% for arms and 66,23% for legs positions on the same set of poses. Although the small sample, the achieved results may indicate that our mobile depth sensor approach can be as viable as methods based fixed depth sensor.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Current Low-Cost Video-Based Motion Analysis Options for Clinical Rehabilitation: A Systematic Review\n",
            "Authors: Parks M.\n",
            "Abstract: Background: Physical therapists, as clinical human movement experts, must qualitatively evaluate patients' functional and biomechanical impairments. There are now low-cost 2- and 3-dimensional video measurement systems that can be used to increase the precision and reliability of these qualitative clinical assessments. Purpose: The purpose of this study was to systematically review current low-cost video-based methods for motion analysis compared with gold-standard 3-dimensional biomechanical methods. Data Sources: Electronic searches were conducted until January 2018 within the following databases: MEDLINE via PubMed, Cumulative Index to Nursing and Allied Health Literature (CINAHL), Cochrane, Scopus, and the Institute of Electrical and Electronics Engineers. Study Selection: Studies designed to evaluate criterion-referenced validity and/or reliability of video-based motion analysis technologies within the last 20 years were included. English-language articles dealing with human rehabilitation were considered. Data Extraction: Data extraction was independently completed by 3 reviewers, and methodological quality was assessed using the 2018 Consensus-Based Standards for the Selection of Health Measurement Instruments checklist. Articles were organized for analysis on the basis of type of motion analyzed and category of each low-cost technology used. Data Synthesis: With 20 articles meeting selection criteria, 10 low-cost motion analysis platforms were presented, each examining different functional movement-dependent variables. Overall article quality was \"low\" or \"very low\" on the basis of Consensus-Based Standards for the Selection of Health Measurement Instruments scoring. Correlations between low-cost and 3-dimensional gold standard systems ranged widely from \"poor\" agreement (r = 0.025) to \"strong\" agreement (r = 0.992). Spatiotemporal gait parameters consistently outperformed planar joint angle data. Reliability was better measured than concurrent validity. A summary table was developed to assist clinicians in choosing which motions could potentially be measured accurately by each low-cost platform on the basis of current findings. Limitations: Databases available to researchers were more clinical/medical in nature, and this review was written from that clinically based perspective. Lack of standardized protocols and methodology within included studies was common, making generalizability difficult. Conclusions: Research attempting to validate newer low-cost movement analysis systems is limited in quality. Measurement of only certain variables should be considered when these tools are used. Further research is warranted, because these devices still have potential clinical utility for supplementing qualitative movement assessment with objective outcome measures.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: SSDPose: A single shot deep pose estimation and analysis\n",
            "Authors: Abobakr A.\n",
            "Abstract: Human posture estimation is a fundamental challenge in computer vision research. This is a task that has received substantial interest due to the importance of evaluating the human performance in several disciplines. The ultimate goal for the vision-based pose estimation task is the markerless accurate prediction of necessary postural information. This paper proposes a single shot deep human posture detection and estimation network. The proposed SSDPose architecture increments standard object detection networks to feature posture estimation. SSDPose is an end-to-end trainable model that detects and estimates the body posture from a single image. Further, our network has been trained to predict joint angles which are essential information for several domains such as biomechanic and ergonomic posture analysis. The reference joint angles have been generated using motion capture sequences and a novel inverse kinematics method. Experimental results demonstrate that SSDPose effectively detects and estimates the posture by achieving person mean average precision (mAP) of 98.2%, an average joint angles MAE of 3. 16 pm 1.23 deg and an RMSE of 4. 22 pm 1.73 deg at up to 30 FPS.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: SSIMLayer: Towards robust deep representation learning via nonlinear structural similarity\n",
            "Authors: Abobakr A.\n",
            "Abstract: Adversarial examples form a major threat to incorporating machine learning (ML) models in critical applications. The existence and generalisation of these attacks have been attributed to the linear nature of ML models, deep neural network models in particular, in the high dimensional space. This paper presents a new nonlinear computational layer to the deep convolutional neural network architectures. This layer performs a set of comprehensive convolution operations that mimics the overall function of the human visual system (HVS) via focusing on learning structural information. The core of its computations is evaluating the components of the structural similarity metric (SSIM) in a setting that allows the kernels to learn to match structural information. The proposed SSIMLayer is inherently nonlinear. Experiments conducted on CIFAR-10 benchmark demonstrate that the SSIMLayer provides high learning capacity and shows more robustness against adversarial attacks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Proactive mental fatigue detection of traffic control operators using bagged trees and gaze-bin analysis\n",
            "Authors: Li F.\n",
            "Abstract: Most of existing eye movement-based fatigue detectors utilize statistical analysis of fixations, saccades, and blinks as inputs. Nevertheless, these parameters require long recording time and heavily depend on eye trackers. In an effort to facilitate proactive detection of mental fatigue, we introduced a complemental fatigue indicator, named gaze-bin analysis, which simply presents the eye-tracking data with histograms. A method which engaged the gaze-bin analysis as inputs of semisupervised bagged trees was developed. A case study in a vessel traffic service center demonstrated that this approach can alleviate the burden of manual labeling as well as improve the performance of fatigue detection model. In addition, the results show that the approach can achieve an excellent accuracy of 89%, which outperformed other methods. In general, this study provided a complemental indicator for detecting mental fatigue as well as enabled the application of a low sampling rate eye tracker in the traffic control center.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Recognizing people's identity in construction sites with computer vision: A spatial and temporal attention pooling network\n",
            "Authors: Wei R.\n",
            "Abstract: Several prototype vision-based approaches have been developed to capture and recognize unsafe behavior in construction automatically. Vision-based approaches have been difficult to use due to their inability to identify individuals who commit unsafe acts when captured using digital images/video. To address this problem, we applied a novel deep learning approach that utilizes a Spatial and Temporal Attention Pooling Network to remove redundant information contained in a video to enable a person's identity to be automatically determined. The deep learning approach we have adopted focuses on: (1) extracting spatial feature maps using the spatial attention network; (2) extracting temporal information using the temporal attention networks; and (3) recognizing a person's identity by computing the distance between features. To validate the feasibility and effectiveness of the adopted deep learning approach, we created a database of videos that contained people performing their work on construction sites, conducted an experiment, and then performed k-fold cross-validation. The results demonstrated that the approach could accurately identify a person's identity from videos captured from construction sites. We suggest that our computer-vision approach can potentially be used by site managers to automatically recognize those individuals that engage in unsafe behavior and therefore be used to provide instantaneous feedback about their actions and possible consequences.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: RGB-D ergonomic assessment system of adopted working postures\n",
            "Authors: Abobakr A.\n",
            "Abstract: Ensuring a healthier working environment is of utmost importance for companies and global health organizations. In manufacturing plants, the ergonomic assessment of adopted working postures is indispensable to avoid risk factors of work-related musculoskeletal disorders. This process receives high research interest and requires extracting plausible postural information as a preliminary step. This paper presents a semi-automated end-to-end ergonomic assessment system of adopted working postures. The proposed system analyzes the human posture holistically, does not rely on any attached markers, uses low cost depth technologies and leverages the state-of-the-art deep learning techniques. In particular, we train a deep convolutional neural network to analyze the articulated posture and predict body joint angles from a single depth image. The proposed method relies on learning from synthetic training images to allow simulating several physical tasks, different body shapes and rendering parameters and obtaining a highly generalizable model. The corresponding ground truth joint angles have been generated using a novel inverse kinematics modeling stage. We validated the proposed system in real environments and achieved a joint angle mean absolute error (MAE)of 3.19±1.57∘ and a rapid upper limb assessment (RULA)grand score prediction accuracy of 89% with Kappa index of 0.71 which means substantial agreement with reference scores. This work facilities evaluating several ergonomic assessment metrics as it provides direct access to necessary postural information overcoming the need for computationally expensive post-processing operations.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Estimating Worker-Centric 3D Spatial Crowdedness for Construction Safety Management Using a Single 2D Camera\n",
            "Authors: Yan X.\n",
            "Abstract: As a major risk factor that leads to struck-by accidents, crowdedness indicates the number of workers within the range of a targeted worker (this range varies according to the construction site). High crowdedness can result in dangerous working conditions, negative workers' behaviors, lack of concern for safety climate, and productivity loss due to saturated and insufficient working areas where workers can perform. An automatic computer vision-based technique could be a novel solution for crowdedness monitoring for proactive safety management. Non-intrusiveness and applicability in a complex outdoor environment are critical considerations for device selection on construction sites. Accordingly, a red, green, and blue (RGB) camera is selected to detect worker-centric crowdedness. This device is less intrusive for workers than wearable sensors and is also widely applied in outdoor construction sites considering complex working areas and various light conditions. Previous RGB camera-based methods for crowdedness detection simplify the proximity estimation process by assuming that the construction site is a two-dimensional (2D) planar surface. These methods use image pixels for proximity calculation. Such simplification can cause a distortion in three-dimensional (3D) spatial proximity due to 2D projection of 3D entities. Moreover, previous methods suffer from lack of reproducibility due to the view variance of a 2D camera. To address these problems, a 3D spatial crowdedness estimation method is developed by generating a 3D space for proximity and crowdedness calculation from 2D video frames. This method has been validated in laboratory and field tests. Results indicate that the proposed method enables the estimation of 3D spatial proximity between two workers within an error of 0.45 m in a real-time and view-invariant manner from a 2D video. The proposed method is expected to enable managers to accurately monitor crowdedness among workers for proactive construction safety management.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Sensing and warning-based technology applications to improve occupational health and safety in the construction industry: A literature review\n",
            "Authors: Antwi-Afari M.F.\n",
            "Abstract: Purpose: Sensing- and warning-based technologies are widely used in the construction industry for occupational health and safety (OHS) monitoring and management. A comprehensive understanding of the different types and specific research topics related to the application of sensing- and warning-based technologies is essential to improve OHS in the construction industry. The purpose of this paper is to examine the current trends, different types and research topics related to the applications of sensing- and warning-based technology for improving OHS through the analysis of articles published between 1996 and 2017 (years inclusive). Design/methodology/approach: A standardized three-step screening and data extraction method was used. A total of 87 articles met the inclusion criteria. Findings: The annual publication trends and relative contributions of individual journals were discussed. Additionally, this review discusses the current trends of different types of sensing- and warning-based technology applications for improving OHS in the industry, six relevant research topics, four major research gaps and future research directions. Originality/value: Overall, this review may serve as a spur for researchers and practitioners to extend sensing- and warning-based technology applications to improve OHS in the construction industry.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Design of wireless smart chair system for people with cognitive deficiency\n",
            "Authors: Moshnyaga V.\n",
            "Abstract: This article describes a sensor-based wireless system which monitors sitting postures of a person with cognitive impairment, assesses risks and alarms both the person and his caregiver if the risk of falling is high. Unlike existing smart chairs, the proposed system identifies postures that might cause a person to fall from chair by using minimal number of sensors and a simple posture classification algorithm. Experimental evaluation shows that the system operates in real-time, is robust yet inexpensive.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Human tracking from single RGB-D camera using online learning\n",
            "Authors: Xiao Y.\n",
            "Abstract: Human detection and tracking is an essential component in several robotics applications, especially in indoor built environments where humans and robots are expected to coexist or collaborate. Due to their low cost and capability to capture both color and depth data, RGB-D cameras have shown significant promise in human detection and tracking for robotic applications. In this paper, a new human tracking method is proposed to detect and track a specific individual from a single RGB-D sensor using online learning classifiers with no ground plane assumption. Given a previous target human position, a candidate sampling method is designed to find potential positive samples while negative samples are obtained by a random sampling process. The kernelized Support Vector Machine (SVM) is employed as the online classifier to recognize the target human and updated using both the positive and negative examples. The experimental results on six RGB-D videos of a public dataset demonstrate that the proposed method achieves higher success rates compared to a 2D tracker and a 3D human detection method at a frame rate of 3.8 fps, and is capable of efficiently retrieving the target human following intermittent occlusion.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A CNN-based 3D patch registration approach for integrating sequential models in support of progress monitoring\n",
            "Authors: Lei L.\n",
            "Abstract: Significant advancements in three-dimensional (3D) imaging technologies have enabled the ability to effectively monitor and manage the progress of works in construction. Traditionally, 3D point clouds have been used in conjunction with building information models to visualize the progress of works. The discrepancies between ‘as-planned’ and ‘actual’ models are unable to be automatically identified using the existing approaches due the absence of an effective registration algorithm. To ensure the registration accuracy of multi-scanned point clouds, an automated method based on a data-driven Convolutional Neural Network (CNN) deep learning algorithm is proposed. In this instance, 3D Point cloud patches are aligned with spatial datasets that are scanned from different locations using range cameras. The registration results are used to automatically detect spatial changes when compared with different point clouds. The quantified changes are utilized to determine the percentage of work that has been completed at fixed intervals. The developed registration approach is tested and validated using a series of experiments. It is demonstrated that discrepancies between ‘as-planned’ and ‘actual’ models can be identified with a higher level of accuracy, which can enable the baseline for monitoring construction to be undertaken in real-time.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Impact assessment of reinforced learning methods on construction workers' fall risk behavior using virtual reality\n",
            "Authors: Shi Y.\n",
            "Abstract: Given the nature of construction activities, construction workers usually work in a collaborative way. Thus, interpersonal influences among workers play a crucial role in forming and affecting construction workers' safety behaviors. The social learning literature indicates that interpersonal learning occurs in two opposing ways – positive reinforcement by demonstrating preferred behaviors, and negative reinforcement by demonstrating negative consequences of inappropriate behaviors. Amid theoretical disagreements in the social learning literature, it remains unclear in the construction safety literature how the two reinforced learning methods affect construction workers in safety training. To fill the gap, a human-subject experiment (n = 126)was conducted to investigate people's social learning behaviors in a hazardous construction situation – walking between two high-rise buildings. The experiment utilizes a multi-user Virtual Reality (VR)system with a motion tracking feature. Participants were randomly assigned to one of three groups: control group (no instruction was given), not-falling group (participants observed an avatar demonstrating appropriate walking behaviors), and falling group (participants watched an avatar quickly walking across a plank and falling off). Indicators, including walking time on the plank, walking speed, and gaze movement, were recorded and analyzed to quantify the effects of the two reinforced learning methods. The results indicate that demonstrating information with positive consequences (not-falling group)encourages people to follow the demonstration and maintain normal walking in a hazardous situation. Showing information with negative consequences (falling group)induced participants to walk faster and more irregularly, which further led to more mistakes and unsafe behaviors. This study demonstrates the effectiveness of using VR in safety studies and provides recommendations for better safety training programs.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Real-time locating systems and safety in construction sites: A literature review\n",
            "Authors: Soltanmohammadlou N.\n",
            "Abstract: Construction site safety is a vital issue in construction project management. Real-time locating and tracking technologies are getting widely used for automated monitoring of the location and direction of onsite resources, specifically workers and equipment in order to prevent hazard exposures and potential accidents. Despite the importance of utilizing real-time locating systems (RTLS) for better site safety, research on this area has been ubiquitous and a systematic review which directly addresses the association between RTLSs and construction safety is lacking. This study aims to conduct a systematic literature review to investigate predominant research streams, achievements, and limitations to the all existing applications of RTLS technology in construction safety management, and suggest potential areas for future research on the integration of RTLS applications into wider scopes of onsite safety management. The main contribution of this review lies on providing a more comprehensive knowledge of the current utilization and further development of RTLS applications on improving construction safety management. RTLSs have aided safety management process in eight major research streams including safety monitoring, accident prevention, behavior-based safety, safety alerts and warnings, ergonomics analysis and physiological status monitoring, communication-based safety, performance evaluation of the developed RTLS-related technologies and on-site safety training. However, there are limitations and gaps in applying each particular application which are highlighted to clarify the future research avenues.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automatic checks from 3D point cloud data for safety regulation compliance for scaffold work platforms\n",
            "Authors: Wang Q.\n",
            "Abstract: Fall from scaffolds is one of the leading causes for injuries and fatalities in the construction industry. To prevent fall from scaffolds, toe-boards and guard-rails must be installed on scaffold work platforms according to relevant safety regulations. Traditionally, the checking of safety regulation conformity relies on manual observation, which is inefficient and inaccurate. To address the limitations of manual checking, this study proposes a technique to automatically check whether scaffold work platforms conform to the safety regulations based on 3D point cloud data. The proposed technique first detects the location of scaffolds from the point cloud data by finding the vertical scaffold components, known as uprights. Then, scaffold work platforms, which are planar and horizontal components, are detected based on the histogram of the Z values of the point cloud data. Once the work platforms are extracted, the toe-boards and guard-rails are detected along all the four sides of each work platform. Then, the detected toe-boards and guard-rails are checked to identify any violation of safety regulations. Validation experiments were conducted on a point cloud dataset acquired from a construction site in Singapore. The experimental results show that the proposed technique could successfully detect scaffolds and work platforms from point cloud data, and extract toe-boards and guard-rails for safety regulation checking. All the violations of safety regulations in the point cloud data were successfully identified using the proposed technique.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Interactive mechanism of working environments and construction behaviors with cognitive work analysis: an elevator installation case study\n",
            "Authors: Wang Y.\n",
            "Abstract: Unsafe behavior is a leading factor in accidents, and the working environment significantly affects behaviors. However, few studies have focused on detailed mechanisms for addressing unsafe behaviors resulting from environmental constraints. This study aims to delineate these mechanisms using cognitive work analysis (CWA) for an elevator installation case study. Elevator installation was selected for study because it involves operations at heights: falls from heights remain a major cause of construction worker mortality. This study adopts a mixed research approach based on three research methodology stages. This research deconstructs the details of the working environment, the workers’ decision-making processes, the strategies chosen given environmental conditions and the conceptual model for workers’ behaviors, which jointly depict environment–behavior mechanisms at length. By applying CWA to the construction industry, environmental constraints can easily be identified, and targeted engineering suggestions can be generated.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A real-time webcam-based method for assessing upper-body postures\n",
            "Authors: Ding Z.\n",
            "Abstract: This paper presents a new vision-based method for real-time assessment of upper-body postures of a subject who is sitting in front of a desk studying or operating a computer. Unlike most existing vision-based methods that perform offline assessment from human skeletons extracted from RGB video or depth maps, the proposed method analyses directly single images captured by a webcam in front of the subject without the prone-to-error process of extracting the skeleton data from the images or depth maps. To this end, this paper proposes to assess postures by classifying them into predefined classes, without explicitly measuring the variables required for calculating risk scores. Each class of postures is associated with a configuration of the upper body, and an ergonomics risk score is assigned by following one of the scoring methods, e.g. Rapid Upper Limb Assessment (RULA). A data set of upper-body postures that cover the various scenarios when a subject is sitting in front of a desk as well as some extreme cases when the subject turns away from the desk is collected for evaluating the proposed method quantitatively. The proposed method achieved an on-average accuracy of 99.5% for binary classification (low- vs. high-risk postures), 88.2% for classification of 19 risk levels and 81.5% for classification of 30 risk levels on the data set, and the demo developed based on the method runs in real time on a regular computer.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Method to Recognize Sleeping Position Using an CNN Model Based on Human Body Pressure Image\n",
            "Authors: Liu Z.\n",
            "Abstract: Sleep is an important part of human life. Recognition of sleeping position is an important part of judging the quality of sleep, warning disease and prevention of pressure sores. At present, the body pressure is being used as a commonly method to recognize sleep gesture, and most of it is based on methods of extracting features, mainly based on local signs and global features. This paper proposes a deep learning method based on CNN deep learning method to deal with recognition of body pressure image. Compared with the previous methods, the method based on CNN neural network achieves higher accuracy of recognition at a lower cost and is suitable for complex application environments, which has good practical value.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Study on Sleep Position Recognition of Body Pressure Image based on KPCA and SVM\n",
            "Authors: Liu Z.\n",
            "Abstract: Sleep is an important part of life, and sleep position recognition is an important indicator which reflects sleep quality, warns diseases and prevents pressure sores. Actually, sleep quality is usually related to the body pressure, which affects muscle comfort and blood circulation during sleep. However, in order to regulate the body pressure, one vital step is to recognize the sleep position. Body pressure is a common indicator of the recognition of sleep position. This investigation put forward a body pressure recognition method combining with kernel principal component analysis (KPCA) and support vector machine. The feature extraction based on KPCA can well solve the nonlinear separable problems as well as dimension reduction processing of PCA, and reduce the system's complexity. Compared with the image recognition method and computer vision recognition method, it realized a higher recognition accuracy at a lower cost. Ultimately, the recognition accuracy of six common sleep positions reached 96.5%.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Design and Development of a Sitting Posture Recognition System\n",
            "Authors: Fragkiadakis E.\n",
            "Abstract: Sitting posture recognition can be used to evaluate the awareness of a person carrying out a task, such as working or driving, and can aid in avoiding accidents or other health risks, such as musculoskeletal disorders. In addition, sitting posture can reveal wellness or unhealthiness for the elderly and mobility disabled individuals. This paper focuses on body posture monitoring, by acquiring the pressure distribution of a sitting person with thirteen piezoresistive sensors placed on a seat. The measurements from the sensors passing through a microcontroller unit fed several machine learning techniques in order to discriminate among five sitting postures (upright, leaning left, leaning right, leaning forward and leaning backward). Experiments with body postures from twelve individuals (six men and six women) of different Body Mass Index (underweight, normal and overweight) were conducted. The developed classifiers achieved average discrimination accuracy over 98% among the aforementioned five body postures.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: ActSen - AI-enabled real-time IoT-Based ergonomic risk assessment system\n",
            "Authors: Low J.X.\n",
            "Abstract: Musculoskeletal Disorders (MSDs) are injuries and disorders that affect the human body's movement or musculoskeletal system. There are three primary ergonomic MSD risk factors, High task repetition, Forceful exertions and Repetitive awkward postures. Exposure to these workplace risk factors fatigue the worker's body beyond their ability to recover, leading to MSD. A variety of ergonomic risk assessment tools have been developed such as Rodgers Muscle Fatigue Analysis to help to evaluate the risk of MSD so that early intervention can be applied to prevent the development of an MSD. However, ergonomic risk assessment tools are usually carried out using subjective observational methods, which require a field expert performing a time-consuming analysis of the postures on site. Monitoring workers under staged environment and high manpower cost make observational methods impractical and not accurate to conduct ergonomic risk assessment especially for dynamic and nonroutine work. In this paper, ActSen, a real-time ergonomic risk assessment system is proposed. ActSen leverages on the recent development of embedded and Artificial Intelligent (AI) technologies. ActSen can continuously (a) acquire workers activities/postures data using various sensors, (b) process, classify and tabulate the workers movements using AI algorithms, (c) conduct real ergonomic risk assessment based on the detected activities/postures, and (d) output to interactive dashboard to facilitate smart scheduling and provide assistance when needed.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Flexible Force Sensors Embedded in Office Chair for Monitoring of Sitting Postures\n",
            "Authors: Ishaku A.A.\n",
            "Abstract: Six flexible force sensors, two on the backrest and four on the seat, were embedded in the upholstery of an off-the-shelf office chair to enable non-intrusive monitoring of sitting postures. Besides the sensors, the monitoring platform comprises an Arduino Nano microcontroller with Wi-Fi transmitter, embedded on the chair, a Wi-Fi receiver communicating with a remote server and a Graphical User Interface (GUI) showing real-time readings. Approximately 26,000 observations corresponding to 9 different postures were collected, labelled and classified using supervised machine learning. The results show that only a subset of the 6 sensors is needed for predicting these 9 sitting postures with high accuracy. This opens up the possibility for intelligent, real-time monitoring systems that can improve safety and wellbeing of today's office workers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An automatic and non-invasive physical fatigue assessment method for construction workers\n",
            "Authors: Yu Y.\n",
            "Abstract: The construction industry around the globe has unsatisfactory occupational health and safety records. One of the major reasons is attributed to high physical demands and hostile working environments. Construction work always requires workers to work for a long duration without sufficient breaks to recover from overexertion and to work under harsh climatic conditions and/or in confined workspaces. Such circumstances can increase the risk of physical fatigue. Traditionally, fatigue monitoring in the construction domain relies on self-reporting or subjective questionnaires. These methods require the manual collection of responses and are impractical for continuous fatigue monitoring. Some researchers have used on-body sensors for fatigue monitoring (such as heart rate monitors and surface electromyography (sEMG) sensors). Although these devices appear to be promising, they are intrusive, requiring sensors to be attached to the worker's body. Such on-body sensors are uncomfortable to wear and could easily cause irritation. Considering the limitations of these methodologies, the current research proposes a novel non-intrusive method to monitor the whole-body physical fatigue with computer vision for construction workers. A computer vision-based 3D motion capture algorithm was developed to model the motion of various body parts using an RGB camera. A fatigue assessment model was developed using the 3D model data from the developed motion capture algorithm and biomechanical analysis. The experiment showed that the proposed physical fatigue assessment method could provide joint-level physical fatigue assessments automatically. Then, a series of experiments demonstrated the potential of the method in assessing the physical fatigue level of different construction task conditions such as site layout and the work-rest schedules.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Adaptive computer vision-based 2D tracking of workers in complex environments\n",
            "Authors: Konstantinou E.\n",
            "Abstract: Monitoring of construction workers is important in managing labour productivity. To date, the construction sector relies either on intensive manual observations or intrusive tag-based practices. Visual tracking methods can provide automated and tag-less monitoring. However, no method to date has succeeded in tracking multiple workers, as construction sites are complex environments due to congestion, background clutter and occlusions. In addition, workers have similar appearance and exhibit illumination/scale/posture variations and abrupt changes in movement over the course of their task. To address these shortcomings, we propose a vision-based method that consists of 3 models. Firstly, an adaptive model provides continuous information about the previous position of workers and their appearance features. Secondly, a prediction model is used to calculate the current position of workers, and finally, an appearance model provides accurate localisation. Experimental results show that the proposed method achieves high performance and outperforms the latest relevant state of the art methods.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Designing of smart chair for monitoring of sitting posture using convolutional neural networks\n",
            "Authors: Kim W.\n",
            "Abstract: Purpose: Sitting in a chair is a typical act of modern people. Prolonged sitting and sitting with improper postures can lead to musculoskeletal disorders. Thus, there is a need for a sitting posture classification monitoring system that can predict a sitting posture. The purpose of this paper is to develop a system for classifying children’s sitting postures for the formation of correct postural habits. Design/methodology/approach: For the data analysis, a pressure sensor of film type was installed on the seat of the chair, and image data of the postu.re were collected. A total of 26 children participated in the experiment and collected image data for a total of seven postures. The authors used convolutional neural networks (CNN) algorithm consisting of seven layers. In addition, to compare the accuracy of classification, artificial neural networks (ANN) technique, one of the machine learning techniques, was used. Findings: The CNN algorithm was used for the sitting position classification and the average accuracy obtained by tenfold cross validation was 97.5 percent. The authors confirmed that classification accuracy through CNN algorithm is superior to conventional machine learning algorithms such as ANN and DNN. Through this study, we confirmed the applicability of the CNN-based algorithm that can be applied to the smart chair to support the correct posture in children. Originality/value: This study successfully performed the posture classification of children using CNN technique, which has not been used in related studies. In addition, by focusing on children, we have expanded the scope of the related research area and expected to contribute to the early postural habits of children.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Designing a web-based Automatic Ergonomic Assessment using Motion Data\n",
            "Authors: Olivas Padilla B.E.\n",
            "Abstract: Manual laborers from the industry sector are often subject to critical physical strain that lead to work-related musculoskeletal disorders. Lifting, poor posture and repetitive movements are among the causes of these disorders. In order to prevent them, several rules and methods have been established to identify ergonomic risks that the worker might be exposed during his/her activities. However, the ergonomic assessment though these methods is not a trivial task and a relevant degree of theoretical knowledge on the part of the analyst is necessary. Therefore in this paper, a web-based automatic ergonomic assessment module is proposed. The proposed module uses segment rotations acquired from inertial measurement units for the assessment and provides as feedback RULA scores, color visualisation and limb angles in a simple, intuitive and meaningful way. RULA is one of the most used observational methods for assessment of occupational risk factors for upper-extremity musculoskeletal disorders. By automatizing RULA an interesting perspective for extracting posture analytics for ergonomic assessment is opened, as well as the inclusion of new features that may complement it. For future work, the use of other features and sensors will be investigated for its implementation on the module.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Monitoring methods of human body joints: State-of-the-art and research challenges\n",
            "Authors: Faisal A.I.\n",
            "Abstract: The world’s population is aging: The expansion of the older adult population with multiple physical and health issues is now a huge socio-economic concern worldwide. Among these issues, the loss of mobility among older adults due to musculoskeletal disorders is especially serious as it has severe social, mental and physical consequences. Human body joint monitoring and early diagnosis of these disorders will be a strong and effective solution to this problem. A smart joint monitoring system can identify and record important musculoskeletal-related parameters. Such devices can be utilized for continuous monitoring of joint movements during the normal daily activities of older adults and the healing process of joints (hips, knees or ankles) during the post-surgery period. A viable monitoring system can be developed by combining miniaturized, durable, low-cost and compact sensors with the advanced communication technologies and data processing techniques. In this study, we have presented and compared different joint monitoring methods and sensing technologies recently reported. A discussion on sensors’ data processing, interpretation, and analysis techniques is also presented. Finally, current research focus, as well as future prospects and development challenges in joint monitoring systems are discussed.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Improving estimation of body lengths using extended kalman filter for squat movement\n",
            "Authors: Eski H.\n",
            "Abstract: Modeling and analyzing of human movements has become easier with the development of sensor technologies. Human movements can be modeled using image processing software with depth and motion sensors in 3D. Measurement errors are also observed in motion detection sensors as in most systems. Special filters have to be developed for each system in order to minimize this error rate and obtain more realistic measurements. Kalman Filter is a well-known method that is commonly used to minimize this type of measurement errors. In this study, the actual body lengths (upper arm, forearm, lower leg, upper leg) are measured and obtained from the human motion sensor. Kalman Filter and Extended Kalman Filter are applied to the obtained data from human motion sensor. All measurements are compared with the actual body lengths and error rate is calculated as using Mean Absolute Percentage Error (MAPE). Kinect data are compared with actual lengths and error rates were calculated at 20%, when the Kalman Filter is applied, the error rate decreased to 14%, while when the Extended Kalman filter is applied, it dropped to 8%. Human motion sensor data have been improved with using Extended Kalman Filter. Thus, actual measurements of candidatescan be easily obtained with only one useful sensor without taking any actual measurements by saving time and budget.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Work ability among italian bank video display terminal operators: Socio-demographic, lifestyle, and occupational correlates\n",
            "Authors: Garzaro G.\n",
            "Abstract: Bank employees, especially video display terminal (VDT) operators, are constantly exposed to various occupational risks, such as the adoption of awkward postures, repetitive finger movements, and utilization of software with poor usability, which may lead to computer visual syndrome, tension headache, lower back pain, and/or stress, which compromises their overall health and work ability (WA). Thus, in this cross-sectional study, we aimed to establish that the determinants among socio-demographic, lifestyle, and occupational characteristics are associated with impaired WA in bank VDT operators. To this end, we administered a set of socio-demographic, lifestyle, occupational, and Work Ability Index (WAI) questionnaires to 2077 Italian bank VDT operators. Univariate linear regression models reveal that their meanWAI score is inversely associated with gender, age, dependent family members, and a part-time job, whereas it is directly associated with the educational level and physical activity. In addition, multivariate analysis shows that their mean WAI score is inversely associated with age and a part-time job, but was directly associated with the educational level, the marital status, and physical activity. Overall, VDT operators working in Italian banks display high WA even though this latter tends to decline with aging. In light of the progressive aging of the workforce in Italy, our results provide the rationale for the design of interventions aimed to mitigate the detrimental effects of aging on WA of bank VDT operators.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Joint-level vision-based ergonomic assessment tool for construction workers\n",
            "Authors: Yu Y.\n",
            "Abstract: Construction workers are commonly subjected to ergonomic risks. Accurate ergonomic assessment is needed to reduce ergonomic risks. However, the diverse and dynamic nature of construction sites makes it difficult to collect workers posture data for ergonomic assessment without intrusiveness. Therefore, this paper proposed a joint-level vision-based ergonomic assessment tool for construction workers (JVEC) to provide automatic and detailed ergonomic assessments of construction workers based on construction videos. JVEC extracts construction workers' skeleton data from videos with advanced deep learning methods, then Rapid Entire Body Assessment (REBA) is used to conduct the joint-level ergonomic assessment. This approach was demonstrated and tested with a laboratory experiment and an on-site experiment, which indicated the accuracy of the ergonomic risk scores (70%-96%) and its feasibility for use on construction sites. This research contributes to an accurate and nonintrusive ergonomic assessment method for construction workers. In addition, this research for the first time introduces two-dimensional (2D) video-based three-dimensional (3D) pose estimation algorithms to the construction industry, which may benefit research on construction health, safety, and productivity by providing long-term and accurate behavior data.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automatic Biomechanical Workload Estimation for Construction Workers by Computer Vision and Smart Insoles\n",
            "Authors: Yu Y.\n",
            "Abstract: Construction workers are commonly subject to ergonomic risks due to awkward working postures or lifting/carrying heavy objects. Accordingly, accurate ergonomic assessment is needed to help improve efficiency and reduce risks. However, the diverse and dynamic nature of construction activities makes it difficult to unobtrusively collect worker behavior data for analysis. To address this issue, an automatic workload approach is proposed for the first time to continuously assess worker body joints using image-based three-dimensional (3D) posture capture smart insoles, and biomechanical analysis to provide detailed and accurate assessments based on real data instead of simulation. This approach was tested in an experiment, indicating that the method was able to automatically collect data concerning the workers' 3D posture, estimate external loads, and provide the estimated loads on key body joints with an error rate of 15%. In addition to helping prevent construction workers' ergonomic risks, the method provides a new data collection approach that may benefit various behavior research fields related to construction safety and productivity management.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A comparative study of in-field motion capture approaches for body kinematics measurement in construction\n",
            "Authors: Seo J.\n",
            "Abstract: Due to physically demanding tasks in construction, workers are exposed to significant safety and health risks. Measuring and evaluating body kinematics while performing tasks helps to identify the fundamental causes of excessive physical demands, enabling practitioners to implement appropriate interventions to reduce them. Recently, non-invasive or minimally invasive motion capture approaches such as vision-based motion capture systems and angular measurement sensors have emerged, which can be used for in-field kinematics measurements, minimally interfering with on-going work. Given that these approaches have pros and cons for kinematic measurement due to adopted sensors and algorithms, an in-depth understanding of the performance of each approach will support better decisions for their adoption in construction. With this background, the authors evaluate the performance of vision-based (RGB-D sensor-, stereovision camera-, and multiple camera-based) and an angular measurement sensor-based (i.e., an optical encoder) approach to measure body angles through experimental testing. Specifically, measured body angles from these approaches were compared with the ones obtained from a marker-based motion capture system that has less than 0.1 mm of errors. The results showed that vision-based approaches have about 5-10 degrees of error in body angles, while an angular measurement sensor-based approach measured body angles with about 3 degrees of error during diverse tasks. The results indicate that, in general, these approaches can be applicable for diverse ergonomic methods to identify potential safety and health risks, such as rough postural assessment, time and motion study or trajectory analysis where some errors in motion data would not significantly sacrifice their reliability. Combined with relatively accurate angular measurement sensors, vision-based motion capture approaches also have great potential to enable us to perform in-depth physical demand analysis such as biomechanical analysis that requires full-body motion data, even though further improvement of accuracy is necessary. Additionally, understanding of body kinematics of workers would enable ergonomic mechanical design for automated machines and assistive robots that helps to reduce physical demands while supporting workers' capabilities.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Instrument-based ergonomic assessment: A perspective on the current state of art and future trends\n",
            "Authors: Cerqueira S.\n",
            "Abstract: The majority of occupational disorders result from Work-Related Musculoskeletal Disorders (WRMSDs). Consequently, through the years, a substantial level of effort has been placed on developing new tools for ergonomic assessment, and nowadays, three major methods can be identified: self-reports, observational methods, and instrument-based. The present paper presents a brief review of the current methodologies for ergonomic-risk assessment, focusing on the instrument-based tools already developed. Additionally, an analysis is conducted on the potentials and future prospects of wearables in the industry 4.0, where the symbiosis between humans and machines is the heart of the concept.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Pipe radius estimation using Kinect range cameras\n",
            "Authors: Nahangi M.\n",
            "Abstract: In the heavy construction industry, pipe spool assembly is geometrically complex and suboptimal fabrication processes inevitably lead to fabrication errors and costly rework. In an attempt to mitigate fabrication risks and improve product quality, computer aided tools are being developed to provide an additional layer of control. In this paper, the data acquisition capabilities of two low-cost range cameras are investigated for the eventual purpose of pipe fitting process monitoring in a smart fabrication facility environment. Range images of various pipes are systematically taken at varying distances from the sensor. By using the proposed radius estimation algorithm, the utility of the data for accurate geometrical pipe feature detection is evaluated by a radius feature metric. Results show that the algorithm reliably extracts radius information from point clouds representing piping. In conjunction with the algorithm, the low-cost range camera hardware was able to characterize pipes, of radius ranging from 2.41 cm to 8.78 cm at a distance from the sensor ranging from 0.5 m to 3.75 m, with an average error of 18% for Kinect 1 and 10% for Kinect 2.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Detection of construction workers under varying poses and changing background in image sequences via very deep residual networks\n",
            "Authors: Son H.\n",
            "Abstract: Analyzing the location and behavior of construction workers using construction site images has been recognized as a means of providing useful information for safety management and productivity analysis. Although effective utilization of analyzed image data requires accurate and timely detection of workers in complex, continuously changing working environments, the previous methods that detect construction workers still require improvement because of the poor detection performance. This study proposes the use of very deep residual networks to accurately and rapidly detect construction workers under varying poses and against changing backgrounds in image sequences. The architecture of construction worker detection in this study is based on convolutional neural networks (CNNs). The proposed method is divided into two stages: extracting feature maps via very deep residual networks (ResNet-152) and bounding box regression and labeling from the original image via Faster regions with CNN features (R-CNN). The experiments were conducted at actual construction sites by acquiring 1.3-megapixel and 3.1-megapixel images from a movable digital camera to verify the proposed method for images from fixed and moving cameras. Faster R-CNN with ResNet-152 had accuracy, precision, and recall rates of 94.3%, 96.03%, and 98.13% for 3241 images, respectively. The proposed method processed 0.2 s per frame (i.e., 5 frames per second) on average. The results show that it is possible to accurately and rapidly detect multiple workers in construction site images by employing very deep residual networks without relying on limited assumptions about workers’ postures, appearance, and background.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automobile Driver Posture Monitoring Systems: A Review (in English)\n",
            "Authors: Wang H.Y.\n",
            "Abstract: With the development of autonomous vehicles, drivers will adopt new postures, which should be considered for optimizing the future passive safety systems. On the other hand, the safety of recent autonomous vehicles is guaranteed by an elaborate interaction between the human driver and the automation system, and this situation will last for quite a long time. Given this context, posture monitoring is necessary to verify the driver's readiness to take over the control when required. Based on a systematic analysis of related literature, a detailed review of recent driver posture monitoring systems classified by the sensor categories and corresponding algorithms was performed. Advantages and disadvantages of different systems were analyzed and summarized. Despite the recent advancements in sensor technologies and algorithms, a cost-effective and robust driver posture monitoring system that can work in various real driving conditions does not exist. In general, most of the existing systems monitor the driver's body parts in isolation for specific research purpose, and few systems consider the body parts in conjunction. Most of the studies were performed in a controlled environment, and lack rigorous and quantitative evaluation in a moving automobile. In addition, real-time posture recognition and prediction methods need to be improved. Finally, future research and development directions to overcome the existing drawbacks are suggested, and a posture monitoring system based on a combination of active stereo vision system and force sensor arrays is recommended. This paper provides valuable insights on developing state-of-the-art driver posture monitoring systems to enhance the road traffic safety. Meanwhile, it also inspires the design of human-machine interfaces.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A review of psychophysiological measures to assess cognitive states in real-world driving\n",
            "Authors: Lohani M.\n",
            "Abstract: As driving functions become increasingly automated, motorists run the risk of becoming cognitively removed from the driving process. Psychophysiological measures may provide added value not captured through behavioral or self-report measures alone. This paper provides a selective review of the psychophysiological measures that can be utilized to assess cognitive states in real-world driving environments. First, the importance of psychophysiological measures within the context of traffic safety is discussed. Next, the most commonly used physiology-based indices of cognitive states are considered as potential candidates relevant for driving research. These include: electroencephalography and event-related potentials, optical imaging, heart rate and heart rate variability, blood pressure, skin conductance, electromyography, thermal imaging, and pupillometry. For each of these measures, an overview is provided, followed by a discussion of the methods for measuring it in a driving context. Drawing from recent empirical driving and psychophysiology research, the relative strengths and limitations of each measure are discussed to highlight each measures' unique value. Challenges and recommendations for valid and reliable quantification from lab to (less predictable) real-world driving settings are considered. Finally, we discuss measures that may be better candidates for a near real-time assessment of motorists' cognitive states that can be utilized in applied settings outside the lab. This review synthesizes the literature on in-vehicle psychophysiological measures to advance the development of effective human-machine driving interfaces and driver support systems.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automobile Driver Posture Monitoring Systems: A Review\n",
            "Authors: Wang H.Y.\n",
            "Abstract: With the development of autonomous vehicles, drivers will adopt new postures, which should be considered for optimizing the future passive safety systems. On the other hand, the safety of recent autonomous vehicles is guaranteed by an elaborate interaction between the human driver and the automation system, and this situation will last for quite a long time. Given this context, posture monitoring is necessary to verify the driver's readiness to take over the control when required. Based on a systematic analysis of related literature, a detailed review of recent driver posture monitoring systems classified by the sensor categories and corresponding algorithms was performed. Advantages and disadvantages of different systems were analyzed and summarized. Despite the recent advancements in sensor technologies and algorithms, a cost-effective and robust driver posture monitoring system that can work in various real driving conditions does not exist. In general, most of the existing systems monitor the driver's body parts in isolation for specific research purpose, and few systems consider the body parts in conjunction. Most of the studies were performed in a controlled environment, and lack rigorous and quantitative evaluation in a moving automobile. In addition, real-time posture recognition and prediction methods need to be improved. Finally, future research and development directions to overcome the existing drawbacks are suggested, and a posture monitoring system based on a combination of active stereo vision system and force sensor arrays is recommended. This paper provides valuable insights on developing state-of-the-art driver posture monitoring systems to enhance the road traffic safety. Meanwhile, it also inspires the design of human-machine interfaces.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automated post-3D visualization ergonomic analysis system for rapid workplace design in modular construction\n",
            "Authors: Li X.\n",
            "Abstract: Conventional risk assessment of physical work methods is time-consuming and requires human subjects to perform the operational task; 3D visualization, alternatively, allows users to simulate the task, which is less time-consuming and eliminates the need for costly onsite devices and the detrimental effect of human error during experimentation. This paper presents the development of an automated post-3D visualization ErgoSystem, a system that automates ergonomic risk assessment based on 3D modelling with the support of user-friendly platform for rapid workplace design. Rapid Entire Body Assessment and Rapid Upper Limb Assessment have also been integrated and adjusted into the proposed system. The system is implemented into the process of comparing various methods of placing insulation onto a modularized panel to demonstrate how the change of movements correlates to the change of workplace design. The objective is to proactively mitigate ergonomic risk at the workplace and to reduce injuries and workers' compensation costs.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Big data platform for health and safety accident prediction\n",
            "Authors: Ajayi A.\n",
            "Abstract: Purpose – The purpose of this paper is to highlight the use of the big data technologies for health and safety risks analytics in the power infrastructure domain with large data sets of health and safety risks, which are usually sparse and noisy. Design/methodology/approach – The study focuses on using the big data frameworks for designing a robust architecture for handling and analysing (exploratory and predictive analytics) accidents in power infrastructure. The designed architecture is based on a well coherent health risk analytics lifecycle. A prototype of the architecture interfaced various technology artefacts was implemented in the Java language to predict the likelihoods of health hazards occurrence. A preliminary evaluation of the proposed architecture was carried out with a subset of an objective data, obtained from a leading UK power infrastructure company offering a broad range of power infrastructure services. Findings – The proposed architecture was able to identify relevant variables and improve preliminary prediction accuracies and explanatory capacities. It has also enabled conclusions to be drawn regarding the causes of health risks. The results represent a significant improvement in terms of managing information on construction accidents, particularly in power infrastructure domain. Originality/value – This study carries out a comprehensive literature review to advance the health and safety risk management in construction. It also highlights the inability of the conventional technologies in handling unstructured and incomplete data set for real-time analytics processing. The study proposes a technique in big data technology for finding complex patterns and establishing the statistical cohesion of hidden patterns for optimal future decision making.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A framework of on-site construction safety management using computer vision and real-time location system\n",
            "Authors: Zhang J.\n",
            "Abstract: Construction safety-related research is either management-driven or technology-driven. Many emerging technologies have been investigated by researchers worldwide in different construction management applications. Although there is some limitations, recent advances in deep learning technology has made computer vison (CV) a very active research topic in the field of construction safety management. However, most CV-based studies focus on detecting unsafe behaviour without extending the work to include identifying, locating, and notifying the people involved. In this paper, a framework is proposed for an on-site construction safety management system using Fast R-Convolution Neural Network (CNN)-based computer vison and Bluetooth Low Energy (BLE)-based real-time location system (RTLS). CV can detect onsite entities, understand their spatial relations in a semantic way, and recognize actions of workers and construction equipment. Moreover, the trajectories of moving objects can be tracked, and the next location can be predicted. Combined with the low-cost and easy-to-implement BLE-based RTLS, workers involved in a potential construction hazard will be warned through a mobile application on their smartphones, via loud sounds and vibrations. Experimental studies were conducted at two construction sites to test the CV-based method and the RTLS-based worker identification and warning.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Static and Dynamic Work Activity Classification from a Single Accelerometer: Implications for Ergonomic Assessment of Manual Handling Tasks\n",
            "Authors: Hosseinian S.M.\n",
            "Abstract: A single wearable sensor (accelerometer) on the chest was employed to classify static and dynamic activities commonly observed in manual handling jobs. Utilizing only two features obtained from this sensor, 15 different simulated activities were classified with 93%–98% accuracy. The classification models developed here could be used to objectively quantify workers’ tasks through the course of their work shifts, thereby enabling more accurate and efficient ergonomic assessments while requiring using only a simple wearable device. Background: The use of accelerometers for recognizing physical activity has increased substantially; however, there is a need to develop activity classification models that are effective for a large range of static and dynamic work activities commonly seen in manual handling. Purpose: This study aimed to develop an efficient classification model to recognize static and dynamic work activities from a single accelerometer attached to the chest. Methods: Accelerometer data were obtained during 15 simulated activities from 27 (13 males, 14 females) healthy adults. First-order differencing was employed to account for between-subject variability. Eighty-one datasets were created using nine different time windows and nine different data samples with randomly-selected start times. Medians of postural angles and the area-under-the-curve of transformed triaxial data were used as predictors in classification models (random forest and support vector machines). Results: In the random-forest models, the highest (98.2%) and lowest (93%) overall accuracies across the 15 activities were associated with time windows of 6 and 2 s, and data samples of 5000 and 1000, respectively. The findings also indicated that accuracy of the random-forest models improved with increasing time window durations and data samples. Finally, activity classification with the support vector machine model, corresponding to the random-forest model with the highest performance, achieved an accuracy of 95.5%. Conclusions: These results suggest that the use of only two features from a single accelerometer can help classify work activities, which in turn can improve real-time or remote ergonomic risk assessments of manual handling tasks. Future work is needed, though, to examine the generalizability of the current models to efficiently classify complex manual handling tasks in diverse worker groups.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A multipath methodology to promote ergonomics, safety and efficiency in agile factories\n",
            "Authors: Ceccacci S.\n",
            "Abstract: An important area of risk management practice for manufacturing companies relates to the prevention of injuries and musculoskeletal disorders (MSDs). The greater benefits can be achieved where a preventive approach is used, based on ergonomic design of workplaces and attention to human requirements and limitations as well as human-machine interaction principles. The research aims at providing a pragmatic approach to support the application of ergonomic risk management in practice. It defines a multipath methodology to investigate human factors impacting on safety by considering the specific workspace, the adopted tools, the overall production environment and the workers’ activity. An industrial case study is described to illustrate the methodology and demonstrate the benefits for companies. Results suggest that the proposed multipath methodology allow to effectively assist analysts in the definition of crucial risk factors and selection of proper ergonomics assessment and measurement tools according to the specific context of application.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Sensing and changing human behavior for workplace wellness\n",
            "Authors: Arakawa Y.\n",
            "Abstract: Recently, companies have begun to care more about the well-being of their employees. With the spread of sensors, the Internet of Things, and artificial intelligence, the movement to build a better working environment by utilizing these technologies has been spreading. Especially, research on behavior that can change lifestyle habits is becoming popular. In this paper, we summarize workplace behavior research and projects for sensing and changing human behavior in a workplace and aim to improve the productivity and wellness of employees. Also, we introduce concepts for future workplaces and some of our related achievements. For physical state sensing, we have developed a continuous posture-sensing chair, which will soon be available commercially. For internal state sensing, we propose a method for estimating quality of life with wearable sensors. Our system have already achieved to estimate QoL (Quality of Life) around 90% with only 9 questions. In addition, we propose interactive digital signage to provide habit-changing reminders. Through one month experiment, we confirmed that our system can be feasible in daily life.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Prediction of Basketball Free Throw Shooting by OpenPose\n",
            "Authors: Nakai M.\n",
            "Abstract: OpenPose, which is developed by Carnegie Mellon University (CMU) presented in CVPR 2017, takes in real-time motion images via a simple web camera and is capable of recognizing skeletons of multiple persons in these images. It also generates recognized skeleton point coordinates to files. OpenPose is featured by CMU’s original top-down method for real-time recognition and it is open online especially for research purposes. Thus we aimed to build a posture analysis model using OpenPose skeletal recognition data and verifying the practicality of OpenPose by verifying the accuracy of the model. As a posture analysis model, we adopted a logistic regression model that predicts the shooting probability of the basketball free throw with skeleton posture data as explanatory variables and the fact whether the ball enters the basket or not as a binary target variable. As the result, sufficiently significant prediction accuracy was obtained. Therefore, posture analysis using OpenPose has been verified to be practical with our model. We consider that with many skeleton data which are easily provided by a simple web camera, OpenPose makes statistical diagnostic approach possible. We also consider it could lower costs (in both financial and time-wise) of such an analysis which has previously required more equipments and more time for preparation regarding motion capture analysis systems.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: AI-powered Posture Training: Application of machine learning in sitting posture recognition using the Lifechair smart cushion\n",
            "Authors: Bourahmoune K.\n",
            "Abstract: Humans spend on average more than half of their day sitting down. The ill-effects of poor sitting posture and prolonged sitting on physical and mental health have been extensively studied, and solutions for curbing this sedentary epidemic have received special attention in recent years. With the recent advances in sensing technologies and Artificial Intelligence (AI), sitting posture monitoring and correction is one of the key problems to address for enhancing human well-being using AI. We present the application of a sitting posture training smart cushion called LifeChair that combines a novel pressure sensing technology, a smartphone app interface and machine learning (ML) for real-time sitting posture recognition and seated stretching guidance. We present our experimental design for sitting posture and stretch pose data collection using our posture training system. We achieved an accuracy of 98.93% in detecting more than 13 different sitting postures using a fast and robust supervised learning algorithm. We also establish the importance of taking into account the divergence in user body mass index in posture monitoring. Additionally, we present the first ML-based human stretch pose recognition system for pressure sensor data and show its performance in classifying six common chair-bound stretches.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of smart helmet for monitoring construction resources based on image matching method\n",
            "Authors: Kang S.\n",
            "Abstract: Construction managers periodically take photographs of on-site resources such as materials and facilities to document various aspects of construction activities. Although digital images can be effectively used for monitoring construction activities, they are not used at all but to show the situation of the site by being attached on the report. In this regard, this study proposes a system and a smart helmet that help site managers identify changes in the conditions of facilities and materials. The smart helmet is equipped with a small camera to record videos around the site, and a small GPS to collect the position data of the site manager wearing the smart helmet. The system includes two separate frameworks-one for fixed resources and the other for mobile resources. The system automatically detects changes in appearance of fixed resources and in locations of mobile resources. The frameworks involve image matching methods which play critical roles in detecting appearance changes of fixed resources as well as cross-checking the identities of mobile resources. Experimental results signify the system's potential uses for effectively monitoring the conditions of on-site facilities and materials.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A low-cost and smart IMU tool for tracking construction activities\n",
            "Authors: Yang X.\n",
            "Abstract: Real-time activity monitoring is becoming one of the most significant technologies on construction sites because it can be applied to a variety of management problems, such as productivity formula and safety monitoring. However, current monitoring technologies are limited to recognizing postures in an ideal environment rather than dealing with the ambient occlusion and people-intensive situations on real construction sites. Therefore, this study develops a low-cost, non-intrusion and portable tool system in order to trace and track construction activities on complex and crowed construction sites. This system is composed of wireless sensors and a smart algorithm. Each sensor consists of an inertial measurement unit, a communication sensor (bluetooth low energy sensor) and several environmental sensors, which broadcasts the identification, acceleration, palstance and environmental measurements at a constant frequency. Since the dimension of the sensor is only 20 x 15 x 2 mm, it can be easily attached or screwed on to the hand tools as well as integrated with power tools. When a laptop or cell phone receives from these sensors, the construction activities are derived by the artificial intelligence algorithm in a timely manner, providing an visual posture monitoring as well as an automatic record of project progress. In the end, practical experiments of a concrete vibrator and a hammer prove the feasibility and effectiveness of the proposed IMU-based tool tracing and tracking system.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: 3D human body reconstruction for worker ergonomic posture analysis with monocular video camera\n",
            "Authors: Chu W.\n",
            "Abstract: In the modular construction industry of Canada, workers experience awkward postures and motions (reaching above shoulder, back bending backward, elbow/wrist flex, etc.) due to improper workstation designs. The awkward postures often lead to worker injuries and accidents, which do not only reduce the productivity but also increases the production cost. Therefore, the ergonomic posture analysis becomes essential to identify, mitigate and prevent the awkward postures of workers when workstation designs are changed. This paper proposes a novel framework to conduct the worker ergonomic posture analysis through the 3D reconstruction of human body from the video sequences captured by a monocular camera. The framework consists of four components: tracking worker of interest; detecting worker joints and body parts; refining 2D worker pose; and generating 3D human body model. The human body model generated from the framework could be used to estimate the joint angles of the workers to identify whether their postures meet the ergonomic requirements. The proposed framework has been tested on real construction videos, and the test results showed its effectiveness.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automated monitoring of physical fatigue using jerk\n",
            "Authors: Zhang L.\n",
            "Abstract: Construction workers are commonly subjected to ergonomic risks due to manual material handling that requires high levels of energy input over long work hours. Fatigue in musculature is associated with decline in postural stability, motor performance, and altered normal motion patterns, leading to heightened risks of work-related musculoskeletal disorders. Physical fatigue has been previously demonstrated to be a good indicator of injury risks, thus, monitoring and detecting muscle fatigue during strenuous work may be advantageous in mitigating these risks. Currently, few researchers have investigated how physical fatigue and exertion can be continuously monitored for practical use outside laboratory settings. Exercise-induced fatigue has been shown to impact motor control; thus, it can be measured using jerk, the time derivative of acceleration. This paper investigates the application of a machine learning approach, Support Vector Machine (SVM), to automatically recognize jerk changes due to physical exertion. We hypothesized that physical exertion and fatigue will influence motions and thus, can be classified based on jerk values. The motion data of six expert masons were collected using IMU sensors during two bricklaying tasks. The pelvis, upper arms, and thighs jerk values were used to classify inter- and intra-subject rested and exerted states. Our results show that on average, intra-subject classification achieved an accuracy of 94% for a five-course wall building experiment and 80% for a first-course experiment, leading us to conclude that jerk changes due to physical exertion can be detected using wearable sensors and SVMs.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: 3D posture estimation from 2D posture data for construction workers\n",
            "Authors: Yu Y.\n",
            "Abstract: Construction workers’ behaviour is important for safety, health and productivity management. Workers’ 3D postures are the data foundation of their behaviours. This paper established a preliminary 3D posture dataset of construction tasks and provided a 3D posture estimation method based on 2D joint locations. The results showed that the method could estimate 3D postures accurately and timely. The mean joint error and estimation time of each frame were 1.10 cm and 0.12 ms respectively. This method makes it possible to estimate construction workers’ 3D postures from construction site images and contributes to a data-based construction workers’ behaviour management.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Application of vision systems to improve the effectiveness of monitoring compliance with technical safety requirements at industrial facilities\n",
            "Authors: Ekimenko A.A.\n",
            "Abstract: According to the Federal State Statistics Service for 2017, over 25,000 injuries at work were registered in Russia, of which 1,138 were fatal. Studies have shown that most of the injuries in the workplace due to non-compliance with technical safety rules, namely the lack of personal protective equipment or their improper use. To improve the efficiency of monitoring compliance with the rules of technical safety at industrial facilities, this paper discusses the use of vision systems for automatic control of the availability of personal protective equipment at workers in the area of industrial work.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Convolutional long short-term memory model for recognizing postures from wearable sensor\n",
            "Authors: Zhao J.\n",
            "Abstract: This research investigates the feasibility and viability of applying Deep Neural Networks (DNN) to improve performance with respect to posture recognition based on multi-channel motion data from Wearable Sensors (WS). The authors use the recognition of posture that can be linked to risk of Musculoskeletal Disorder (MSD)- among construction workers as the testbed. The proposed approach is based on the use of a DNN model integrating Convolutional Neural Network (CNN) and Long short-term memory (LSTM) that can achieve automated feature engineering and sequential pattern detection. The model performance was evaluated using datasets collected from four construction workers. The proposed model outperformed baseline CNN and LSTM models. Under the personalized modelling approach, it improved recognition performance by 3% from the benchmark Machine Learning models; the improvement is 2% for generalized modelling approach. The proposed model achieves high-performance posture recognition, which facilitates the MSD prevention in construction through monitoring injury-related postures.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Posture tracking using a machine learning algorithm for a home AAL environment\n",
            "Authors: Sandybekov M.\n",
            "Abstract: The number of home office workers sitting for many hours is increasing. The sensor chair is tracking users’ sitting behavior which the help of pressure sensors and tries to avoid wrong postures which may cause diseases. The system provides live monitoring of the pressure distribution via web interface, as well as sitting posture prediction in real time. Posture analysis is realized through machine learning algorithm using a decision tree classifier that is compared to a random forest. Data acquisition and aggregation for the learning process happens with a mobile app adding users biometrical data and the taken sitting posture as label. The sensor chair is able to differentiate between an arched back, a neutral posture or a laid back position taken on the chair. The classifier achieves an accuracy of 97.4% on our test set and is comparable to the performance of the random forest with 98.9%.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The role of a new harvest platform in alleviation of apple workers' occupational injuries during harvest\n",
            "Authors: Zhang Z.\n",
            "Abstract: Migrant seasonal workers manually harvest apples throughout the U.S. using ladders and buckets due to the care required for prevention of bruises and other physical damage. The motions associated with hand harvest have potential to cause musculoskeletal disorders of the neck, shoulder, and back/trunk. A prototype harvest platform was developed, aimed at alleviating occupational injuries and increasing harvest productivity by replacing ladders for reaching high apples. This study evaluated the activities of three harvest methods, i.e., conventional harvest (using ladders and buckets), harvest platform (for high apples only), and combined method (conventional harvest for low and middle apples and harvest platform for high apples) using the Rapid Upper Limb Assessment (RULA) method performed by trained researchers. Postures/activities with RULA grand scores > 5 were categorized as awkward (causing occupational injuries); otherwise, they were considered comfortable (not leading to health issues). Experimental results demonstrated that awkward activities in conventional harvest were mainly related to the use of ladders. Activities with the harvest platform were comfortable due to the elimination of ladders and buckets. The combined method significantly decreased the workers' time spent in awkward postures (from 64% with conventional harvest to 30% with the combined method) by eliminating awkward activities and increased the overall harvest productivity by approximately 40%. Apple growers and workers are therefore suggested to use the combined method to replace conventional harvest.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Cervical Vertebrae Health Score Method Based on Multiple Instance Learning\n",
            "Authors: Li J.\n",
            "Abstract: This paper introduces an online scoring method for cervical vertebrae health based on multiple instance learning (MIL) of multiple-valued input, in order to assess cervical vertebrae health score and solve the data labeling difficulty. It is only necessary to simply label the long-term sequence of cervical vertebrae motion data during the training phase to estimate the health score of the cervical short-term state. Firstly, the multiple-valued input is divided into sub-classifiers of multiple binary inputs and trained separately. Then use the Gaussian model to fuse the instance scores trained by each sub-classifier. Finally, the bag score is calculated with a new scoring mechanism and the cervical vertebrae health can be assessed in real-time. Qualitative and quantitative experiments include the bag score prediction accuracy, instance visualization analysis, bag score curve analysis and real-time scoring analysis, which illustrate the effectiveness of the algorithm in assessing the health of the cervical vertebrae.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The role of movement analysis in diagnosing and monitoring neurodegenerative conditions: Insights from gait and postural control\n",
            "Authors: Buckley C.\n",
            "Abstract: Quantifying gait and postural control adds valuable information that aids in understanding neurological conditions where motor symptoms predominate and cause considerable functional impairment. Disease-specific clinical scales exist; however, they are often susceptible to subjectivity, and can lack sensitivity when identifying subtle gait and postural impairments in prodromal cohorts and longitudinally to document disease progression. Numerous devices are available to objectively quantify a range of measurement outcomes pertaining to gait and postural control; however, efforts are required to standardise and harmonise approaches that are specific to the neurological condition and clinical assessment. Tools are urgently needed that address a number of unmet needs in neurological practice. Namely, these include timely and accurate diagnosis; disease stratification; risk prediction; tracking disease progression; and decision making for intervention optimisation and maximising therapeutic response (such as medication selection, disease staging, and targeted support). Using some recent examples of research across a range of relevant neurological conditions—including Parkinson’s disease, ataxia, and dementia— we will illustrate evidence that supports progress against these unmet clinical needs. We summarise the novel ‘big data’ approaches that utilise data mining and machine learning techniques to improve disease classification and risk prediction, and conclude with recommendations for future direction.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Back flexion and extension: The effects of static posture on children using mobile devices\n",
            "Authors: Pope-Ford R.\n",
            "Abstract: In 2016, smartphone sales grew five percent, with nearly 1.5 billion smartphones sold worldwide. In the United States (US), there were 220 million users. These 220 million users represent the 77% of American households who own a smartphone. A large number of the smartphone users are children. The intent of this study is to understand the effect smartphone use might have on the musculoskeletal system of young children. Eighteen participants, 11 males and 7 females, ages 10–12, were interviewed. The participants were observed and quantitative data was collected as 17 trials were performed; noting back posture while children used a smartphone and tablet. A goniometer was used to measure back flexion and extension. Measured back flexion ranged from 8.5 to 54° and back extension ranged from 12 to 24°. Results indicate that back support and/or correct posture are important when using mobile devices.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: E-health of Construction Works: A Proactive Injury Prevention Approach\n",
            "Authors: Zhao J.\n",
            "Abstract: This research is direct at developing an e-health approach for preventing the Musculoskeletal Disorders in construction through monitoring injury risk. The proposed approach leverages activities recognition through motion capturing techniques to monitor, assess, and reduce injury risk. More specifically, the authors used the Inertia Measurement Units, a motion-sensing tool to develop a concept for a wearable motion-data capturing prototype. The captured motion data was analyzed using data-driven, Machine Learning techniques to identify injury-prone activities. Instead of adopting a generic recognition model, a novel rapid model training process was investigated to configure a user-specific activity recognition model, aiming at improving the recognition accuracy with reduced computational effort. The customized model was based on the optimal configuration of data segmentation window size, feature sets, and classification algorithms for a specific user's activity data. The feasibility study of the proposed approach has shown the personalized model achieved an average overall recognition accuracy of 0.81 and 0.74 for two sets of activities. The recognition model's operation time was also reduced to under 0.01 seconds. The proposed approach can help to address the scalability challenge for data-driven activity recognition, and further, improve the effectiveness and practicality for proactive injury prevention on construction job site.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Workers' compensation injury claims among workers in the private ambulance services industry—Ohio, 2001–2011\n",
            "Authors: Reichard A.A.\n",
            "Abstract: Background: Ambulance service workers frequently transfer and transport patients. These tasks involve occupational injury risks such as heavy lifting, awkward postures, and frequent motor vehicle travel. Methods: We examined Ohio workers’ compensation injury claims among state-insured ambulance service workers working for private employers from 2001 to 2011. Injury claim counts and rates are presented by claim types, diagnoses, and injury events; only counts are available by worker characteristics. Results: We analyzed a total of 5882 claims. The majority were medical-only (<8 days away from work). The overall injury claim rate for medical-only and lost-time cases was 12.1 per 100 full-time equivalents. Sprains and strains accounted for 60% of all injury claims. Overexertion from patient handling was the leading injury event, followed by motor vehicle roadway incidents. Conclusions: Study results can guide the development or improvement of injury prevention strategies. Focused efforts related to patient handling and vehicle incidents are needed.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Computer-Aided Optimization of Surveillance Cameras Placement on Construction Sites\n",
            "Authors: Yang X.\n",
            "Abstract: Surveillance system is becoming an indispensable system on construction sites with the fast development of computer vision techniques, thus an optimal placement of surveillance cameras is essential for the successful performance of this system. However, to develop effective models and solutions for large-scale camera placement still remain as opening challenges. Therefore, this study investigated two fundamental placement problems and proposed a multiobjective placement problem, where the maximum-coverage problem is to monitor the construction layout as much as possible with a limited budget; the minimum-cost problem is to minimize the cost given a layout required to be fully covered; and the multiobjective problem is to identify the Pareto fronts of cost and coverage ratio of the system. To solve these problems, the objective space and search space were discretized, and the deterministic and heuristic approaches were revised and developed to provide effective solutions. Finally, experiments in a practical project in Hong Kong were conducted to verify the sufficiency of the developed algorithms and findings revealed potential implementations in many scenarios.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Wearable insole pressure system for automated detection and classification of awkward working postures in construction workers\n",
            "Authors: Antwi-Afari M.F.\n",
            "Abstract: Awkward working postures are the main risk factor for work-related musculoskeletal disorders (WMSDs) causing non-fatal occupational injuries among construction workers. However, it remains a challenge to use existing risk assessment methods for detecting and classifying awkward working postures because these methods are either intrusive or rely on subjective judgment. Therefore, this study developed a novel and non-invasive method to automatically detect and classify awkward working postures based on foot plantar pressure distribution data measured by a wearable insole pressure system. Ten asymptomatic participants performed five different types of awkward working postures (i.e., overhead working, squatting, stooping, semi-squatting, and one-legged kneeling) in a laboratory setting. Four supervised machine learning classifiers (i.e., artificial neural network (ANN), decision tree (DT), K-nearest neighbor (KNN), and support vector machine (SVM)) were used for classification performance using a 0.32 s window size. Cross-validation results showed that the SVM classifier (i.e., the best classifier) obtained a classification performance with an accuracy of 99.70% and a sensitivity of each awkward working posture was above 99.00% at 0.32 s window size. The findings substantiated that it is feasible to use a wearable insole pressure system to identify risk factors for developing WMSDs, and could help safety managers to minimize workers’ exposure to awkward working postures.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A simulation and visualization-based framework of labor efficiency and safety analysis for prevention through design and planning\n",
            "Authors: Golabchi A.\n",
            "Abstract: Considering the physically demanding nature of manual tasks in the construction industry, an effective approach to mitigating ergonomic risks is to prevent the unsafe working conditions proactively during design and planning, also known as Prevention through Design (PtD). However, there is a lack of approaches for identifying the potential ergonomic risks of a proposed design that can effectively address designers' lack of familiarity with ergonomic risks and understanding of the PtD concept and its implementation. Furthermore, it is difficult to evaluate the impact of ergonomic interventions on productivity and vice versa using available tools. Thus, an integrated approach to PtD is proposed by developing a comprehensive framework that uses simulation modeling, coupled with Predetermined Motion Time Systems (PMTS) and ergonomic and biomechanical assessment, as well as workplace visualization, in order to incorporate both productivity and safety analysis into the design process. The results of implementing the proposed approach indicate its effectiveness in achieving optimum designs in terms of efficiency and safety by evaluating different scenarios of carrying out construction manual operations. The proposed framework also enables evaluating the relationship between safety and productivity from a physical perspective.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Test-retest reliability of posture measurements in adolescents with idiopathic scoliosis\n",
            "Authors: Heitz P.H.\n",
            "Abstract: Background Context: Posture changes are a major consequence of idiopathic scoliosis (IS). Posture changes can lead to psychosocial and physical impairments in adolescents with IS. Therefore, it is important to assess posture, but the test-retest reliability of posture measurements still remains unknown in this population. Purpose: The primary objective of the present study was to determine the test-retest reliability of 25 head and trunk posture indices using the Clinical Photographic Postural Assessment Tool (CPPAT) in adolescents with IS. The secondary objective was to determine the standard error of measurement and the minimal detectable change. Study Design/Setting: This is a prospective test-retest reliability study carried out at two tertiary university hospital centers. Patients Sample: Forty-one adolescents with IS, aged 10–16 years old with curves 10°–45° and treated by medical intervention, were recruited. Methods: Two posture assessments were done using the CPPAT 5–10 days apart following a standardized procedure. Photographs were analyzed with the CPPAT software by digitizing reference landmarks placed on the participant by a physiotherapist evaluator. Generalizability theory was used to obtain a coefficient of dependability, standard error of measurement, and the minimal detectable change at 90% confidence interval. Results: Fourteen of 25 posture indices had a good reliability (ϕ≥0.78), 10 had moderate reliability (ϕ=0.55–0.74), and 1 had poor reliability (ϕ=0.45). The most reliable posture indices were waist angle asymmetry (ϕ=0.93), right waist angle (ϕ=0.91), and frontal trunk list (ϕ=0.92). Right sagittal trunk list was the least reliable posture index (ϕ=0.45). The MDC90 values ranged from 2.6 to 10.3° for angular measurements and from 8.4 to 35.1 mm for linear measurements. Conclusions: The present study demonstrates that most posture indices, especially the trunk posture indices, are reproducible in time among adolescents with IS and provides reference values. Clinicians and researchers can use these reference values to assess change in posture over time attributable to treatment effectiveness.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A non-intrusive system for seated posture identification\n",
            "Authors: Bibbo D.\n",
            "Abstract: In this contribution a system for seated posture identification is presented. The assessment tools is based on an office-chair equipped with sensors. In more details, a set of textile pressure sensors has been placed on a chair both on the chair backrest and on the seat. The position of the sensors has been selected for maximizing the possibility of sensing minimum variations of the subject's posture. To validate the system, an extensive subjective experiment has been performed in which the subject undergoes an increasing stress-level test. The collected results show that this instrument is effective in assessing the attention/fatigue of a subject in seating condition by the analysis of body posture.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An integrated ergonomics framework for evaluation and design of construction operations\n",
            "Authors: Golabchi A.\n",
            "Abstract: Labor is one of the most critical resources in the construction industry due to its impact on the productivity, safety, quality, and cost of a construction project. Ergonomic assessment, as a tool and method for analyzing human activities and their interactions with the surrounding environment, is thus crucial for designing operations and workplaces that achieve both high productivity and safety. In construction, however, the constantly changing work environments and laborious tasks cause traditional approaches to ergonomic analysis, such as manual observations and measurements, to require substantial time and effort to yield reliable results. Therefore, to simplify and automate the assessment processes, this study explores the adaptation and integration of various existing methods for data collection, analysis, and output representation potentially available for comprehensive ergonomic analysis. The proposed framework integrates sensing for data collection, action recognition and simulation modeling for productivity and ergonomic analysis, and point cloud model generation and human motion animation for output visualization. The proposed framework is demonstrated through a case study using data from an off-site construction job site. The results indicate that integrating the various techniques can facilitate the assessment of manual operations and thereby enhance the implementation of ergonomic practices during a construction project by reducing the time, effort, and complexity required to apply the techniques.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The acceptance of the clinical photographic posture assessment tool (CPPAT)\n",
            "Authors: Fortin C.\n",
            "Abstract: Background: There is a lack of evidence-based quantitative clinical methods to adequately assess posture. Our team developed a clinical photographic posture assessment tool (CPPAT) and implemented this tool in clinical practice to standardize posture assessment. The objectives were to determine the level of acceptance of the CPPAT and to document predictors as well as facilitators of and barriers to the acceptance of this tool by clinicians doing posture re-education. Methods: This is a prospective study focussing on technology acceptance. Thirty-two clinician participants (physical therapists and sport therapists) received a 3-5 h training workshop explaining how to use the CPPAT. Over a three-month trial, they recorded time-on-task for a complete posture evaluation (photo - and photo-processing). Subsequently, participants rated their acceptance of the tool and commented on facilitators and barriers of the clinical method. Results: Twenty-three clinician participants completed the trial. They took 22 (mean) ± 10 min (SD) for photo acquisition and 36 min ± 19 min for photo-processing. Acceptance of the CPPAT was high. Perceived ease of use was an indirect predictor of intention to use, mediated by perceived usefulness. Analysis time was an indirect predictor, mediated by perceived usefulness, and a marginally significant direct predictor. Principal facilitators were objective measurements, visualization, utility, and ease of use. Barriers were time to do a complete analysis of posture, quality of human-computer interaction, non-automation of posture index calculation and photo transfer, and lack of versatility. Conclusion: The CPPAT is perceived as useful and easy to use by clinicians and may facilitate the quantitative analysis of posture. Adapting the user-interface and functionality to quantify posture may facilitate a wider adoption of the tool.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Sentiment analysis in organizational work: Towards an ontology of people analytics\n",
            "Authors: Gelbard R.\n",
            "Abstract: The present paper proposes a conceptual ontology to evaluate human factors by modelling their key performance indicators and defining these indicators' explanatory factors, manifestations, and diverse corresponding digital footprints. Our methodology incorporates 6 main human resource constructs: performance, engagement, leadership, workplace dynamics, organizational developmental support, and learning and knowledge creation. Using sentiment analysis, we introduce a potential way to evaluate several components of the proposed human factors ontology. We use the Enron email corpus as a test case, to demonstrate how digital footprints can predict such phenomena. In so doing, we hope to encourage further research applying data mining techniques to allow real-time, less costly, and more reliable assessments of human factor patterns and trends.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Quantifying the physical intensity of construction workers, a mechanical energy approach\n",
            "Authors: Kong L.\n",
            "Abstract: Construction workers typically undertake highly demanding physical tasks involving various types of stresses from awkward postures, using excessive force, highly repetitive actions, and excessive energy expenditure, which increases the likelihood of unsafe actions, productivity loss, and human errors. Biomechanical models have been developed to estimate joint loadings, which can help avoid strenuous physical exertion, potentially enhancing construction workforce productivity, safety, and well-being. However, the models used are mainly in 2D, or to predict static strength ignored their velocity and acceleration or using marker-based method for dynamic motion data collection. To address this issue, this paper proposes a novel framework for investigating the mechanical energy expenditure (MEE) of workers using a 3D biomechanical model based on computer vision-based techniques. Human 3D Pose Estimation algorithm based on 2D videos is applied to approximate the coordinates of human joints for working postures, and smart insoles are used to collect foot pressures and plantar accelerations, as input data for the biomechanical analyses. The results show a detailed MEE rate for the whole body, at which joints the maximum and minimum values were obtained to avoid excessive physical exertion. The proposed method can approximate the total daily MEE of construction tasks by summing the assumed cost of individual tasks (such as walking, lifting, and stooping), providing suggestions for the design of a daily workload that workers can sustain without developing cumulative fatigue.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Towards efficient and objective work sampling: Recognizing workers’ activities in site surveillance videos with two-stream convolutional networks\n",
            "Authors: Luo X.\n",
            "Abstract: Capturing the working states of workers on foot allows managers to precisely quantify and benchmark labor productivity, which in turn enables them to evaluate productivity losses and identify causes. Work sampling is a widely used method for this task, while suffers from low efficiency as only one worker is selected for each observation. Attentional selection asymmetry can also bias its uniform object selection assumption. Existing vision-based methods are primarily oriented towards recognizing single, separated activities involving few workers or equipment. In this paper, we introduce an activity recognition method, which receives surveillance videos as input and produces diverse and continuous activity labels of individual workers in the field of view. Convolutional networks are used to recognize activities, which are encoded in spatial and temporal streams. A new fusion strategy is developed to combine the recognition results of the two streams. The experimental results show that our activity recognition method has achieved an average accuracy of 80.5%, which is comparable with the state-of-the-art of activity recognition in the computer vision community, given the severe camera motion and low resolution of site surveillance videos and the marginal inter-class difference and significant intra-class variation of workers’ activities. We also demonstrate that our method can underpin the implementation of efficient and objective work sampling. The training and test datasets of the study are publicly available.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Convolutional neural networks: Computer vision-based workforce activity assessment in construction\n",
            "Authors: Luo H.\n",
            "Abstract: Computer vision approaches have been widely used to automatically recognize the activities of workers from videos. While considerable advancements have been made to capture complementary information from still frames, it remains a challenge to obtain motion between them. As a result, this has hindered the ability to conduct real-time monitoring. Considering this challenge, an improved convolutional neural network (CNN) that integrates Red-Green-Blue (RGB), optical flow, and gray stream CNNs, is proposed to accurately monitor and automatically assess workers’ activities associated with installing reinforcement during construction. A database containing photographs of workers installing reinforcement is created from activities undertaken on several construction projects in Wuhan, China. The database is then used to train and test the developed CNN network. Results demonstrate that the developed method can accurately detect the activities of workers. The developed computer vision-based approach can be used by construction managers as a mechanism to assist them to ensure that projects meet pre-determined deliverables.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic posture recognition using 3D view-invariant features from single ordinary camera\n",
            "Authors: Zhang H.\n",
            "Abstract: Manual construction tasks are physically demanding, requiring prolonged awkward postures that can cause pain and injury. Person posture recognition (PPR) is essential in postural ergonomic hazard assessment. This paper proposed an ergonomic posture recognition method using 3D view-invariant features from a single 2D camera that is non-intrusive and widely installed on construction sites. Based on the detected 2D skeletons, view-invariant relative 3D joint position (R3DJP) and joint angle are extracted as classification features by employing a multi-stage convolutional nerual network (CNN) architecture, so that the learned classifier is not sensitive to camera viewpoints. Three posture classifiers regarding arms, back, and legs are trained, so that they can be simultaneously classified in one video frame. The posture recognition accuracies of three body parts are 98.6%, 99.5%, 99.8%, respectively. For generalization ability, the relevant accuracies are 94.9%, 93.9%, 94.6%, respectively. Both the classification accuracy and generalization ability of the method outperform previous vision-based methods in construction. The proposed method enables reliable and accurate postural ergonomic assessment for improving construction workers' safety and healthy.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Accuracy of a novel marker tracking approach based on the low-cost Microsoft Kinect v2 sensor\n",
            "Authors: Timmi A.\n",
            "Abstract: Microsoft Kinect for Windows v2 is a motion analysis system that features a markerless human pose estimation algorithm. Given its affordability and portability, Kinect v2 has potential for use in biomechanical research and within clinical settings; however, recent studies suggest high inaccuracy of the markerless algorithm compared to marker-based motion capture systems. A novel tracking method was developed using Kinect v2, employing custom-made colored markers and computer vision techniques. The aim of this study was to test the accuracy of this approach relative to a conventional Vicon motion analysis system, performing a Bland–Altman analysis of agreement. Twenty participants were recruited, and markers placed on bony prominences near hip, knee and ankle. Three-dimensional coordinates of the markers were recorded during treadmill walking and running. The limits of agreement (LOA) of marker coordinates were narrower than − 10 and 10 mm in most conditions, however a negative relationship between accuracy and treadmill speed was observed along Kinect depth direction. LOA of the surrogate knee angles were within − 1.8° 1.7° for flexion in all conditions and − 2.9° 1.7° for adduction during fast walking. The proposed methodology exhibited good agreement with a marker-based system over a range of gait speeds and, for this reason, may be useful as low-cost motion analysis tool for selected biomechanical applications.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Classification of children's sitting postures using machine learning algorithms\n",
            "Authors: Kim Y.M.\n",
            "Abstract: Sitting on a chair in an awkward posture or sitting for a long period of time is a risk factor for musculoskeletal disorders. A postural habit that has been formed cannot be changed easily. It is important to form a proper postural habit from childhood as the lumbar disease during childhood caused by their improper posture is most likely to recur. Thus, there is a need for a monitoring system that classifies children's sitting postures. The purpose of this paper is to develop a system for classifying sitting postures for children using machine learning algorithms. The convolutional neural network (CNN) algorithm was used in addition to the conventional algorithms: Naïve Bayes classifier (NB), decision tree (DT), neural network (NN), multinomial logistic regression (MLR), and support vector machine (SVM). To collect data for classifying sitting postures, a sensing cushion was developed by mounting a pressure sensor mat (8 × 8) inside children's chair seat cushion. Ten children participated, and sensor data was collected by taking a static posture for the five prescribed postures. The accuracy of CNN was found to be the highest as compared with those of the other algorithms. It is expected that the comprehensive posture monitoring system would be established through future research on enhancing the classification algorithm and providing an effective feedback system.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A conceptual framework of ITSMCA for a building collapse accident\n",
            "Authors: Yan X.\n",
            "Abstract: Purpose: The purpose of this paper is to timely control of a construction collapse accident effectively during its development process by constructing a stage model and then aligning IT with each stage to help provide the information for decision making. Design/methodology/approach: Through comprehensive literature review, this paper first identifies the various IT applications in on-site construction monitoring and analyzes the existed disaster/crisis stage models, also the stage models are compared with the causation models to illustrate the strengths. Then, a three-step methodology was conducted to develop and apply the conceptual framework, including the construction of the four-stage model; the establishment of the conceptual framework of information technology (IT) support for management of construction accidents (ITSMCA); and a building collapse accident used to illustrate the proposed framework. Findings: The accident is divided into four stages, which are incubation stage, outbreak stage, spreading stage and final stage. The real-time staged information to support decision making, such as the contributing factors of on-site workers, materials, equipment and workplace, can be provided by emerging IT. Therefore, IT is aligned with the variations of contributing factors’ attributes in the four stages and ITSMCA is constructed to help accidents management. Research limitations/implications: The focus of the framework presented in this paper is that the stage model is effective for it catches the variations of the attributes whose values can be provided by IT rather than research on the practical application of the IT system. The construction and application of the IT system will be the research focus in the future. Originality/value: This paper presents a stage model of a building collapse accident and gives a comprehensive conceptual framework of ITSMCA, which align the IT with different stages of the collapse accident. The ITSMCA proposes a feasible ideology and practical method for real-time management of the collapse accident during the process.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Design and implementation of ergonomic risk assessment feedback system for improved work posture assessment\n",
            "Authors: Mgbemena C.E.\n",
            "Abstract: Ergonomic risk factors which include force, repetition and awkward postures, can result in Work-Related Musculoskeletal Disorders (WMSDs) among workers. Hence, systems that provide real-time feedback to the worker concerning his current ergonomic behaviours are desirable. This paper presents the design and implementation of a human-machine interface posture assessment feedback system whose conceptual model is developed through a model-driven development perspective using the Unified Modeling Language (UML) and interface flow diagrams. The resulting system provides a shop floor with a simple, cost-effective and automatic tool for real-time display of worker's postures. Testing the system on volunteer participants reveals that it is easy to use, achieves real-time posture assessment and provides easy-to-understand feedback to workers. This system may be useful for reducing the rate of occurrence of awkward postures, one of the contributing factors to risk of WMSDs among workers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Wearable DAQ (Data Acquisition System) for Measurement of R.U.L.A.(Rapid Upper Limb Assessment) Rating of Vehicles\n",
            "Authors: Doshi M.\n",
            "Abstract: R.U.L.A.(Rapid Upper Limb Assessment)is a measure of the ergonomic risk factors developed to evaluate the exposure of individual workers to upper extremity Musculoskeletal Disorders. Since a driver has to drive for long hours while maintaining his composure and comfort, this can be ensured by following R.U.L.A as ergonomics is one of the most crucial factors for chassis design of vehicles. R.U.L.A. calculation is usually performed using software only, in this paper we have designed a wearable data acquisition system which measures posture and angle values of the driver's body and gives us an accurate R. U. L.A. rating of the driver in order to validate and compare the software simulation values as obtained on Catia.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Falls from heights: A computer vision-based approach for safety harness detection\n",
            "Authors: Fang W.\n",
            "Abstract: Falls from heights (FFH) are major contributors of injuries and deaths in construction. Yet, despite workers being made aware of the dangers associated with not wearing a safety harness, many forget or purposefully do not wear them when working at heights. To address this problem, this paper develops an automated computer vision-based method that uses two convolutional neural network (CNN) models to determine if workers are wearing their harness when performing tasks while working at heights. The algorithms developed are: (1) a Faster-R-CNN to detect the presence of a worker; and (2) a deep CNN model to identify the harness. A database of photographs of people working at heights was created from activities undertaken on several construction projects in Wuhan, China. The database was then used to test and train the developed networks. The precision and recall rates for the Faster R-CNN were 99% and 95%, and the CNN models 80% and 98%, respectively. The results demonstrate that the developed method can accurately detect workers not wearing their harness. Thus, the computer vision-based approach developed can be used by construction and safety managers as a mechanism to proactively identify unsafe behavior and therefore take immediate action to mitigate the likelihood of a FFH occurring.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The amount of postural change experienced by adolescent computer users developing seated –related upper quadrant musculoskeletal pain\n",
            "Authors: Brink Y.\n",
            "Abstract: Background: Improved techniques of measuring sitting posture have not led to a more comprehensive understanding of poor posture, nor its association with pain. There is also an evidence gap regarding critical thresholds of sitting postural change over time related to pain production. This paper describes postural angle changes over a 12-month period, and describes the process of placing defensible cut-points in the angle change data, to better understand associations between posture change over time, and onset of upper quadrant musculoskeletal pain (UQMP). Methods: This paper reports on data captured at baseline and 12-month follow-up, in adolescents in school using computers. Four sitting postural angles, head flexion (HF), neck flexion (NF), craniocervical angle (CCA) and trunk flexion (TF), and self-reported seated UQMP in the previous month were captured at each time-point. Research questions were: 1) What is the magnitude and direction of change in each postural angle over 12 months? 2) What are best cut-points in the continuous posture change distribution to most sensitively test the association between posture change and UQMP? 3) Is gender-specific cut-points required? The 12-month posture angle change data was divided into quintiles (0–20th%; 21-40 th %, 41-60 th %, 61-80 th %, >80 th %), and the odds of UQMP occurring in each posture change quintile were calculated using logistic regression models. Results: Two hundred and eleven students participated at baseline, of which 153 were followed-up at one year. Both males and females with postural change into extension (which represents lesser flexion range) were more at risk for the development of UQMP, than any other group. The best cut-point for HF was 40 th % (≤−3.9°), NF was 20th% (≤−2.9°) and TF was 40 th % (≤−1.1°). For CCA however, change at or beyond 40 th % for extension or beyond 60% for flexion was associated with UQMP. Conclusions: Identification of critical postural angle change cut-points assists in considering the pain-producing mechanisms for adolescents using desk top computers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An Inexpensive 6D Motion Tracking System for Posturography\n",
            "Authors: Figtree W.V.C.\n",
            "Abstract: Computerized posturography is most often performed with a force plate measuring center-of-pressure (COP). COP is related to postural control actions but does not monitor the outcome of those actions, i.e., center-of-mass (COM) stability. For a more complete analysis of postural control COM should also be measured; however, existing motion tracking technology is prohibitively expensive and overcomplicated for routine use. The objective of this work was to create and validate an inexpensive and convenient stereo vision system which measured a trunk-fixed target's 3D position and orientation relating to COM. The stereo vision system would be complementary to typical force plate methods providing precise 6D position measurements under laboratory conditions. The developed system's measurement accuracy was worst in the inferior-superior axis (depth) and pitch coordinates with accuracy measures 1.1 mm and 0.8°, respectively. The system's precision was worst in the depth and roll coordinates with values 0.1 mm and 0.15°, respectively. Computer modeling successfully predicted this precision with 11.3% mean error. Correlation between in vivo target position (TP) and COP was above 0.73 with COP generally demonstrating larger excursions oscillating around TP. Power spectral analysis of TP revealed 99% of the signal was bound below 1.1 Hz matching expectations for COM. The new complementary measurement method enables identification of postural control strategies and as a result more complete analysis. Stereo vision is a useful complement to typical force plate equipment. The system presented here is inexpensive and convenient demonstrating potential for routine use in clinic and research. In order to use this system in clinic, future work is required in interpretation of this system's data and normal reference values must be established across gender and age in a healthy population followed by values from patients with different pathologies.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Risk factors identification and visualization for work-related musculoskeletal disorders with wearable and connected gait analytics system and kinect skeleton models\n",
            "Authors: Chen D.\n",
            "Abstract: Risk factors, such as overexertion, awkward postures, excessive repetition, and the combination of these factors are main causes of work-related musculoskeletal disorders (WMSDs). In this paper, we proposed an automatic WMSDs risk factors identification and visualization method based on Wearable and Connected Gait Analytics System (WCGAS) and Kinect skeleton models. WCGAS was capable of recording plantar pressure from which postures, force exertions, and repetitions could be recognized with algorithms such as sequential minimal optimization (SMO) algorithm and long short term memory (LSTM) network. Kinect skeleton models were used to make the WMSDs risk factors visualized. Experiments with quasi-static and sequential postures were designed to evaluate the recognition performance of work-related motion type (i.e. “lifting” “carrying” “bending” “pulling” and “pushing”). A load variable (with/without 10 kg load) was introduced for evaluating the performance of force exertions recognition. 5 repetitions of each motion were used for evaluating the performance of repetitions recognition. Results showed that quasi-static postures could be recognized with 100% accuracy and the accuracy for sequential motions recognition were 74%, 79%, 92%, 99% and 99% for “bending” “carrying” “lifting” “pulling” and “pushing” respectively. Force exertions were recognized with 100% accuracy. For repetitions recognition, except the accuracy in the “bending” motion was 80%, the repetitions of other motions could be recognized correctly. Kinect skeleton model showed its ability of making the WMSDs risk factors vivid which would contribute to the accuracy of WMSDs risks evaluation. These results indicated that it is possible to use WCGAS and Kinect skeleton models for WMSDs risk factors identification and visualization applications.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Hip and trunk kinematics estimation in gait through kalman filter using IMU data at the ankle\n",
            "Authors: Baghdadi A.\n",
            "Abstract: The purpose of this paper is to provide a new method of estimating the hip acceleration and trunk posture in the sagittal plane during a walking task using an extended Kalman filter (EKF) and an unscented Kalman filter (UKF). A comparison between these two estimation techniques is also provided. Considering the periodic nature of gait, a modified biomechanical model with Fourier series approximations are utilized as a priori knowledge. Inertial measurement units (IMUs) are placed on the right side of the ankle, hip, and middle of the trunk of twenty recruited participants, as input, a posteriori data, and the ground truth for the model, separately. The results show a better performance of the EKF in estimating the hip acceleration (6.5% error) and the trunk posture (3.12% error). Moreover, both the EKF and the UKF provide low error rates for the trunk posture in comparison to the hip acceleration. This paper provides an inexpensive and novel method to estimate and filter the kinematics of motion for different body locations from a single accurate IMU attached to the ankle considering the periodic nature of gait that can be extended to other activities as well as real-time applications.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Shoe-insole technology for injury prevention in walking\n",
            "Authors: Nagano H.\n",
            "Abstract: Impaired walking increases injury risk during locomotion, including falls-related acute injuries and overuse damage to lower limb joints. Gait impairments seriously restrict voluntary, habitual engagement in injury prevention activities, such as recreational walking and exercise. There is, therefore, an urgent need for technology-based interventions for gait disorders that are cost effective, willingly taken-up, and provide immediate positive effects on walking. Gait control using shoe-insoles has potential as an effective population-based intervention, and new sensor technologies will enhance the effectiveness of these devices. Shoe-insole modifications include: (i) ankle joint support for falls prevention; (ii) shock absorption by utilising lower-resilience materials at the heel; (iii) improving reaction speed by stimulating cutaneous receptors; and (iv) preserving dynamic balance via foot centre of pressure control. Using sensor technology, such as in-shoe pressure measurement and motion capture systems, gait can be precisely monitored, allowing us to visualise how shoe-insoles change walking patterns. In addition, in-shoe systems, such as pressure monitoring and inertial sensors, can be incorporated into the insole to monitor gait in real-time. Inertial sensors coupled with in-shoe foot pressure sensors and global positioning systems (GPS) could be used to monitor spatiotemporal parameters in real-time. Real-time, online data management will enable ‘big-data’ applications to everyday gait control characteristics.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Recognizing Diverse Construction Activities in Site Images via Relevance Networks of Construction-Related Objects Detected by Convolutional Neural Networks\n",
            "Authors: Luo X.\n",
            "Abstract: Timely and overall knowledge of the states and resource allocation of diverse activities on construction sites is critical to resource leveling, progress tracking, and productivity analysis. Despite its importance, this task is still performed manually. Previous studies have taken a significant step forward in introducing computer vision technologies, although they have been oriented toward limited classes of objects or limited types of activities. Furthermore, they especially focus on single activity recognition, where an image contains only the execution of an activity by one or a few objects. This paper introduces a two-step method for recognizing diverse construction activities in still site images. It detects 22 classes of construction-related objects using convolutional neural networks. With objects detected, semantic relevance representing the likelihood of the cooperation or coexistence between two objects in a construction activity, spatial relevance representing the two-dimensional pixel proximity in the image coordinates, and activity patterns are defined to recognize 17 types of construction activities. The advantage of the proposed method is its potential to recognize diverse concurrent construction activities in a fully automatic way. Therefore, it is possible to save managers' valuable time in manual data collection and concentrate their attention on solving problems that necessarily demand their expertise.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Dynamic Evaluation and Treatment of the Movement Amplitude Using Kinect Sensor\n",
            "Authors: Da Cunha Neto J.S.\n",
            "Abstract: This paper presents a hybrid solution (software and hardware) integrating the computer and the Kinect sensor. The proposed solution, named GoNet v2, is an instrument for the dynamic and automatic evaluation of biomechanical rehabilitation processes. Experimental tests to evaluate the range of motion of body joints, especially for elbow flexion, elbow extension, shoulder abduction, shoulder flexion, radial deviation, and ulnar deviation, are presented and discussed. We also presented the exergamers for rehabilitation tests, based on Kabat diagonal and squatting. Ten healthy individuals were evaluated using the GoNet v2 and the universal goniometer, and twelve professionals evaluated the instrument through a survey. The intraclass correlation coefficient (ICC) was used to analyze the reproducibility, and for the accuracy analysis the errors were compared using the mean of the worst cases with movement. Regarding intra-examiner and inter-examiner reproducibility, high ICC values were found for the range of flexion/extension of the shoulder, abduction of the shoulder, and ulnar deviation, thus showing its optimum precision. According to the evaluation of the specialists, the GoNet v2 gave better results for the flexion/extension of the shoulder (3.61%) and elbow (3.17%), and also the abduction (2.11%) of the shoulder compared with the goniometer. The results showed that the GoNet v2 had a high reproducibility, except for radial deviation. The accuracy results were good for the abduction measurements of the shoulder and the flexion/extension measurements of the elbow and shoulder.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Electronic Assessment of Physical Decline in Geriatric Cancer Patients\n",
            "Authors: Fallahzadeh R.\n",
            "Abstract: Purpose of Review: The purpose of this review is to explore state-of-the-art remote monitoring and emerging new sensing technologies for in-home physical assessment and their application/potential in cancer care. In addition, we discuss the main functional and non-functional requirements and research challenges of employing such technologies in real-world settings. Recent Findings: With rapid growth in aging population, effective and efficient patient care has become an important topic. Advances in remote monitoring and in its forefront in-home physical assessment technologies play a fundamental role in reducing the cost and improving the quality of care by complementing the traditional in-clinic healthcare. However, there is a gap in medical research community regarding the applicability and potential outcomes of such systems. Summary: While some studies reported positive outcomes using remote assessment technologies, such as web/smart phone-based self-reports and wearable sensors, the cancer research community is still lacking far behind. Thorough investigation of more advanced technologies in cancer care is warranted.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automated Fiducial Points Detection Using Human Body Segmentation\n",
            "Authors: Rajbdad F.\n",
            "Abstract: Accurately detected human body fiducial points provide an easy and efficient method for human body posture analysis and the extraction of anthropometric parameters. In the proposed work, an efficient algorithm for automated and accurate detection of fiducial points is developed for both the frontal and the lateral images. An algorithm for automatic human body segmentation of the frontal image is also developed using automatically detected set of primary fiducial points. Additional fiducial points are obtained by applying peak and valley algorithm on the silhouettes of each segment. The detection accuracy of the automatically detected fiducial points is calculated by comparing their locations with the manually marked fiducial points. The proposed algorithm is tested on 45 subjects including both male and female genders and variable Body Mass Indexes. In most cases, the algorithm successfully detects seventy fiducial points for each subject in the testing set. A quantitative analysis of the error in the position of the detected fiducial points shows that the algorithm performs better than the state-of-the-art algorithms found in the existing literature. In the evaluation of the algorithm, the percentage accuracy of the detected fiducial points is calculated and it is observed that the proposed algorithm performs better for the majority of the fiducial points.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Real-time simulation of construction workers using combined human body and hand tracking for robotic construction worker system\n",
            "Authors: Kurien M.\n",
            "Abstract: Construction is an inherently less safe sector than other sectors because it exposes workers to harsh and dangerous working environments. The nature of the construction industry results in a comparatively high incidence of serious injuries and death caused by falls from a height, musculoskeletal disorders and being struck by objects. This paper presents a new concept that can tackle this problem in the future. The central hypothesis of this study is that it is possible to eliminate injuries if we move the human construction worker off-site and remotely link his/her motions to a Robotic Construction Worker (RCW) on-site. As a first steppingstone towards this ultimate goal, two systems essential for the RCW were developed in this study. First, a novel system that combines 3D body and hand position tracking was developed to capture the movements of human construction worker. This combination of tracking enables the capture of changes in the orientations and articulations of the entire human body. Second, a real-time simulation system that connects a human construction worker off-site to a virtual RCW was developed to demonstrate the proposed concept in a variety of construction scenarios. The simulation results demonstrate the future viability of the RCW concept and indicate the promise of this system for eliminating the health and safety risks faced by human construction workers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A deep hybrid learning model to detect unsafe behavior: Integrating convolution neural networks and long short-term memory\n",
            "Authors: Ding L.\n",
            "Abstract: Computer vision and pattern recognition approaches have been applied to determine unsafe behaviors on construction sites. Such approaches have been reliant on the computation of artificially complex image features that utilize a cumbersome parameter re-adjustment process. The creation of image features that can recognize unsafe actions, however, poses a significant research challenge on construction sites. This due to the prevailing complexity of spatio-temporal features, lighting, and the array of viewpoints that are required to identify an unsafe action. Considering these challenges, a new hybrid deep learning model that integrates a convolution neural network (CNN) and long short-term memory (LSTM) that automatically recognizes workers' unsafe actions is developed. The proposed hybrid deep learning model is used to: (1) identify unsafe actions; (2) collect motion data and site videos; (3) extract the visual features from videos using a CNN model; and (4) sequence the learning features that are enabled by the use of LSTM models. An experiment is used to test the model's ability to detect unsafe actions. The results reveal that the developed hybrid model (CNN + LSTM) is able to accurately detect safe/unsafe actions conducted by workers on-site. The model's accuracy exceeds the current state-of-the-art descriptor-based methods for detecting points of interest on images.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Estimating construction workers’ physical workload by fusing computer vision and smart insole technologies\n",
            "Authors: Yu Y.\n",
            "Abstract: Construction workers are commonly subjected to ergonomic risks due to awkward postures and/or excessive manual material handling. Accurate ergonomic assessment will facilitate ergonomic risk identification and the subsequent mitigation. Traditional assessment methods such as visual observation and on-body sensors rely on subjective judgement and are intrusive in nature. To cope up with the limitations of the existing technologies, a computer vision and smart insole-based joint-level ergonomic workload calculation methodology is proposed for construction workers. Accordingly, this method could provide an objective and detailed ergonomic assessment for various construction tasks. Firstly, construction workers’ skeleton data is extracted using a smartphone camera with an advanced deep learning algorithm. Secondly, smart insoles are used to quantify the plantar pressures while the worker performs a construction activity. Finally, the gathered data is fed to an inverse dynamic model in order to calculate the joint torques and workloads. The aforementioned approach was tested with experiments comprising simulations of material handling, plastering and rebar. The results reveal that the developed methodology has the potential to provide detailed and accurate ergonomic assessment. Overall, this research contributes to the knowledge of occupational safety and health in construction management by providing a novel approach to assess the risk factors of work-related musculoskeletal disorders (WMSDs).\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Upper limb joints and motions sampling system using Kinect camera\n",
            "Authors: Albawab T.M.M.\n",
            "Abstract: The needs of research on human posture and its joint-motion relationships are important. Providing a real-time postural measurement tool has attracted the attention of many human postural-related researchers. This study has developed and performed a validation analysis on a new innovative system for sampling and finding the angles of motions of each posture with its related joints using Kinect camera. The validation investigated the static and dynamic accuracy analyses by comparing to a Jamar goniometer and ErgoFellow system. The results showed that Mean Absolute Errors of Kinect in static and dynamic motions are 15.12% and 45.33% respectively. It is concluded that the postural measurement system developed by this study requires further improvements.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Research on office chair based on modern office posture\n",
            "Authors: Sun X.\n",
            "Abstract: The office sitting position of the staff is closely related to the design of the office chair. We use the dynamic capture system of Microsoft Kinect sensor to study office sitting posture, in order to capture sitting posture and form three-dimensional coordinate data and RGB images, and then with the help of GBR and FCM methods to cluster Kinect data in MTATLAB data analysis software, getting the average sitting posture and sitting position type and transformation rules. The results show that there are four types of office posture. The data shows that these four types of postures can be divided into skill posture, adaptive posture and initiative attitude, and then analyzed corresponding task scene, office tasks and office equipment. Category 1 posture scenario is using computer, which belongs to the skill posture. Category 2 posture scene is mobile working, which is initiative attitude; Category 3 posture scene is to talking on the phone, belonging to the adaptive posture; Category 4 pose is a rest scene, belonging to the adaptive posture. The time of Category 1 of changing sitting position is 11.6 min; The time of Category 2 of changing sitting position is 13.7 min; the time of Category 3 of changing sitting position is 2.8 min; the time of Category 4 of changing sitting position is 17.2 min.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Mapping the usage of technology in construction worker safety research\n",
            "Authors: Subedi S.\n",
            "Abstract: Real-time construction site monitoring requires real-time tracking of resources. Recent researches in real-time data collection have transformed traditional construction practices and skyrocketed productivity, safety and quality on site while serving as a basis for tremendous cost savings. This paper studies available literature to identify and map several types of real-time data that can be collected directly on a construction site or indirectly when real-time automated data collection is not feasible and human intervention is required to record desired information. This paper will focus on construction safety and classify the factors that pertain to worker safety. Systematic Literature Review (SLR) method will be used to map the factors and technologies that have been tested on sites for construction safety. This paper will explore both hard data (like location and physiological status) and soft data (like attitude and experience of workers, and information pertaining to safety training and safety culture in an organization). This paper will serve as an index for researchers and practitioners working on construction safety or wanting to learn about real-time construction worker safety research. The maps resulting from this study will serve as a guide to understand what data types are required for a specific problem, how to collect them and how the data can be analyzed. Such maps can potentially reveal trends in automation and technologies use in construction safety research with respect to time.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Risk driving behaviors detection using pressure cushion\n",
            "Authors: Yang Z.\n",
            "Abstract: With the increasing frequency of traffic accidents, traffic safety has attracted attention of the researchers. Most of the traffic accidents are related to the driver’s risky behavior or some improper driving habits, such as leaning against the window/door, picking up things, or looking backwards when driving at high speed. In this paper, to detect such risky behaviors, we propose a decision tree for classification that recognizes four kinds of driving behaviors: normal driving, looking backwards, leaning against the window and picking up things. A time series of pressure data were measured from a mat with 2 × 2 pressure sensors which are distributed on the driver seat. Regarding the preprocessing phase, a digital filter is used for noise reduction. Results show that our method can achieve an average recognition rate of 88.25%.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Biobjective Model for Manual Materials Handling with Energy Consumption Being Accounted for\n",
            "Authors: Zhang W.\n",
            "Abstract: Aiming at production environment and operation design in manual materials handling which often overlook workers' physiological factors and cause fatigue, even work-related musculoskeletal disorders, we construct a biobjective model based on economics and ergonomics. In the model, two objectives include functions about handling time and energy consumption. Based on the openness of IGRIP/ERGO simulation software combined with MATLAB, we design and develop the interactive simulation platform, where program language can be automatically generated. Then, we analyze the case about handling operations in an automobile brake pad manufacturing company, and the number of input materials and process scheduling are taken as research objects. Finally, the results show that the win-win optimal solution can be usually obtained between productivity and ergonomics for decision makers according to the proposed biobjective model. Moreover, the case study demonstrates that the interactive simulation platform can be devoted to providing the solution for modern production operation directly and conveniently, which can make the production environment and operation design in accordance with ergonomics.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Towards a data-driven approach to injury prevention in construction\n",
            "Authors: Zhao J.\n",
            "Abstract: The research discussed in this paper is part of a project directed at increasing productivity in construction through mitigating the risk of Musculoskeletal Disorders (MSD). Postures and activities recognition through motion capturing techniques have shown promising potential for monitoring, assessing, and reducing such risks. Current motion sensing systems require a complex whole-body senor placement to capture and recognize construction activities, which limits the practicality and requires great computational effort. This challenge can be addressed through using a machine learning approach that recognizes specific activities from human motion data. The feasibility of reducing the computational effort through using fewer sensors rather than whole-body sensor placement was assessed through a case study. Five sensors were placed in targeted motion areas. The authors propose a novel automatic model configuration process to improve recognition performance under the selected sensor placement. It is based on designing optimal combination of data segmentation window size, feature sets, and classification algorithms for a specific set of injury-prone construction activities. The proposed approach achieved an average overall recognition accuracy of 0.81 and 0.74 for two sets of activities. The recognition model operation time is also reduced to less than 0.01 s under the proposed approach. In this initial case study, the model configuration process was developed iteratively based on the output from the test case. In subsequent efforts, the authors will develop a generic activity recognition model with predefined rules and criteria. This will further accelerate and automate the model configuration process.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Assessing the effects of tool-loading formation on construction workers' postural stability\n",
            "Authors: Jebelli H.\n",
            "Abstract: Falls are a leading cause of fatal and nonfatal injuries in construction. One of the most important steps toward preventing falls is to identify and measure the factors that can affect the construction workers' fall risk. While several intrinsic and extrinsic factors can affect workers' fall risk - such as the effects of aging workers, job site environments, walking habits, workers' experience, and workers' equipment - one unexpected factor that can increase fall risk is the incorrect use of personal protective equipment - including safety harnesses - since when these safety tools are misapplied, they cause instability in the workers' body. The objective of this study was to assess the effects of the formation of tools connected to construction workers' full body harnesses on the fall risk of construction workers. Using the time-series quantitative kinematic measures obtained from inertial measurement units (IMUs) connected to the workers' waistline, the postural stability of a group of subjects was measured by calculating the velocity of Center of Pressure (COPv) and the resultant Accelerometer (rAcc) - lower rAcc and COPv values mean lower fall risk for construction workers. The postural stability for each worker was calculated for two different postures (standing and squatting) and three different formations of the tools attached to the full-body harness. The t-tests' results in the mean values of the calculated rAcc and COPv showed significant differences in the postural stability of subjects with different formations of tools connected to the full body harness. When tools were not connected, workers had the lowest rAcc and COPv values; asymmetric loading formations' rAcc and COPv had higher values than symmetric loading formations. The higher risk caused by asymmetric connected-tools formation express the importance of tools attaching formation to construction workers' safety.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An approach for skeleton fitting in long-Wavelength infrared images first results for a robust head localisation using probability masks\n",
            "Authors: Richter J.\n",
            "Abstract: Human skeleton extraction has become a key instrument for motion analysis in the fields of surveillance, entertainment and medical diagnostics. While a vast amount of research has been carried out on skeleton extraction using RGB and depth images, far too little attention has been paid to extraction methods using long-wavelength infrared images. This paper provides an overview about existing approaches and explores their limitations. So far, extant studies have exploited thermal data only for silhouette generation as a pre-processing step. Moreover, they make strong assumptions, such as T-pose initialization. On this basis, we are developing an algorithm to fit the joints of a skeleton model into thermal images without such restrictions. We propose to find the head location as an initial step by using probability masks. These masks are designed to allow a robust head localisation in unrestricted settings. For the future algorithm design, we plan to localise the remaining skeleton joints by means of geometrical constraints. At this point, we will also consider sequences where persons wear thick clothes, which is aggravating the extraction procedure. This paper presents the current state of this project and outlines further approaches that have to be investigated to extract the complete skeleton.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic assessment of working postures for the design of university computer workstations\n",
            "Authors: Chowdhury N.\n",
            "Abstract: BACKGROUND: There is an extensive body of research reviewing the ergonomics needs of industrial office workers. However, very few studies have considered evaluating the working postures of students or professors in universities who are exposed to prolonged sitting while working at a computer workstation. OBJECTIVE: The purpose of the study was threefold: (1) to determine the major ergonomic issues university employees encounter while working at computer workstations, (2) to compare the two ergonomic assessment tools (RULA and REBA) to see how similarly or differently they assess the risks present in the same working condition and (3) to develop a model that correlates working condition, work posture and computer workstation design with their negative effects on musculoskeletal system. METHODS: This research was constituted of a comprehensive survey (5 minutes) and a quantitative risk assessment session (20 minutes) conducted over 72 university personnel and their workstations in a university workplace. Along with a pre-assessment questionnaire; the Cornell Musculoskeletal Discomfort Questionnaire (CMDQ) and two ergonomic assessment tools namely Rapid Entire Body Assessment (REBA) and Rapid Upper Limb Assessment (RULA) were used to quantify the ergonomic risk factors. To evaluate the computer workstations \"OSHA Computer Workstations eTool-Evaluation Checklist\" was used. RESULTS: The upper limbs of computer workstation users seem to be more prone to Work-related Musculoskeletal Disorders (WMSD) and Repetitive Stress Injuries (RSI) symptoms. In 85.5% of cases, RULA scores were the same or more than that of REBA, which indicates work of office employees may cause a disorder more in the upper limbs than the lower limbs. CONCLUSIONS: Alignment of the monitor was found to be the most significant design parameter. Among different body parts, trunk was the most affected one, as a result of poor posture and/or workplace design followed by shoulder and upper arm, and forearm and wrist.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: 3D Visualization-Based Ergonomic Risk Assessment and Work Modification Framework and Its Validation for a Lifting Task\n",
            "Authors: Li X.\n",
            "Abstract: The construction manufacturing industry in North America has a disproportionately high number of lost-time injuries because of the high physical demand of the labor-intensive tasks it involves. It is thus essential to investigate the physical demands of body movement in the construction manufacturing workplace to proactively identify worker exposure to ergonomic risk. This paper proposes a methodology to use three-dimensional (3D) skeletal modeling to imitate human body movement in an actual construction manufacturing plant for ergonomic risk assessment of a workstation. The inputs for the creation of an accurate and reliable 3D model are also identified. Through 3D modeling, continuous human body motion data can be obtained (such as joint coordinates and joint angles) for risk assessment analysis using existing risk assessment algorithms. The presented framework enables risk evaluation by detecting awkward body postures and evaluating the handled force/load and frequency that cause ergonomic risks during manufacturing operations. The results of the analysis are expected to facilitate the development of modified work to the workstation, which will potentially reduce injuries and workers' compensation insurance costs in the long term for construction manufacturers. The proposed framework can also be expanded to evaluate workstations in the design phase without the need for physical imitation by human subjects. In this paper, the proposed 3D visualization-based ergonomic risk assessment methodology is validated through an optical marker-based motion capture experiment for a lifting task in order to prove the feasibility and reliability of the framework. It is also compared to the traditional manual observation method. Three subjects are selected to conduct the experiment and three levels of comparison are completed: joint angles comparison, risk rating comparison for body segments, and Rapid Entire Body Assessment/Rapid Upper Limb Assessment (REBA/RULA) total risk rating and risk level comparison.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Detecting non-hardhat-use by a deep learning method from far-field surveillance videos\n",
            "Authors: Fang Q.\n",
            "Abstract: Hardhats are an important safety measure used to protect construction workers from accidents. However, accidents caused in ignorance of wearing hardhats still occur. In order to strengthen the supervision of construction workers to avoid accidents, automatic non-hardhat-use (NHU) detection technology can play an important role. Existing automatic methods of detecting hardhat avoidance are commonly limited to the detection of objects in near-field surveillance videos. This paper proposes the use of a high precision, high speed and widely applicable Faster R-CNN method to detect construction workers' NHU. To evaluate the performance of Faster R-CNN, more than 100,000 construction worker image frames were randomly selected from the far-field surveillance videos of 25 different construction sites over a period of more than a year. The research analyzed various visual conditions of the construction sites and classified image frames according to their visual conditions. The image frames were input into Faster R-CNN according to different visual categories. The experimental results demonstrate that the high precision, high recall and fast speed of the method can effectively detect construction workers' NHU in different construction site conditions, and can facilitate improved safety inspection and supervision.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic assessment tool for real-time risk assessment of seated work postures\n",
            "Authors: Mgbemena C.\n",
            "Abstract: This paper presents a posture assessment tool which utilizes the depth sensing techniques of a 3D imaging sensor for ergonomic risk assessment of seated worker’s postures during controlled manual handling tasks. The tool, which has been developed to utilize the manual handling guidelines by the Health and Safety Regulators of some selected countries to measure and assess the postures of the upper bodies of Operators, is tested to ascertain its effectiveness in assessing seated postures. The tool offers real-time posture assessment with real-time feedback to inform Operators on when to adjust awkward seated postures. An experiment has been performed to record, assess and display the work postures of some seated Operators in real-time with ‘Good’ and ‘Awkward’ postures identified with real-time feedback provided to the Operators. Results show that the tool can assess seated work postures in real-time which helps to reduce the rate of occurrence of Work-Related Musculoskeletal Disorders.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Human-robot interaction assessment using dynamic engagement profiles\n",
            "Authors: Poltorak N.\n",
            "Abstract: This paper addresses the use of convolutional neural networks for image analysis resulting in an engagement metric that can be used to assess the quality of human robot interactions. We propose a method based on a pretrained convolutional network able to map emotions onto a continuous [0-1] interval, where 0 represents disengaged and 1 fully engaged. The network shows a good accuracy at recognizing the engagement state of humans given positive emotions. A time based analysis of interaction experiments between small humanoid robots and humans provides time series of engagement estimates, which are further used to understand the nature of the interaction as well as the overall mood and interest of the participant during the experiment. The method allows a real-Time implementation and supports a quantitative and qualitative assessment of a human robot interaction with respect to a positive engagement and is applicable to humanoid robotics as well as other related contexts.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Identifying poses of safe and productive masons using machine learning\n",
            "Authors: Alwasel A.\n",
            "Abstract: This paper presents a framework to classify work poses among groups of masons during the building of a standard wall of concrete masonry units. The experience of the group composed of masonry instructors and master masons averaged five times that of the other groups, their productivity was highest, and the loads on their joints were the lowest. Thus, they were deemed experts in this paper. Inertial measurement units (IMU) and video cameras were used to collect kinematic data of the masons, from which pose clusters were identified. A Support Vector Machine (SVM) algorithm was used to classify masons' poses into expert and inexpert classes based on the relative frequency of poses in the motions used to lay each of 945 masonry units. Two classification scenarios were tested. While both scenarios achieved similar levels of accuracy, 91.23% and 92.04% respectively, the processing time for binary classification was only 13 s compared to 523 s for inter-group multiclass SVM. Like characteristic vibration frequencies in machine diagnostics and system identification, the characteristic poses identified provide insight into differing methods between expert and less experienced masons. For example, results show that experts utilize fewer and more ergonomicaly safe poses, while being more productive, which indicates lower energy expenditure (less wasted motions). The classification method and the poses identified contribute knowledge to help develop affordable mason training systems that utilize IMU and video feedback to improve health and productivity of apprentice masons.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: RGB-D human posture analysis for ergonomic studies using deep convolutional neural network\n",
            "Authors: Abobakr A.\n",
            "Abstract: Human posture analysis is a task of utmost importance for several disciplines. For ergonomists, extracting postural information such as joint angles is necessary to evaluating ergonomic assessment metrics. This allows the early identification of potential work-related musculoskeletal disorders in manufacturing industries, and thus providing adequate interventions. In this paper, we present a holistic posture analysis system that estimates body joint angles from an input depth image. The proposed method utilizes the low cost Kinect sensor for data acquisition and a deep convolutional neural network model for joint angles regression. Further, we rely on learning from synthetic training images to allow simulating several physical tasks by different workers and obtain a highly generalizable learning model. The corresponding ground truth joint angles have been generated using a novel inverse kinematic stage. The proposed method achieves high joint angels prediction rate by recording an average MAE of 4.67 deg and RMSE of 6.64 deg.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Biomechanical analysis of risk factors for work-related musculoskeletal disorders during repetitive lifting task in construction workers\n",
            "Authors: Antwi-Afari M.F.\n",
            "Abstract: Work-related musculoskeletal disorders (WMSDs) represent major health issues for construction workers yet risk factors associated with repetitive lifting tasks remain unexplored. This study evaluates the effects of lifting weights and postures on spinal biomechanics (i.e. muscle activity and muscle fatigue) during a simulated repetitive lifting task undertaken within a strictly controlled laboratory experimental environment. Twenty healthy male participants performed simulated repetitive lifting tasks with three different lifting weights using either a stoop (n = 10) or a squat (n = 10) lifting posture until subjective fatigue (a point in time at which the participant cannot continue lifting further). Spinal biomechanics during repetitive lifting tasks were measured by surface electromyography (sEMG). Results revealed that (1) increased lifting weights significantly increased sEMG activity and muscle fatigue of the biceps brachii (BB), brachioradialis (BR), lumbar erector spinae (LES), and medial gastrocnemius (MG) muscles but not the rectus femoris (RF) muscle; (2) sEMG activity and muscle fatigue rate of the LES muscle were higher than all other muscles; (3) a significant difference of sEMG activity of the RF and MG muscles was observed between lifting postures, however no significant difference of muscle fatigue was apparent (p > 0.05). These findings suggest that risk factors such as lifting weights, repetitions and lifting postures may alleviate the risk of developing WMSDs. However, future research is required to investigate the effectiveness of using ergonomic interventions (such as using team lifting and adjustable lift equipment) in reducing WMSDs risks in construction workers. This work represents the first laboratory-based simulated testing conducted to investigate work-related musculoskeletal disorders (WMSDs) primarily caused by repetitive lifting tasks and manual handling. Cumulatively, the results and ensuing discussion offer insight into how these risks can be measured and mitigated.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Using the Microsoft Kinect™ to assess 3-D shoulder kinematics during computer use\n",
            "Authors: Xu X.\n",
            "Abstract: Shoulder joint kinematics has been used as a representative indicator to investigate musculoskeletal symptoms among computer users for office ergonomics studies. The traditional measurement of shoulder kinematics normally requires a laboratory-based motion tracking system which limits the field studies. In the current study, a portable, low cost, and marker-less Microsoft Kinect™ sensor was examined for its feasibility on shoulder kinematics measurement during computer tasks. Eleven healthy participants performed a standardized computer task, and their shoulder kinematics data were measured by a Kinect sensor and a motion tracking system concurrently. The results indicated that placing the Kinect sensor in front of the participants would yielded a more accurate shoulder kinematics measurements then placing the Kinect sensor 15° or 30° to one side. The results also showed that the Kinect sensor had a better estimate on shoulder flexion/extension, compared with shoulder adduction/abduction and shoulder axial rotation. The RMSE of front-placed Kinect sensor on shoulder flexion/extension was less than 10° for both the right and the left shoulder. The measurement error of the front-placed Kinect sensor on the shoulder adduction/abduction was approximately 10° to 15°, and the magnitude of error is proportional to the magnitude of that joint angle. After the calibration, the RMSE on shoulder adduction/abduction were less than 10° based on an independent dataset of 5 additional participants. For shoulder axial rotation, the RMSE of front-placed Kinect sensor ranged between approximately 15° to 30°. The results of the study suggest that the Kinect sensor can provide some insight on shoulder kinematics for improving office ergonomics.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Real time RULA assessment using Kinect v2 sensor\n",
            "Authors: Manghisi V.M.\n",
            "Abstract: The evaluation of the exposure to risk factors in workplaces and their subsequent redesign represent one of the practices to lessen the frequency of work-related musculoskeletal disorders. In this paper we present K2RULA, a semi-automatic RULA evaluation software based on the Microsoft Kinect v2 depth camera, aimed at detecting awkward postures in real time, but also in off-line analysis. We validated our tool with two experiments. In the first one, we compared the K2RULA grand-scores with those obtained with a reference optical motion capture system and we found a statistical perfect match according to the Landis and Koch scale (proportion agreement index = 0.97, k = 0.87). In the second experiment, we evaluated the agreement of the grand-scores returned by the proposed application with those obtained by a RULA expert rater, finding again a statistical perfect match (proportion agreement index = 0.96, k = 0.84), whereas a commercial software based on Kinect v1 sensor showed a lower agreement (proportion agreement index = 0.82, k = 0.34).\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A kinect-based workplace postural analysis system using deep residual networks\n",
            "Authors: Abobakr A.\n",
            "Abstract: Human behavior understanding is a well-known area of interest for computer vision researchers. This discipline aims at evaluating several aspects of interactions among humans and system components to ensure long term human well-being. The robust human posture analysis is a crucial step towards achieving this target. In this paper, the deep representation learning paradigm is used to analyze the articulated human posture and assess the risk of having work-related musculoskeletal discomfort in manufacturing industries. Particularly, we train a deep residual convolutional neural network model to predict body joint angles from a single depth image. Estimated joint angles are essential for ergonomists to evaluate ergonomic assessment metrics. The proposed method applies the deep residual learning framework that has demonstrated impressive convergence speed and generalization capabilities in addressing different vision tasks such as object recognition, localization and detection. Moreover, we extend the state-of-the-art data generation pipeline to synthesize a dataset that features simulations of manual tasks performed by different workers. An inverse kinematics stage is proposed to generate the corresponding ground truth joint angles. Experimental results demonstrate the generalization performance of the proposed method.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Validity of the Microsoft Kinect for measurement of neck angle: comparison with electrogoniometry\n",
            "Authors: Allahyari T.\n",
            "Abstract: Introduction. Considering the importance of evaluating working postures, many techniques and tools have been developed to identify and eliminate awkward postures and prevent musculoskeletal disorders (MSDs). The introduction of the Microsoft Kinect sensor, which is a low-cost, easy to set up and markerless motion capture system, offers promising possibilities for postural studies. Objectives. Considering the Kinect’s special ability in head-pose and facial-expression tracking and complexity of cervical spine movements, this study aimed to assess concurrent validity of the Microsoft Kinect against an electrogoniometer for neck angle measurements. Methods. A special software program was developed to calculate the neck angle based on Kinect skeleton tracking data. Neck angles were measured simultaneously by electrogoniometer and the developed software program in 10 volunteers. The results were recorded in degrees and the time required for each method was also measured. Results. The Kinect’s ability to identify body joints was reliable and precise. There was moderate to excellent agreement between the Kinect-based method and the electrogoniometer (paired-sample t test, p ≥ 0.25; intraclass correlation for test–retest reliability, ≥0.75). Conclusion. Kinect-based measurement was much faster and required less equipment, but accurate measurement with Microsoft Kinect was only possible if the participant was in its field of view.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of ergonomic posture recognition technique based on 2D ordinary camera for construction hazard prevention through view-invariant features in 2D skeleton motion\n",
            "Authors: Yan X.\n",
            "Abstract: Outdoor tasks operated by construction workers are physically demanding, requiring awkward postures leading to pain, injury, accident, or permanent disability. Ergonomic posture recognition (EPR) technique could be a novel solution for ergonomic hazard monitoring and assessment, yet non-intrusiveness and applicability in complex outdoor environment are always critical considerations for device selection in construction site. Thus, we choose RGB camera to capture skeleton motions, which is non-intrusive for workers compared with wearable sensors. It is also stable and widely used in an outdoor construction site considering various light conditions and complex working areas. This study aims to develop an ergonomic posture recognition technique based on 2D ordinary camera for construction hazard prevention through view-invariant features in 2D skeleton motion. Based on captured 2D skeleton motion samples in the test-run, view-invariant features as classifier inputs were extracted to ensure the learned classifier not sensitive to various camera viewpoints and distances to a worker. Three posture classifiers regarding human back, arms, and legs were employed to ensure three postures to be recognized simultaneously in one video frame. The average accuracies of three classifiers in 5-fold cross validation were as high as 95.0%, 96.5%, and 97.6%, respectively, and the overall accuracies tested by three new activities regarding ergonomic assessment scores captured from different camera heights and viewpoints were 89.2%, 88.3%, and 87.6%, respectively. The developed EPR-aided construction accident auto-prevention technique demonstrated robust accuracy to support on-site postural ergonomic assessment for construction workers’ safety and health assurance.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Activity level assessment using a smart cushion for people with a sedentary lifestyle\n",
            "Authors: Ma C.\n",
            "Abstract: As a sedentary lifestyle leads to numerous health problems, it is important to keep constant motivation for a more active lifestyle. A large majority of the worldwide population, such as office workers, long journey vehicle drivers and wheelchair users, spends several hours every day in sedentary activities. The postures that sedentary lifestyle users assume during daily activities hide valuable information that can reveal their wellness and general health condition. Aiming at mining such underlying information, we developed a cushion-based system to assess their activity levels and recognize the activity from the information hidden in sitting postures. By placing the smart cushion on the chair, we can monitor users’ postures and body swings, using the sensors deployed in the cushion. Specifically, we construct a body posture analysis model to recognize sitting behaviors. In addition, we provided a smart cushion that effectively combine pressure and inertial sensors. Finally, we propose a method to assess the activity levels based on the evaluation of the activity assessment index (AAI) in time sliding windows. Activity level assessment can be used to provide statistical results in a defined period and deliver recommendation exercise to the users. For practical implications and actual significance of results, we selected wheelchair users among the participants to our experiments. Features in terms of standard deviation and approximate entropy were compared to recognize the activities and activity levels. The results showed that, using the novel designed smart cushion and the standard deviation features, we are able to achieve an accuracy of (>89%) for activity recognition and (>98%) for activity level recognition.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Risk Factors Identification for Work-Related Musculoskeletal Disorders with Wearable and Connected Gait Analytics System\n",
            "Authors: Chen D.\n",
            "Abstract: Risk factors, such as overexertion, awkward postures, excessive repetition, and the combination of these factors are main causes of work-related musculoskeletal disorders (WMSDs) which are reported to be the leading nonfatal occupational injuries. However, it is difficult for commonly used risk factors identification methods (e.g. observational methods) to give an objective and comprehensive analysis on these risk factors. To address the above problem, we proposed an automatic WMSDs risk factors identification method based on Wearable and Connected Gait Analytics System (WCGAS). WKGAS was capable of recording plantar pressure from which postures, force exertions, and repetitions could be recognized with algorithms such as sequential minimal optimization (SMO) algorithm and long short term memory (LSTM) network. Experiments with quasi-static and sequential postures were designed to evaluate the recognition performance of work-related motion type (i.e. 'lifting', 'carrying', 'bending', 'pulling', and 'pushing'). A load variable (with/without 10 Kg load) was introduced for evaluating the performance of force exertions recognition. 5 repetitions of each motion were used for evaluating the performance of repetitions recognition. Results showed that quasi-static postures could be recognized with 100% accuracy and the accuracy for sequential motions recognition were 74%, 79%, 92%, 99% and 99% for 'bending', 'carrying', 'lifting', 'pulling' and 'pushing', respectively. Force exertions were recognized with 100% accuracy. For repetitions recognition, except the accuracy in the 'bending' motion was 80%, the repetitions of other motions could be recognized correctly. These results indicated that it is possible to use WCGAS for WMSDs risk factors identification.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Driver Movement Patterns Indicate Distraction and Engagement\n",
            "Authors: Radwin R.G.\n",
            "Abstract: Objective This research considers how driver movements in video clips of naturalistic driving are related to observer subjective ratings of distraction and engagement behaviors. Background Naturalistic driving video provides a unique window into driver behavior unmatched by crash data, roadside observations, or driving simulator experiments. However, manually coding many thousands of hours of video is impractical. An objective method is needed to identify driver behaviors suggestive of distracted or disengaged driving for automated computer vision analysis to access this rich source of data. Method Visual analog scales ranging from 0 to 10 were created, and observers rated their perception of driver distraction and engagement behaviors from selected naturalistic driving videos. Driver kinematics time series were extracted from frame-by-frame coding of driver motions, including head rotation, head flexion/extension, and hands on/off the steering wheel. Results The ratings were consistent among participants. A statistical model predicting average ratings from the kinematic features accounted for 54% of distraction rating variance and 50% of engagement rating variance. Conclusion Rated distraction behavior was positively related to the magnitude of head rotation and fraction of time the hands were off the wheel. Rated engagement behavior was positively related to the variation of head rotation and negatively related to the fraction of time the hands were off the wheel. Application If automated computer vision can code simple kinematic features, such as driver head and hand movements, then large-volume naturalistic driving videos could be automatically analyzed to identify instances when drivers were distracted or disengaged.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Flexible feedback system for posture monitoring and correction\n",
            "Authors: Baptista R.\n",
            "Abstract: In this paper, we propose a framework for guiding patients and/or users in how to correct their posture in real-time without requiring a physical or a direct intervention of a therapist or a sports specialist. In order to support posture monitoring and correction, this paper presents a flexible system that continuously evaluates postural defects of the user. In case deviations from a correct posture are identified, then feedback information is provided in order to guide the user to converge to an appropriate and stable body condition. The core of the proposed approach is the analysis of the motion required for aligning body-parts with respect to postural constraints and pre-specified template skeleton poses. Experimental results in two scenarios (sitting and weight lifting) show the potential of the proposed framework.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Postural Assessment in Dentistry Based on Multiple Markers Tracking\n",
            "Authors: Marcon M.\n",
            "Abstract: Postural assessment is a fundamental aspect to prevent long-term Musculoskeletal disorders (MSDs) due to fatiguing jobs. Operative dentistry also belongs to this category and we developed a Computer Vision approach to automatically analyze the dentist posture during operations obtaining an evaluation of MSD risk according to some well-established criteria like RULA and NERPA. In particular we analyze three different set-ups where the dentist operates with naked eyes, medical loupes or using a surgical microscope and we compared the postural effects of these three different configurations. The results present a significant improvement in posture using the microscope and validated our approach as a feasible and effective method to assess posture in fatiguing jobs. The proposed approach allows a continuous monitoring of job activity evaluating accurately posture criticalities. Furthermore the risk of MSD based on international criteria is evaluated in an objective and accurate way. The whole proposed system follows a non-invasive approach based on Augmented Reality markers tracked from a distant camera and can be applied to effective monitoring different working activities providing an accurate and objective estimation of MSD according to modern posture assessment criteria.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Ergonomic analysis of construction worker's body postures using wearable mobile sensors\n",
            "Authors: Nath N.D.\n",
            "Abstract: Construction jobs are more labor-intensive compared to other industries. As such, construction workers are often required to exceed their natural physical capability to cope with the increasing complexity and challenges in this industry. Over long periods of time, this sustained physical labor causes bodily injuries to the workers which in turn, conveys huge losses to the industry in terms of money, time, and productivity. Various safety and health organizations have established rules and regulations that limit the amount and intensity of workers' physical movements to mitigate work-related bodily injuries. A precursor to enforcing and implementing such regulations and improving the ergonomics conditions on the jobsite is to identify physical risks associated with a particular task. Manually assessing a field activity to identify the ergonomic risks is not trivial and often requires extra effort which may render it to be challenging if not impossible. In this paper, a low-cost ubiquitous approach is presented and validated which deploys built-in smartphone sensors to unobtrusively monitor workers’ bodily postures and autonomously identify potential work-related ergonomic risks. Results indicates that measurements of trunk and shoulder flexions of a worker by smartphone sensory data are very close to corresponding measurements by observation. The proposed method is applicable for workers in various occupations who are exposed to WMSDs due to awkward postures. Examples include, but are not limited to industry laborers, carpenters, welders, farmers, health assistants, teachers, and office workers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Patient handling activity recognition through pressure-map manifold learning using a footwear sensor\n",
            "Authors: Lin F.\n",
            "Abstract: The risk of overexertion injury caused by patient handling and movement activities causes chronic pain and other physical and social impairments among the nursing force. The accurate recognition of patient handling activities (PHA) is the first step to reduce injury risk for caregivers. The current practice on workplace activity recognition is neither accurate nor convenient to perform. In this paper, we propose a novel solution comprising a smart footwear device and an action manifold learning framework to address the challenge. The wearable device, called Smart Insole, is equipped with a rich set of sensors and can provide an unobtrusive approach to obtain and characterize the action information of patient handling activities. Our proposed action manifold learning (AML) framework extracts the intrinsic signature structure by projecting raw pressure data from a high-dimensional input space to a low-dimensional manifold space. This framework not only performs dimension reduction but also reduces motion artifacts, which is robust against the noise and inter-class/intra-class variation in PHA recognition. To validate the effectiveness of the proposed framework, we perform a pilot study with eight subjects including eight common activities in a nursing room. The intrinsic dimensionality of the manifold is estimated by comparing the residual variances of different dimensionality settings. The experimental results show the overall classification accuracy achieves 86.6%. Meanwhile, the qualitative profile and load level can also be classified with accuracies of 98.9% and 88.3%, respectively.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Normative 3D opto-electronic stereophotogrammetric posture and spine morphology data in young healthy adult population\n",
            "Authors: D'Amico M.\n",
            "Abstract: Design: Observational cross-sectional study. The current study aims to yield normative data: i.e., the physiological standard for 30 selected quantitative 3D parameters that accurately capture and describe a full-skeleton, upright-standing attitude. Specific and exclusive consideration was given to three distinct categories: postural, spine morphology and pelvic parameters. To capture such 3D parameters, the authors selected a non-ionising 3D optoelectronic stereo-photogrammetric approach. This required the identification and measurement of 27 body landmarks, each specifically tagged with a skin marker. As subjects for the measurement of these parameters, a cohort of 124 asymptomatic young adult volunteers was recruited. All parameters were identified and measured within this group. Postural and spine morphology data have been compared between genders. In this regard, only five statistically significant differences were found: pelvis width, pelvis torsion, the \"lumbar\" lordosis angle value, the lumbar curve length, and the T12-L5 anatomically-bound lumbar angle value. The \"thoracic\" kyphosis mean angle value was the same in both sexes and, even if, derived from skin markers placed on spinous processes it resulted in perfect agreement with the X-ray based literature. As regards lordosis, a direct comparison was more difficult because methods proposed in the literature differ as to the number and position of vertebrae under consideration, and their related angle values. However, when the L1 superior-L5 inferior end plate Cobb angle was considered, these results aligned strongly with the existing literature. Asymmetry was a standard postural-spinal feature for both sexes. Each subject presented some degree of leg length discrepancy (LLD) with μ = 9.37mm. This was associated with four factors: unbalanced posture and/or underfoot loads, spinal curvature in the frontal plane, and pelvis torsion. This led to the additional study of the effect of LLD equalisation influence on upright posture, relying on a sub-sample of 100 subjects (51 males, 49 females). As a result of the equalisation, about 82% of this sub-sample showed improvement in standing posture, mainly in the frontal plane; while in the sagittal plane less than 1/3 of the sub-sample showed evidence of change in spinal angles. A significant variation was found in relation to pelvis torsion: 46% of subjects showed improvement, 49% worsening. The method described in study presents several advantages: non-invasive aspect; relatively short time for a complete postural evaluation with many clinically useful 3D and 2D anatomical/biomechanical/clinical parameters; analysis of real neutral unconstrained upright standing posture.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Experience, Productivity, and Musculoskeletal Injury among Masonry Workers\n",
            "Authors: Alwasel A.\n",
            "Abstract: Masonry is a highly physical occupation with a low retention rate in the workforce beyond 5 years. Predominantly, workers leave the workforce because of injuries. In particular, musculoskeletal disorders are depleting the construction workforce. Previous studies have contrasted the safety records of journeymen versus novices. However, no study to date has examined the combined effects of experience level on safety, productivity, and the balance between them. The purpose of this study is to fill this gap and to investigate the underlying reasons for these effects. Twenty-one masons distributed in four experience levels were recruited to build a 72-block six-course wall using standard concrete masonry units. Participants' body kinematics were tracked using inertial measurement units and video cameras simultaneously. Biomechanical analysis was carried out to examine the loads experienced by major body joints during bricklaying. Results indicate that journeymen with more than 5 years of experience as well as novice masons work in ergonomically safer ways than apprentices with 1 and 3 years of experience. It was found that apprentices gain proficiency and increase productivity at the cost of higher risk of musculoskeletal injury. The results indicate that those masons who gain experience in ergonomic safety and productivity in tandem are more likely to remain in the workforce beyond the 5-year mark. Thus, it is essential to alter apprentice training to guarantee this outcome.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Toward Unobtrusive Patient Handling Activity Recognition for Injury Reduction among At-Risk Caregivers\n",
            "Authors: Lin F.\n",
            "Abstract: Nurses regularly perform patient handling activities. These activities with awkward postures expose healthcare providers to a high risk of overexertion injury. The recognition of patient handling activities is the first step to reduce injury risk for caregivers. The current practice on workplace activity recognition is based on human observational approach, which is neither accurate nor projectable to a large population. In this paper, we aim at addressing these challenges. Our solution comprises a smart wearable device and a novel spatiooral warping (STW) pattern recognition framework. The wearable device, named Smart Insole 2.0, is equipped with a rich set of sensors and can provide an unobtrusive way to automatically capture the information of patient handling activities. The STW pattern recognition framework fully exploits the spatial and temporal characteristics of plantar pressure by calculating a novel warped spatiooral distance, to quantify the similarity for the purpose of activity recognition. To validate the effectiveness of our framework, we perform a pilot study with eight subjects, including eight common activities in a nursing room. The experimental results show the overall classification accuracy achieves 91.7%. Meanwhile, the qualitative profile and load level can also be classified with accuracies of 98.3% and 92.5%, respectively.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Construction worker's awkward posture recognition through supervised motion tensor decomposition\n",
            "Authors: Chen J.\n",
            "Abstract: Awkward postures in construction activities pose substantial hazards in both instantaneous injuries and long-term work-related musculoskeletal disorders (WMSDs). Posture recognition using motion capturing systems shows promising potential in avoiding and minimizing workers’ exposure to awkward postures. However, current motion capturing systems require huge computational resources and complicated processes to recognize postures in construction tasks. To address this issue, we proposed an abstract and efficient motion tensor decomposition approach to compress and reorganize the motion data. Together with a multi-classification algorithm, the proposed approach is able to efficiently and accurately differentiate various postures. To validate the approach, we employed a system based on inertial measurement units (IMUs) to examine two sample activities composed of sequencing postures. The results indicate the proposed approach is able to provide sufficient recognition accuracy with less computation power and memory. Also, the idea of tensorization and tensor decomposition in this paper is extendable to other studies in the construction industry.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: An Intelligent Body Posture Analysis Model Using Multi-Sensors for Long-Term Physical Rehabilitation\n",
            "Authors: Lai C.F.\n",
            "Abstract: Sensors can be installed on various body parts to provide information for computer diagnosis to identify the current body state. However, as human posture is subject to gravity, the direction of the force on each limb differs. For example, the directions of gravitational force on legs and trunk differ. In addition, each person’s height and structure of limbs differs, hence, the acceleration and rotation resulted from such differences on force and length of the limbs of a person in motion would be different, and be presented by cases of different postures. Thus, how to present body postures through skeleton system equations, and achieve an long-term physical rehabilitation, according to the different limb characteristics of each person, is a challenging research issue. This paper proposes a novel scheme named as “Intelligent Body Posture Analysis Model”, which uses multiple acceleration sensors and gyroscopes to detect body motion patterns. The effectiveness of the proposed scheme is proved by conducting a large number of practical experiments and tests.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Observer variability in posture assessment from video recordings: The effect of partly visible periods\n",
            "Authors: Trask C.\n",
            "Abstract: Observers rank partly visible postures on video frames differently than fully visible postures, but it's not clear if this is due to differences in observer perception. This study investigated the effect of posture visibility on between-observer variability in assessments of trunk and arm posture. Trained observers assessed trunk and arm postures from video recordings of 84 pulp mill shifts using a work sampling approach; postures were also categorized as ‘fully’ or ‘partly’ visible. Between-worker, between-day, and between-observer variance components and corresponding confidence intervals were calculated. Although no consistent gradient was seen for the trunk, right upper arm posture showed smaller between-observer variance when all observers rated a posture as fully visible. This suggests that, partly-visible data, especially when observers disagree as to the level of visibility, introduces more between-observer variability when compared to fully visible data. Some previously-identified differences in daily posture summaries may be related to this phenomenon.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automatic Sleep System Recommendation by Multi-modal RBG-Depth-Pressure Anthropometric Analysis\n",
            "Authors: Palmero C.\n",
            "Abstract: This paper presents a novel system for automatic sleep system recommendation using RGB, depth and pressure information. It consists of a validated clinical knowledge-based model that, along with a set of prescription variables extracted automatically, obtains a personalized bed design recommendation. The automatic process starts by performing multi-part human body RGB-D segmentation combining GrabCut, 3D Shape Context descriptor and Thin Plate Splines, to then extract a set of anthropometric landmark points by applying orthogonal plates to the segmented human body. The extracted variables are introduced to the computerized clinical model to calculate body circumferences, weight, morphotype and Body Mass Index categorization. Furthermore, pressure image analysis is performed to extract pressure values and at-risk points, which are also introduced to the model to eventually obtain the final prescription of mattress, topper, and pillow. We validate the complete system in a set of 200 subjects, showing accurate category classification and high correlation results with respect to manual measures.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Healthy human sitting posture estimation in RGB-D scenes using object context\n",
            "Authors: Liu B.\n",
            "Abstract: Unhealthy sitting posture leads to cervical spondylosis and other related cumulative trauma disorders (CTDs). Unfortunately, the research on the investigation of heathy sitting posture is rare. The current research is to estimate heathy sitting posture based on a computer workstation ergonomics perspective. A novel RGB-D scene healthy human sitting posture estimation framework was developed to estimate the sitting posture, in which a human posture is represented by 15 skeletal joints. A healthy human sitting posture configuration is defined from the view of ergonomics, a Naïve Bayes classifier was used to learn the health-constrained spatial and context relationships between objects and the human skeletal joints in the RGB-D scene. At the estimation stage, the object spatial features (e.g., coordinate, distance, height and angle) in the RGB-D scene were obtained through conducting the scene labeling. 15 human skeletal joints were extracted simultaneously from Kinect as primary inputs, and then algorithms were developed to generate and to classify the candidate healthy skeleton joints. Through skeleton refinement, the skeleton joints distribution of a healthy sitting posture was produced. The framework was tested on a dataset comprised of RGB-D scenes, which were collected from 3 subjects (3 types of sitting postures, each in 3 different offices). The experiment results indicate that the framework is feasible and reliable.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Human Context Sensing in Smart Cities\n",
            "Authors: Ranjan J.\n",
            "Abstract: This chapter discusses the concept of human context sensing, the definitions of the four main types of human contexts, and the current technological sensing mechanisms. The types of human context sensing are physiological sensing, emotive sensing, functional sensing, and location sensing. Together, these facets capture the mental states, physical body conditions, lifestyles, and location of individuals. The goals and applications for each category unify in improving the quality of life of an individual by monitoring different aspects of life that can help the smart city provide an individual with the right level of assistance and facilities. the chapter also discusses the impact of the four main technological thrusts in each category of human context sensing: video and audio, wearables, smartphones, and environmental sensing. Each type of technology has a unique set of sensing abilities as well as constraints. Additionally, each has practical uses, costs, and privacy implications for use in a smart city.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Safety activity analysis framework to evaluate safety performance in construction\n",
            "Authors: Awolusi I.G.\n",
            "Abstract: The construction work environment remains one of the most hazardous worldwide. As a result of dangerous working environments, construction workers often face safety and health risks throughout the construction process. However, an emphasis on construction safety has increased mainly in the aspect of safety performance, and efforts are required to not only monitor but also seek to improve safety performance. This research develops a safety activity analysis framework and tool to facilitate the collection and analysis of the safety activity data for continuous evaluation of safety performance. A case study is also carried out on an active construction project to implement and validate the framework and tool. The findings of the case study show that the safety index of the construction site increased from 37.0 to 62.8% and was in consonance with the actual site records of the project's total recordable incident rate, which decreased from 7.11 to 1.42. This study contributes to the body of knowledge by providing a methodical and operational safety activity analysis framework that can be used to proactively monitor safety performance, set improvement targets, and provide continuous feedback to enhance safety performance on construction sites. This research also provides a safety activity analysis tool that is a management information system that transforms a laborious and ineffective manual method of collecting and analyzing safety data into a more functional computer-based approach.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A practical computer based vision system for posture and movement sensing in occupational medicine\n",
            "Authors: Marfia G.\n",
            "Abstract: Back pain and upper extremities injuries due to overexertion account for over twenty percent of leave days from work in the US. This explains why a vast amount of initiatives have been, to this date, carried out aiming at reducing the occurrence of such type of injuries. However, although such type of lesions are among the most studied in occupational medicine, no automatic detection and prevention technologies are pervasively available, to this date, at workplaces. Such deficiency is ascribable to the absence of any flexible and cost-effective tectaphnology that may play such role. This work aims at filling such gap: the contribution of this paper is the design and implementation of a movement-posture computer-vision based system that, performing as a sensor, can detect overexertion movements, helping avoid the most common injuries that these cause. Such tasks are carried out with the use of a simple webcam, thus not requiring any expensive or specialized (e.g., Microsoft Kinect) hardware device. The proposed technology is, hence, easily affordable by any type of company and production plant throughout the world and easy adaptable to recognize and detect a wide set of movements and postures. The validity of such approach is demonstrated in realistic settings through a wide set of experiments.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A type-2 fuzzy logic recommendation system for adaptive teaching\n",
            "Authors: Almohammadi K.\n",
            "Abstract: E-learning platforms facilitate the interaction between students and instructors while mitigating temporal or spatial constraints. Nevertheless, such platforms require measuring the degree of students’ engagement with the delivered course content and teaching style. Such information is highly valuable for evaluating the quality of the teaching and altering the teaching delivery style in massively crowded online learning platforms. When the number of learners is high, it is essential to attain overall engagement and feedback, yet doing so is highly challenging due to the high levels of uncertainties related to students and the learning context. To handle these uncertainties more robustly, we present a method based on type-2 fuzzy logic utilizing visual RGB-D features, including head pose direction and facial expressions captured from Kinect v2, a low-cost but robust 3D camera, to measure the engagement degree of students in both remote and on-site education. This system augments another self-learning type-2 fuzzy logic system that helps teachers with recommendations of how to adaptively vary their teaching methods to suit the level of students and enhance their instruction delivery. This proposed dynamic e-learning environment integrates both on-site and distance students as well as teachers who instruct both groups of students. The rules are learned from the students’ and teachers’ learning/teaching behaviors, and the system is continuously updated to give the teacher the ability to adapt the delivery approach to varied learners’ engagement levels. The efficiency of the proposed system has been tested through various real-world experiments in the University of Essex iClassroom among a group of thirty students and six teachers. These experiments demonstrate the capabilities—compared to type-1 fuzzy systems and non-adaptive systems—of the proposed interval type-2 fuzzy logic-based system to handle the uncertainties and improve average learners’ motivations to engage during learning.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A new kinect approach to judge unhealthy sitting posture based on neck angle and torso angle\n",
            "Authors: Yao L.\n",
            "Abstract: Sitting posture has a close relationship with our health, keeping right sitting posture is important for people to avoid chronic diseases. However, automatic unhealthy sitting posture detection system is rare, especially for those based on computer vision technology. This paper proposes a new method of judging unhealthy sitting posture based on neck angle and torso angle detection using Kinect sensor. The method tracks neck angle and torso angle as two representative features from the depth image in a given period of time to judge whether the sitting posture is healthy or not. Experimental results show that the proposed method can judge sitting posture effectively for different unhealthy sitting types. Compared with the existing methods of action recognition, our method only needs a Kinect sensor without any other wearable sensors and is time efficient and robust because of only calculating two angles.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Skeleton-free RULA ergonomic assessment using Kinect sensors\n",
            "Authors: Nahavandi D.\n",
            "Abstract: Ergonomic analysis methods and postural assessments assist in preventing work related musculoskeletal injuries. The primary outcome of this is to provide safer workplace environments and reduce the total number of work related injury occurrences. The dedicated marker- or sensor-based 3D motion capture solutions impose a series of portability and cost challenges when applied to work place environments. The Kinect motion recording system, which was introduced in the Xbox game console, provides a marker-less, portable and low-cost motion capture solution. This technology is capable of recording 3D coordinates of a moving body parts with an accuracy comparable to the state of the art systems. This paper investigates the utilisation of Kinect sensors for real time rapid upper limb assessment (RULA) to aid in ergonomic analysis for assembly operations in industrial environments. Unlike earlier similar attempts, the work presented in this paper does not rely on tracking body parts and extracting a kinematically sound skeleton. In this paper, identifying a RULA score is formulated as a semantic segmentation problem. A random decision forest (RDF) classifier is used to give each pixel a different RULA score based on postures captured with a Kinect camera. Results demonstrate a converging accuracy of 93% for the proposed method.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automated ergonomic risk assessment based on 3D visualization\n",
            "Authors: Li X.\n",
            "Abstract: Conventional ergonomic risk assessment of physical work is conducted through observation and direct/indirect physiological measurements. However, these methods are time-consuming and require human subjects to actually perform the motion in order to obtain detailed body movement data. 3D visualization, alternatively, allows users to simulate an operational task on the computer screen, a process that is less timeconsuming and which eliminates the need for costly onsite devices, as well as the detrimental effect of human error during experimentation. It can also proactively visualize a proposed design prior to implementation in the real world. This paper presents an automated ergonomic risk assessment framework based on 3D modelling with the support of a user-friendly interface for data-post processing. 3ds Max is utilized together with its built-in MAXScript. The presented system enables the automation of body motion risk identification by detecting awkward body postures, evaluating the handled force/load and frequency that cause ergonomic risk during body movements of workers. As the outcome, it provides detailed risk scores for body segments, such that users are able to review the continuous motion and corresponding risk by precise time frame. The capability of this 3D visualizationbased ergonomic risk assessment can be extended to support the re-design of the workplace and optimization of human body movement accordingly. The ultimate goal of this study is to proactively mitigate ergonomic risk and further reduce potential injuries and workers' compensation insurance costs in the long term.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Image processing based rapid upper limb assessment method\n",
            "Authors: Can G.F.\n",
            "Abstract: Occupational Musculoskeletal System Disorders (OMSDs) are disorders that inflict a great deal of economical burden on enterprises and nations, decrease quality, productivity and cause inability to sustain livings of employees. One of the most important factor that cause OMSDs is working posture. In literature, there are various methods for determining risk levels of working postures. In this study because of its common usage, Rapid Upper Limb Assessment Method that identfies hazard level created by working postures on employees' upper limb musculoskeletal health is selected for improving with image processing systems. It is necassary to improve RULA's performance due to complications stemming from its implementation method based on observation, lack of information on the best duration of observation, subjectivity on results and extensive analysis time etc. For compansate these requirements a modified method is proposed in this study named as Advanced RULA (ARULA). Reliability and validity analysis are implemented statistically for ARULA. As a result, ARULA is recommended as a practical tool for analyzing risk levels of working postures for tasks that contain intensive usage of upper extremity.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automated Model-Based Finding of 3D Objects in Cluttered Construction Point Cloud Models\n",
            "Authors: Sharif M.M.\n",
            "Abstract: Finding construction components in cluttered point clouds is a critical pre-processing task that requires intensive and manual operations. Accurate isolation of an object from point clouds is a key for further processing steps such as positive identification, scan-to-building information modeling (BIM), and robotic manipulation. Manual isolaton is tedious, time consuming, and disconnected from the automated tasks involved in the process. This article adapts and examines a method for finding objects within 3D point clouds robustly, quickly, and automatically. A local feature on a pair of points is employed for representing 3D shapes. The method has three steps: (1) offline model library generation, (2) online searching and matching, and (3) match refinement and isolation. Experimental tests are carried out for finding industrial (curvilinear) and structural (rectilinear) elements. The method is verified under various circumstances in order to measure its performance toward addressing the major challenges involved in 3D object finding. Results show that the method is sufficiently quick and robust to be integrated with automated process control frameworks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Musculoskeletal disorders: OWAS review\n",
            "Authors: Gómez-Galán M.\n",
            "Abstract: The prevention of musculoskeletal disorders (MSD) is very important in the world. Governments and companies are the most interested. The objective of the present work is to review the literature on the applications of the OWAS method in the diverse sectors or fields of knowledge and countries from its publication to March 2017. The use of OWAS method has been classified by categories of knowledge, by country and by year. The search was made by selecting only the main collection of the Web of Science. This was selected by the option “Advanced search” using the term OWAS (ts=OWAS) for the time period of 1900 to 2017. A total of 166 results were found, consisting of conference papers and articles in scientific journals. In conclusion, the OWAS has been applied mainly in two sectors: “Manufacturing industries” and “Healthcare and Social assistance activi-ties”. This method needs to be complemented with other indirect or direct methods. Also, whenever the OWAS has been used, whether individually or together with other methods, musculoskeletal disorders risks have been detected, this perhaps being an indicator to review the evaluation parameters because overestimating the risk.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Visualization technology-based construction safety management: A review\n",
            "Authors: Guo H.\n",
            "Abstract: Construction safety management has been a popular issue in research and practice in recent years due to the high accident and death rates in the construction industry. The complexity and variability of construction sites makes safety management more difficult to implement than in other industries. As a promising technology, visualization has been extensively explored to aid construction safety management. However, a comprehensive critical review of the visualization technology in construction safety management is absent in the literature. This paper provides a comprehensive review to investigate research and development, application methods, achievements and barriers to the use of visualization technology in safety management, and suggests possible future research directions to extend its application. It is found that visualization technology can improve safety management by aiding safety training, job hazard area (JHA) identification and on-site safety monitoring and warnings, but there are barriers or limitations involved. Existing location technologies, for instance, can perform well only in relatively small areas due to their generally poor penetrating performance. Finally, possible future research directions are proposed to benefit the extensive application of visualization technology for construction safety management in both theory and practice.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Are behavioral measures useful for detecting cognitive workload during human-computer interaction?\n",
            "Authors: Elkin-Frankston S.\n",
            "Abstract: Commonly used techniques for measuring cognitive workload during human-computer interactions can be cumbersome or intrusive to task performance. In the current work, we examine the utility of heuristic behavior analysis, including keystroke dynamics, mouse tracking, and body positioning for measuring cognitive workload during direct interactions between humans and computers. We present a method for modeling behavioral measures as well as physiological and neurophysiological data using probabilistic, statistical, and machine learning algorithms for real-time estimation of human states. We believe this discussion will inform the capability to provide estimates of cognitive workload in real-world scenarios.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Data acquisition technologies for construction progress tracking\n",
            "Authors: Omar T.\n",
            "Abstract: Falling behind schedule and having discrepancy between the as-built and designed baseline plans are unfavourable events that often occur in construction projects. Hence, real-time progress tracking and monitoring of construction components remains a vital part of project management and is critical to achieving project objectives. Yet manual approaches for progress tracking lack the required accuracy for integration with other construction interfaces. Conversely, automatic progress tracking can result in timely detection of potential time delays and construction discrepancies and directly supports project control decision-making. This paper examines different technologies of automated and electronic construction data collection. In particular, enhanced IT, geo-spatial, 3D imaging, and augmented reality technologies have recently achieved significant advances in this field. Each of these technologies is discussed herein in terms of its advantages and limitations. Comparisons of such technologies to identify various trends concerning their applicability in real-time data acquisition of construction projects are made, along with recommendations for their suitability in different projects. This should assist construction stakeholders in choosing appropriate tools to enhance time and cost effectiveness and achieve better control and more effective decisions during construction. It is also hoped that this review will stimulate further research on and development of these technologies.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Non-invasive methods of computer vision in the posture evaluation of adolescent idiopathic scoliosis\n",
            "Authors: Aroeira R.M.C.\n",
            "Abstract: Purpose Reviewing techniques for non-invasive postural evaluation of adolescent idiopathic scoliosis (AIS) based on information extraction from images based on computer methods. Methods The Scopus, Web of Science, MEDLINE, ScieLo and PubMed databases were used, for the period 2011–2015. Results 131 articles were found based on keyword of which 15 articles met the established eligibility criteria. Of these, 4 were based on photogrammetry, and 11 based on laser, structured light, ultrasound, and Moiré projection. In these studies, the methodological quality varied from low to high. Conclusions The findings indicated diversity in methodologies; 14/15 articles reviewed were limited to the evaluation of the topography of the posterior back. A study, using two-dimensional photogrammetry, presented a whole body postural evaluation. As the asymmetry in AIS can be extended to the whole body, more attention should be given to develop full body assessment techniques to provide important additional data to aid in treatment decisions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Experience design: Video without faces increases engagement but not empathy\n",
            "Authors: Westling C.E.I.\n",
            "Abstract: Counter to prior claims that empathy is required for higher levels of engagement in human-computer interaction, our team has previously found that, in an analysis of 844 stimulus presentations, empathy is sufficient for high engagement, but is not necessary. Here, we ran a carefully controlled study of human-computer interactions with musical stimuli - with and without visuals, and with and without recognizable people - to directly test whether we could design an engaging stimulus that did not elicit empathy, by avoiding human faces or personal interaction. We measured subjective responses by visual analogue scale and found that the faceless stimulus was as engaging as the face-containing stimulus, but much less empathy-provoking. Therefore, we propose that empathy and engagement be considered independently during interaction design, because they are not monotonically related.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Occupational sitting behaviour and its relationship with back pain - A pilot study\n",
            "Authors: Zemp R.\n",
            "Abstract: Nowadays, working in an office environment is ubiquitous. At the same time, progressively more people suffer from occupational musculoskeletal disorders. Therefore, the aim of this pilot study was to analyse the influence of back pain on sitting behaviour in the office environment. A textile pressure mat (64-sensor-matrix) placed on the seat pan was used to identify the adopted sitting positions of 20 office workers by means of random forest classification. Additionally, two standardised questionnaires (Korff, BPI) were used to assess short and long-term back pain in order to divide the subjects into two groups (with and without back pain). Independent t-test indicated that subjects who registered back pain within the last 24 h showed a clear trend towards a more static sitting behaviour. Therefore, the developed sensor system has successfully been introduced to characterise and compare sitting behaviour of subjects with and without back pain.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Sensing from the Bottom: Smart Insole Enabled Patient Handling Activity Recognition Through Manifold Learning\n",
            "Authors: Lin F.\n",
            "Abstract: The risk of overexertion injury caused by patient handling and movement activities causes chronic pain and severe social issues among the nursing force. The accurate recognition of patient handling activities (PHA) is the first step to reduce injury risk for caregivers. In this paper, we propose a novel solution comprising a smart footwear device and an action manifold learning framework to address the challenge. The wearable device, called Smart Insole, is equipped with arich set of sensors and can provide an unobtrusive approachto obtain and characterize the action information of patienthandling activities. Our proposed action manifold learning(AML) framework extracts the intrinsic signature structure byprojecting raw pressure data from a high-dimensional inputspace to a low-dimensional manifold space. We performeda pilot study with eight subjects including eight commonactivities in a nursing room. The experimental results showthe overall classification accuracy achieves 86.6%. Meanwhile, the qualitative profile and load level can also be classified withaccuracies of 98.9% and 88.3%, respectively.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Online Classification and Sensor Selection Optimization with Applications to Human Material Handling Tasks Using Wearable Sensing Technologies\n",
            "Authors: Bastani K.\n",
            "Abstract: Occupational jobs often involve different types of manual material handling (MMH) tasks. Performing such tasks can be physically demanding, and which may put workers at an increased risk of work-related musculoskeletal disorders (WMSDs). To control and prevent WMSDs, there has been a growing interest in online posture monitoring using wearable sensors. In this paper, we developed an online, supervised, task classification algorithm for monitoring and evaluation of MMH activities. The classification algorithm is based on a fast sparse estimation methodology, which makes it computationally efficient for online decision making. We further propose an optimization approach to improve classification performance, by differentially weighting sensors, thereby representing the relative influence of a sensor in classification performance. Optimizing these weights enables us to determine the most relevant sensors for classification. A case study using 37 sensors with 111 channels of data was completed to validate performance of the proposed method. With only 30 optimally selected sensor channels, our method provides high classification accuracy (>84%) and outperforms several benchmark methods, including support vector machine, quadratic discriminant analysis, and neural network.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Smart-surface: Large scale textile pressure sensors arrays for activity recognition\n",
            "Authors: Cheng J.\n",
            "Abstract: In this paper we present textile-based surface pressure mapping as a novel, unobtrusive information source for activity recognition. The concept is motivated by the observation that the vast majority of human activities are associated with certain types of surface contact (walking, running, etc. on the floor; sitting on a chair/sofa; eating, writing, etc. at a table; exercising on a fitness mat, and many others). A key hypothesis which we validate in this paper is: by analysing subtle features of such interaction, various complex activities, often ones that are difficult to distinguish using other unobtrusive sensors, can be well recognised. A core contribution of our work is a sensing and recognition system based on cheap, easy-to-produce textile components. These components can be integrated into matrices with tens of thousands of elements, a spatial pitch as fine as 1 cm2, temporal granularity of up to 40 Hz and pressure dynamic range from 0.25×105 to 5×105 Pa. We present the evaluation of the concept and the technology in five scenarios, through matrix monitoring driver motions at a car seat (32×32 sensors on 32×32 cm2), a Smart-YogaMat (80×80 sensors on 80×80 cm2) detecting and counting exercises, to a Smart-Tablecloth (30×42 sensors on 30×42 cm2) recognising various types of food being eaten.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Tracking-based 3D human skeleton extraction from stereo video camera toward an on-site safety and ergonomic analysis\n",
            "Authors: Liu M.\n",
            "Abstract: Purpose - As a means of data acquisition for the situation awareness, computer vision-based motioncapture technologies have increased the potential to observe and assess manual activities for theprevention of accidents and injuries in construction. This study thus aims to present a computationallyefficient and robust method of human motion data capture for the on-site motion sensing and analysis. Design/methodology/approach - This study investigated a tracking approach to threedimensional(3D) human skeleton extraction from stereo video streams. Instead of detecting body jointson each image, the proposed method tracks locations of the body joints over all the successive frames bylearning from the initialized body posture. The corresponding body joints to the ones tracked are thenidentified and matched on the image sequences from the other lens and reconstructed in a 3D spacethrough triangulation to build 3D skeleton models. For validation, a lab test is conducted to evaluate theaccuracy and working ranges of the proposed method, respectively. Findings - Results of the test reveal that the tracking approach produces accurate outcomes at a distance, withnearly real-time computational processing, and can be potentially used for site data collection. Thus, the proposedapproach has a potential for various field analyses for construction workers' safety and ergonomics. Originality/value - Recently, motion capture technologies have rapidly been developed and studiedin construction. However, existing sensing technologies are not yet readily applicable to constructionenvironments. This study explores two smartphones as stereo cameras as a potentially suitable meansof data collection in construction for the less operational constrains (e.g. no on-body sensor required, lesssensitivity to sunlight, and flexible ranges of operations).\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Mannequin system for the self-training of nurses in the changing of clothes\n",
            "Authors: Ogata T.\n",
            "Abstract: Purpose – For self-training of nursing students, this paper developed a mannequin to simulate and measure the movement of a patient’s arms while nurses changed the patient’s clothes on a bed. In addition, using the mannequin the purpose of this paper is to determine the difference in the handling of a patient’s arms between nursing teachers and students. Design/methodology/approach – The target patient was an old man with complete paralysis. Three-degrees-of-freedom (DOF) shoulder joints and one-DOF elbow joints were applied to the mannequin. The angles of all joints were measured using a potentiometer, and those angles were transmitted to a computer via Bluetooth. Findings – In a preliminary experiment, the two nursing teachers confirmed that the mannequin arms simulated the motion of the arms of a paralyzed patient. In the experiment, two teachers and six students changed the clothes of the mannequin. The average joint angle of the left elbow and the moving frequency of the left elbow, right shoulder adduction/abduction and right shoulder internal/external rotation were lower in the case of teachers dressing the mannequin than when students were dressing it. Originality/value – The proposed system can simulate a completely paralyzed patient that nursing students would normally be almost unable to train with. Additionally, the proposed approach can reveal differences between skilled and non-skilled people in the treatment of a patient’s body.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Accuracy and repeatability of an inertial measurement unit system for field-based occupational studies\n",
            "Authors: Schall M.C.\n",
            "Abstract: The accuracy and repeatability of an inertial measurement unit (IMU) system for directly measuring trunk angular displacement and upper arm elevation were evaluated over eight hours (i) in comparison to a gold standard, optical motion capture (OMC) system in a laboratory setting, and (ii) during a field-based assessment of dairy parlour work. Sample-to-sample root mean square differences between the IMU and OMC system ranged from 4.1° to 6.6° for the trunk and 7.2°–12.1° for the upper arm depending on the processing method. Estimates of mean angular displacement and angular displacement variation (difference between the 90th and 10th percentiles of angular displacement) were observed to change <4.5° on average in the laboratory and <1.5° on average in the field per eight hours of data collection. Results suggest the IMU system may serve as an acceptable instrument for directly measuring trunk and upper arm postures in field-based occupational exposure assessment studies with long sampling durations. Few studies have evaluated inertial measurement unit (IMU) systems in the field or over long sampling durations. Results of this study indicate that the IMU system evaluated has reasonably good accuracy and repeatability for use in a field setting over a long sampling duration.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Towards a Mixed Reality System for Construction Trade Training\n",
            "Authors: Bosché F.\n",
            "Abstract: Apprenticeship training is at the heart of government skills policy worldwide. Application of cutting-edge information and communication technologies (ICTs) can enhance the quality of construction training, and help in attracting youth to an industry that traditionally has a poor image and slow in uptaking innovation. This paper reports on the development of a novel mixed reality (MR) system uniquely targeted for the training of construction trade workers, i.e., skilled manual workers. From a general training viewpoint, the system aims to address the shortcomings of existing construction trades training, in particular the lack of solutions for enabling trainees to train in realistic and challenging site conditions, while eliminating occupational health and safety risks. From a technical viewpoint, the system currently integrates state-of-the-art virtual reality goggles with a novel cost-effective 6-degree-of-freedom (DOF) head pose tracking system supporting the movement of trainees in room-size spaces, as well as a game engine to effectively manage the generation of the views of the virtual three-dimensional environment projected on the VR goggles. Experimental results demonstrate the performance of the 6-DOF head pose tracking system, which is the main computational contribution of the research reported in this paper. Then, preliminary results reveal its value to enable trainees to experience construction site conditions, particularly being at height, in different settings. Details are provided regarding future work to extend the system into the envisioned full MR system whereby a trainee would be performing an actual task, e.g., bricklaying, while being immersed in a virtual project environment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Real-time locating systems applications in construction\n",
            "Authors: Li H.\n",
            "Abstract: Real-time locating systems (RTLSs) are considered an effective way to identify and track the location of an object in both indoor and outdoor environments. Various RTLSs have been developed and made commercially available in recent years. Research into RTLSs in the construction sector is ubiquitous, and results have been published in many construction-related academic journals over the past decade. A succinct and systematic review of current applications would help academics, researchers, and industry practitioners in identifying existing research deficiencies and therefore future research directions. However, such a review is lacking to date. This paper provides a framework for understanding RTLS research and development in the construction literature over the last decade. The research opportunities and directions of construction RTLS are highlighted. Background information relating to construction RTLS trends, accuracy, deployment, cost, purposes, advantages, and limitations is provided. Four major research gaps are identified and research opportunities and directions are highlighted.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Non-Instrumental Movement Inhibition (NIMI) Differentially Suppresses Head and Thigh Movements during Screenic Engagement: Dependence on Interaction\n",
            "Authors: Witchel H.J.\n",
            "Abstract: Background: Estimating engagement levels from postural micromovements has been summarized by some researchers as: increased proximity to the screen is a marker for engagement, while increased postural movement is a signal for disengagement or negative affect. However, these findings are inconclusive: the movement hypothesis challenges other findings of dyadic interaction in humans, and experiments on the positional hypothesis diverge from it. Hypotheses: (1) Under controlled conditions, adding a relevant visual stimulus to an auditory stimulus will preferentially result in Non-Instrumental Movement Inhibition (NIMI) of the head. (2) When instrumental movements are eliminated and computer-interaction rate is held constant, for two identically-structured stimuli, cognitive engagement (i.e., interest) will result in measurable NIMI of the body generally. Methods: Twenty-seven healthy participants were seated in front of a computer monitor and speakers. Discrete 3-min stimuli were presented with interactions mediated via a handheld trackball without any keyboard, to minimize instrumental movements of the participant's body. Music videos and audio-only music were used to test hypothesis (1). Time-sensitive, highly interactive stimuli were used to test hypothesis (2). Subjective responses were assessed via visual analog scales. The computer users' movements were quantified using video motion tracking from the lateral aspect. Repeated measures ANOVAs with Tukey post hoc comparisons were performed. Results: For two equivalently-engaging music videos, eliminating the visual content elicited significantly increased non-instrumental movements of the head (while also decreasing subjective engagement); a highly engaging user-selected piece of favorite music led to further increased non-instrumental movement. For two comparable reading tasks, the more engaging reading significantly inhibited (42%) movement of the head and thigh; however, when a highly engaging video game was compared to the boring reading, even though the reading task and the game had similar levels of interaction (trackball clicks), only thigh movement was significantly inhibited, not head movement. Conclusions: NIMI can be elicited by adding a relevant visual accompaniment to an audio-only stimulus or by making a stimulus cognitively engaging. However, these results presume that all other factors are held constant, because total movement rates can be affected by cognitive engagement, instrumental movements, visual requirements, and the time-sensitivity of the stimulus.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Handbook of Digital Human Modeling: Research for Applied Ergonomics and Human Factors Engineering\n",
            "Authors: Duffy V.G.\n",
            "Abstract: The rapid introduction of sophisticated computers, services, telecommunications systems, and manufacturing systems has caused a major shift in the way people use and work with technology. It is not surprising that computer-aided modeling has emerged as a promising method for ensuring products meet the requirements of the consumer. The Handbook of Digital human Modeling.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of computer vision based face tracking measurement for sitting ergonomics\n",
            "Authors: Lintilä T.\n",
            "Abstract: Sitting causes major health problems. Both bad sitting posture and prolonged sitting time increases the likelihood of back pain. The object of our research was to study if it is possible to measure sitting ergonomics using a webcam video. The webcam placed in front of a subject was tracking the movements of subject’s face, which were used to derive the pose of subject’s head. Different algorithms to detect bad posture based on head pose and movement were developed according to the physiological recommendations. The accuracy of these algorithms were investigated in a real environment testing. Although the results are promising, more research is needed to develop better algorithms for a more accurate and versatile detection of sitting ergonomics.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Vision-based excavator detection and tracking using hybrid kinematic shapes and key nodes\n",
            "Authors: Yuan C.\n",
            "Abstract: Enhancing workplace safety continues to be a major task in the construction industry. Approximately 75% of struck-by fatalities are caused by inappropriate spatial-temporal relationships between construction workers and heavy equipment. Construction safety can be improved if the location and movement of heavy equipment are tracked in real time. However, detecting and tracking heavy equipment with kinematic joints and changing poses, such as excavators, is still a challenge for vision-based sensing methods. This study proposes to detect and track excavators using stereo cameras based on hybrid kinematic shape and key node features. Specifically, templates of excavator components are synthesized for detection following kinematic constraints of each component. Thereafter, a fast directional chamfer matching algorithm is used to detect the excavator components, and the detected components are articulated at the key nodes. Finally, the three-dimensional positions of the key nodes are tracked through triangulation to depict the excavator movements. Results from field experiments demonstrated that concatenating the detected components following a matching order enhances the detection performance. It is also found that the stereo triangulation enables efficient tracking of excavator movements by targeting at the key nodes.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Application of Machine Learning Approaches for Classifying Sitting Posture Based on Force and Acceleration Sensors\n",
            "Authors: Zemp R.\n",
            "Abstract: Occupational musculoskeletal disorders, particularly chronic low back pain (LBP), are ubiquitous due to prolonged static sitting or nonergonomic sitting positions. Therefore, the aim of this study was to develop an instrumented chair with force and acceleration sensors to determine the accuracy of automatically identifying the user's sitting position by applying five different machine learning methods (Support Vector Machines, Multinomial Regression, Boosting, Neural Networks, and Random Forest). Forty-one subjects were requested to sit four times in seven different prescribed sitting positions (total 1148 samples). Sixteen force sensor values and the backrest angle were used as the explanatory variables (features) for the classification. The different classification methods were compared by means of a Leave-One-Out cross-validation approach. The best performance was achieved using the Random Forest classification algorithm, producing a mean classification accuracy of 90.9% for subjects with which the algorithm was not familiar. The classification accuracy varied between 81% and 98% for the seven different sitting positions. The present study showed the possibility of accurately classifying different sitting positions by means of the introduced instrumented office chair combined with machine learning analyses. The use of such novel approaches for the accurate assessment of chair usage could offer insights into the relationships between sitting position, sitting behaviour, and the occurrence of musculoskeletal disorders.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Mood measurement with Pick-A-Mood: Review of current methods and design of a pictorial self-report scale\n",
            "Authors: Desmet P.M.A.\n",
            "Abstract: This paper introduces Pick-A-Mood, a character-based pictorial scale for reporting and expressing moods. Pick-A-Mood consists of three characters that each express eight mood states, representing four main categories: excited and cheerful (for energised-pleasant), irritated and tense (for energised-unpleasant), relaxed and calm (for calm-pleasant), and bored and sad (for calm-unpleasant). Using Pick-A-Mood requires little effort on the part of respondents, making it suitable for design research applications in which people often have little time or motivation to report their moods. Contrary to what is often assumed, mood and emotion are distinct phenomena with different measurable manifestations. These differences are discussed, and a review of existing methods is provided, indicating to what extent current methods that measure emotion are suitable for measuring mood. The development and validation of Pick-A-Mood is reported, and application examples and research opportunities are discussed.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automatic imagery data analysis for diagnosing human factors in the outage of a nuclear plant\n",
            "Authors: Tang P.\n",
            "Abstract: Nuclear power plant (NPP) outages involve maintenance and repair activities of a large number of workers in limited workspaces, while having tight schedules and zero-tolerance for accidents. During an outage, thousands of workers will be working around the NPP. Extremely high outage costs and expensive delays in maintenance projects (around $1.5 million per day) require tight outage schedules (typically 20 days). In such packed workspaces, real-time human behavior monitoring is critical for ensuring safe collaboration among workers, minimal wastes of time and resources due to the lack of situational awareness, and timely project control. Current methods for detailed human behavior monitoring on construction sites rely on manual imagery data collection and analysis, which is tedious and error-prone. This paper presents a framework of automatic imagery data analysis that enables real-time detection and diagnosis of anomalous human behaviors during outages, through the integration of 4D construction simulation and object tracking algorithms.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automated Postural Ergonomic Assessment Using a Computer Vision-Based Posture Classification\n",
            "Authors: Seo J.\n",
            "Abstract: In construction, workers are frequently exposed to manual handling tasks involving repetitive and forceful activities with awkward postures. As a result, construction workers are at about a fifty percent higher risk of work-related musculoskeletal disorders (WMSDs) than workers in other industries. Several ergonomic methods for evaluating workers' postural stresses through observations (e.g., OWAS, PATH, or RULA) have been applied to identify the risks of WMSDs during occupational tasks including construction. While inexpensive and practical to use, these methods are constrained by time-consuming procedures, observer bias, and the need for a well-trained analyst. These issues are exacerbated in the context of construction. In contrast to other factory-based (e.g., manufacturing) industries, construction is subject to irregular work patterns, relatively longer cycle time, and a wide variety of tasks. To address these issues, we propose computer vision-based posture classification that can automate existing observation-based postural evaluation methods such as OWAS. Specifically, the proposed method can classify workers' postures according to pre-defined ergonomic checklists using shape- and radial histogram-based features from video sequences. To test the feasibility of the proposed approach, we conducted a laboratory test with five subjects by simulating three representative postures according to upper limbs, back, and lower limbs. The results from the case study demonstrate that it can provide more reliable posture classification results with about 93% of accuracy. The proposed approach enables practitioners to identify the risk of WMSDs through automated ergonomic postural evaluation of on-going tasks only by taking videos at sites, which helps to prevent WMSDs for diverse occupational tasks including construction.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Evaluating the Impact of Motion Sensing Errors on Ergonomic Analysis\n",
            "Authors: Golabchi A.\n",
            "Abstract: The use of motion sensing technologies for ergonomic analysis of worker motions has gained increasing attention in construction. Using motion capture data enables extracting ergonomic assessment inputs more accurately than through a human observer. Accordingly, methods of collecting and analyzing human motion data have been developed to automate the ergonomic evaluation process for effective identification of ergonomic risk factors associated with manual operations. However, despite advancements in motion capture technologies, there is still inaccuracy associated with the resulting motion capture data, which leads to impreciseness of the output of the ergonomic assessment. This study investigates the impact that the imprecision of the motion capture data has on the results of ergonomic analysis, to evaluate the technical feasibility of a motion sensing approach to ergonomic analysis and to discuss the potential solutions by incorporating sensing errors into the motion analysis. Specifically, different possible sensing errors pertaining to a body joint location have been considered and the sensitivity of the errors on the results of ergonomic evaluation has been quantified. The results can be used to obtain an accurate and realistic adjustment for the results of ergonomic assessment based on the amount of error associated with any motion capture technology.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Personalized kinematics for human-robot collaborative manipulation\n",
            "Authors: Bestick A.M.\n",
            "Abstract: We present a framework for parameter and state estimation of personalized human kinematic models from motion capture data. These models can be used to optimize a variety of human-robot collaboration scenarios for the comfort or ergonomics of an individual human collaborator. Our approach offers two main advantages over prior approaches from the literature and commercial software: the kinematic models are estimated for a specific individual without a priori assumptions on limb dimensions or range of motion, and our kinematic formalism explicitly encodes the natural kinematic constraints of the human body. The personalized models are tested in a human-robot collaborative manipulation experiment. We find that human subjects with a restricted range of motion rotate their torso significantly less during bimanual object handoffs if the robot uses a personalized kinematic model to plan the handoff configuration, as compared to previous approaches using generic human kinematic models.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Managing children's postural risk when using mobile technology at home: Challenges and strategies\n",
            "Authors: Ciccarelli M.\n",
            "Abstract: Maintaining the musculoskeletal health of children using mobile information and communication technologies (ICT) at home presents a challenge. The physical environment influences postures during ICT use and can contribute to musculoskeletal complaints. Few studies have assessed postures of children using ICT in home environments. The present study investigated the Rapid Upper Limb Assessment (RULA) scores determined by 16 novice and 16 experienced raters. Each rater viewed 11 videotaped scenarios of a child using two types of mobile ICT at home. The Grand Scores and Action Levels determined by study participants were compared to those of an ergonomist experienced in postural assessment. All postures assessed were rated with an Action Level of 2 or above; representing a postural risk that required further investigation and/or intervention. The sensitivity of RULA to assess some of the unconventional postures adopted by children in the home is questioned.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Using physiological sensors to detect levels of user frustration induced by system delays\n",
            "Authors: Taylor B.\n",
            "Abstract: In mobile computing, varying access to resources makes it difficult for developers to ensure that satisfactory system response times will be maintained at all times. Wearable physiological sensors offer a way to dynamically detect user frustration in response to increased system delays. However, most prior efforts have focused on binary classifiers designed to detect the presence or absence of a task-specific stimulus. In this paper, we make two contributions. Our first contribution is in identifying the use of variable length system response delays, a universal and task-independent feature of computing, as a stimulus for driving different levels of frustration. By doing so, we are able to make our second and primary contribution, which is the development of models that predict multiple levels of user frustration from psycho-physiological responses caused by system response delays. We investigate how incorporating different sensor features, application settings, and timing constraints impact the performance of our models. We demonstrate that our models of physiological responses can be used to classify five levels of frustration in near real-Time with over 80% accuracy, which is comparable to the accuracy of binary classifiers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Design for mood: Twenty activity-based opportunities to design for mood regulation\n",
            "Authors: Desmet P.M.A.\n",
            "Abstract: This paper introduces a theory-based approach to design for mood regulation. The main proposition is that design can best influence mood by enabling and stimulating people to engage in a broad range of mood-regulating activities. The first part of the manuscript reviews state-of-the art mood-focused design research initiatives, grouped into four basic intentions, exploring how technology can measure, express, adapt to, or influence mood. The second part provides a functional explanation of the mood phenomenon, addressing how mood can be described, the function of mood, manifestations of mood, and how mood differs from emotion. The third and final part of the manuscript introduces an overview of novel mood-regulation strategies, and explores how these strategies can inspire design interventions. Twenty activity-based opportunities to design for mood regulation are grouped into three main focal categories: seeking relief, restoring balance, and building resilience.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Image processing-aided working posture analysis: I-OWAS\n",
            "Authors: Fiʇlali N.\n",
            "Abstract: Abstract Musculoskeletal Disorders (MSDs) rank among the commonest health problems both in the frequency of concurrency and in the money spent on these disorders, which mainly stem from poor working posture it also negatively affects employees in terms of job productivity, life quality, and both physical and social activities. Analyzing and improving working postures with scientific methods provides significant contributions in the field of controlling job performance and decreasing MSDs. OWAS (Ovako Working Posture Analyzing System) is one of the methods for analyzing working postures and can be applied to very diverse areas successfully. In this study, a prototype of integrated software, which is based on image processing techniques, was developed (I-OWAS), and the performance of the model was presented. I-OWAS begins with separating the video film into frames, producing OWAS codes belonging to working posture in each frame, and then classifying the images according to risk categories. Despite OWAS being a successful method for analyzing working postures, it requires an expert analysis. Also the manual analyzing process is so laborious and time consuming. I-OWAS provide the computer support for the manual coding stage and eliminates the need for an expert analyst; hence, the method can be widely used in industry.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automating measurement process to improve quality management for piping fabrication\n",
            "Authors: Safa M.\n",
            "Abstract: Addressing deficiencies and defects that occur during construction projects, particularly in piping fabrication, is costly and time consuming. The current quality management process associated with piping fabrication has a number of limitations, resulting primarily from human error and lack of consistency. This research therefore introduces an automated process for construction quality management that employs automated technologies for detecting defects, to contribute to the existing body of knowledge. The system relies on piping construction data collected with the use of photogrammetry and laser scanning, which are then used as a means of comparing the work actually performed to that designed. The developed three-station quality management model has the potential to decrease the overall cost of a project by reducing the fabrication rework required as well as by avoiding costly and time-consuming site assembly realignments, which are often caused by defects in the fabrication and delivery processes.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The future of video analytics for surveillance and its ethical implications\n",
            "Authors: Adams A.A.\n",
            "Abstract: The current state of the art and direction of research in computer vision aimed at automating the analysis of CCTV images is presented. This includes low level identification of objects within the field of view of cameras, following those objects over time and between cameras, and the interpretation of those objects' appearance and movements with respect to models of behaviour (and therefore intentions inferred). The potential ethical problems (and some potential opportunities) such developments may pose if and when deployed in the real world are presented, and suggestions made as to the necessary new regulations which will be needed if such systems are not to further enhance the power of the surveillers against the surveilled.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Motion data-driven biomechanical analysis during construction tasks on sites\n",
            "Authors: Seo J.\n",
            "Abstract: Work-related musculoskeletal disorders (WMSDs) are one of the major health issues that workers frequently experience due to awkward postures or forceful exertions during construction tasks. Among available job analysis methods, biomechanical models have been widely applied to assess musculoskeletal risks that may contribute to the development of WMSDs based on motion data during occupational tasks. Recently, with the advent of vision-based motion capture approaches, it has become possible to collect the motion data required for biomechanical analysis under real conditions. However, vision-based motion capture approaches have not been applied to biomechanical analysis because of compatibility issues in body models of the motion data and computerized biomechanical analysis tools. To address this issue, automated data processing is focused on to convert motion data into available data in existing biomechanical analysis tools, given the BVH motion data from vision-based approaches. To examine the feasibility of the proposed motion data processing, an experiment for both static and dynamic biomechanical analyses was conducted on lifting tasks. The results indicate that vision-based motion capture data - converted as proposed in this paper - can provide a sufficient level of detail on human kinematics to conduct biomechanical analysis, thus allowing for the identification of particular body parts where excessive forces are placed during tasks. The issues and directions of future research are also discussed to perform on-site biomechanical analysis during construction tasks.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Risk assessment of work-related musculoskeletal disorders in construction: State-of-the-art review\n",
            "Authors: Wang D.\n",
            "Abstract: Work-related musculoskeletal disorders (WMSDs) have long been a primary cause of non-fatal injuries in construction. They involve sudden or continuous stresses on a worker's musculoskeletal system (e.g., muscles, tendons, ligaments, bones) and may impair the ability of the worker to perform his or her job, or even cause permanent disability. Although assessing exposure to risk factors of WMSDs has proven to be feasible to alleviate the incidence rate of this injury, the field remains underdeveloped because of a lack of knowledge among construction professionals regarding the enabling techniques and their performance and limits. This paper reviews the available techniques for WMSD risk assessments, summarizes their benefits and limitations, and identifies areas in which further studies are still needed. Current techniques are categorized into self-report, observation, direct measurement, and remote sensing assessment. Particular interests are revealed in the wearable-sensor and vision-based techniques within the construction community. This review helps the industry to better understand the severity of WMSDs and the related risks in construction. This review also provides the construction research community with a holistic view on available techniques, their limitations, and the need for research in achieving automatic assessments on construction sites.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Wearable Sensing for Solid Biomechanics: A Review\n",
            "Authors: Wong C.\n",
            "Abstract: Understanding the solid biomechanics of the human body is important to the study of structure and function of the body, which can have a range of applications in health care, sport, well-being, and workflow analysis. Conventional laboratory-based biomechanical analysis systems and observation-based tests are designed only to capture brief snapshots of the mechanics of movement. With recent developments in wearable sensing technologies, biomechanical analysis can be conducted in less-constrained environments, thus allowing continuous monitoring and analysis beyond laboratory settings. In this paper, we review the current research in wearable sensing technologies for biomechanical analysis, focusing on sensing and analytics that enable continuous, long-term monitoring of kinematics and kinetics in a free-living environment. The main technical challenges, including measurement drift, external interferences, nonlinear sensor properties, sensor placement, and muscle variations, that can affect the accuracy and robustness of existing methods and different methods for reducing the impact of these sources of errors are described in this paper. Recent developments in motion estimation in kinematics, mobile force sensing in kinematics, sensor reduction for electromyography, and the future direction of sensing for biomechanics are also discussed.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Construction performance monitoring via still images, time-lapse photos, and video streams: Now, tomorrow, and the future\n",
            "Authors: Yang J.\n",
            "Abstract: Timely and accurate monitoring of onsite construction operations can bring an immediate awareness on project specific issues. It provides practitioners with the information they need to easily and quickly make project control decisions. Despite their importance, the current practices are still time-consuming, costly, and prone to errors. To facilitate the process of collecting and analyzing performance data, researchers have focused on devising methods that can semi-automatically or automatically assess ongoing operations both at project level and operation level. A major line of work has particularly focused on developing computer vision techniques that can leverage still images, time-lapse photos and video streams for documenting the work in progress. To this end, this paper extensively reviews these state-of-the-art vision-based construction performance monitoring methods. Based on the level of information perceived and the types of output, these methods are mainly divided into two categories (namely project level: visual monitoring of civil infrastructure or building elements vs. operation level: visual monitoring of construction equipment and workers). The underlying formulations and assumptions used in these methods are discussed in detail. Finally the gaps in knowledge that need to be addressed in future research are identified.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Computer vision techniques for construction safety and health monitoring\n",
            "Authors: Seo J.\n",
            "Abstract: For construction safety and health, continuous monitoring of unsafe conditions and action is essential in order to eliminate potential hazards in a timely manner. As a robust and automated means of field observation, computer vision techniques have been applied for the extraction of safety related information from site images and videos, and regarded as effective solutions complementary to current time-consuming and unreliable manual observational practices. Although some research efforts have been directed toward computer vision-based safety and health monitoring, its application in real practice remains premature due to a number of technical issues and research challenges in terms of reliability, accuracy, and applicability. This paper thus reviews previous attempts in construction applications from both technical and practical perspectives in order to understand the current status of computer vision techniques, which in turn suggests the direction of future research in the field of computer vision-based safety and health monitoring. Specifically, this paper categorizes previous studies into three groups - object detection, object tracking, and action recognition - based on types of information required to evaluate unsafe conditions and acts. The results demonstrate that major research challenges include comprehensive scene understanding, varying tracking accuracy by camera position, and action recognition of multiple equipment and workers. In addition, we identified several practical issues including a lack of task-specific and quantifiable metrics to evaluate the extracted information in safety context, technical obstacles due to dynamic conditions at construction sites and privacy issues. These challenges indicate a need for further research in these areas. Accordingly, this paper provides researchers insights into advancing knowledge and techniques for computer vision-based safety and health monitoring, and offers fresh opportunities and considerations to practitioners in understanding and adopting the techniques.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Status quo and open challenges in vision-based sensing and tracking of temporary resources on infrastructure construction sites\n",
            "Authors: Teizer J.\n",
            "Abstract: Modern construction projects require sufficient planning and management of resources to become successful. Core issues are tasks that deal with maintaining the schedule, such as procuring materials, guaranteeing the supply chain, controlling the work status, and monitoring safety and quality. Timely feedback of project status aids project management by providing accurate percentages of task completions and appropriately allocating resources (workforce, equipment, material) to coordinate the next work packages. However, current methods for measuring project status or progress, especially on large infrastructure projects, are mostly based on manual assessments. Recent academic research and commercial development has focused on semi- or fully-automated approaches to collect and process images of evolving worksites. Preliminary results are promising and show capturing, analyzing, and documenting construction progress and linking to information models is possible. This article presents first an overview to vision-based sensing technology available for temporary resource tracking at infrastructure construction sites. Second, it provides the status quo of research applications by highlighting exemplary case. Third, a discussion follows on existing advantages and current limitations of vision based sensing and tracking. Open challenges that need to be addressed in future research efforts conclude this paper.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Pose estimation with a kinect for ergonomic studies: Evaluation of the accuracy using a virtual mannequin\n",
            "Authors: Plantard P.\n",
            "Abstract: Analyzing human poses with a Kinect is a promising method to evaluate potentials risks of musculoskeletal disorders at workstations. In ecological situations, complex 3D poses and constraints imposed by the environment make it difficult to obtain reliable kinematic information. Thus, being able to predict the potential accuracy of the measurement for such complex 3D poses and sensor placements is challenging in classical experimental setups. To tackle this problem, we propose a new evaluation method based on a virtual mannequin. In this study, we apply this method to the evaluation of joint positions (shoulder, elbow, and wrist), joint angles (shoulder and elbow), and the corresponding RULA (a popular ergonomics assessment grid) upper-limb score for a large set of poses and sensor placements. Thanks to this evaluation method, more than 500,000 configurations have been automatically tested, which would be almost impossible to evaluate with classical protocols. The results show that the kinematic information obtained by the Kinect software is generally accurate enough to fill in ergonomic assessment grids. However inaccuracy strongly increases for some specific poses and sensor positions. Using this evaluation method enabled us to report configurations that could lead to these high inaccuracies. As a supplementary material, we provide a software tool to help designers to evaluate the expected accuracy of this sensor for a set of upper-limb configurations. Results obtained with the virtual mannequin are in accordance with those obtained from a real subject for a limited set of poses and sensor placements.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Designing User-Centered Lighting Scenarios\n",
            "Authors: Suk H.J.\n",
            "Abstract: This paper presents how people may use chromatic lighting to enhance the affective quality of their daily lives. Three cases are introduced in regard to how the chromatic quantity of LED lighting was manipulated in contexts of the office, classroom, and home.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Natural user interfaces for exploring and modeling medical images and defining gesture description technology\n",
            "Authors: None\n",
            "Abstract: None\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Using the startle eye-blink to measure affect in players\n",
            "Authors: Nesbitt K.\n",
            "Abstract: The startle eye-blink is part of a non-voluntary response that typically occurs when an individual encounters a sudden and unexpected stimulus, such as a loud noise or increase in light. Modulations of the startle reflex can be used to infer affective processing in players. The response can be elicited using simple auditory, visual, electric, or mechanical stimuli. The magnitude of the startle eye-blink is used to infer the unconscious positive (pleasant) or negative (unpleasant) emotional state of the player. It is frequently used in psychology where variations in the magnitude, latency, and duration of the startle response are used to understand attention, workload, affective processing, and psychopathologies such as schizophrenia. By comparison, there has been limited use of this objective measure for studying games. As such, there are opportunities to adapt this measure to studies of player affect in the context of game design. We provide a review of the concepts of “affect” and “affective computing” as they relate to game design and also explain in detail the use of the startle eye-blink for objectively measuring player affect. Finally, the use of the approach is illustrated in a case study for evaluating a serious game design.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Towards creation of implicit HCI model for prediction and prevention of operators’ error\n",
            "Authors: Mijović P.\n",
            "Abstract: This paper describes development of a new generation of the interactive industrial workplace, through introduction of a novel implicit Human Computer Interaction (HCI) model. Proposed framework aims at being a foundation of a computer-based system that enables an increase of workers safety and well-being in industrial environments. Further aim is to enable an increase in production levels, together with improvement of ergonomics of the workplace. Specifically targeted environments are industrial workplaces that include repetitive tasks, which are in most of the cases monotonic in nature. Implicit HCI model could enable development of a specific technical solution that is meant to be an integral and inseparable part of a future workplace and should serve to predict human errors and communicate a warning to a worker. As such, system is meant to increase situational awareness of the workers and prevent errors in operating that would otherwise lead to work-related injuries (including causalities).\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: System for posture evaluation and correction: Development of a second prototype for an intelligent chair\n",
            "Authors: Pereira H.\n",
            "Abstract: The sitting position has become one of the most common postures in developed countries. However, assuming a poor sitting posture leads to several health problems, namely back, shoulder and neck pain. In a previous work, an intelligent chair was developed and was shown to classify and correct the seating position. This work describes improvements on this intelligent chair prototype culminating with the development of a new prototype. The improvements of this new prototype are presented, resulting in new studies for posture identification. Pressure maps for 12 sitting postures were gathered in order to automatically detect user's posture through a neural network algorithm, obtaining an overall posture classification of around 81%.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Effect of inspection side and grasp position on upper limb load during visual inspection\n",
            "Authors: Hida T.\n",
            "Abstract: Visual inspection is one way to ensure product quality, and although automated visual inspection has been introduced, it is costly and associated with technical issues. Thus, human visual inspection still plays a major role in visual inspection in the industry. Many studies have focused on the visual fatigue of the inspectors. However, upper limb load caused by handling objects and maintaining a specific posture is also considered a problem in visual inspection. If the inspection object is lightweight but large in size (e.g., a plastic part), the inspectors tend to maintain an awkward posture due to difficulty in handling the object. Despite these findings, few studies have elucidated the effect of upper limb load. In this study, we intended to assess the effect of inspection side and object size on upper limb load. Ten healthy male subjects were instructed to inspect objects using a combination of six inspection side conditions (i.e., the sides of front with horizontal LED, top, under, front with vertical LED, right, and left) and two object size conditions (i.e., big: a square, 450 mm each side, and small: a square, 150 mm each side). Muscle activity and joint moment were the evaluation indices. We also investigated subjective indices for burden and task difficulty. Electromyography was performed on the subjects' sternomastoid muscle, the upper part of the trapezius, the clavicular part of the pectoralis major, the middle part of the deltoid, the biceps brachii, the extensor carpi radialis, and the flexor carpi ulnaris muscle. The results showed that the muscle load of the upper limb is highest when the inspection side condition is under side. Additionally, if the object is big, the muscle load of the neck and upper limb is greater.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Towards pervasive mobility assessments in clinical and domestic environments\n",
            "Authors: Isken M.\n",
            "Abstract: This paper provides an overview of current research and open problems in sensor-based mobility analysis. It is focused on geriatric assessment tests and the idea to provide easier and more objective results by using sensor technologies. A lot of research has been done in the field of measuring personal movement/mobility by technical approaches but there are few developments to measure a complete geriatric assessment test. Such automated tests can very likely offer more accurate, reliable and objective results than currently used methods. Additionally, those tests may reduce costs in public health systems as well as set standards for comparability of the tests. New sensor technologies and initiatives for data standardization in health processes offer increased possibilities in system development. This paper will highlight some open problems that still exist to bring automated mobility assessment tests into pervasive clinical and domestic use.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Comparative study of motion features for similarity-based modeling and classification of unsafe actions in construction\n",
            "Authors: Han S.\n",
            "Abstract: Rapid development of motion sensors and video processing has triggered growing attention to action recognition for safety and health analysis, as well as operation analysis, in construction. Specifically for occupational safety and health, worker behavior monitoring allows for the automatic detection of workers' unsafe actions and for feedback on their behavior, both of which enable the proactive prevention of an accident by reducing the number of unsafe actions that occur. Previous studies provide insight into tracking human movements and recognizing actions, but further research efforts are needed to understand the following characteristics of motion data, which can significantly affect classification performances: (1) various motion data types extracted from motion capture data, (2) variations of postures and actions, and (3) temporal and sequential relations of motion data. This paper thus presents a modeling and classification methodology for the recognition of unsafe actions, particularly focusing on (1) the description and comparison of four motion data types (i.e., rotation angles, joint angles, position vectors, and movement direction) that will be used as a feature for classification, (2) the estimation of actions' mean trajectory in order to model various patterns of action, and (3) the classification of actions based on spatial-temporal similarity. With a concentration on motion analysis, experiments were undertaken for the modeling and detection of actions during ladder climbing using an red, green, blue plus depth (RGB-D) sensor. Through the experimental study, we found that the proposed approach performs well (i.e., an accuracy of up to 99.5% in lab experiments), that a rotation angle outperforms a joint angle and a position vector, and that movement direction explicitly improves the accuracy of motion classification as combined with each of the other three. © 2014 American Society of Civil Engineers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A biomechanical analysis system of posture\n",
            "Authors: Bucciero A.\n",
            "Abstract: The number of scenarios that may gain benefits from postural analysis performed with sustainable economic costs is virtually limitless. They range from clinical and outpatient studies to sport and dance practicing, from posture learning and replication for humanoid robots to body control techniques. Therefore the authors firmly believe that the Microsoft Kinect, a novel optical markerless, model-free motion/capture commercial system can pave the way towards this direction due to its ease of usage and its low costs. In this paper, a Model-View-Controller based framework for Kinect-based postural analysis is presented in terms of both system architecture and selected test environment. A first prototypal version of the system has been employed to perform a preliminary stabilometric analysis in a real test case, in order to illustrate the adopted natural user interface and the overall system behavior.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Learner engagement measurement and classification in 1:1 learning\n",
            "Authors: Aslan S.\n",
            "Abstract: We explore the feasibility of measuring learner engagement and classifying the engagement level based on machine learning applied on data from 2D/3D camera sensors and eye trackers in a 1:1 learning setting. Our results are based on nine pilot sessions held in a local high school where we recorded features related to student engagement while consuming educational content. We label the collected data as Engaged or NotEngaged while observing videos of the students and their screens. Based on the collected data, perceptual user features (e.g., body posture, facial points, and gaze) are extracted. We use feature selection and classification methods to produce classifiers that can detect whether a student is engaged or not. Accuracies of up to 85-95% are achieved on the collected dataset. We believe our work pioneers in the successful classification of student engagement based on perceptual user features in a 1:1 authentic learning setting.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Implementation of a markerless motion analysis method to quantify hyperkinesis in males with fragile X syndrome\n",
            "Authors: O'Keefe J.\n",
            "Abstract: Hyperactive behavior - and implicitly, motion - in Fragile X syndrome (FXS) has been historically described using behavioral rating scales. While rating scales are the current standard outcome measures used in clinical research, they have limitations including their qualitative nature and subjectivity. The advent of new motion capture technologies has provided the opportunity to develop quantitative methods for measuring hyperactive motion. The hypotheses for this study were that a novel markerless motion analysis method (1) can quantitatively measure kinematic parameters, (2) can differentiate the level of hyperkinesis between control and FXS populations, and (3) will correlate with blind-reviewer synchronous video-capture methods and behavioral rating scale scores. Twenty young males (7-control, 13-FXS; ages 9-32) were studied using a standardized protocol in a markerless motion analysis suite. Behavioral scale questionnaires were filled out by parents and those scores were correlated with motion parameters (frequency and total traveled distance) of body segments during 30. s of story listening while standing in the observation space. The markerless system was able to track subjects and the two populations displayed significantly different quantities of motion, with larger amounts of motion in the FXS group (p<. 0.05). Pearson's correlation coefficients between frequency counts obtained from the markerless system and rater-based video capture were between 0.969 and 0.996 (p<. 0.001). Significant correlations between rating scale scores and motion parameters ranged from 0.462. ≤. r≤. 0.568 (p≤. 0.040). These results suggest feasibility and validity of a markerless system as a non-invasive method able to quantify motion in individuals with hyperkinesis. © 2013 Elsevier B.V.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Methods for improving visibility measurement standards of powered industrial vehicles\n",
            "Authors: Bostelman R.\n",
            "Abstract: Poor visibility of powered industrial vehicles, such as forklifts, used in industry is often the cause of accidents that include pedestrians. Current standards allow up to 20% non-visible regions for forklifts where measurement of these regions is performed by using lamps. A collaboration of research organizations, including National Institute of Standards and Technology, Georgia Institute of Technology (NIST), and Direct Dimensions, has been evaluating advanced methods for measuring a forklift operator's visibility. These methods can potentially improve visibility standards. They can also aid forklift and sensor manufacturers to (a) perform different facets blind spot analysis without requiring extensive and time consuming infrastructure set up (b) develop techniques to efficiently utilize visibility-assist sensors and (c) find the optimal location where worker-on-foot or obstacle avoidance proximity detection and avoidance sensors or alerts can be mounted on forklifts. This paper includes explanation of visibility measurement experiments performed and results, associated language suggested to standards organizations, and a prototype design for measuring the visibility of forklifts automatically. © 2013.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A drowsy driver detection system based on a new method of head posture estimation\n",
            "Authors: Teyeb I.\n",
            "Abstract: A drowsy driver detection system based on a new method for head posture estimation is proposed. In the first part, we introduced six possible models of head positions that can be detected by our algorithm which is explained in the second part. Indeed, there are three key stages characterizing our method: First of all, we proceed with driver's face detection by Viola and Jones algorithm. Then, we extract the image reference and the non image reference coordinates from the face bounding's box. Finally, based on measuring both the head inclination's angle and distances between the extracted coordinates, we classify the head state (normal or inclined). Test results demonstrate that the proposed system can efficiently measure the aforementioned parameters and detect the head state as a sign of driver's drowsiness.... © 2014 Springer International Publishing Switzerland.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Context-aware posture analysis in a workstation-oriented office environment\n",
            "Authors: Wongpatikaseree K.\n",
            "Abstract: Among current research trends, correction of the sitting posture is attracting growing attention. Most office workers suffer several health problems during their work. The two greatest causes of health problems in the office environment are simple things. The first is poor sitting posture. Sitting with poor posture in front of a computer for hours causes cumulative damage. The second is an inappropriate workstation environment. The workstation environment is related to good sitting posture. For example, if the desk is too low, the user has to lean forward to look at the display. To address this problem, we propose a sitting posture recognition system that can recognize both human posture and the context of the workstation environment. The proposed system has three components. First, skeleton tracking is used to create a sideways view of the human skeleton. The skeleton model in this research is used to measure the joint angles of the human body. Second, we detect information on objects using a proposed workstation environment tracking system. Three types of features are used to filter the objects from the depth image. Finally, we compare the overall information with a standard sitting posture in a model-matching component. Experimental studies showed that the system can provide the necessary information for analyzing the human posture. A physician or user can apply this information to achieve correct sitting posture or prevent health problems in the office using the provided results. © 2014 Springer International Publishing Switzerland.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Old problems and new perspectives for postural analysis\n",
            "Authors: do Rosário J.L.P.\n",
            "Abstract: The study of posture is not an easy task, mainly because postural assessment is still scientifically inaccurate. Photographs of bipedalism in the frontal and sagittal planes are one of the most widely used methods for this assessment. Motion capture allows 3D assessment with increased accuracy, but is considered expensive yet with the introduction of new technologies it is becoming more cost effective. This chapter presents a review of the literature which aims to discuss the advantages and disadvantages of the various types of optical systems for postural assessment. Medline and Lilacs databases were searched for the period from 2002 to 2012, using the following key terms: \"posture\" and \"postural\". Articles needed to have a description of an optical postural assessment. From the literature explored, it was noted that the advantages of photos are relate to their cost effectiveness and portability. It is even possible to find smart phones apps for postural analysis. Nevertheless, the chances of errors increase with this method. For example, issues in pinpointing body landmarks and finding the correct position of the camera (small rotation can distort the picture) are reported as the two major flaws. They can however be minimized with a better landmark choice and fixed camera positioning. In comparison, motion capture systems have several advantages over pictures. It can assess the patient from different angles simultaneously, assess not just the posture, but also gait and the dynamical part of the posture, which better satisfies the non-stillness postural concept. However, besides the same landmarks problems found in pictures, motion capture systems can be far more expensive and take much more space, and it can be a challenge to transport the system from one venue to the next. A markerless system using a good algorithm can be an option to be tested for accuracy. Whilst 3D sensors such as Microsoft Kinect at present can be considered as not the optimal solution, they may be in a near future. They are inexpensive, portable and do not require markers to determine anatomical landmarks, and consequently may overcome the limitations associated with laboratory-based movement analysis systems. The limitation however is the lack of precision, but new technologies such as the time of flight cameras are improving in accuracy. Researchers and clinicians should carefully choose their assessment equipment based on accuracy, pre-assessment preparation time, space available for equipment installation and cost.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A stereo vision-based approach to marker-less motion capture for on-site kinematic modeling of construction worker tasks\n",
            "Authors: Starbuck R.\n",
            "Abstract: Marker-less motion capture has been extensively studied in recent years as a means of evaluating productivity, safety, and workplace design for manual operations on-site. These technologies are ideal for circumstances in which traditional motion capture systems are ineffective due to the need for a laboratory setting and movement-inhibiting markers or sensors. However, many marker-less motion capture systems rely on RGB-D sensors that have limited range and susceptibility to interference from sunlight and ferromagnetic radiation, making them unsuitable for modeling worker actions on construction sites. To address this issue, we propose a marker-less motion capture approach utilizing optical images and depth data obtained from stereo vision cameras. Multiple camera lenses and triangulation algorithms generate depths maps similar to those produced by RGB-D sensors, while still utilizing an optical recording process unhindered by potentially harsh construction site conditions. These data are adapted for existing kinematic modeling systems (i.e. iPiMocap Studio) for 3-D pose estimation. The experiments show that the proposed approach can provide data precision comparable to that of RGB-D-based systems with fewer operational constraints; thus, motion data can be collected where previously developed methods fail due to environmental or maneuverability restrictions. With the proposed approach, kinematic modeling of human movements can be carried out on construction sites without inhibiting the mobility of the recorded subject.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Dynamic biomechanical analysis for construction tasks using motion data from vision-based motion capture approaches\n",
            "Authors: Seo J.O.\n",
            "Abstract: In the labor-intensive construction industry, workers are frequently exposed to manual handling tasks involving forceful exertions and awkward postures. As a result, construction workers are at about a 16 percent higher risk of work-related musculoskeletal disorders (WMSDs) than workers in other industries. A biomechanical model-based musculoskeletal stress analysis is one of the widely used methods to identify the risk of WMSDs during occupational tasks. However, the use of biomechanical analysis has been limited to only laboratory experiments due to the difficulty of collecting motion data required for biomechanical models under real conditions. To reflect postural variations when performing construction tasks, an effective and easily accessible mean that enables us to conduct biomechanical analysis under real conditions is required. To address this issue, we propose a motion-data-driven biomechanical analysis by enabling automatic processes to convert motion data from vision-based motion capture into available data for representing motions in biomechanical analysis tools. We conduct a case study on masonry work to determine the feasibility of the proposed method. The results show that the proposed approach has the potential to assess an individual's motions and to provide personalized feedback for the purpose of reducing biomechanical loads and WMSD risk in real workplaces.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Towards a cyber-physical gaming system for training in the construction and engineering industry\n",
            "Authors: Sivanathan A.\n",
            "Abstract: Introducing serious gaming systems (SGS) has the potential to enhance trainee experience and performance across the construction industry and its supply chain, such as mechanical engineering services. SGS as an 'enabler' in architectural engineering has received limited research in its role to assess and enhance the performance of its workforce. In a personnel high-risk environment, improving training standards to eliminate or reduce health and safety risks, in addition to providing an understanding of workers' ergonomics, ensures sustainability of both the project and its workforce. This paper presents an activity tracking and feedback system that captures the physical activity of a construction worker climbing a ladder. Climbing is captured with a 3D motion capture system and processed in real-time to identify potential areas of underperformance. A simple and representative scoring method was established as a reporting method (game statistics) for giving feedback about the correctness of the activity. It can nonetheless be tuned to characterise and adjust to various complexity levels in-line with the required training standards. Furthermore, the motion data and feedback information are fed into a virtual gaming environment enabling the real-time visualisation of the trainee's motion and experiential learning of the performance through visual and audio feedback. The gaming concepts are employed here with multiple purposes, particularly for accelerating and facilitating the learning process of the trainee. In addition to the 3D motion capturing system, this paper outlines and tests a proposed serious cyber-physical gaming system that incorporates wearable technologies that has the potential to support both construction training and practice.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Vision-based workface assessment using depth images for activity analysis of interior construction operations\n",
            "Authors: Khosrowpour A.\n",
            "Abstract: Workface assessment - the process of determining the overall activity rates of onsite construction workers throughout a day - typically involves manual visual observations which are time-consuming and labor-intensive. To minimize subjectivity and the time required for conducting detailed assessments, and allowing managers to spend their time on the more important task of assessing and implementing improvements, we propose a new inexpensive vision-based method using RGB-D sensors that is applicable to interior construction operations. This is a particularly challenging task as construction activities have a large range of intra-class variability including varying sequences of body posture and time-spent on each individual activity. The skeleton extraction algorithms from RGB-D sequences produce noisy outputs when workers interact with tools or when there is a significant body occlusion within the camera's field-of-view. Existing vision-based methods are also limited as they can primarily classify \"atomic\" activities from RGB-D sequences involving one worker conducting a single activity. To address these limitations, our method includes three components: 1) an algorithm for detecting, tracking, and extracting body skeleton features from depth images; 2) a discriminative bag-of-poses activity classifier for classifying single visual activities from a given body skeleton sequence; and 3) a Hidden Markov Model to represent emission probabilities in the form of a statistical distribution of single activity classifiers. For training and testing purposes, we introduce a new dataset of eleven RGB-D sequences for interior drywall construction operations involving three actual construction workers conducting eight different activities in various interior locations. Our results with an average accuracy of 76% on the testing dataset show the promise of vision-based methods using RGB-D sequences for facilitating the activity analysis workface assessment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Writing-state classification by ambient sedentary behavior sensing in desk work\n",
            "Authors: Matsumoto S.\n",
            "Abstract: This paper presents a technique for writing-state classification by sedentary behavior sensing with a sensor-equipped chair, which wirelessly monitors the user's states such as behaviors or physiological and psychological conditions, for estimation of the user's subjective difficulty with a studying problem on a desktop. Avoiding user discomfort, four load cells are mounted behind the seat plate of a regular office chair. The system simply measures the weight and the center of pressure of the seat. These data are divided into time segments, which are labeled into four sedentary-body sway primitives by the decision tree algorithm, and then the behaviors are derived from the number and pitch of those primitives in a certain interval. In system-evaluation experiments, it achieved more than 80% labeling accuracy for untrained users. We conducted a user experiment showing its potential for desk work applications. The results of the experiment showed that our proposed system could classify user states into the writing state and other states such as reading a document and watching a movie at a classification rate of 87%.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automatic detection of nonverbal behavior predicts learning in dyadic interactions\n",
            "Authors: Won A.\n",
            "Abstract: Nonverbal behavior can reveal the psychological states of those engaged in interpersonal interaction. Previous research has highlighted the relationship between gesture and learning during instruction. In the current study we applied readily available computer vision hardware and machine learning algorithms to the gestures of teacher/student dyads (it N = 106) during a learning session to automatically distinguish between high and low success learning interactions, operationalized by recall for information presented during that learning session. Models predicted learning performance of the dyad with accuracies as high as 85.7 percent when tested on dyads not included in the training set. In addition, correlations were found between summed measures of body movement and learning score. We discuss theoretical and applied implications for learning. © 2012 IEEE.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automated worker activity analysis in indoor environments for direct-work rate improvement from long sequences of RGB-D images\n",
            "Authors: Khosrowpour A.\n",
            "Abstract: This paper presents a new method for activity analysis of construction workers using inexpensive RGB+depth sensors. This is an important task, as no current workforce assessment method can provide detailed and continuous information to help project managers identify bottlenecks affecting labor's productivity. Previous work using RGB-D images focuses on action recognition form short video sequences wherein only one action is represented within each video. Automating this analysis for long sequences of RGB-D images is challenging because the start and the end of each action is unknown, recognizing single actions is still challenging, and there are no data sets and validation metrics to evaluate algorithms. Given an input sequence of RGB-D images, our algorithm divides it into temporal segments and automatically classifies the observed actions. To do so, the algorithm first detects body postures in real time. Then a kernel density estimation (KDE) model is trained to model classification scores from discriminatively trained bag-of-poses action classifiers. Further, a hidden Markov model (HMM) labels sequences of actions that are most discriminative. The performance of our model is tested on unprecedented data sets of actual drywall construction operations. Experimental results, in addition to the perceived benefits and limitations of the proposed method, are discussed in detail. © 2014 American Society of Civil Engineers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Quantifying driver frustration to improve road safety\n",
            "Authors: Taib R.\n",
            "Abstract: Automatically identifying driver inattention could dramatically improve road safety. This paper presents a preliminary study aiming to correlate high levels of frustration with posture information collected from the driver's seat. Using a driving simulator, participants had to drive under normal and frustrating conditions, for example parking in a tight spot with some time constraint. Binary classification using a range of machine learning algorithms provided encouraging results, showing that posture features could help reflect frustration and possibly other drivers' mental states.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A distributed data collection and management framework for tracking construction operations\n",
            "Authors: Vasenev A.\n",
            "Abstract: Construction work typically means producing on shifting locations. Moving materials, equipment and men efficiently from place to place, in and in between projects, depends on good coordination and requires specialized information systems. The key to such information systems are appropriate approaches to collect de-centralized sensor readings and to process, and distribute them to multiple end users at different locations both during the construction process and after the project is finished. This paper introduces a framework for the support of such distributed data collection and management to foster real-time data collection and processing along with the provision of opportunities to retain highly precise data for post-process analyses. In particular, the framework suggests a scheme to benefit from exploiting readings from the same sensors in varying levels of detail for informing different levels of decision making: operational, tactical, and strategic. The sensor readings collected in this way are not only potentially useful to track, assess, and analyse construction operations, but can also serve as reference during the maintenance stage. To this extent, the framework contributes to the existing body of knowledge of construction informatics. The operationality of the framework is demonstrated by developing and applying two on site information systems to track asphalt paving operations. © 2014 Elsevier Ltd. All rights reserved.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Using Kinect™ sensor in observational methods for assessing postures at work\n",
            "Authors: Diego-Mas J.A.\n",
            "Abstract: This paper examines the potential use of Kinect™ range sensor in observational methods for assessing postural loads. Range sensors can detect the position of the joints at high sampling rates without attaching sensors or markers directly to the subject under study. First, a computerized OWAS ergonomic assessment system was implemented to permit the data acquisition from Kinect™ and data processing in order to identify the risk level of each recorded postures. Output data were compared with the results provided by human observers, and were used to determine the influence of the sensor view angle relative to the worker. The tests show high inter-method agreement in the classification of risk categories (Proportion agreement index=0.89 κ=0.83) when the tracked subject is facing the sensor. The camera's point of view relative to the position of the tracked subject significantly affects the correct classification of the postures. Although the results are promising, some aspects involved in the use of low-cost range sensors should be further studied for their use in real environments. © 2013 Elsevier Ltd and The Ergonomics Society.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automatic evaluation of trainee nurses' patient transfer skills using multiple kinect sensors\n",
            "Authors: Huang Z.\n",
            "Abstract: To help student nurses learn to transfer patients from a bed to a wheelchair, this paper proposes a system for automatic skill evaluation in nurses' training for this task. Multiple Kinect sensors were employed, in conjunction with colored markers attached to the trainee's and patient's clothing and to the wheelchair, in order to measure both participants' postures as they interacted closely during the transfer and to assess the correctness of the trainee's movements and use of equipment. The measurement method involved identifying body joints, and features of the wheelchair, via the colors of the attached markers and calculating their 3D positions by combining color and depth data from two sensors. We first developed an automatic segmentation method to convert a continuous recording of the patient transfer process into discrete steps, by extracting from the raw sensor data the defining features of the movements of both participants during each stage of the transfer. Next, a checklist of 20 evaluation items was defined in order to evaluate the trainee nurses' skills in performing the patient transfer. The items were divided into two types, and two corresponding methods were proposed for classifying trainee performance as correct or incorrect. One method was based on whether the participants' relevant body parts were positioned in a predefined spatial range that was considered 'correct' in terms of safety and efficacy (e.g., feet placed appropriately for balance). The second method was based on quantitative indexes and thresholds for parameters describing the participants' postures and movements, as determined by a Bayesian minimum-error method. A prototype system was constructed and experiments were performed to assess the proposed approach. The evaluation of nurses' patient transfer skills was performed successfully and automatically. The automatic evaluation results were compared with evaluation by human teachers and achieved an accuracy exceeding 80%. Copyright © 2014 The Institute of Electronics, Inf rmation and Communication Engineers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Intelligent chair sensor - classification and correction of sitting posture\n",
            "Authors: Martins L.\n",
            "Abstract: In order to build an intelligent chair capable of posture detection and correction we developed a prototype that measures a pressure map of the chair's seat pad and backrest and classifies the user posture. The posture classification was done using neural networks that were trained for 5 standardized postures achieving an overall classification of around 98%. Those neural networks were exported to a mobile application in order to do real-time classification of those postures. Using the same mobile application we devised two correction algorithms that were implemented in order to create an intelligent chair capable of posture detection and correction. The posture correction is forced through the change of the conformation of the chair's seat and backrest by changing the pressure of eight pneumatic bladders. © Springer International Publishing Switzerland 2014.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Empirical assessment of a RGB-D sensor on motion capture and action recognition for construction worker monitoring\n",
            "Authors: Han S.U.\n",
            "Abstract: Background: For construction management, data collection is a critical process for gathering and measuring information for the evaluation and control of ongoing project performances. Taking into account that construction involves a significant amount of manual work, worker monitoring can play a key role in analyzing operations and improving productivity and safety. However, time-consuming tasks involved in field observation have brought up the issue of implementing worker observation in daily management practice. Methods: In an effort to address the issue, this paper investigates the performances of a cost-effective and portable RGB-D sensor, based on recent research efforts extended from our previous study. The performance of an RGB-D sensor is evaluated in terms of (1) the 3D positions of the body parts tracked by the sensor, (2) the 3D rotation angles at joints, and (3) the impact of the RGB-D sensor’s accuracy on motion analysis. For the assessment, experimental studies were undertaken to collect motion capture datasets using an RGB-D sensor and a marker-based motion capture system, VICON, and to analyze errors as compared with the VICON used as the ground truth. As a test case, 25 trials of ascending and descending during ladder climbing were recorded simultaneously with both systems, and the resulting motion capture datasets (i.e., 3D skeleton models) were temporally and spatially synchronized for their comparison. Results: Through the comparative assessment, we found a discrepancy of 10.7 cm in the tracked locations of body parts, and a difference of 16.2 degrees in rotation angles. However, motion detection results show that the inaccuracy of an RGB-D sensor does not have a considerable effect on action recognition in the experiment. Conclusions: This paper thus provides insight into the accuracy of an RGB-D sensor on motion capture in various measures and directions of further research for the improvement of accuracy.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Development of a cost effective three-dimensional posture analysis tool: Validity and reliability\n",
            "Authors: Brink Y.\n",
            "Abstract: Background: The lack of clear understanding of the association between sitting posture and adolescent musculoskeletal pain, might reflect invalid and/or unreliable posture measurement instruments. The psychometric properties of any new measurement instrument should be demonstrated prior to use for research or clinical purposes. This paper describes psychometric testing of a new three-dimensional (3D), portable, non-invasive posture analysis tool (3D-PAT), from sequential studies using a mannequin and high school students. Methods. The first study compared the 3D-(X-, Y- and Z-) coordinates of reflective markers placed on a mannequin using the 3D-PAT, and the Vicon motion analysis system. This study also tested the reliability of taking repeated measures of the 3D-coordinates of the reflective markers. The second study determined the concurrent validity and test-retest reliability of the 3D-PAT measurements of nine sitting postural angles of high school students undertaking a standard computing task. In both studies, concordance correlation coefficients and Intraclass correlation coefficients described test-retest reliability, whilst Pearson product moment correlation coefficients and Bland-Altman plots demonstrated concurrent validity. Results: The 3D-PAT provides reliable and valid 3D measurements of five of the nine postural angles i.e. head flexion, neck flexion, cranio-cervical angle, trunk flexion and head lateral bending in adolescents undertaking a standard task. Conclusions: The 3D-PAT is appropriate for research and clinical settings to measure five upper quadrant postural angles in three dimensions. As a measurement instrument it can provide further understanding of the relationship between sitting posture, changes to sitting posture and adolescent musculoskeletal pain. © 2013 Brink et al.; licensee BioMed Central Ltd.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Vision-based action recognition of earthmoving equipment using spatio-temporal features and support vector machine classifiers\n",
            "Authors: Golparvar-Fard M.\n",
            "Abstract: Video recordings of earthmoving construction operations provide understandable data that can be used for benchmarking and analyzing their performance. These recordings further support project managers to take corrective actions on performance deviations and in turn improve operational efficiency. Despite these benefits, manual stopwatch studies of previously recorded videos can be labor-intensive, may suffer from biases of the observers, and are impractical after substantial period of observations. This paper presents a new computer vision based algorithm for recognizing single actions of earthmoving construction equipment. This is particularly a challenging task as equipment can be partially occluded in site video streams and usually come in wide variety of sizes and appearances. The scale and pose of the equipment actions can also significantly vary based on the camera configurations. In the proposed method, a video is initially represented as a collection of spatio-temporal visual features by extracting space-time interest points and describing each feature with a Histogram of Oriented Gradients (HOG). The algorithm automatically learns the distributions of the spatio-temporal features and action categories using a multi-class Support Vector Machine (SVM) classifier. This strategy handles noisy feature points arisen from typical dynamic backgrounds. Given a video sequence captured from a fixed camera, the multi-class SVM classifier recognizes and localizes equipment actions. For the purpose of evaluation, a new video dataset is introduced which contains 859 sequences from excavator and truck actions. This dataset contains large variations of equipment pose and scale, and has varied backgrounds and levels of occlusion. The experimental results with average accuracies of 86.33% and 98.33% show that our supervised method outperforms previous algorithms for excavator and truck action recognition. The results hold the promise for applicability of the proposed method for construction activity analysis. © 2013 Elsevier Ltd. All rights reserved.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: ECushion: A textile pressure sensor array design and calibration for sitting posture analysis\n",
            "Authors: Xu W.\n",
            "Abstract: Sitting posture analysis is widely applied in many daily applications in biomedical, education, and health care domains. It is interesting to monitor sitting postures in an economic and comfortable manner. Accordingly, we present a textile-based sensing system, called Smart Cushion, which analyzes the sitting posture of human being accurately and non-invasively. First, we introduce the electrical textile sensor and its electrical characteristics, such as offset, scaling, crosstalk, and rotation. Second, we present the design and implementation of the Smart Cushion system. Several effective techniques have been proposed to improve the recognition rate of sitting postures, including sensor calibration, data representation, and dynamic time warping-based classification. Last, our experimental results show that the recognition rate of our Smart Cushion system is in excess of 85.9%. © 2013 IEEE.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Posture analysis and range of movement estimation using depth maps\n",
            "Authors: Reyes M.\n",
            "Abstract: World Health Organization estimates that 80% of the world population is affected of back pain during his life. Current practices to analyze back problems are expensive, subjective, and invasive. In this work, we propose a novel tool for posture and range of movement estimation based on the analysis of 3D information from depth maps. Given a set of keypoints defined by the user, RGB and depth data are aligned, depth surface is reconstructed, keypoints are matching using a novel point-to-point fitting procedure, and accurate measurements about posture, spinal curvature, and range of movement are computed. The system shows high precision and reliable measurements, being useful for posture reeducation purposes to prevent musculoskeletal disorders, such as back pain, as well as tracking the posture evolution of patients in rehabilitation treatments. © 2013 Springer-Verlag.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The embodiment of focus: Investigating the impact of leaning behavior on our cognitive state and other's perception of our cognitive state\n",
            "Authors: Chisholm J.D.\n",
            "Abstract: The emerging literature on embodied cognition highlights the role that the body plays in cognitive and affective processes. We investigated whether different body postures, specifically leaning postures thought to reflect different states of cognitive focus, can impact cognitive focus and task performance. In three experiments we confirmed that different postures are perceived reliably by others to convey distinct and different states of cognitive focus. However, the individuals who actually adopted the postures did not experience any subjective change in cognitive focus nor demonstrate any influence of leaning posture on performance across a range of tasks that varied in their naturalness and complexity. Only by instructing participants to adopt a posture associated with a focused or unfocused cognitive state did an association between performance and posture emerge. These data indicate that changes in one's body do not necessarily yield a reliable change in one's cognitive state, even when (a) those changes in body are reliably perceived by others as inducing a change in cognitive state, and (b) changes in cognitive state lead to robust changes in the body. In light of these findings, we propose two related accounts that point to leaning behavior as being the result of one's increasing need to focus. Thus, rather than influencing cognitive state, leaning behavior may instead reflect the embodiment of one's cognitive state of focus. © 2012 American Psychological Association.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A robust static hand gesture recognition system using geometry based normalizations and Krawtchouk moments\n",
            "Authors: Padam Priyal S.\n",
            "Abstract: Static hand gesture recognition involves interpretation of hand shapes by a computer. This work addresses three main issues in developing a gesture interpretation system. They are (i) the separation of the hand from the forearm region, (ii) rotation normalization using the geometry of gestures and (iii) user and view independent gesture recognition. The gesture image comprising the hand and the forearm is detected through skin color detection and segmented to obtain a binary silhouette. A novel method based on the anthropometric measures of the hand is proposed for extracting the regions constituting the hand and the forearm. An efficient rotation normalization method that depends on the gesture geometry is devised for aligning the extracted hand. These normalized binary silhouettes are represented using the Krawtchouk moment features and classified using a minimum distance classifier. The Krawtchouk features are found to be robust to viewpoint changes and capable of achieving good recognition for a small number of training samples. Hence, these features exhibit user independence. The developed gesture recognition system is robust to similarity transformations and perspective distortions. It can be well realized for real-time implementation of gesture based applications. © 2013 Elsevier Ltd.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Accurate telemonitoring of Parkinson's disease diagnosis using robust inference system\n",
            "Authors: Mandal I.\n",
            "Abstract: This work presents more precise computational methods for improving the diagnosis of Parkinson's disease based on the detection of dysphonia. New methods are presented for enhanced evaluation and recognize Parkinson's disease affected patients at early stage. Analysis is performed with significant level of error tolerance rate and established our results with corrected T-test. Here new ensembles and other machine learning methods consisting of multinomial logistic regression classifier with Haar wavelets transformation as projection filter that outperform logistic regression is used. Finally a novel and reliable inference system is presented for early recognition of people affected by this disease and presents a new measure of the severity of the disease. Feature selection method is based on Support Vector Machines and ranker search method. Performance analysis of each model is compared to the existing methods and examines the main advancements and concludes with propitious results. Reliable methods are proposed for treating Parkinson's disease that includes sparse multinomial logistic regression, Bayesian network, Support Vector Machines, Artificial Neural Networks, Boosting methods and their ensembles. The study aim at improving the quality of Parkinson's disease treatment by tracking them and reinforce the viability of cost effective, regular and precise telemonitoring application. © 2012 Elsevier Ireland Ltd.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Data fusion of real-time location sensing and physiological status monitoring for ergonomics analysis of construction workers\n",
            "Authors: Cheng T.\n",
            "Abstract: Previous research and applications in construction resource optimization have focused on tracking the location of material and equipment. There is a lack of studies on remote monitoring for improving safety and health of the construction workforce. This paper presents a new approach for monitoring ergonomically safe and unsafe behavior of construction workers. The study relies on a methodology that utilizes fusion of data from continuous remote monitoring of construction workers' location and physiological status. To monitor construction workers activities, the authors deployed nonintrusive real-time worker location sensing (RTLS) and physiological status monitoring (PSM) technology. This paper presents the background and need for a data fusion approach, the framework, the test bed environment, and results to some case studies that were used to automatically identify unhealthy work behavior. Results of this study suggest a new approach for automating remote monitoring of construction workers safety performance by fusing data on their location and physical strain. © 2013 American Society of Civil Engineers.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automated video exposure assessment of repetitive hand activity level for a load transfer task\n",
            "Authors: Chen C.H.\n",
            "Abstract: Objective: A new method is described for automatically quantifying repetitive hand activity with the use of digital video processing. Background: The hand activity level (HAL) is widely used for evaluating repetitive hand work. Conventional methods involving either a trained observer on- or off-site or manual off-site video analysis are often considered inaccurate, cumbersome, or impractical for routine work assessment. Method: A cross-correlation-based template-matching algorithm was programmed to track the motion trajectory of a selected region of interest across successive video frames for a single camera to measure repetition frequency, duty cycle, and HAL. A simple, paced, load transfer task was used to simulate a repetitive industrial activity. A total of 12 participants were videoed performing the task for varying HAL conditions. The automatically predicted HAL was compared with the manually measured HAL with the use of frame-by-frame video analysis. Results: Predicted frequency, duty cycle, and HAL were in concert with the manually measured HAL conditions. The linear regression slopes of the automatically predicted values with respect to the manually measured values were 0.98 (R2 = .79), 1.27 (R 2 = .63), and 1.06 (R2 = .77) for frequency, duty cycle, and HAL, respectively. Conclusion: A proof-of-concept for automatic video-based direct exposure assessment was demonstrated. Application: The video assessment method for repetitive motion is promising for automatic, unobtrusive, and objective exposure assessment, which may offer broad availability with the use of a camera-enabled mobile device for helping evaluate, prevent, and control exposure to repetitive motions related to upper-extremity injuries in the workplace. Copyright © 2012, Human Factors and Ergonomics Society.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Evaluation of Implement Monitoring Systems\n",
            "Authors: Rakhra A.\n",
            "Abstract: During monitoring of rear-mounted equipment, frequent rearward turning of tractor drivers causes awkward postures that can cause musculoskeletal disorders related to the back, neck, and shoulders. The objective of this study was to compare three implement monitoring strategies (direct viewing via physical turning, indirect viewing via rear-view mirrors, and indirect viewing via a camera-monitor system) in a lab environment using a tractor and air seeder driving simulator. Comparison was based on monitoring performance of the operator (i.e., response error), physical impact on the operator (i.e., head/neck acceleration and increase in neck muscle temperature), and operator preference. Indirect viewing via a camera-monitor system caused the least physical impact on subjects and was the preferred implement monitoring strategy. No significant differences (α = 0.05) in monitoring performance were observed. © 2013 ASABE ISSN 1074-7583.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Emotion, design and technology\n",
            "Authors: Uğur S.\n",
            "Abstract: This chapter addresses the nature of emotions and the applications of emotional theories on both product design and technologies. Throughout history, emotions have been studied by many scholars in order to understand how and why it occurs in the human body. Emotional expression that is an important element of face-to-face communication has many functions that enhance personal wellbeing and support interpersonal relationships. On the other hand, emotion that is a matter of human body and consciousness is one of the most important issues that design and technology deals with. Although technology seems quite opposite of human emotions, today it can even act emotionally. Technologies with emotional intelligence can sense and learn emotional patterns. Affective computing, wearable technology and haptic technologies seem to open new avenues of emotional embodiment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automatic digital biometry analysis based on depth maps\n",
            "Authors: Reyes M.\n",
            "Abstract: World Health Organization estimates that 80% of the world population is affected by back-related disorders during his life. Current practices to analyze musculo-skeletal disorders (MSDs) are expensive, subjective, and invasive. In this work, we propose a tool for static body posture analysis and dynamic range of movement estimation of the skeleton joints based on 3D anthropometric information from multi-modal data. Given a set of keypoints, RGB and depth data are aligned, depth surface is reconstructed, keypoints are matched, and accurate measurements about posture and spinal curvature are computed. Given a set of joints, range of movement measurements is also obtained. Moreover, gesture recognition based on joint movements is performed to look for the correctness in the development of physical exercises. The system shows high precision and reliable measurements, being useful for posture reeducation purposes to prevent MSDs, as well as tracking the posture evolution of patients in rehabilitation treatments. © 2013 Elsevier B.V. All rights reserved.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Dynamic biomechanical simulation for identifying risk factors for work-related musculoskeletal disorders during construction tasks\n",
            "Authors: Seo J.\n",
            "Abstract: We propose a dynamic biomechanical simulation method that uses motion capture to evaluate the risk of Work-related Musculoskeletal Disorders (WMSDs). Statistics show that WMSDs accounted for 33% of all non-fatal occupational injuries and illness in construction in 2009, and were a leading cause of temporary and permanent disability. Present methods rely largely on self-reports from workers, observational techniques, and direct measurements of motion and muscle activity to assess awkward postures, physical loads, repetitiveness, and the duration of exposure. While these methods have helped to prevent WMSDs in construction work, they may not be suitable for estimating the internal tissue loads associated with WMSDs. We propose a dynamic biomechanical simulation method to estimate internal forces and moments at each body joint of construction workers with motion capture data. Particularly, we explore the biomechanical loads by simulating active 3D musculoskeletal models based on measured postures and movements. To demonstrate the feasibility of this approach, we studied a ladder climbing task using a portable ladder under controlled laboratory conditions. Postures and motions were determined with a commercial motion capture system (e.g., VICON). The results were analyzed to investigate the feasibility of identifying risk factors based on biomechanical simulation. The results show that the proposed approach allows us to determine the biomechanical basis for WMSDs, and to identify postures and movements associated with excessive physical demands on each body joint. When combined with marker-less motion capture which is our ongoing work, the proposed approach has the potential to assess an individual's motions and to provide personalized feedback for the purpose of reducing biomechanical loads and WMSD risk in real workplaces.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Remote sensing enabling technologies for assessment of construction worker's musculoskeletal disorder risks: A review and future extension\n",
            "Authors: Dai F.\n",
            "Abstract: Musculoskeletal disorders (MSDs) are a group of painful disorders that affect muscles, tendons, nerves, joints, cartilage, and ligaments. They are a serious problem among the workforce in the United States. In the construction industry, high physically demanding tasks expose construction workers to a number of well recognized MSDs risk factors such as repetitive motion, high force exertion, and awkward body posture. Finding ways to effectively identify and evaluate risks of MSDs can significantly alleviate this problem. To this end, this paper reviews state of practice and research in the assessment of risks of MSDs among construction workers, in which a number of biomechanical models have been developed to evaluate joint and tissue loading with the aid of state-of-the-art remote sensing technologies. Findings from the review reveal that despite the advances in tracking human motion and muscle activities, current remote sensing approaches still involve sophisticated instrumentation and expensive experiment setup. These factors greatly limited the applicability of such approaches in real construction settings. How can we detect and evaluate the construction worker's MSDs risk in real work environments? In this paper, strategies by utilizing video surveillance systems are presented, to set the stage for addressing the above question and discussing future research in real-time, marker-less, and cost-effective MSDs risk assessment.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Real-time control of 3D virtual human motion using a depth-sensing camera for agricultural machinery training\n",
            "Authors: Wang C.\n",
            "Abstract: To recreate human movements in a virtual environment in real time, we propose a new method for real-time tracking of 3D virtual full-body motion using a depth-sensing camera. The method uses natural interaction and a non-contact mode. The 3D virtual environment was constructed using a 3D graphics engine and human joint data were calculated using images acquired from a Prime Sense depth-sensing camera. Then skeletal data for the human model in a skinned mesh animation were separated by improving the mesh modules using a 3D graphics engine. Finally, motion data from the depth sensor were combined with joint data for the human model to yield full-body control of a virtual human (VH). Experimental results show that the proposed method can drive VH full-body movements in real time based on motion-sensing data. The method was applied in virtual driving training for agricultural machinery. Trainees can become familiar with the basic operations required for driving agricultural machinery using full-body motion instead of a mouse and keyboard. The training system is inexpensive and has high safety and a strong sense of immersion. © 2012 Elsevier Ltd.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Writing state classification by ambient sedentary behavior sensing in desk work\n",
            "Authors: Matsumoto S.\n",
            "Abstract: This paper presents a writing state classification technique by a sedentary behavior sensing with a sensor equipped chair, which wirelessly monitors user's states such as his/her behaviors or physiological and psychological conditions, for the estimation of the user's subjective difficulty of a studying problem on a desktop. Avoiding user's discomfort, four load cells are equipped behind the seat plate of a regular office chair. The system simply measures the weight and the CoP (Center of Pressure) of the seat. These data are divided into time segments, which are labeled into four sedentary body sway primitives by the decision tree algorithm, and then the behaviors are derived from the number and the pitch of those primitives in a certain interval. System evaluation experiments resulted that it achieved more than 80% of labeling accuracy for the untrained users. We finally conducted a user experiment that shows its potential for desk work applications. The result of the experiment showed that our proposed system could classify user's states into writing state and the other states such as reading a document and watching movie at the classification rate of 87%. © 2013 The Institute of Electrical Engineers of Japan.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Supporting system for self training of bed-making using image processing with color and distance information\n",
            "Authors: Nagata A.\n",
            "Abstract: The purpose of this paper was to develop a support system to help nursing trainees learn the skill of bed-making. The system consisted of three steps: measurement, evaluation, and feedback. This paper focused on the first two issues. First, the evaluation points of bed-making were determined. Next, a measurement system was constructed using color and distance information provided by Kinects and image processing. The system extracted specific segments of whole images depicting trainees, a bed, and necessary equipment. Finally, the procedure used by trainees in making beds was quantitatively evaluated using thresholds that were determined in advance by observing teachers and students involved in bed-making. Compared to the evaluation of nursing teachers, the accuracy of the evaluation system was as much as 70%. © 2012 IEEE.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Posture study for self-training system of patient transfer\n",
            "Authors: Huang Z.\n",
            "Abstract: Sufficient training with feedback was important for nursing students to learn the techniques. In view of this, we studied the method for measuring and evaluating the performance of nursing students in order to develop a self-training system. Focusing on the training of transferring a patient from a bed to a wheelchair, we defined seven evaluation items related with the postures. In addition, evaluation indexes of each item were determined. Then, we established a prototype system based on two Kinect range cameras. Using the system, first, we recognized the body parts and joints through the color of the markers attached on the bodies. After that, the body joints' spatial locations and body parts' inclination angles were measured via the combination of color and depth information in order to calculate the indexes. We applied Bayes minimum error decision to classify nursing students' performance of each items as correct or incorrect. Ten inexperienced nursing students and five experienced nurses were asked to transfer patient from a bed to a wheelchair at least twice. Every time the patient was transferred, the nursing teacher evaluated the trainee's performance. In addition, proposed system measured and recorded the data. The significant difference between correct and incorrect performance of each item was observed through the determined indexes (P<0.01). Accuracy of performance classification was examined by the leave one-out cross-validation. The average of accuracy was up to 80%. These results suggested that the defined index was effective and the proposed classification approach could classify the performance of the nursing students as almost the same as the nursing teacher did. © 2012 IEEE.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Comparing four technologies for measuring postural micromovements during monitor engagement\n",
            "Authors: Witchel H.J.\n",
            "Abstract: Objective metrics of engagement are valuable for estimating user experience or progression through interactional narratives. Postural micromovements of seated individuals during computer engagement have been previously measured with magnetic field sensors and chair-mounted force matrix detection mats. Here we compare readings from a head-mounted accelerometer, single camera sagittal motion tracking, and force distribution changes using floor-mounted force plates against a Vicon 8-camera motion capture system. Measurements were recorded on five participants who were watching or interacting with a computer monitor. Our results show that sagittal and coronal plane measurements for Vicon, the accelerometer and the single camera produced nearly identical data, were precisely synchronized in time, and in many cases proportional in amplitude. None of the systems tested were able to match the Vicon's measurement of yaw. Copyright 2012 ACM.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Tele-medical applications in home-based health care\n",
            "Authors: Al-Attas R.\n",
            "Abstract: Tele-home-care systems are becoming more important for patients and society at large. Despite some surveys focusing on medical devices interoperability used on home-care systems, electronic measurements in rehabilitation, configuration of body area networks, a survey and taxonomy of enabling technologies for tele-home-care systems does not exist. This paper presents a survey and taxonomy of the design approaches. The discussion of open issues and suggestions for further research are detailed in this paper. © 2012 IEEE.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Real-time posture analysis of construction workers for ergonomics training\n",
            "Authors: Ray S.J.\n",
            "Abstract: Work related fatigue and injuries are critical issues in the construction industry. Repetitive and physically demanding nature of the activities and awkward work postures are the primary reasons for work related fatigues and injuries. In view of this, worker training on ergonomics is necessary before the start of any construction activity. Traditional methods of worker monitoring are tedious and in efficient. Recent approaches to understand worker ergonomics use specialized devices to physically monitor the health of workers. In addition to this, attempts have been made to use computer vision techniques to understand workers ergonomics; however they mostly focus on estimating the posture of workers. In this research, we present a framework for integrating posture analysis of workers and a predefined set of rules to categorize work tasks as ergonomic or non-ergonomic. © 2012 ASCE.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Intelligent chair sensor-actuator: A novel sensor type for seated posture detection and correction\n",
            "Authors: Lucena R.\n",
            "Abstract: In order to build an intelligent chair capable of posture guidance and correction we propose a new sensor/actuator pressure cell capable of measuring applied pressure and conformation change, which will allow posture evaluation, guidance and correction. We developed and applied the pressure cells to the seat pad of an office chair to test if both the cells and their placement were suitable for pressure map reconstruction. When tested for 10 different postures, the results showed distinguishable pressure maps for each posture, making the pressure cells suitable for pressure map reconstruction and posture evaluation. This paper also presents a briefly description of our vision and goals for the intelligent chair project.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Real-time construction worker posture analysis for ergonomics training\n",
            "Authors: Ray S.J.\n",
            "Abstract: Construction activities performed by workers are usually repetitive and physically demanding. Execution of such tasks in awkward postures can strain their body parts and can result in fatigue, injuries or in severe cases permanent disabilities. In view of this, it is essential to train workers, before the commencement of any construction activity. Furthermore, traditional worker monitoring methods are tedious, inefficient and are carried out manually whereas, an automated approach, apart from monitoring, can yield valuable information concerning work-related behavior of worker that can be beneficial for worker training in a virtual reality world. Our research work focuses on developing an automated approach for posture estimation and classification using a range camera for posture analysis and categorizing it as ergonomic or non-ergonomic. Using a range camera, first we classify worker's pose to determine whether a worker is 'standing', 'bending', 'sitting', or 'crawling' and then estimate the posture of the worker using OpenNI middleware to get the body joint angles and spatial locations. A predefined set of rules is then formulated to use this body posture information to categorize tasks as ergonomic or non-ergonomic. © 2012 Elsevier Ltd. All rights reserved.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Physical sensor difference-based method and virtual sensor difference-basedmethod for visual and quantitative estimation of lower limb 3D gait posture using accelerometers and magnetometers\n",
            "Authors: Kun L.\n",
            "Abstract: An approach using a physical sensor difference-based algorithm and a virtual sensor difference-based algorithm to visually and quantitatively confirm lower limb posture was proposed. Three accelerometers and two MAG 3s (inertial sensor module) were used to measure the accelerations and magnetic field data for the calculation of flexion/extension (FE) and abduction/adduction (AA) angles of hip joint and FE, AA and internal/external rotation (IE) angles of knee joint; then, the trajectories of knee and ankle jointswere obtainedwith the joint angles and segment lengths.There was no integration of acceleration or angular velocity for the joint rotations and positions, which is an improvement on the previous method in recent literature. Compared with the camera motion capture system, the correlation coefficients in five trials were above 0.91 and 0.92 for the hip FE and AA, respectively, and higher than 0.94, 0.93 and 0.93 for the knee joint FE, AA and IE, respectively. © 2012 Taylor & Francis.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Work posture assessment of computer users using CARULA: (Computer aided rapid upper limb assessment)\n",
            "Authors: Singh L.P.\n",
            "Abstract: It’s the computer era and pcs (personal computers) are daily used by thousands of people. When people at work they used pcs (personal computers) minimum for four hours per day which cause a lots of pain in a various parts of the body .Computer Vision Syndrome (CVS), low back pain, tightness headaches and psychosocial pressure are some common problem faced by computer users. Rapid Upper Limb Assessment (RULA) is a method concerned with work related to upper part of the body which includes wrist position, upper arm position, lower arm position, neck position and trunk position. RULA done manual calculations by entering values into the work sheet equivalent to the position which is observed, if there are bulky numbers of working employees it means manual calculations are more, it can become monotonous if many activities and corresponding postures need to be analyzed and there are more chances of subjective biasness. In this paper, Computer Aided Rapid Upper Limb Assessment (CARULA) will help to decide the correct work posture analysis for industry. The present work focused on the calculation of RULA score with the help of introducing new algorithm CARULA which is quite efficient and precise than the manual calculations. CARULA has been computerized to calculations in a user friendly environment with pictorial representation using MATLAB. We have tested this CARULA by analyzing on 10 different work posture; CARULA is relatively much faster and significantly reduced the risk of subjective biasness as compared to manual RULA.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Risk factors for health disorders in computer operators in telecom Serbia\n",
            "Authors: Blagojević L.\n",
            "Abstract: Computer operators are at risk to develop health disorders related to prolonged computer use. We assessed the occupational risk factors for computer-related health disorders and evaluated health conditions of 939 Serbian computer operators. Musculoskeletal (55.8%), ocular (27.3%) and mental disorders (7.1%) were reported most frequently. Risk factors for health disorders, in both male and female populations, were age; overtime work; negative working atmosphere; awkward posture at work; the presence of vibrations, noise, dust and chemical pollution in the workplace. Negative working atmosphere, body mass index > 30, total job tenure and duration of exposed employment were risk factors for developing health disorders only in males, while smoking was a risk factor only in the female population. Our study showed high prevalence of muscu-loskeletal and ocular disorders in Serbian computer operators. More effective preventive measures are necessary to improve computer operators ‘ health. © 2012, Taylor & Francis Group, LLC. All rights reserved.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Involuntary postural responses of users as input to Attentive Computing Systems: An investigation on head movements\n",
            "Authors: Dirican A.\n",
            "Abstract: Automatic motor or involuntary postural behaviors of users have been receiving an increasing interest in recent years, as unobtrusive measures of cognitive states. In this paper, we investigate the involuntary postural responses of seated users derived from their cognitive changes as input for Attentive Computing Systems. The paper first introduces seated posture, its advantages for cognitive state assessment and connections with cognitive states and, related studies in order to provide a research background for this emerging area of research. We then focus on head posture of seated users and examine the involuntary head movements correlated with task engagement and changing task difficulty through an experiment conducted using a display-oriented cognitive task with changing difficulties. The experiment included 31 participants. Based on different measures, head response and speed, data gathered from user studies were analyzed. Repeated measures Analysis of Variances revealed that head response and speed could serve as cognitive engagement measures. The results indicated that participants get closer to a computer display and became more stationary when they were engaged in a task. The task difficulty analysis results, conversely, partially fulfilled our initial expectations. Head response and speed exhibited limited sensitive behaviors as task difficulties changed. © 2012 Elsevier Ltd. All rights reserved.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Individual hand model to reconstruct behavior from motion capture data\n",
            "Authors: Miyata N.\n",
            "Abstract: This paper proposes a method to build an individual hand model that consists of a surface skin and an inside link model, which can be used to reconstruct hand behavior from motion capture (MoCap) data. Our system uses a static posture data, a palmar side photo and marker positions captured simultaneously by MoCap, to reduce extra time and effort demanded for each subject to build a model. From this modeling scan, several hand dimensions and marker positions are obtained. Joint centers are estimated based on regression analysis about joint centers, marker positions and some hand dimensions derived from magnetic resonance (MR) images of eight subjects. The skin surface is built by scaling a generic hand model so that it satisfies the measured dimensions. The proposed system will be validated through an experiment to build four subjects' hand models. © 2011 IEEE.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: User independent system of hand postures recognition using part-based shape representation\n",
            "Authors: Dahmani D.\n",
            "Abstract: We present in this paper, new method for recognizing hand postures from their shapes. Firstly, convex and concave points with high curvature values are extracted from the contour of the hand's posture shape. Then curves are fitted to the concave points. These curves are used for partitioning 2D hand's posture shape into subparts representing the fingers and palm. Using this partitioning we define textual descriptor of hand's posture shape. In addition we introduce a part description based on attributes consisting of relative lengths, widths and inclination angles,. Recognition of postures of the hand is performed on exploiting these local descriptors and the anthropometric relations defined in [1]. The experimental results show that the proposed approach recognizes a large number of hand postures back of palm or palm faces camera (adduction, abduction, flexion and rotation). Our descriptor is a scale change invariant. © 2011 IEEE.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Computer vision techniques for worker motion analysis to reduce musculoskeletal disorders in construction\n",
            "Authors: Li C.\n",
            "Abstract: Worker health is a serious issue in construction. Injuries and illnesses result in days away from work and incur tremendous costs for construction organizations. Musculoskeletal disorders, in particular, constitute a major category of worker injury. The repetitive movements, awkward postures, and forceful exertions involved in trade work are leading causes of this type of injury. To reduce the number of these injuries, worker activities must be tracked and analyzed. Traditional methods to measure work activities rely upon manual on-site observations which are time-consuming and inefficient. To address these limitations, computer vision techniques for worker motion analysis are proposed to automatically identify non-ergonomic postures and movements without on-site work interruption. Specifically, we intend to acquire 2D skeleton extracting joints from image sequences and, while obtaining 3D coordinates for each joint, reconstruct 3D human skeletons for each frame; these then can be used for diverse ergonomic analyses (e.g., joint angle comparisons with the suggested ergonomic guidelines for trades). In this paper, we therefore discuss how 3D skeleton video images can be reconstructed with two 2D skeleton images recorded from two network surveillance cameras. The results demonstrate that the obtained 3D skeleton video with coordinates of joints have enough detail to be used for motion analysis and have great potential to identify non-ergonomic postures and movements. This information can be used to reduce musculoskeletal disorders in the construction industry. © 2011 ASCE.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: eCushion: An eTextile device for sitting posture monitoring\n",
            "Authors: Xu W.\n",
            "Abstract: Sitting posture analysis is critical for daily applications in biomedical, education and healthcare fields. However, it remains unclear how to monitor sitting posture economically and comfortably. To this end, we presented an eTextile device, called eCushion, in this paper, which can analyze the sitting posture of human being accurately and non-invasively. First, we discussed the implementation of eCushion and design challenges of sensing data, such as scale, offset, rotation and crosstalk. Then, several effective techniques have been proposed to improve the recognition rate of sitting posture. Our experimental results show that the recognition rate of our eCushion system could achieve 92% for object-oriented cases and 79% for general cases. © 2011 IEEE.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A semi-automatic system for posture risk assessment\n",
            "Authors: Gonçalves P.J.S.\n",
            "Abstract: RULA (Rapid Upper Limb Assessment) is a survey method that assesses biomechanical and postural loading on the whole body with particular attention to the neck, trunk and upper limbs. In this paper we present a semi-automatic posture recognition system, to collect data and to evaluate human posture risk based on RULA. The proposed system uses two synchronized video cameras to capture images or posture samples of the operator performing its job. RULA scores are then automatically computed from these posture samples, based on semi-automatic and automatic image processing algorithms. These algorithms can extract visual features from the human upper limb, and obtain its model. The resulting scoring generates an action list which indicated the level of intervention required to reduce the risks of injury due to physical loading on the operator. The developed system is intended to be used as a tool for ergonomic investigations of workplaces.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Human body pose interpretation and classification for social human-robot interaction\n",
            "Authors: Mccoll D.\n",
            "Abstract: A novel breed of robots known as socially assistive robots is emerging. These robots are capable of providing assistance to individuals through social and cognitive interaction. However, there are a number of research issues that need to be addressed in order to design such robots. In this paper, we address one main challenge in the development of intelligent socially assistive robots: The robot's ability to identify human non-verbal communication during assistive interactions. In particular, we present a unique non-contact and non-restricting automated sensor-based approach for identification and categorization of human upper body language in determining how accessible a person is to the robot during natural real-time human-robot interaction (HRI). This classification will allow a robot to effectively determine its own reactive task-driven behavior during assistive interactions. Human body language is an important aspect of communicative nonverbal behavior. Body pose and position can play a vital role in conveying human intent, moods, attitudes and affect. Preliminary experiments show the potential of integrating the proposed body language recognition and classification technique into socially assistive robotic systems partaking in HRI scenarios. © Springer Science & Business Media BV 2011.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: A Novel Approach for Attention Management in E-learning Systems\n",
            "Authors: Costagliola G.\n",
            "Abstract: This study presents new approaches for the detection and treatment of the attention of a student by an e-learning system through the use of the information given by the implicit interaction of the student with the system and the data coming from non-invasive devices such as webcams. Furthermore, the paper proposes two models for the treatment of the attention of students to be applied to an existing e-learning environment, in order to provide personalized content to the students and thus improving their learning experience.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Designing lifting task in shoe industry using genetic algorithm\n",
            "Authors: Srivastava S.\n",
            "Abstract: We present an application of a genetic algorithm (GA) based method to the design of hide-unloading job, an asymmetric lifting task in shoe industry of Agra, India. In India, which has the second largest shoe industry in the world, it is labor intensive and concentrated in the small and cottage industry sector with Agra being a major production hub. Due to awkward postures and high load handling in hide-unloading, workers are exposed to ergonomic hazards. The design of hide-unloading job in the present work with an aim to reduce the risk to back injury in the purview of revised NIOSH equation. We carry out our study in four shoe manufacturing firms in Agra. The study was conducted on a total of 20 workers, 5 from each firm. It is observed that workers assume different awkward postures mainly due to bulky and unstable load handling. The potency of the study is to present multiple optimal solutions to the design problem using GA while meeting safety and productivity requirements in a given workplace environment conditions. Multiple optimal solutions provide greater agility to ergonomist to implement the recommended design solutions. ©2010 IEEE.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Affective tutors: Automatic detection of and response to student emotion\n",
            "Authors: Woolf B.P.\n",
            "Abstract: This chapter describes the automatic recognition of and response to human emotion within intelligent tutors. Tutors can recognize student emotion with more than 80%accuracy compared to student self-reports, using wireless sensors that provide data about posture, movement, grip tension, facially expressed mental states and arousal. Pedagogical agents have been used that provide emotional or motivational feedback. Students using such agents increased their math value, self-concept and mastery orientation, with females reporting more confidence and less frustration. Low-achieving students-one third of whom have learning disabilities-report higher affective needs than their higher-achieving peers. After interacting with affective pedagogical agents, low-achieving students improved their affective outcomes and reported reduced frustration and anxiety. © 2010 Springer-Verlag Berlin Heidelberg.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Towards a vision-based system exploring 3D driver posture dynamics for driver assistance: Issues and possibilities\n",
            "Authors: Tran C.\n",
            "Abstract: Driver's body posture in 3D contains information potentially related to driver intent, driver affective state, and driver distraction. In this paper, we discuss issues and possibilities in developing a vision-based, markerless system to systematically explore the role of 3D driver posture dynamics for driver assistance. At high level, two main emphases in the proposed system are: (i) The coordination between real world driving testbed and simulation environment and (ii) The usefulness of driver posture dynamics is studied not only as an individual cue but also in relation with other contextual information (e.g. head dynamics, facial features, and vehicle dynamics). Some initial results in our experiment following these guidelines show the feasibility and promise of extracting and using 3D driver posture dynamics for driver assistance. © 2010 IEEE.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: What does your chair know about your stress level?\n",
            "Authors: Arnrich B.\n",
            "Abstract: The inferred cost of work-related stress call for early prevention strategies. In this, we see a new opportunity for affective and pervasive computing by detecting early warning signs. This paper goes one step toward this goal. A collective of 33 subjects underwent a laboratory stress intervention, while a set of physiological signals was collected. In this paper, we investigate whether affective information related to stress can be found in the posture channel during office work. Following more recent work in this field, we directly associate features that are derived from the pressure distribution on a chair with affective states. We found that nervous subjects reveal higher variance of movements under stress. Furthermore, we show that a person-independent discrimination of stress from cognitive load is feasible when using pressure data only. A supervised variant of a self-organizing map, which is able to adapt to different patterns of stress responses, reaches an overall accuracy of 73.75% with unknown subjects. © 2009 IEEE.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Designing lifting task in shoe industry using genetic algorithm\n",
            "Authors: Srivastava S.\n",
            "Abstract: In this paper we present an application of a genetic algorithm (GA) based method to the design of hide-unloading job, an asymmetric lifting task in shoe industry of Agra, India. In India, which has the second largest shoe industry in the world, it is labor intensive and concentrated in the small and cottage industry sector with Agra being a major production hub. Due to awkward postures and high load handling in hide-unloading, workers are exposed to ergonomic hazards. We focus the design of hide-unloading job in the present work with an aim to reduce the risk to back injury in the purview of revised NIOSH equation. We carried out our study in four shoe manufacturing firms in Agra. The study was conducted on a total of 20 workers, 5 from each firm. It is observed that workers assume different awkward postures mainly due to bulky and unstable load handling. The potency of the study is to present multiple optimal solutions to the design problem using GA while meeting safety and productivity requirements in a given workplace environment conditions. Multiple optimal solutions provide greater agility to ergonomist to implement the recommended design solutions.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Physical-Sensor and Virtual-Sensor Based Method for Estimation of Lower Limb Gait Posture Using Accelerometers and Gyroscopes\n",
            "Authors: Liu K.\n",
            "Abstract: An approach using physical-sensor difference and virtual-sensor difference based algorithm to visually and quantitatively confirm lower limb posture was proposed and a wearable sensor system was developed. Flexion/extension (FE) and abduction/adduction (AA) hip joint angles and FE knee joint angle were estimated for orientations of the lower limb segments; the knee and ankle joint trajectories were calculated using the segmental orientation angles and lengths to estimate the positions of lower limb joints. In the wearable sensor system, an accelerometer on the hip and two MAG3s (inertial sensor module) on the thigh were in grouped to measure the data for estimating the thigh orientation and knee joint position using the double-sensor difference based algorithm. Two MAG3s on the thigh and shank near the knee joint were in grouped to measure the data for estimating the knee joint angle and ankle joint position using the virtual-sensor difference based algorithm. Compared with the camera motion capture system, the correlation coefficients in five trials were above 0.89 for the hip FE angle, higher than 0.9 for the hip AA angle and better than 0.88 for the knee FE angle. There was no integration of acceleration or angular velocity for the joint rotations and positions in this method. The developed wearable sensor system was able to visually and quantitatively confirm the lower limb posture with fewer sensors and higher accuracy than with other methods. It can be used as a substitute for the camera system for patient gait posture analysis in daily life. © 2010, The Japan Society of Mechanical Engineers. All rights reserved.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Recognizing and responding to student affect\n",
            "Authors: Woolf B.\n",
            "Abstract: This paper describes the use of wireless sensors to recognize student emotion and the use of pedagogical agents to respond to students with these emotions. Minimally invasive sensor technology has reached such a maturity level that students engaged in classroom work can us sensors while using a computer-based tutor. The sensors, located on each of 25 student's chair, mouse, monitor, and wrist, provide data about posture, movement, grip tension, facially expressed mental states and arousal. This data has demonstrated that intelligent tutoring systems can provide adaptive feedback based on an individual student's affective state. We also describe the evaluation of emotional embodied animated pedagogical agents and their impact on student motivation and achievement. Empirical studies show that students using the agents increased their math value, self-concept and mastery orientation. © 2009 Springer Berlin Heidelberg.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Optimization-based posture prediction for human upper body\n",
            "Authors: Mi Z.\n",
            "Abstract: A general methodology and associated computational algorithm for predicting postures of the digital human upper body is presented. The basic plot for this effort is an optimization-based approach, where we believe that different human performance measures govern different tasks. The underlying problem is characterized by the calculation (or prediction) of the human performance measure in such a way as to accomplish a specified task. In this work, we have not limited the number of degrees of freedom associated with the model. Each task has been defined by a number of human performance measures that are mathematically represented by cost functions that evaluate to a real number. Cost functions are then optimized, i.e., minimized or maximized, subject to a number of constraints, including joint limits. The formulation is demonstrated and validated. We present this computational formulation as a broadly applicable algorithm for predicting postures using one or more human performance measures. © 2008 Cambridge University Press.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: The Role of Emotion-Inspired Abilities in Relational Robots\n",
            "Authors: Breazeal C.\n",
            "Abstract: This chapter summarizes ongoing work in developing and embedding affective technologies in learning interactions with automated systems, such robotic learning companions. The primary motivation for building robots with social-emotional-inspired capabilities is to develop \"relational robots\" and their associated applications in diverse areas such as health, education, or work productivity where the human user derives performance benefit from establishing a kind of social rapport with the robot. The chapter describes some of the future applications for such robots, provides a brief summary of the current capabilities of state-of-the-art socially interactive robots, presents recent findings in human-computer interaction, and concludes with a few challenges that should be addressed in future research.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Fundamentals of physiological computing\n",
            "Authors: Fairclough S.H.\n",
            "Abstract: This review paper is concerned with the development of physiological computing systems that employ real-time measures of psychophysiology to communicate the psychological state of the user to an adaptive system. It is argued that physiological computing has enormous potential to innovate human-computer interaction by extending the communication bandwidth to enable the development of 'smart' technology. This paper focuses on six fundamental issues for physiological computing systems through a review and synthesis of existing literature, these are (1) the complexity of the psychophysiological inference, (2) validating the psychophysiological inference, (3) representing the psychological state of the user, (4) designing explicit and implicit system interventions, (5) defining the biocybernetic loop that controls system adaptation, and (6) ethical implications. The paper concludes that physiological computing provides opportunities to innovate HCI but complex methodological/conceptual issues must be fully tackled during the research and development phase if this nascent technology is to achieve its potential. © 2008 Elsevier B.V. All rights reserved.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Measurement of Cervical Posture in the Sagittal Plane\n",
            "Authors: Grimmer-Somers K.\n",
            "Abstract: Background: This article provides a historical perspective and an overview of different ways of measuring sagittal plane cervical posture in clinical and research settings. Special Features: Measures of cervical posture are considered, in terms of their purpose, their reliability and validity, and their capacity to provide knowledge about cervical posture. Summary: Despite technological advances in measurement techniques, there is still much to learn about cervical posture in terms of understanding how the neck balances the head against the force of gravity. The individual spinal segments of the neck assume different relative positions, depending on the individual's genetics; anatomical construction; occupational demands; muscle strength and endurance; as well as mental state, personality, and culture. Valid measures which can capture this objectively and reliably continue to challenge clinicians and researchers. © 2008 National University of Health Sciences.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Evaluating Children's Interactive Products: Principles and Practices for Interaction Designers\n",
            "Authors: Markopoulos P.\n",
            "Abstract: Evaluating Children's Interactive Products directly addresses the need to ensure that interactive products designed for children - whether toys, games, educational products, or websites - are safe, effective, and entertaining. It presents an essential background in child development and child psychology, particularly as they relate to technology; captures best practices for observing and surveying children, training evaluators, and capturing the child user experience using audio and visual technology; and examines ethical and legal issues involved in working with children and offers guidelines for effective risk management. Based on the authors' workshops, conference courses, and own design experience and research, this highly practical book reads like a handbook, while being thoroughly grounded in the latest research. Throughout, the authors illustrate techniques and principles with numerous mini case studies and highlight practical information in tips and exercises and conclude with three in-depth case studies. This book is recommended for usability experts, product developers, and researchers in the field.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Evaluating Children's Interactive Products\n",
            "Authors: Markopoulos P.\n",
            "Abstract: Interactive products designed for childrenwhether toys, games, educational products, or websitesare increasingly embedded in childrens lives and school experiences. Making these products safe, effective, and entertaining requires new methodologies for carrying out sound and unbiased evaluations for these users with unique requirements, environments, and ethical considerations. This book directly addresses this need by thoroughly covering the evaluation of all types of interactive technology for children. Based on the authors' workshops, conference courses, and own design experience and research, this highly practical book reads like a handbook, while being thoroughly grounded in the latest research. Throughout, the authors illustrate techniques and principles with numerous mini case studies and highlight practical information in tips and exercises and conclude with three in-depth case studies. Essential reading for usability experts, product developers, and researchers in the field. * Presents an essential background in child development and child psychology, particularly as they relate to technology. * Captures best practices for observing and surveying children, training evaluators, and capturing the child user experience using audio and visual technology. * Examines ethical and legal issues involved in working with children and offers guidelines for effective risk management. © 2008 Elsevier Inc. All rights reserved.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Toward computer-aided affective learning systems: A literature review\n",
            "Authors: Moridis C.N.\n",
            "Abstract: The aim of this survey is to provide an overview of the various components of \"computer aided affective learning systems.\" The research is classified into 3 main scientific areas that are integral parts of the development of these kinds of systems. The three main scientific areas are: I) emotions and their connection to learning; ii) affect recognition; and iii) emotional instruction and design. Affective learning instructional technology is a new, multidisciplinary research area, which has been developed during the last decade. This article depicts the development of the core relevant areas and describes the concerns. © 2008, Baywood Publishing Co., Inc.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Weight measurement using image-based pose analysis\n",
            "Authors: Zhang H.\n",
            "Abstract: Image-based gait analysis as a means of biometric identification has attracted much research attention. Most of the existing methods focus on human identification, posture analysis and movement tracking. There have been few investigations on measuring the carried load based on the carrier's gait characteristics by automatic image processing. Nevertheless, this measurement is very useful in a number of applications, such as the study of the carried load on the postural development of children and adolescence. In this paper, we investigate how to automatically estimate the carried weight from a sequence of images. We present a method to extract human gait silhouette based on an observation that humans tend to minimize the energy during motion. We compute several angles of body leaning and determine the relationship of the carried weight, the leaning angles and the centroid location according to a human kinetic study. Our weight determination method has been verified successfully by experiments. © 2008 National Natural Science Foundation of China and Chinese Academy of Sciences. Published by Elsevier Limited and Science in China Press. All rights reserved.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Advanced motion control and sensing for intelligent vehicles\n",
            "Authors: Li L.\n",
            "Abstract: Advanced Motion Control and Sensing for Intelligent Vehicles provides the latest information in intelligent vehicle control, sensing, and intelligent transportation. It addresses the growing need for safe, comfortable, time and energy-efficient modes of transportation with emphasis on the latest key findings, current trends, and likely future developments in this rapidly expanding field. Highlights: Discusses individual vehicle dynamics, sensory and multiple ground-vehicle interactions Includes systematic review of past and current research achievements Presents case studies in cutting-edge directions such as vehicle steering motion, vehicle vision systems, cooperative driving, intersection safety, and tire pressure monitoring Assesses the likely future developments of this field This book is useful for both practicing engineers and researchers in the automotive industry. © 2007 Springer Science+Business Media, LLC. All rights reserved.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Robust, low-cost, non-intrusive sensing and recognition of seated postures\n",
            "Authors: Mutlu B.\n",
            "Abstract: In this paper, we present a methodology for recognizing seated postures using data from pressure sensors installed on a chair. Information about seated postures could be used to help avoid adverse effects of sitting for long periods of time or to predict seated activities for a human-computer interface. Our system design displays accurate near-real-time classification performance on data from subjects on which the posture recognition system was trained by using a set of carefully designed, subject-invariant signal features. By using a near-optimal sensor placement strategy, we keep the number of required sensors low thereby reducing cost and computational complexity. We evaluated the performance of our technology using a series of empirical methods including (1) cross-validation (classification accuracy of 87% for ten postures using data from 31 sensors), and (2) a physical deployment of our system (78% classification accuracy using data from 19 sensors). Copyright 2007 ACM.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Vision-based hand pose estimation: A review\n",
            "Authors: Erol A.\n",
            "Abstract: Direct use of the hand as an input device is an attractive method for providing natural human-computer interaction (HCI). Currently, the only technology that satisfies the advanced requirements of hand-based input for HCI is glove-based sensing. This technology, however, has several drawbacks including that it hinders the ease and naturalness with which the user can interact with the computer-controlled environment, and it requires long calibration and setup procedures. Computer vision (CV) has the potential to provide more natural, non-contact solutions. As a result, there have been considerable research efforts to use the hand as an input device for HCI. In particular, two types of research directions have emerged. One is based on gesture classification and aims to extract high-level abstract information corresponding to motion patterns or postures of the hand. The second is based on pose estimation systems and aims to capture the real 3D motion of the hand. This paper presents a literature review on the latter research direction, which is a very challenging problem in the context of HCI. © 2007 Elsevier Inc. All rights reserved.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Experiments with a robotic computer: Body, affect and cognition interactions\n",
            "Authors: Breazeal C.\n",
            "Abstract: We present RoCo, the first robotic computer designed with the ability to move its monitor in subtly expressive ways that respond to and encourage its user¿s own postural movement. We use RoCo in a novel user study to explore whether a computer¿s \"posture\" can in fluence its use''s subsequent posture, and if the interaction of the user's body state with their affective state during a task leads to improved task measures such as persistence in problem solving. We believe this is possible in light of new theories that link physical posture and its in uence on affect and cognition. Initial results with 71 subjects support the hypothesis that RoCo's posture not only manipulates the user¿s posture, but also is associated with hypothesized posture-affect interactions. Specifically, we found effects on increased persistence on a subsequent cognitive task, and effects on perceived level of comfort. Copyright 2007 ACM.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Looking-in and looking-out of a vehicle: Computer-vision-based enhanced vehicle safety\n",
            "Authors: Trivedi M.M.\n",
            "Abstract: This paper presents investigations into the role of computer-vision technology in developing safer automobiles. We consider vision systems, which cannot only look out of the vehicle to detect and track roads and avoid hitting obstacles or pedestrians but simultaneously look inside the vehicle to monitor the attentiveness of the driver and even predict her intentions. In this paper, a systems-oriented framework for developing computer-vision technology for safer automobiles is presented. We will consider three main components of the system: environment, vehicle, and driver. We will discuss various issues and ideas for developing models for these main components as well as activities associated with the complex task of safe driving. This paper includes a discussion of novel sensory systems and algorithms for capturing not only the dynamic surround information of the vehicle but also the state, intent, and activity patterns of drivers. © 2007 IEEE.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Marker-based monitoring of seated spinal posture using a calibrated single-variable threshold model\n",
            "Authors: Walsh P.\n",
            "Abstract: This work, as part of a larger project developing wearable posture monitors for the work environment, seeks to monitor and model seated posture during computer use. A non-wearable marker-based optoelectronic motion capture system was used to monitor seated posture for ten healthy subjects during a calibration exercise and a typing task. Machine learning techniques were used to select overall spinal sagittal flexion as the best indicator of posture from a set of marker and vector variables. Overall flexion data from the calibration exercise were used to define a threshold model designed to classify posture for each subject, which was then applied to the typing task data. Results of the model were analysed visually by qualified physiotherapists with experience in ergonomics and posture analysis to confirm the accuracy of the calibration. The calibration formula was found to be accurate on 100% subjects. This process will be used as a comparative measure in the evaluation of several wearable posture sensors, and to inform the design of the wearable system. © 2006 IEEE.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Video-based lane estimation and tracking for driver assistance: Survey, system, and evaluation\n",
            "Authors: McCall J.\n",
            "Abstract: Driver-assistance systems that monitor driver intent, warn drivers of lane departures, or assist in vehicle guidance are all being actively considered. It is therefore important to take a critical look at key aspects of these systems, one of which is lane-position tracking. It is for these driver-assistance objectives that motivate the development of the novel \"video-based lane estimation and tracking\" (VioLET) system. The system is designed using steerable filters for robust and accurate lane-marking detection. Steerable filters provide an efficient method for detecting circular-reflector markings, solid-line markings, and segmented-line markings under varying lighting and road conditions. They help in providing robustness to complex shadowing, lighting changes from overpasses and tunnels, and road-surface variations. They are efficient for lane-marking extraction because by computing only three separable convolutions, we can extract a wide variety of lane markings. Curvature detection is made more robust by incorporating both visual cues (lane markings and lane texture) and vehicle-state information. The experiment design and evaluation of the VioLET system is shown using multiple quantitative metrics over a wide variety of test conditions on a large test path using a unique instrumented vehicle. A justification for the choice of metrics based on a previous study with human-factors applications as well as extensive ground-truth testing from different times of day, road conditions, weather, and driving scenarios is also presented. In order to design the VioLET system, an up-to-date and comprehensive analysis of the current state of the art in lane-detection research was first performed. In doing so, a comparison of a wide variety of methods, pointing out the similarities and differences between methods as well as when and where various methods are most useful, is presented. © 2006 IEEE.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Status of digital human body modeling from the aspect of information inclusion\n",
            "Authors: Horváth I.\n",
            "Abstract: This paper surveys the current state of art of digital human body modeling with a focus on information inclusion and analyzes the results from the aspects of design and engineering. It presents the results of a literature study, which intended to investigate the modeling approaches within the mentioned categories, and to investigate the fidelity of models based on the information content. In view of the fact that modeling is always a simplified representation of reality, models with different information contents are developed for different applications. It is also discussed in this paper that the information content of human body models however reflects not only the aspect of application, but also the level of fidelity, or functional sophistication. Taking into consideration the sorts of information needed to model human body as a complex organic system, the authors propose an information content-based categorization. The major categories of aspect models of human body that have been incorporated in a stratified reasoning scheme are: morphological, material, structural, mechanical, physiological and behavioral models. One conclusion is that remarkable progress has been achieved in terms of sophistication of models (i.e., of information inclusion and processing methods). Another conclusion is that further increase of the fidelity of models will not be possible without the proper treatment of the concomitant complexities. Integration of various aspect models and real time computational processing of human models are inevitable in several fields of application. However, development of human body models of such a high sophistication goes together with an exponential growth in the required capacities. This leads us to a trade-off problem in digital human body modeling. Copyright © 2005 by ASME.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Affective learning - a manifesto\n",
            "Authors: Picard R.W.\n",
            "Abstract: The use of the computer as a model, metaphor, and modelling tool has tended to privilege the 'cognitive' over the 'affective' by engendering theories in which thinking and learning are viewed as information processing and affect is ignored or marginalised. In the last decade there has been an accelerated flow of findings in multiple disciplines supporting a view of affect as complexly intertwined with cognition in guiding rational behaviour, memory retrieval, decision-making, creativity, and more. It is time to redress the imbalance by developing theories and technologies in which affect and cognition are appropriately integrated with one another. This paper describes work in that direction at the MIT Media Lab and projects a large perspective of new research in which computer technology is used to redress the imbalance that was caused (or, at least, accentuated) by the computer itself.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Realistic posture prediction for maximum dexterity\n",
            "Authors: Abdel-Malek K.\n",
            "Abstract: This paper presents an efficient numerical formulation for the prediction of realistic postures. This problem is defined by the method (or procedure) used to predict the posture of a human, given a point in the reachable space. The exposition addresses (1) the determination whether a point is reachable (i.e., does is it exist within the reach envelope) and (2) the calculation of a posture for a given point. While many researchers have used either statistical models of empirical data or the traditional geometric inverse kinematics method for posture prediction, we present a method based on kinematics for modeling, but one that uses optimization of a cost function to predict a realistic posture. It is shown that this method replicates the human mind in selecting a posture from an infinite number of possible postures. We illustrate the methodology and an accompanying experimental code through a planar and a spatial example, and validation using commercial human modeling and simulation code. Copyright © 2001 Society of Automotive Engineers, Inc.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Marker-less systems for tracking working postures - Results from two experiments\n",
            "Authors: Pinzke S.\n",
            "Abstract: Two experiments are performed to examine the usability of different marker-less approaches in image analysis and computer vision for automatic registration of OWAS (Ovako working posture analysing system) postures from video film. In experiment 1, a parametric method based on image analysis routines is developed both for separating the subject from its background and for relating the shapes of the extracted subject to OWAS postures. All 12 analysed images were correctly classified by the method. In experiment 2 a computer neural network is taught to relate postures of a subject to OWAS postures. When the network was trained with 53 images the rest of the set of 138 images was correctly classified. The experiments described in this paper show promising results regarding the use of image analysis and computer vision for tracking and assessing working postures. However, further research is needed including tests of different human models, neural networks, and template matching for making the OWAS method more useful in identifying and evaluating potentially harmful working postures. Copyright © 2001 Elsevier Science Ltd.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n",
            "Title: Automatic registration of OWAS postures from video film\n",
            "Authors: Pinzke S.\n",
            "Abstract: The aim of this paper is to contribute to the development of a system for automatic registration of working postures from video film according to the OWAS method. The automatic system provides several advantages as compared with traditional manual systems. For the operator, it is a less demanding task and the analyses are more comprehensive. The system is a marker-less method based on image analysis and computer vision. Routines are developed both for separating the subject from its background and for relating the shapes of the extracted subject to OWAS postures. Several type of filters are used for the segmentation process and length and angle calculations on different segments of the extracted figure are executed to determine the corresponding OWAS posture. The determined angles can be used as input in biomechanical programs for calculating forces and load moments. Another approach for the development of the automatic system is to use neural network and feature matching. For that approach a neutral network is taught to relate postures of a subject to postures in the OWAS system.\n",
            "keywords:No Keywords\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = all_results\n",
        "\n",
        "for entry in data:\n",
        "    print(f\"Title: {entry.get('dc:title')}\")\n",
        "    print(f\"Authors: {entry.get('dc:creator')}\")\n",
        "    print(f\"Abstract: {entry.get('dc:description')}\")\n",
        "    keywords = entry.get('dc:keywords') or entry.get('dc:subject') or 'No Keywords'\n",
        "    print(f\"keywords:{keywords}\")\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "acxdlB5Y8qdz"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "\n",
        "## Login to hugging face using the required token\n",
        "\n",
        "# HfToken = userdata.get('HF_TOKEN')\n",
        "\n",
        "\n",
        "# login(token=HfToken)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SrFJq9axkPB",
        "outputId": "fd065703-6aa5-4aef-930f-c4b93a3436fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sensor usage across all abstracts\n",
            "RGB camera: 96\n",
            "RGB-D: 68\n",
            "IMU: 58\n",
            "EMG: 44\n",
            "EEG: 8\n",
            "Depth camera: 4\n",
            "FSR: 3\n",
            "ECG: 3\n",
            "PPG: 2\n",
            "WiFi CSI: 1\n",
            "Infrared camera: 1\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "sensor_variants = {\n",
        "    \"IMU\": [\"imu\", \"inertial measurement unit\"],\n",
        "    \"ECG\": [\"ecg\", \"electrocardiogram\"],\n",
        "    \"EEG\": [\"eeg\", \"electroencephalogram\"],\n",
        "    \"EMG\": [\"emg\", \"electromyography\"],\n",
        "    \"EDA\": [\"eda\", \"electrodermal activity\"],\n",
        "    \"PPG\": [\"ppg\", \"photoplethysmography\"],\n",
        "    \"GSR\": [\"gsr\", \"galvanic skin response\"],\n",
        "    \"SpO2\": [\"spo2 sensor\", \"oxygen saturation sensor\"],\n",
        "    \"ToF camera\": [\"tof camera\", \"time-of-flight camera\"],\n",
        "    \"WiFi CSI\": [\"wifi csi\", \"channel state information\"],\n",
        "    \"WiFi RSSI\": [\"wifi rssi\", \"received signal strength indicator\"],\n",
        "    \"RFID\": [\"rfid\", \"radio-frequency identification\"],\n",
        "    \"UWB\": [\"uwb\", \"ultra wideband\"],\n",
        "    \"NFC\": [\"nfc\", \"near-field communication sensor\"],\n",
        "    \"FSR\": [\"fsr\", \"force sensitive resistor\"],\n",
        "    \"IMES\": [\"imes\", \"intramuscular electromyographic sensor\"],\n",
        "    \"mmWave radar\": [\"mmwave radar\", \"millimeter wave radar\"],\n",
        "\n",
        "\n",
        "    \"RGB camera\": [\"camera\", \"visual sensor\", \"rgb camera\", \"stereo camera\", \"multiple cameras\"],\n",
        "    \"Depth camera\": [\"depth camera\"],\n",
        "    \"Infrared camera\": [\"infrared camera\"],\n",
        "    \"Thermal camera\": [\"thermal camera\"],\n",
        "    \"RGB-D\": [\"Microsoft's kinect\", \"kinect\", \"rgb-d\", \"KinectV2\"],\n",
        "\n",
        "    \"RADAR\": [\"radar\", \"doppler radar\", \"mmwave\"]\n",
        "}\n",
        "\n",
        "\n",
        "variant_to_canonical = {}\n",
        "for canonical, variants in sensor_variants.items():\n",
        "    for variant in variants:\n",
        "        variant_to_canonical[variant] = canonical\n",
        "\n",
        "# print(variant_to_canonical)\n",
        "\n",
        "sensor_counter = Counter()\n",
        "\n",
        "## finding the matching sensors in the abstract\n",
        "for entry in all_results:\n",
        "    abstract = entry.get(\"dc:description\", \"\").lower()\n",
        "    for variant, canonical in variant_to_canonical.items():\n",
        "        if re.search(rf\"\\b{re.escape(variant)}\\b\", abstract):\n",
        "            sensor_counter[canonical] += 1\n",
        "\n",
        "\n",
        "print(\"Sensor usage across all abstracts\")\n",
        "for sensor, count in sensor_counter.most_common():\n",
        "    print(f\"{sensor}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOZVRQMPBh9b"
      },
      "outputs": [],
      "source": [
        "# print( sensor_counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "MTGzQ-tEsCgh",
        "outputId": "e9f1ab90-1283-42e6-b0d0-099350c6521f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-cb946a099921>:5: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
            "  colors = plt.cm.get_cmap(\"tab20\", len(sensors))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sensors = [sensor for sensor, count in sensor_counter.most_common()]\n",
        "counts = [count for sensor, count in sensor_counter.most_common()]\n",
        "\n",
        "\n",
        "colors = plt.cm.get_cmap(\"tab20\", len(sensors))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(sensors, counts, color=colors(range(len(sensors))))\n",
        "plt.xlabel('Frequency')\n",
        "plt.title('Sensor used for awkward posture recognition')\n",
        "plt.gca().invert_yaxis()  # Most common sensor on top\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475,
          "referenced_widgets": [
            "7dd5deee2a7a4c0fbec1ee2653b1bad5",
            "d0d99f5acee74184bb9ec6c14b7cbda5",
            "d8a738f0b1564db8a02fded2ae320e73",
            "5b3922a568b84a7cadb7617b779f1ae4",
            "9444e4c2d1b846cdbb88951a53efa7ea",
            "794c919a8b80432cbe41fcd042463b6c",
            "963d7f80197f4dfc8898b346e2e3147b",
            "0c8aa1321ed14a169c062c11eca6f55d",
            "3b843a37c48b4425a4ed538ee75d44a2",
            "e9a429b975754fd0bd6893bdd593dd53",
            "624fff1fe9064ef2a8196db5c35c79c3",
            "3f91563d056c47638ec49d552359e1d9",
            "557376c99a0844a38e578b9fb2fff762",
            "ec8eb85210e94b2cba0e4cf7c1b26c1f",
            "b9b1096b9fe44a9c91a2faadc068af37",
            "b4bd102d92fe4713b288eccbff80ee36",
            "6ba841fa367b497b95d8ae2b21b469b3",
            "e33412dd2bcf42f1a6e16245ac5e7ff7",
            "c8a4f9af6eeb42a6a00670738735822a",
            "0470706a845e4164a9e6f1ebe34740da",
            "51e8735b41d14889ad14ce70435fca28",
            "077a37a8ab9c48018fae261111cc8957",
            "e5727ee180ec42dc8f974060a6e002e4",
            "5428ab132dbb43659b451e5f95d6f20c",
            "166496e96a2140b6afe71398f5211df6",
            "dda9e62d15384367a116fd4557293f90",
            "b97210133eca41349b89911537e8f5dc",
            "2215b4f832c241d1a4398ed55f7c0c23",
            "86907a109a884040b4820f0382fee264",
            "e5440a0ffff64c8abfb8fed672c03ba6",
            "a68c3c6eaf93406b92c882d8cac22211",
            "9aba57a7865a4979bbf93c6520f73b2b",
            "8898bbe0ebb147909da8040015707958",
            "7e1dd7fc9a1d4cec9d32cb682c3b1d2f",
            "afdd765a6f55488c97f75992694e524b",
            "b6b1e1d509b14beabf754699f46611ca",
            "4d7c9de955e148a8b90f9ef04b00a124",
            "bc125a004f894824b88e54a653d0c604",
            "237287f1ee574c628bd236b366b63683",
            "1791b03cbd074013853ad8bb62163da7",
            "a7de10701ca348cc8b2ae57b31c7a3bd",
            "7ac489727d144093a9bb13059ceac601",
            "744e39759d2540cb93dbb0ae379383f0",
            "ce9b609454f642e39a7718f2850c0abe",
            "937275af866443378e64532c10075d95",
            "e9081604033e43a584b72873d232d15e",
            "1cfebf0070334cc0953226bd4b204195",
            "660b9d1beb894239b3077ca07c1af432",
            "dd98f8ce5a514550993985a09ef33267",
            "8d07638b43214725af7ab363fb6fbdbd",
            "0bcf0783c6ca4d70a52aade2065dd91b",
            "e1b40c80406b43e6b42673d0a000c36a",
            "e57385e78bc14f409f45a60776d9a51a",
            "efe0a1a916f045028bc90e103732df9f",
            "4efb460840a447848ac5ee1759fca285",
            "f71448569f9c42c0adc424e8e270d038",
            "45e415ba07f84523b74a4e6618d21752",
            "981d8e7c4fa2416fa7491d1fd77233a7",
            "fccc92fadedb4dc0a04734409a4ebcfb",
            "6ca6d85565aa4de09e97fca46dfca541",
            "dfee8d5f0595487eb397e17f68b1c201",
            "8260ec04db2d4518879c320d2d98c7ed",
            "3c01265d29ea47f1a0c8b697ca6cb49f",
            "fd260b282eff49a5a576291ec04b7f75",
            "772af2af97504b608c96b307dd48bb18",
            "c3807d4ba16648d3bd5e5d72b233420e",
            "7bf69ea89531454abc3ba71c9e515a43",
            "cd27c2baa5fa4c6b993f48c2903fab83",
            "772e46aec26d48e6a7dd03b5fcd173b3",
            "7e272559a9764c6589fe0c35cfaa0f1d",
            "1afc300d1f5a442089cdaf0b220edef8",
            "7a491f131b49471eb94be01f7a2f2ac6",
            "0ee15c8cc43540a388f979c348acf7cb",
            "99311076f1e4466d8e1f8b60f6f18bd0",
            "13524cbd254941168ca72100158d668e",
            "a48dc05285a9421b9190239f136f101f",
            "2de58d52fad74cf09e5573f4e94bf55d",
            "d531003e7e8d4635952aeac5b1dfe1d5",
            "c2b3fe3011714a059c687f3967a79c4e",
            "71c97dfe10ff419faca95a00c34a61a8",
            "862e2930d11249c39bdc4d1d0245469c",
            "a06b482233be47359653ed8a4dc5c660",
            "2e0d75d870ce4f2a8114e29af72998c6",
            "3e383bdc2c5f46e194934466545beb03",
            "29c0570b80de45a4a8c17e70c741b242",
            "efdc9c8b388d4437978b7a00ee980dd5",
            "4a8fa6b4480b44e0b20269c89182d90b",
            "68812764227941ae94d29faefe9434a4",
            "f110b364d7e54f2ea7b0af54025e41b6",
            "850fca8e11bf4c41ad31bd32cd3a0016",
            "edb4b49095d94cd3b54af823e8bda7a2",
            "2eae276adc7c4f7591bed460995d2098",
            "c375f73eb6ef43bba27aa95b170a0469",
            "083dc50bfa3b4787b3d2c8f2b5295367",
            "8ca9e7df87d04cdb8c82134d345cd902",
            "69ad9af0ddf14d468c7e6cc60f45b8ad",
            "c59694e5a21e413694616fdbe8b6cc52",
            "dd1a166d69c749ba95b9bc0192547d2e",
            "187ac2686c2b43c1b5e92d1d17c823be",
            "7cf3f4832c5845338b2afe1c09122e99",
            "fe992624877740e5aabd273cde6d71be",
            "b22adf63247849948d4d5468ca53b9ba",
            "52fb5c0562c44619914b0f313781e1b6",
            "86e4b3cd515645fa979c76e19c771e5b",
            "dabc524e69e14d0c9b0c8335c7f5b462",
            "b2b575825eae4631aa9e60cd0d60f8bc",
            "04d8c5bcf1af4ef08cd5321b3c116f5a",
            "14071981c19f46c1a23d82e9cdab3238",
            "a4443859ed124210b65c6106dc4b67fd",
            "6207da55c40c49f2ba138b5c94252868",
            "31bc3d7d39564a9392b474c2d1d71d15",
            "aff7f5ace13a46ad9020438b535becc4",
            "5087168562074bc2920bc3bb4b1a7d23",
            "443a8eacc7c54c48ac34b02f096835cf",
            "fdc1594e24054874929e02da1b98580a",
            "f4b14567ac9340368cb9fbed2d07833a",
            "728d08db5090481984c35326f1f0ad56",
            "ba5b97ef3b2740fab505ec1ae415c8e1",
            "966ce07938d34eb29cd9d792d2da1284",
            "4a827628b48b4e7a8add26904d2af941",
            "600f5b729fcf4d9983d482502a0dde04",
            "332c0eee53e24b21b1f7f82bb0ec7dd5",
            "78eaa2b563b547a98f7d222ee1357637",
            "fedb78b7d12549dd890e15e2c65cc702",
            "a779006ca9b6433499afc157a38cf8f3",
            "b48b542197b04380847b9e008e785487",
            "e55e8700bfd74b299e816cdf5407405f",
            "c18a1ca7020348a28ac6b6c2d8eb144d",
            "c1b6cdf972b7472ab7d7837293f2b66c",
            "5e558dff0dba4cdd9d919e6643c26b85",
            "0ac49f560b8a46a08d53e8a42e5903a1",
            "2089368b45ba42dfa9a838efc4cb5c1f"
          ]
        },
        "id": "DEZ1d43WBiE2",
        "outputId": "87d50a1c-2fdc-4649-90f2-767007c3f7b9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7dd5deee2a7a4c0fbec1ee2653b1bad5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/3.48k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f91563d056c47638ec49d552359e1d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5727ee180ec42dc8f974060a6e002e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e1dd7fc9a1d4cec9d32cb682c3b1d2f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "937275af866443378e64532c10075d95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f71448569f9c42c0adc424e8e270d038",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7bf69ea89531454abc3ba71c9e515a43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d531003e7e8d4635952aeac5b1dfe1d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f110b364d7e54f2ea7b0af54025e41b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7cf3f4832c5845338b2afe1c09122e99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31bc3d7d39564a9392b474c2d1d71d15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "332c0eee53e24b21b1f7f82bb0ec7dd5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing abstracts:   0%|          | 0/932 [00:00<?, ?it/s]<ipython-input-10-58dcdcd2947f>:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():\n",
            "Processing abstracts: 100%|██████████| 932/932 [13:22<00:00,  1.16it/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "from torch.cuda.amp import autocast\n",
        "from collections import Counter\n",
        "import torch\n",
        "\n",
        "## Counter for sensor got through LLM\n",
        "sensor_counterLLM = Counter()\n",
        "\n",
        "## Loading model\n",
        "model_name = \"microsoft/Phi-3-mini-128k-instruct\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Loop through all abstracts\n",
        "for entry in tqdm(all_results, desc=\"Processing abstracts\"):\n",
        "    abstract = entry.get(\"dc:description\", \"\").strip().lower()\n",
        "    if not abstract:\n",
        "        continue\n",
        "\n",
        "    ## creating a prompt to extract relevant sensor names only\n",
        "    prompt = f\"Extract the primary sensors names used only for awkward posture recognition that is mentioned in the following abstract:\\n\\n{abstract}\\n\\n Only list the names of sensors used for awkward posture. Note: only consider abstract in which research is related to awkward posture recognition.\"\n",
        "\n",
        "    ## Direct tokenization and passing input to model\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    ## Reduced the number of output token to make the processing a bit faster\n",
        "    with torch.no_grad(), autocast():\n",
        "        generated_ids = model.generate(**inputs, max_new_tokens=30)\n",
        "\n",
        "    ## Decoding the output\n",
        "    output = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    ## Check for sensor counts in the output\n",
        "    for variant, canonical in variant_to_canonical.items():\n",
        "        if re.search(rf\"\\b{re.escape(variant)}\\b\", output):\n",
        "            sensor_counterLLM[canonical] += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-CQcZiQwbp05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c8c8dc2-5f1c-4bff-a424-611a3f421416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sensor usage across all abstracts:\n",
            "\n",
            "RGB camera: 100\n",
            "RGB-D: 68\n",
            "IMU: 59\n",
            "EMG: 44\n",
            "EEG: 8\n",
            "Depth camera: 4\n",
            "FSR: 3\n",
            "ECG: 3\n",
            "PPG: 2\n",
            "WiFi CSI: 1\n",
            "Infrared camera: 1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Print total counts for each sensor\n",
        "print(\"Sensor usage across all abstracts:\\n\")\n",
        "for sensor, count in sensor_counterLLM.most_common():\n",
        "    print(f\"{sensor}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ju20jcICbL9m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "outputId": "70ff01ce-0e45-4481-bb82-2a2cd900f49d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-feb8d2fb4d8c>:5: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
            "  colors = plt.cm.get_cmap(\"tab20\", len(sensors))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sensors = [sensor for sensor, count in sensor_counterLLM.most_common()]\n",
        "counts = [count for sensor, count in sensor_counterLLM.most_common()]\n",
        "\n",
        "\n",
        "colors = plt.cm.get_cmap(\"tab20\", len(sensors))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(sensors, counts, color=colors(range(len(sensors))))\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Sensor Name')\n",
        "plt.title('Sensors used for awkward posture recognition')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "h2NhrEhSDndO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "147f4bf7-dc07-4cbd-cbf3-6dc528f04e63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-cfec5f302fbf>:6: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
            "  colors = plt.cm.get_cmap(\"tab20\", len(sensors))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_da2b17b4-b4eb-43a9-adee-622e6aa1da02\", \"sensor_usage_plot.png\", 301276)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "sensors = [sensor for sensor, count in sensor_counterLLM.most_common()]\n",
        "counts = [count for sensor, count in sensor_counterLLM.most_common()]\n",
        "\n",
        "colors = plt.cm.get_cmap(\"tab20\", len(sensors))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "bars = plt.barh(sensors, counts, color=colors(range(len(sensors))))\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Sensor Name')\n",
        "plt.title('Sensors used for awkward posture recognition')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "\n",
        "# Add count labels next to each bar\n",
        "for bar in bars:\n",
        "    width = bar.get_width()\n",
        "    plt.text(width + 1, bar.get_y() + bar.get_height()/2,\n",
        "             str(int(width)),\n",
        "             va='center', fontsize=9, color='black')\n",
        "\n",
        "# Save the plot as a PNG\n",
        "plot_filename = \"sensor_usage_plot.png\"\n",
        "plt.savefig(plot_filename, dpi=600)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "# Download the image\n",
        "files.download(plot_filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5B7o9wNI6EG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNdqb1daycAc5ZGXMU5/PAM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7dd5deee2a7a4c0fbec1ee2653b1bad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0d99f5acee74184bb9ec6c14b7cbda5",
              "IPY_MODEL_d8a738f0b1564db8a02fded2ae320e73",
              "IPY_MODEL_5b3922a568b84a7cadb7617b779f1ae4"
            ],
            "layout": "IPY_MODEL_9444e4c2d1b846cdbb88951a53efa7ea"
          }
        },
        "d0d99f5acee74184bb9ec6c14b7cbda5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_794c919a8b80432cbe41fcd042463b6c",
            "placeholder": "​",
            "style": "IPY_MODEL_963d7f80197f4dfc8898b346e2e3147b",
            "value": "config.json: 100%"
          }
        },
        "d8a738f0b1564db8a02fded2ae320e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c8aa1321ed14a169c062c11eca6f55d",
            "max": 3484,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b843a37c48b4425a4ed538ee75d44a2",
            "value": 3484
          }
        },
        "5b3922a568b84a7cadb7617b779f1ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9a429b975754fd0bd6893bdd593dd53",
            "placeholder": "​",
            "style": "IPY_MODEL_624fff1fe9064ef2a8196db5c35c79c3",
            "value": " 3.48k/3.48k [00:00&lt;00:00, 441kB/s]"
          }
        },
        "9444e4c2d1b846cdbb88951a53efa7ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "794c919a8b80432cbe41fcd042463b6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "963d7f80197f4dfc8898b346e2e3147b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c8aa1321ed14a169c062c11eca6f55d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b843a37c48b4425a4ed538ee75d44a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9a429b975754fd0bd6893bdd593dd53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "624fff1fe9064ef2a8196db5c35c79c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f91563d056c47638ec49d552359e1d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_557376c99a0844a38e578b9fb2fff762",
              "IPY_MODEL_ec8eb85210e94b2cba0e4cf7c1b26c1f",
              "IPY_MODEL_b9b1096b9fe44a9c91a2faadc068af37"
            ],
            "layout": "IPY_MODEL_b4bd102d92fe4713b288eccbff80ee36"
          }
        },
        "557376c99a0844a38e578b9fb2fff762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ba841fa367b497b95d8ae2b21b469b3",
            "placeholder": "​",
            "style": "IPY_MODEL_e33412dd2bcf42f1a6e16245ac5e7ff7",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "ec8eb85210e94b2cba0e4cf7c1b26c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8a4f9af6eeb42a6a00670738735822a",
            "max": 16331,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0470706a845e4164a9e6f1ebe34740da",
            "value": 16331
          }
        },
        "b9b1096b9fe44a9c91a2faadc068af37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51e8735b41d14889ad14ce70435fca28",
            "placeholder": "​",
            "style": "IPY_MODEL_077a37a8ab9c48018fae261111cc8957",
            "value": " 16.3k/16.3k [00:00&lt;00:00, 1.81MB/s]"
          }
        },
        "b4bd102d92fe4713b288eccbff80ee36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ba841fa367b497b95d8ae2b21b469b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e33412dd2bcf42f1a6e16245ac5e7ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8a4f9af6eeb42a6a00670738735822a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0470706a845e4164a9e6f1ebe34740da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51e8735b41d14889ad14ce70435fca28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "077a37a8ab9c48018fae261111cc8957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5727ee180ec42dc8f974060a6e002e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5428ab132dbb43659b451e5f95d6f20c",
              "IPY_MODEL_166496e96a2140b6afe71398f5211df6",
              "IPY_MODEL_dda9e62d15384367a116fd4557293f90"
            ],
            "layout": "IPY_MODEL_b97210133eca41349b89911537e8f5dc"
          }
        },
        "5428ab132dbb43659b451e5f95d6f20c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2215b4f832c241d1a4398ed55f7c0c23",
            "placeholder": "​",
            "style": "IPY_MODEL_86907a109a884040b4820f0382fee264",
            "value": "Fetching 2 files: 100%"
          }
        },
        "166496e96a2140b6afe71398f5211df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5440a0ffff64c8abfb8fed672c03ba6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a68c3c6eaf93406b92c882d8cac22211",
            "value": 2
          }
        },
        "dda9e62d15384367a116fd4557293f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aba57a7865a4979bbf93c6520f73b2b",
            "placeholder": "​",
            "style": "IPY_MODEL_8898bbe0ebb147909da8040015707958",
            "value": " 2/2 [00:29&lt;00:00, 29.28s/it]"
          }
        },
        "b97210133eca41349b89911537e8f5dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2215b4f832c241d1a4398ed55f7c0c23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86907a109a884040b4820f0382fee264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5440a0ffff64c8abfb8fed672c03ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a68c3c6eaf93406b92c882d8cac22211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9aba57a7865a4979bbf93c6520f73b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8898bbe0ebb147909da8040015707958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e1dd7fc9a1d4cec9d32cb682c3b1d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afdd765a6f55488c97f75992694e524b",
              "IPY_MODEL_b6b1e1d509b14beabf754699f46611ca",
              "IPY_MODEL_4d7c9de955e148a8b90f9ef04b00a124"
            ],
            "layout": "IPY_MODEL_bc125a004f894824b88e54a653d0c604"
          }
        },
        "afdd765a6f55488c97f75992694e524b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_237287f1ee574c628bd236b366b63683",
            "placeholder": "​",
            "style": "IPY_MODEL_1791b03cbd074013853ad8bb62163da7",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "b6b1e1d509b14beabf754699f46611ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7de10701ca348cc8b2ae57b31c7a3bd",
            "max": 2669692552,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ac489727d144093a9bb13059ceac601",
            "value": 2669692552
          }
        },
        "4d7c9de955e148a8b90f9ef04b00a124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_744e39759d2540cb93dbb0ae379383f0",
            "placeholder": "​",
            "style": "IPY_MODEL_ce9b609454f642e39a7718f2850c0abe",
            "value": " 2.67G/2.67G [00:26&lt;00:00, 107MB/s]"
          }
        },
        "bc125a004f894824b88e54a653d0c604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "237287f1ee574c628bd236b366b63683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1791b03cbd074013853ad8bb62163da7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7de10701ca348cc8b2ae57b31c7a3bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ac489727d144093a9bb13059ceac601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "744e39759d2540cb93dbb0ae379383f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce9b609454f642e39a7718f2850c0abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "937275af866443378e64532c10075d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9081604033e43a584b72873d232d15e",
              "IPY_MODEL_1cfebf0070334cc0953226bd4b204195",
              "IPY_MODEL_660b9d1beb894239b3077ca07c1af432"
            ],
            "layout": "IPY_MODEL_dd98f8ce5a514550993985a09ef33267"
          }
        },
        "e9081604033e43a584b72873d232d15e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d07638b43214725af7ab363fb6fbdbd",
            "placeholder": "​",
            "style": "IPY_MODEL_0bcf0783c6ca4d70a52aade2065dd91b",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "1cfebf0070334cc0953226bd4b204195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1b40c80406b43e6b42673d0a000c36a",
            "max": 4972489328,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e57385e78bc14f409f45a60776d9a51a",
            "value": 4972489328
          }
        },
        "660b9d1beb894239b3077ca07c1af432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efe0a1a916f045028bc90e103732df9f",
            "placeholder": "​",
            "style": "IPY_MODEL_4efb460840a447848ac5ee1759fca285",
            "value": " 4.97G/4.97G [00:29&lt;00:00, 198MB/s]"
          }
        },
        "dd98f8ce5a514550993985a09ef33267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d07638b43214725af7ab363fb6fbdbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bcf0783c6ca4d70a52aade2065dd91b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1b40c80406b43e6b42673d0a000c36a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e57385e78bc14f409f45a60776d9a51a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efe0a1a916f045028bc90e103732df9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4efb460840a447848ac5ee1759fca285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f71448569f9c42c0adc424e8e270d038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45e415ba07f84523b74a4e6618d21752",
              "IPY_MODEL_981d8e7c4fa2416fa7491d1fd77233a7",
              "IPY_MODEL_fccc92fadedb4dc0a04734409a4ebcfb"
            ],
            "layout": "IPY_MODEL_6ca6d85565aa4de09e97fca46dfca541"
          }
        },
        "45e415ba07f84523b74a4e6618d21752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfee8d5f0595487eb397e17f68b1c201",
            "placeholder": "​",
            "style": "IPY_MODEL_8260ec04db2d4518879c320d2d98c7ed",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "981d8e7c4fa2416fa7491d1fd77233a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c01265d29ea47f1a0c8b697ca6cb49f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd260b282eff49a5a576291ec04b7f75",
            "value": 2
          }
        },
        "fccc92fadedb4dc0a04734409a4ebcfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_772af2af97504b608c96b307dd48bb18",
            "placeholder": "​",
            "style": "IPY_MODEL_c3807d4ba16648d3bd5e5d72b233420e",
            "value": " 2/2 [00:02&lt;00:00,  1.06s/it]"
          }
        },
        "6ca6d85565aa4de09e97fca46dfca541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfee8d5f0595487eb397e17f68b1c201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8260ec04db2d4518879c320d2d98c7ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c01265d29ea47f1a0c8b697ca6cb49f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd260b282eff49a5a576291ec04b7f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "772af2af97504b608c96b307dd48bb18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3807d4ba16648d3bd5e5d72b233420e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bf69ea89531454abc3ba71c9e515a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd27c2baa5fa4c6b993f48c2903fab83",
              "IPY_MODEL_772e46aec26d48e6a7dd03b5fcd173b3",
              "IPY_MODEL_7e272559a9764c6589fe0c35cfaa0f1d"
            ],
            "layout": "IPY_MODEL_1afc300d1f5a442089cdaf0b220edef8"
          }
        },
        "cd27c2baa5fa4c6b993f48c2903fab83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a491f131b49471eb94be01f7a2f2ac6",
            "placeholder": "​",
            "style": "IPY_MODEL_0ee15c8cc43540a388f979c348acf7cb",
            "value": "generation_config.json: 100%"
          }
        },
        "772e46aec26d48e6a7dd03b5fcd173b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99311076f1e4466d8e1f8b60f6f18bd0",
            "max": 181,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13524cbd254941168ca72100158d668e",
            "value": 181
          }
        },
        "7e272559a9764c6589fe0c35cfaa0f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a48dc05285a9421b9190239f136f101f",
            "placeholder": "​",
            "style": "IPY_MODEL_2de58d52fad74cf09e5573f4e94bf55d",
            "value": " 181/181 [00:00&lt;00:00, 21.6kB/s]"
          }
        },
        "1afc300d1f5a442089cdaf0b220edef8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a491f131b49471eb94be01f7a2f2ac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee15c8cc43540a388f979c348acf7cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99311076f1e4466d8e1f8b60f6f18bd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13524cbd254941168ca72100158d668e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a48dc05285a9421b9190239f136f101f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2de58d52fad74cf09e5573f4e94bf55d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d531003e7e8d4635952aeac5b1dfe1d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2b3fe3011714a059c687f3967a79c4e",
              "IPY_MODEL_71c97dfe10ff419faca95a00c34a61a8",
              "IPY_MODEL_862e2930d11249c39bdc4d1d0245469c"
            ],
            "layout": "IPY_MODEL_a06b482233be47359653ed8a4dc5c660"
          }
        },
        "c2b3fe3011714a059c687f3967a79c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e0d75d870ce4f2a8114e29af72998c6",
            "placeholder": "​",
            "style": "IPY_MODEL_3e383bdc2c5f46e194934466545beb03",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "71c97dfe10ff419faca95a00c34a61a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29c0570b80de45a4a8c17e70c741b242",
            "max": 3443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efdc9c8b388d4437978b7a00ee980dd5",
            "value": 3443
          }
        },
        "862e2930d11249c39bdc4d1d0245469c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a8fa6b4480b44e0b20269c89182d90b",
            "placeholder": "​",
            "style": "IPY_MODEL_68812764227941ae94d29faefe9434a4",
            "value": " 3.44k/3.44k [00:00&lt;00:00, 430kB/s]"
          }
        },
        "a06b482233be47359653ed8a4dc5c660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e0d75d870ce4f2a8114e29af72998c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e383bdc2c5f46e194934466545beb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29c0570b80de45a4a8c17e70c741b242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efdc9c8b388d4437978b7a00ee980dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a8fa6b4480b44e0b20269c89182d90b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68812764227941ae94d29faefe9434a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f110b364d7e54f2ea7b0af54025e41b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_850fca8e11bf4c41ad31bd32cd3a0016",
              "IPY_MODEL_edb4b49095d94cd3b54af823e8bda7a2",
              "IPY_MODEL_2eae276adc7c4f7591bed460995d2098"
            ],
            "layout": "IPY_MODEL_c375f73eb6ef43bba27aa95b170a0469"
          }
        },
        "850fca8e11bf4c41ad31bd32cd3a0016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_083dc50bfa3b4787b3d2c8f2b5295367",
            "placeholder": "​",
            "style": "IPY_MODEL_8ca9e7df87d04cdb8c82134d345cd902",
            "value": "tokenizer.model: 100%"
          }
        },
        "edb4b49095d94cd3b54af823e8bda7a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69ad9af0ddf14d468c7e6cc60f45b8ad",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c59694e5a21e413694616fdbe8b6cc52",
            "value": 499723
          }
        },
        "2eae276adc7c4f7591bed460995d2098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd1a166d69c749ba95b9bc0192547d2e",
            "placeholder": "​",
            "style": "IPY_MODEL_187ac2686c2b43c1b5e92d1d17c823be",
            "value": " 500k/500k [00:00&lt;00:00, 5.20MB/s]"
          }
        },
        "c375f73eb6ef43bba27aa95b170a0469": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "083dc50bfa3b4787b3d2c8f2b5295367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ca9e7df87d04cdb8c82134d345cd902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69ad9af0ddf14d468c7e6cc60f45b8ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c59694e5a21e413694616fdbe8b6cc52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd1a166d69c749ba95b9bc0192547d2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "187ac2686c2b43c1b5e92d1d17c823be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cf3f4832c5845338b2afe1c09122e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe992624877740e5aabd273cde6d71be",
              "IPY_MODEL_b22adf63247849948d4d5468ca53b9ba",
              "IPY_MODEL_52fb5c0562c44619914b0f313781e1b6"
            ],
            "layout": "IPY_MODEL_86e4b3cd515645fa979c76e19c771e5b"
          }
        },
        "fe992624877740e5aabd273cde6d71be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dabc524e69e14d0c9b0c8335c7f5b462",
            "placeholder": "​",
            "style": "IPY_MODEL_b2b575825eae4631aa9e60cd0d60f8bc",
            "value": "tokenizer.json: 100%"
          }
        },
        "b22adf63247849948d4d5468ca53b9ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04d8c5bcf1af4ef08cd5321b3c116f5a",
            "max": 1937869,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14071981c19f46c1a23d82e9cdab3238",
            "value": 1937869
          }
        },
        "52fb5c0562c44619914b0f313781e1b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4443859ed124210b65c6106dc4b67fd",
            "placeholder": "​",
            "style": "IPY_MODEL_6207da55c40c49f2ba138b5c94252868",
            "value": " 1.94M/1.94M [00:00&lt;00:00, 15.3MB/s]"
          }
        },
        "86e4b3cd515645fa979c76e19c771e5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dabc524e69e14d0c9b0c8335c7f5b462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2b575825eae4631aa9e60cd0d60f8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04d8c5bcf1af4ef08cd5321b3c116f5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14071981c19f46c1a23d82e9cdab3238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4443859ed124210b65c6106dc4b67fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6207da55c40c49f2ba138b5c94252868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31bc3d7d39564a9392b474c2d1d71d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aff7f5ace13a46ad9020438b535becc4",
              "IPY_MODEL_5087168562074bc2920bc3bb4b1a7d23",
              "IPY_MODEL_443a8eacc7c54c48ac34b02f096835cf"
            ],
            "layout": "IPY_MODEL_fdc1594e24054874929e02da1b98580a"
          }
        },
        "aff7f5ace13a46ad9020438b535becc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4b14567ac9340368cb9fbed2d07833a",
            "placeholder": "​",
            "style": "IPY_MODEL_728d08db5090481984c35326f1f0ad56",
            "value": "added_tokens.json: 100%"
          }
        },
        "5087168562074bc2920bc3bb4b1a7d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba5b97ef3b2740fab505ec1ae415c8e1",
            "max": 306,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_966ce07938d34eb29cd9d792d2da1284",
            "value": 306
          }
        },
        "443a8eacc7c54c48ac34b02f096835cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a827628b48b4e7a8add26904d2af941",
            "placeholder": "​",
            "style": "IPY_MODEL_600f5b729fcf4d9983d482502a0dde04",
            "value": " 306/306 [00:00&lt;00:00, 38.9kB/s]"
          }
        },
        "fdc1594e24054874929e02da1b98580a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4b14567ac9340368cb9fbed2d07833a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "728d08db5090481984c35326f1f0ad56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba5b97ef3b2740fab505ec1ae415c8e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "966ce07938d34eb29cd9d792d2da1284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a827628b48b4e7a8add26904d2af941": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "600f5b729fcf4d9983d482502a0dde04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "332c0eee53e24b21b1f7f82bb0ec7dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78eaa2b563b547a98f7d222ee1357637",
              "IPY_MODEL_fedb78b7d12549dd890e15e2c65cc702",
              "IPY_MODEL_a779006ca9b6433499afc157a38cf8f3"
            ],
            "layout": "IPY_MODEL_b48b542197b04380847b9e008e785487"
          }
        },
        "78eaa2b563b547a98f7d222ee1357637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e55e8700bfd74b299e816cdf5407405f",
            "placeholder": "​",
            "style": "IPY_MODEL_c18a1ca7020348a28ac6b6c2d8eb144d",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "fedb78b7d12549dd890e15e2c65cc702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1b6cdf972b7472ab7d7837293f2b66c",
            "max": 599,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e558dff0dba4cdd9d919e6643c26b85",
            "value": 599
          }
        },
        "a779006ca9b6433499afc157a38cf8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ac49f560b8a46a08d53e8a42e5903a1",
            "placeholder": "​",
            "style": "IPY_MODEL_2089368b45ba42dfa9a838efc4cb5c1f",
            "value": " 599/599 [00:00&lt;00:00, 74.4kB/s]"
          }
        },
        "b48b542197b04380847b9e008e785487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e55e8700bfd74b299e816cdf5407405f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c18a1ca7020348a28ac6b6c2d8eb144d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1b6cdf972b7472ab7d7837293f2b66c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e558dff0dba4cdd9d919e6643c26b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ac49f560b8a46a08d53e8a42e5903a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2089368b45ba42dfa9a838efc4cb5c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}